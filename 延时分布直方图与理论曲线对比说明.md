# 延时分布直方图与理论曲线对比 - 代码与流程说明

## 一、概述

本功能用于可视化绝对延时数据的分布情况，并将实际数据直方图与理论正态分布曲线进行对比，以评估延时数据是否符合正态分布。

**核心文件位置**：
- 单算法模式：`backend/piano_analysis_backend.py:generate_delay_histogram_plot()`
- 多算法模式：`backend/multi_algorithm_plot_generator.py:generate_multi_algorithm_delay_histogram_plot()`

---

## 二、完整流程

```
1. 数据提取：从offset_data中提取带符号的keyon_offset，转换为绝对延时(ms)
   ↓
2. 绘制直方图：使用概率密度归一化，总面积=1
   ↓
3. 计算统计量：样本均值μ和样本标准差σ（使用n-1分母，无偏估计）
   ↓
4. 确定绘制范围：数据范围 ∪ 3σ范围（取并集）
   ↓
5. 生成采样点：在范围内均匀生成200个x坐标点
   ↓
6. 计算概率密度：对每个x点，使用正态分布PDF公式计算y值
   ↓
7. 绘制曲线：用线段连接所有(x, y)点，形成连续平滑的红色曲线
```

---

## 三、详细代码实现

### 3.1 单算法模式代码

**文件**：`backend/piano_analysis_backend.py`

```python
def generate_delay_histogram_plot(self) -> Any:
    """
    生成延时分布直方图，并叠加正态拟合曲线（基于绝对延时）。
    x轴：绝对延时 (ms)，y轴：概率密度
    """
    if not self.analyzer or not self.analyzer.note_matcher:
        return self.plot_generator._create_empty_plot("没有分析器")

    offset_data = self.analyzer.get_offset_alignment_data()
    if not offset_data:
        return self.plot_generator._create_empty_plot("无匹配数据")

    # ========== 步骤1：数据提取与转换 ==========
    # keyon_offset = replay_keyon - record_keyon
    # 正值表示延迟，负值表示提前，零值表示无延时
    delays_ms = [item.get('keyon_offset', 0.0) / 10.0 for item in offset_data]
    if not delays_ms:
        return self.plot_generator._create_empty_plot("无有效延时数据")

    import plotly.graph_objects as go
    import math
    fig = go.Figure()

    # ========== 步骤2：绘制直方图 ==========
    fig.add_trace(go.Histogram(
        x=delays_ms,
        histnorm='probability density',  # 关键：概率密度归一化
        name='延时分布',
        marker_color='rgba(33, 150, 243, 0.6)',
        opacity=0.7
    ))

    # ========== 步骤3：计算统计量 ==========
    # 计算样本均值和样本标准差（使用n-1作为分母，无偏估计）
    n = len(delays_ms)
    mean_val = sum(delays_ms) / n  # 样本均值：μ = (1/n) * Σx_i
    
    if n > 1:
        # 样本方差：s² = (1/(n-1)) * Σ(x_i - μ)²
        var = sum((x - mean_val) ** 2 for x in delays_ms) / (n - 1)
        std_val = var ** 0.5  # 样本标准差：s = √s²
    else:
        std_val = 0.0  # 只有一个数据点，无法计算标准差

    # ========== 步骤4：生成正态拟合曲线 ==========
    if std_val > 0:  # 只有当标准差大于0时才绘制曲线（需要离散性）
        # ----- 4.1 确定曲线绘制范围 -----
        # 获取实际数据的最小值和最大值
        min_x = min(delays_ms)  # 数据最小值（可能为负，表示提前）
        max_x = max(delays_ms)  # 数据最大值（可能为正，表示延迟）
        
        # 计算3σ范围（正态分布中约99.7%的数据落在[μ-3σ, μ+3σ]范围内）
        # max(1e-6, ...) 防止标准差极小导致范围过小或除零错误
        span = max(1e-6, 3 * std_val)  # 3σ范围的一半宽度
        
        # 确定曲线起点和终点：取数据范围与3σ范围的并集
        # 这样既覆盖实际数据，又展示理论分布特征
        x_start = min(mean_val - span, min_x)  # 起点：理论下界与实际最小值的较小者
        x_end = max(mean_val + span, max_x)    # 终点：理论上界与实际最大值的较大者
        
        # ----- 4.2 生成均匀分布的x坐标点 -----
        # 在[x_start, x_end]范围内均匀生成200个点，用于绘制平滑曲线
        num_pts = 200  # 固定200个点，足够平滑且计算高效
        step = (x_end - x_start) / (num_pts - 1) if num_pts > 1 else 1.0  # 点之间的间距
        xs = [x_start + i * step for i in range(num_pts)]  # 生成均匀分布的x坐标序列
        
        # ----- 4.3 计算每个x点的概率密度值（正态分布PDF） -----
        # 正态分布概率密度函数：f(x) = (1/(σ√(2π))) * exp(-0.5 * ((x-μ)/σ)²)
        # 其中：
        #   - 1/(σ√(2π))：归一化常数，确保曲线下面积为1
        #   - exp(-0.5 * ((x-μ)/σ)²)：指数项，在均值处最大，远离均值时快速衰减
        #   - (x-μ)/σ：标准化偏差（z-score），表示距离均值有多少个标准差
        ys = [(1.0 / (std_val * (2 * math.pi) ** 0.5)) * 
              math.exp(-0.5 * ((x - mean_val) / std_val) ** 2) 
              for x in xs]
        
        # ----- 4.4 绘制正态拟合曲线 -----
        # 使用Scatter图用线段连接所有(x, y)点，形成连续平滑的曲线
        fig.add_trace(go.Scatter(
            x=xs,  # 200个x坐标（延时值，单位：ms）
            y=ys,  # 200个对应的概率密度值
            mode='lines',  # 用线段连接点，形成连续曲线
            name=f"正态拟合 (μ={mean_val:.2f}ms, σ={std_val:.2f}ms)",  # 图例显示均值和标准差
            line=dict(color='#e53935', width=2)  # 红色曲线，线宽2像素
        ))

    # ========== 步骤5：设置图表布局 ==========
    fig.update_layout(
        title={
            'text': '延时分布直方图（附正态拟合曲线）',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 18, 'color': '#2c3e50'}
        },
        xaxis_title='延时 (ms)',
        yaxis_title='概率密度',
        bargap=0.05,
        plot_bgcolor='white',
        paper_bgcolor='white',
        font=dict(size=12),
        height=500,
        legend=dict(
            orientation='h',
            yanchor='bottom',
            y=1.02,
            xanchor='left',
            x=0.0
        )
    )
    
    return fig
```

### 3.2 多算法模式代码

**文件**：`backend/multi_algorithm_plot_generator.py`

```python
def generate_multi_algorithm_delay_histogram_plot(
    self,
    algorithms: List[AlgorithmDataset]
) -> Any:
    """
    生成多算法延时分布直方图（叠加显示，不同颜色，图例控制）
    
    为每个算法生成直方图和正态拟合曲线，使用不同颜色区分，叠加显示在同一图表中。
    """
    if not algorithms:
        return self._create_empty_plot("没有激活的算法")
    
    import plotly.graph_objects as go
    import math
    fig = go.Figure()
    
    # 为每个算法分配颜色
    colors = [
        '#1f77b4',  # 蓝色
        '#ff7f0e',  # 橙色
        '#2ca02c',  # 绿色
        '#d62728',  # 红色
        '#9467bd',  # 紫色
        '#8c564b',  # 棕色
        '#e377c2',  # 粉色
        '#7f7f7f'   # 灰色
    ]
    
    all_delays = []  # 用于确定全局范围
    
    for alg_idx, algorithm in enumerate(ready_algorithms):
        algorithm_name = algorithm.metadata.algorithm_name
        
        if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
            continue
        
        try:
            # 步骤1：数据提取
            offset_data = algorithm.analyzer.get_offset_alignment_data()
            if not offset_data:
                continue
            
            delays_ms = [item.get('keyon_offset', 0.0) / 10.0 for item in offset_data]
            if not delays_ms:
                continue
            
            all_delays.extend(delays_ms)
            
            # 步骤2：计算统计量
            n = len(delays_ms)
            mean_val = sum(delays_ms) / n
            if n > 1:
                var = sum((x - mean_val) ** 2 for x in delays_ms) / (n - 1)
                std_val = var ** 0.5
            else:
                std_val = 0.0
            
            color = colors[alg_idx % len(colors)]
            
            # 步骤3：添加直方图
            fig.add_trace(go.Histogram(
                x=delays_ms,
                histnorm='probability density',
                name=f'{algorithm_name} - 延时分布',
                marker_color=color,
                opacity=0.6,
                legendgroup=algorithm_name,
                showlegend=True
            ))
            
            # 步骤4：生成正态拟合曲线
            if std_val > 0:
                min_x = min(delays_ms)
                max_x = max(delays_ms)
                span = max(1e-6, 3 * std_val)
                x_start = min(mean_val - span, min_x)
                x_end = max(mean_val + span, max_x)
                
                num_pts = 200
                step = (x_end - x_start) / (num_pts - 1) if num_pts > 1 else 1.0
                xs = [x_start + i * step for i in range(num_pts)]
                
                # 正态分布PDF公式
                ys = [(1.0 / (std_val * (2 * math.pi) ** 0.5)) * 
                      math.exp(-0.5 * ((x - mean_val) / std_val) ** 2) 
                      for x in xs]
                
                # 添加正态拟合曲线
                fig.add_trace(go.Scatter(
                    x=xs,
                    y=ys,
                    mode='lines',
                    name=f'{algorithm_name} - 正态拟合 (μ={mean_val:.2f}ms, σ={std_val:.2f}ms)',
                    line=dict(color=color, width=2),
                    legendgroup=algorithm_name,
                    showlegend=True
                ))
                
        except Exception as e:
            logger.warning(f"⚠️ 获取算法 '{algorithm_name}' 的延时数据失败: {e}")
            continue
    
    # 设置布局
    fig.update_layout(
        title={
            'text': '多算法延时分布直方图（附正态拟合曲线）',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 18, 'color': '#2c3e50'}
        },
        xaxis_title='延时 (ms)',
        yaxis_title='概率密度',
        bargap=0.05,
        plot_bgcolor='white',
        paper_bgcolor='white',
        font=dict(size=12),
        height=500,
        legend=dict(
            orientation='h',
            yanchor='bottom',
            y=1.02,
            xanchor='left',
            x=0.0
        )
    )
    
    return fig
```

---

## 四、关键概念详解

### 4.1 数据提取

```python
delays_ms = [item.get('keyon_offset', 0.0) / 10.0 for item in offset_data]
```

- **`keyon_offset`**：带符号的延时值（单位：0.1ms）
  - 正值：回放滞后于录制（延迟）
  - 负值：回放提前于录制（提前）
  - 零值：无延时
- **转换**：除以10.0转换为ms单位

### 4.2 概率密度归一化

```python
histnorm='probability density'
```

**归一化公式**：
$$
f(x) = \frac{F_k}{n \cdot \Delta x}
$$

其中：
- $F_k$：区间k的频数
- $n$：总数据点数
- $\Delta x$：区间宽度

**效果**：
- 直方图总面积 = 1
- 与正态分布PDF的面积一致
- 便于对比评估

### 4.3 统计量计算

**样本均值**：
$$
\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i
$$

**样本方差**（贝塞尔校正，无偏估计）：
$$
s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2
$$

**样本标准差**：
$$
s = \sqrt{s^2}
$$

**为什么使用n-1？**
- 贝塞尔校正，得到总体方差的无偏估计
- 当样本量较小时，n-1能更好地估计总体方差

### 4.4 正态分布概率密度函数（PDF）

**公式**：
$$
f(x) = \frac{1}{\sigma\sqrt{2\pi}} \exp\left(-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right)
$$

**代码实现**：
```python
ys = [(1.0 / (std_val * (2 * math.pi) ** 0.5)) * 
      math.exp(-0.5 * ((x - mean_val) / std_val) ** 2) 
      for x in xs]
```

**组成部分**：
1. **归一化常数**：$\frac{1}{\sigma\sqrt{2\pi}}$，确保曲线下面积为1
2. **指数项**：$\exp\left(-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right)$
   - 在均值$\mu$处最大
   - 远离均值时快速衰减
3. **标准化偏差**：$\frac{x-\mu}{\sigma}$（z-score），表示距离均值有多少个标准差

### 4.5 绘制范围确定

```python
min_x = min(delays_ms)  # 数据最小值
max_x = max(delays_ms)  # 数据最大值
span = max(1e-6, 3 * std_val)  # 3σ范围的一半宽度
x_start = min(mean_val - span, min_x)  # 起点：理论下界与实际最小值的较小者
x_end = max(mean_val + span, max_x)    # 终点：理论上界与实际最大值的较大者
```

**设计原理**：
- **3σ规则**：正态分布中约99.7%的数据落在$[\mu-3\sigma, \mu+3\sigma]$范围内
- **取并集**：`数据范围 ∪ 3σ范围`
  - 既覆盖实际数据
  - 又展示理论分布特征
- **`max(1e-6, ...)`**：防止标准差极小导致范围过小或除零错误

### 4.6 采样点生成

```python
num_pts = 200  # 固定200个点
step = (x_end - x_start) / (num_pts - 1) if num_pts > 1 else 1.0
xs = [x_start + i * step for i in range(num_pts)]
```

**为什么使用200个点？**
- **足够多**：保证曲线平滑，视觉上连续
- **不会太多**：不会浪费计算资源，性能平衡
- **经验值**：对于大多数显示分辨率，200个点已经足够平滑

---

## 五、关键数字总结

| 参数 | 值 | 说明 |
|------|-----|------|
| **采样点数** | 200 | 平衡平滑度与计算效率 |
| **3σ范围** | $[\mu-3\sigma, \mu+3\sigma]$ | 覆盖约99.7%的数据 |
| **样本标准差分母** | n-1 | 贝塞尔校正，无偏估计 |
| **归一化方式** | probability density | 总面积=1，便于对比 |
| **最小span保护** | 1e-6 | 防止标准差极小导致除零错误 |

---

## 六、使用示例

### 6.1 单算法模式

```python
backend = PianoAnalysisBackend(session_id)
fig = backend.generate_delay_histogram_plot()
# fig是Plotly figure对象，可以直接用于dcc.Graph组件
```

### 6.2 多算法模式

```python
backend = PianoAnalysisBackend(session_id)
active_algorithms = backend.get_active_algorithms()
multi_plot_generator = MultiAlgorithmPlotGenerator()
fig = multi_plot_generator.generate_multi_algorithm_delay_histogram_plot(active_algorithms)
```

### 6.3 UI回调

**文件**：`ui/callbacks.py`

```python
@app.callback(
    Output('delay-histogram-plot', 'figure'),
    [Input('report-content', 'children')],
    [State('session-id', 'data')],
    prevent_initial_call=True
)
def handle_generate_delay_histogram(report_content, session_id):
    backend = session_manager.get_backend(session_id)
    if not backend:
        return no_update
    
    try:
        fig = backend.generate_delay_histogram_plot()
        return fig
    except Exception as e:
        logger.error(f"❌ 生成延时分布直方图失败: {e}")
        return backend.plot_generator._create_empty_plot(f"生成失败: {str(e)}")
```

---

## 七、常见问题

### Q1: 为什么有些曲线有负数区间，有些没有？

**有负数区间的情况**：
1. 数据中包含负值（提前的按键）：`min_x < 0`，曲线至少延伸到`min_x`
2. 数据中没有负值，但均值较小且标准差较大：`mean_val - 3*std_val < 0`，曲线会延伸到负数区间（展示理论分布）

**没有负数区间的情况**：
- 数据中没有负值，且`mean_val - 3*std_val >= 0`：曲线起点在0或正数区间

### Q2: 为什么使用概率密度归一化？

- **直方图总面积 = 1**，与正态分布的面积一致
- **直方图和拟合曲线在同一尺度上**，便于对比评估
- **归一化公式**：$f(x) = \frac{F_k}{n \times \Delta x}$

### Q3: 为什么使用n-1作为方差分母？

- **贝塞尔校正**：得到总体方差的无偏估计
- 当样本量较小时，n-1能更好地估计总体方差
- 这是统计学中的标准做法

---

## 八、总结

本功能通过以下步骤实现数据直方图与理论曲线的对比：

1. **数据提取**：从offset_data中提取带符号的延时值
2. **绘制直方图**：使用概率密度归一化，总面积=1
3. **计算统计量**：样本均值μ和样本标准差σ（n-1分母）
4. **确定绘制范围**：数据范围 ∪ 3σ范围
5. **生成采样点**：在范围内均匀生成200个x坐标点
6. **计算概率密度**：对每个x点，使用正态分布PDF公式计算y值
7. **绘制曲线**：用线段连接所有(x, y)点，形成连续平滑的曲线

通过这种方式，可以直观地评估延时数据是否符合正态分布，以及实际数据与理论分布的差异。


