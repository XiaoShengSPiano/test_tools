"""
ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ç‚¹å‡»å¤„ç†å™¨
é‡æ„è‡ª ui/callbacks.py ä¸­çš„ handle_relative_delay_distribution_click å‡½æ•°
"""

import logging
import numpy as np
from typing import Dict, List, Any, Tuple, Optional

logger = logging.getLogger(__name__)


class RelativeDelayDistributionHandler:
    """ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ç‚¹å‡»å¤„ç†å™¨ç±»"""

    def __init__(self, session_manager):
        self.session_manager = session_manager

    def handle_click(self, click_data, session_id, plot_id) -> Tuple[List[Dict], Dict, str, Dict, str]:
        """å¤„ç†ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ç‚¹å‡»äº‹ä»¶"""
        try:
            # éªŒè¯è¾“å…¥å¹¶åˆå§‹åŒ–
            validation_result = self._validate_inputs_and_init(click_data, session_id, plot_id)
            if not validation_result['valid']:
                return validation_result['result']

            backend = validation_result['backend']
            click_data = validation_result['click_data']
            plot_id = validation_result['plot_id']

            # è§£æå­å›¾ä¿¡æ¯
            subplot_result = self._parse_subplot_info(plot_id)
            if not subplot_result['valid']:
                return subplot_result['result']

            subplot_idx = subplot_result['subplot_idx']

            # å¤„ç†ç‚¹å‡»æ•°æ®
            click_result = self._process_click_data(click_data, backend, subplot_idx)
            if not click_result['valid']:
                return click_result['result']

            x_value = click_result['x_value']
            target_info = click_result['target_info']
            all_songs = click_result['all_songs']

            # è·å–æ•°æ®ç‚¹
            data_result = self._get_data_points_in_range(backend, target_info, x_value)
            if not data_result['valid']:
                return data_result['result']

            data_points = data_result['data_points']
            bin_left = data_result['bin_left']
            bin_right = data_result['bin_right']
            subplot_index = data_result['subplot_index']
            subplot_title = data_result['subplot_title']

            # å‡†å¤‡è¡¨æ ¼æ•°æ®
            table_result = self._prepare_table_data(data_points, bin_left, bin_right)

            return table_result['table_data'], table_result['table_style'], \
                   table_result['info_text'], table_result['modal_style'], \
                   table_result['subplot_title']

        except Exception as e:
            logger.error(f"[ERROR] å¤„ç†ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ç‚¹å‡»äº‹ä»¶å¤±è´¥: {e}")
            return [], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px'}, \
                   f"å¤„ç†å¤±è´¥: {str(e)}", {'display': 'none'}, ""

    def _validate_inputs_and_init(self, click_data, session_id, plot_id) -> Dict[str, Any]:
        """éªŒè¯è¾“å…¥å¹¶åˆå§‹åŒ–"""
        logger.info(f"ğŸ” ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ç‚¹å‡»å›è°ƒè¢«è§¦å‘ï¼Œclick_data: {click_data}")

        backend = self.session_manager.get_backend(session_id)
        if not backend:
            logger.warning("[WARNING] backend ä¸ºç©º")
            return {
                'valid': False,
                'result': ([], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px'},
                          "", {'display': 'none'}, "")
            }

        # å¦‚æœæ²¡æœ‰ç‚¹å‡»æ•°æ®ï¼Œéšè—è¡¨æ ¼
        if not click_data:
            logger.info("[WARNING] click_data ä¸ºç©º")
            return {
                'valid': False,
                'result': ([], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px'},
                          "", {'display': 'none'}, "")
            }

        if 'points' not in click_data or not click_data['points']:
            logger.info("[WARNING] click_data ä¸­æ²¡æœ‰ points æˆ– points ä¸ºç©º")
            return {
                'valid': False,
                'result': ([], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px'},
                          "", {'display': 'none'}, "")
            }

        return {
            'valid': True,
            'backend': backend,
            'click_data': click_data,
            'plot_id': plot_id
        }

    def _parse_subplot_info(self, plot_id) -> Dict[str, Any]:
        """è§£æå­å›¾ä¿¡æ¯"""
        # ä»plot_idè·å–å­å›¾ç´¢å¼•ï¼ˆPattern Matching Callbacksï¼‰
        subplot_idx = plot_id.get('index') if isinstance(plot_id, dict) else None
        if subplot_idx is None:
            logger.warning("[WARNING] æ— æ³•ä»plot_idè·å–å­å›¾ç´¢å¼•")
            return {
                'valid': False,
                'result': ([], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px'},
                          "", {'display': 'none'}, "")
            }

        logger.info(f"[STATS] ç‚¹å‡»çš„å­å›¾ç´¢å¼•: {subplot_idx}")
        return {
            'valid': True,
            'subplot_idx': subplot_idx
        }

    def _process_click_data(self, click_data, backend, subplot_idx) -> Dict[str, Any]:
        """å¤„ç†ç‚¹å‡»æ•°æ®"""
        # è·å–ç‚¹å‡»çš„æŸ±çŠ¶å›¾ä¿¡æ¯
        point = click_data['points'][0]
        logger.info(f"[STATS] ç‚¹å‡»çš„ point æ•°æ®: {point}")

        # è·å–ç‚¹å‡»çš„xå€¼ï¼ˆç›¸å¯¹å»¶æ—¶å€¼ï¼‰
        x_value = point.get('x')
        if x_value is None:
            logger.warning("[WARNING] point ä¸­æ²¡æœ‰ x å€¼")
            return {
                'valid': False,
                'result': ([], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px'},
                          "", {'display': 'none'}, "")
            }

        # è·å–åˆ†æç»“æœä»¥ç¡®å®šå­å›¾ä¿¡æ¯
        analysis_result = backend.get_same_algorithm_relative_delay_analysis()
        if analysis_result.get('status') != 'success':
            logger.warning("[WARNING] æ— æ³•è·å–åˆ†æç»“æœ")
            return {
                'valid': False,
                'result': ([], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px'},
                          "", {'display': 'none'}, "")
            }

        algorithm_groups = analysis_result.get('algorithm_groups', {})
        if not algorithm_groups:
            logger.warning("[WARNING] æ²¡æœ‰ç®—æ³•ç»„æ•°æ®")
            return {
                'valid': False,
                'result': ([], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px'},
                          "", {'display': 'none'}, "")
            }

        # æ„å»ºå­å›¾åˆ—è¡¨
        all_songs = self._build_subplot_list(algorithm_groups)

        # æ ¹æ®subplot_idxç›´æ¥ç¡®å®šç›®æ ‡å­å›¾ï¼ˆç´¢å¼•ä»1å¼€å§‹ï¼‰
        if subplot_idx < 1 or subplot_idx > len(all_songs):
            logger.warning(f"[WARNING] å­å›¾ç´¢å¼•è¶…å‡ºèŒƒå›´: subplot_idx={subplot_idx}, æ€»å­å›¾æ•°={len(all_songs)}")
            return {
                'valid': False,
                'result': ([], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px'},
                          "", {'display': 'none'}, "")
            }

        target_info = all_songs[subplot_idx - 1]
        logger.info(f"[OK] ç¡®å®šçš„å­å›¾: subplot_idx={subplot_idx}, display_name={target_info[0]}, filename_display={target_info[1]}")

        return {
            'valid': True,
            'x_value': x_value,
            'target_info': target_info,
            'all_songs': all_songs
        }

    def _build_subplot_list(self, algorithm_groups) -> List[Tuple]:
        """æ„å»ºå­å›¾åˆ—è¡¨"""
        all_songs = []
        for display_name, group_data in algorithm_groups.items():
            song_data = group_data.get('song_data', [])
            group_relative_delays = group_data.get('relative_delays', [])

            if not group_relative_delays:
                continue

            # æ·»åŠ æ¯ä¸ªæ›²å­
            for song_info in song_data:
                song_relative_delays = song_info.get('relative_delays', [])
                if song_relative_delays:
                    filename_display = song_info.get('filename_display', song_info.get('filename', 'æœªçŸ¥æ–‡ä»¶'))
                    all_songs.append((display_name, filename_display, song_relative_delays, None))

            # æ·»åŠ æ±‡æ€»
            all_songs.append((display_name, 'æ±‡æ€»', None, group_relative_delays))

        return all_songs

    def _get_data_points_in_range(self, backend, target_info, x_value) -> Dict[str, Any]:
        """è·å–æŒ‡å®šèŒƒå›´å†…çš„æ•°æ®ç‚¹"""
        target_display_name, target_filename_display, song_relative_delays, group_relative_delays = target_info

        # ç¡®å®šä½¿ç”¨çš„æ•°æ®
        if target_filename_display == 'æ±‡æ€»':
            target_delays = np.array(group_relative_delays)
        else:
            target_delays = np.array(song_relative_delays)

        if len(target_delays) == 0:
            logger.warning(f"[WARNING] ç›®æ ‡å­å›¾æ²¡æœ‰æ•°æ®")
            return {
                'valid': False,
                'result': ([], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px'},
                          "", {'display': 'none'}, "")
            }

        # è®¡ç®—binèŒƒå›´
        hist, bin_edges = np.histogram(target_delays, bins=50, density=False)
        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2

        # æ‰¾åˆ°åŒ…å«x_valueçš„bin
        bin_idx = np.argmin(np.abs(bin_centers - x_value))
        if bin_idx >= len(bin_edges) - 1:
            bin_idx = len(bin_edges) - 2

        bin_left = float(bin_edges[bin_idx])
        bin_right = float(bin_edges[bin_idx + 1])

        logger.info(f"[STATS] ç¡®å®šçš„binèŒƒå›´: [{bin_left:.2f}, {bin_right:.2f}]")

        # è·å–è¯¥ç›¸å¯¹å»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹
        data_points = backend.get_relative_delay_range_data_points_by_subplot(
            target_display_name, target_filename_display, bin_left, bin_right
        )

        # æ³¨æ„ï¼šsubplot_index åœ¨è¿™é‡Œæš‚æ—¶è®¾ä¸º Noneï¼Œå› ä¸ºéœ€è¦ä» all_songs ä¸­è®¡ç®—
        # ä½†è¿™ä¸ªé€»è¾‘åœ¨åŸæ¥çš„ä»£ç ä¸­æ˜¯å†—ä½™çš„ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨ _process_click_data ä¸­ç¡®å®šäº†ç›®æ ‡å­å›¾
        subplot_index = None

        # ç”Ÿæˆå­å›¾æ ‡é¢˜
        if target_filename_display == 'æ±‡æ€»':
            subplot_title = f"[STATS] {target_display_name} (æ±‡æ€») - æ•°æ®è¯¦æƒ…"
        else:
            subplot_title = f"[STATS] {target_display_name} - {target_filename_display} - æ•°æ®è¯¦æƒ…"

        return {
            'valid': True,
            'data_points': data_points,
            'bin_left': bin_left,
            'bin_right': bin_right,
            'subplot_index': subplot_index,
            'subplot_title': subplot_title
        }

    def _prepare_table_data(self, data_points, bin_left, bin_right) -> Dict[str, Any]:
        """å‡†å¤‡è¡¨æ ¼æ•°æ®"""
        if not data_points:
            info_text = f"ç›¸å¯¹å»¶æ—¶èŒƒå›´ [{bin_left:.2f}ms, {bin_right:.2f}ms] å†…æ²¡æœ‰æ•°æ®ç‚¹"
            return {
                'table_data': [],
                'table_style': {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px'},
                'info_text': info_text,
                'modal_style': {'display': 'block'},
                'subplot_title': ""
            }

        # å‡†å¤‡è¡¨æ ¼æ•°æ®
        table_data = []
        for item in data_points:
            table_data.append({
                'algorithm_name': item.get('algorithm_name', 'N/A'),
                'key_id': item.get('key_id', 'N/A'),
                'relative_delay_ms': item.get('relative_delay_ms', 0.0),
                'absolute_delay_ms': item.get('absolute_delay_ms', 0.0),
                'record_index': item.get('record_index', 'N/A'),
                'replay_index': item.get('replay_index', 'N/A'),
                'record_keyon': item.get('record_keyon', 'N/A'),
                'replay_keyon': item.get('replay_keyon', 'N/A'),
                'duration_offset': item.get('duration_offset', 'N/A'),
            })

        # æ˜¾ç¤ºä¿¡æ¯
        info_text = f"ç›¸å¯¹å»¶æ—¶èŒƒå›´ [{bin_left:.2f}ms, {bin_right:.2f}ms] å†…å…±æœ‰ {len(data_points)} ä¸ªæ•°æ®ç‚¹"

        # æ˜¾ç¤ºè¡¨æ ¼ï¼Œæ·»åŠ å‚ç›´æ»šåŠ¨æ¡ï¼Œé™åˆ¶æœ€å¤§é«˜åº¦ä¸º600px
        table_style = {
            'overflowX': 'auto',
            'overflowY': 'auto',
            'maxHeight': '600px',
        }

        return {
            'table_data': table_data,
            'table_style': table_style,
            'info_text': info_text,
            'modal_style': {'display': 'block'},
            'subplot_title': ""
        }
    
    def handle_table_click(self, active_cells, close_modal_clicks, close_btn_clicks, 
                          table_data_list, session_id, current_style):
        """
        å¤„ç†ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾è¯¦æƒ…è¡¨æ ¼ç‚¹å‡»ï¼Œæ˜¾ç¤ºå½•åˆ¶ä¸æ’­æ”¾å¯¹æ¯”æ›²çº¿
        
        Args:
            active_cells: æ´»åŠ¨å•å…ƒæ ¼åˆ—è¡¨
            close_modal_clicks: å…³é—­æŒ‰é’®ç‚¹å‡»æ¬¡æ•°
            close_btn_clicks: å…³é—­æŒ‰é’®2ç‚¹å‡»æ¬¡æ•°
            table_data_list: è¡¨æ ¼æ•°æ®åˆ—è¡¨
            session_id: ä¼šè¯ID
            current_style: å½“å‰æ¨¡æ€æ¡†æ ·å¼
            
        Returns:
            Tuple[modal_style, comparison_container_children, clicked_point_info]
        """
        from dash import no_update, dcc
        from dash._callback_context import callback_context
        
        try:
            # æ£€æµ‹è§¦å‘æº
            trigger_result = self._handle_table_trigger_detection(close_modal_clicks, close_btn_clicks)
            if trigger_result.get('is_close'):
                return trigger_result['modal_style'], [], no_update
            if trigger_result.get('should_skip'):
                return current_style, [], no_update
            
            # è·å–åç«¯
            backend = self.session_manager.get_backend(session_id)
            if not backend:
                logger.warning("[WARNING] backendä¸ºç©º")
                return current_style, [], no_update
            
            # è§£æè¡¨æ ¼ç‚¹å‡»æ•°æ®
            table_result = self._parse_table_click_data(active_cells, table_data_list)
            if not table_result['valid']:
                return current_style, [], no_update
            
            # æŸ¥æ‰¾ç›®æ ‡ç®—æ³•å’ŒéŸ³ç¬¦
            match_result = self._find_algorithm_and_notes(
                backend, 
                table_result['algorithm_name'],
                table_result['record_index'],
                table_result['replay_index'],
                table_result['key_id']
            )
            if not match_result['valid']:
                return current_style, [], no_update
            
            # ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
            chart_result = self._generate_table_comparison_chart(
                backend,
                match_result['record_note'],
                match_result['replay_note'],
                match_result['algorithm_name'],
                match_result['target_algorithm']
            )
            
            # å‡†å¤‡è¿”å›æ•°æ®
            return self._prepare_table_click_return_data(
                chart_result['figure'],
                match_result,
                table_result,
                table_result.get('triggered_table_idx', 0)
            )
            
        except Exception as e:
            logger.error(f"[ERROR] å¤„ç†è¡¨æ ¼ç‚¹å‡»å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return current_style, [], no_update
    
    def _handle_table_trigger_detection(self, close_modal_clicks, close_btn_clicks) -> Dict[str, Any]:
        """æ£€æµ‹è¡¨æ ¼ç‚¹å‡»çš„è§¦å‘æº"""
        from dash._callback_context import callback_context
        
        ctx = callback_context
        if not ctx.triggered:
            return {'should_skip': True}
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            return {
                'is_close': True,
                'modal_style': {'display': 'none'}
            }
        
        return {'is_close': False, 'should_skip': False}
    
    def _parse_table_click_data(self, active_cells, table_data_list) -> Dict[str, Any]:
        """è§£æè¡¨æ ¼ç‚¹å‡»æ•°æ®"""
        try:
            # è·å–è§¦å‘çš„è¡¨æ ¼ç´¢å¼•
            triggered_table_idx = next((i for i, cell in enumerate(active_cells) if cell), None)
            if triggered_table_idx is None or triggered_table_idx >= len(table_data_list):
                logger.warning("[WARNING] æœªæ‰¾åˆ°è§¦å‘çš„è¡¨æ ¼")
                return {'valid': False}
            
            table_data = table_data_list[triggered_table_idx]
            active_cell = active_cells[triggered_table_idx]
            
            if not active_cell or not table_data:
                logger.warning("[WARNING] active_cellæˆ–table_dataä¸ºç©º")
                return {'valid': False}
            
            # è·å–è¡Œæ•°æ®
            row_data = table_data[active_cell.get('row')]
            record_index = int(row_data.get('record_index'))
            replay_index = int(row_data.get('replay_index'))
            key_id = int(row_data.get('key_id')) if row_data.get('key_id') != 'N/A' else None
            algorithm_name = row_data.get('algorithm_name')
            
            logger.info(f"[STATS] ç‚¹å‡»è¡Œ: rec={record_index}, rep={replay_index}, key={key_id}, alg={algorithm_name}")
            
            return {
                'valid': True,
                'triggered_table_idx': triggered_table_idx,
                'record_index': record_index,
                'replay_index': replay_index,
                'key_id': key_id,
                'algorithm_name': algorithm_name
            }
        except Exception as e:
            logger.error(f"[ERROR] è§£æè¡¨æ ¼æ•°æ®å¤±è´¥: {e}")
            return {'valid': False}
    
    def _find_algorithm_and_notes(self, backend, algorithm_name, record_index, 
                                  replay_index, key_id) -> Dict[str, Any]:
        """æŸ¥æ‰¾ç›®æ ‡ç®—æ³•å®ä¾‹å’ŒéŸ³ç¬¦æ•°æ®"""
        # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms() if backend.multi_algorithm_manager else []
        if len(active_algorithms) <= 1:
            logger.warning("[WARNING] éå¤šç®—æ³•æ¨¡å¼æˆ–æ— æ•ˆè°ƒç”¨")
            return {'valid': False}
        
        # æŸ¥æ‰¾ç›®æ ‡ç®—æ³•å®ä¾‹
        target_algorithm = None
        for algorithm in active_algorithms:
            if algorithm.metadata.algorithm_name == algorithm_name:
                # éªŒè¯matched_pairsä¸­æ˜¯å¦æœ‰æ­¤åŒ¹é…å¯¹
                if algorithm.analyzer and hasattr(algorithm.analyzer, 'matched_pairs'):
                    for r_idx, p_idx, r_note, p_note in algorithm.analyzer.matched_pairs:
                        if r_idx == record_index and p_idx == replay_index:
                            target_algorithm = algorithm
                            break
                if target_algorithm:
                    break
        
        if not target_algorithm:
            logger.warning(f"[WARNING] æœªæ‰¾åˆ°åŒ¹é…ç®—æ³•: {algorithm_name}")
            return {'valid': False}
        
        # è·å–éŸ³ç¬¦æ•°æ®
        record_note = None
        replay_note = None
        center_time_ms = None
        
        for r_idx, p_idx, r_note, p_note in target_algorithm.analyzer.matched_pairs:
            if r_idx == record_index and p_idx == replay_index:
                record_note = r_note
                replay_note = p_note
                
                # è®¡ç®—ä¸­å¿ƒæ—¶é—´
                try:
                    record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
                    replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
                    center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                except Exception as e:
                    logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                    center_time_ms = None
                
                break
        
        if not record_note or not replay_note:
            logger.error("[ERROR] æ— æ³•è·å–éŸ³ç¬¦å¯¹è±¡")
            return {'valid': False}
        
        return {
            'valid': True,
            'target_algorithm': target_algorithm,
            'algorithm_name': target_algorithm.metadata.algorithm_name,
            'record_note': record_note,
            'replay_note': replay_note,
            'center_time_ms': center_time_ms
        }
    
    def _generate_table_comparison_chart(self, backend, record_note, replay_note, 
                                         algorithm_name, target_algorithm) -> Dict[str, Any]:
        """ç”Ÿæˆå¯¹æ¯”æ›²çº¿å›¾"""
        # è®¡ç®—å¹³å‡å»¶æ—¶
        mean_delay = 0.0
        if target_algorithm.analyzer:
            mean_delay = target_algorithm.analyzer.get_mean_error() / 10.0
        
        # ç”Ÿæˆå›¾è¡¨
        detail_figure = backend.plot_generator.generate_note_comparison_plot(
            record_note,
            replay_note,
            algorithm_name=algorithm_name,
            other_algorithm_notes=[],
            mean_delays={algorithm_name: mean_delay}
        )
        
        if not detail_figure:
            logger.error("[ERROR] å›¾è¡¨ç”Ÿæˆå¤±è´¥")
            return {'valid': False}
        
        return {
            'valid': True,
            'figure': detail_figure
        }
    
    def _prepare_table_click_return_data(self, figure, match_result, table_result, 
                                         triggered_table_idx):
        """å‡†å¤‡è¡¨æ ¼ç‚¹å‡»çš„è¿”å›æ•°æ®"""
        from dash import dcc
        
        # æ„å»ºç‚¹å‡»ä¿¡æ¯
        point_info = {
            'algorithm_name': match_result['algorithm_name'],
            'record_idx': table_result['record_index'],
            'replay_idx': table_result['replay_index'],
            'key_id': table_result['key_id'],
            'source_plot_id': 'relative-delay-distribution-plot',
            'source_subplot_idx': triggered_table_idx + 1,
            'center_time_ms': match_result['center_time_ms']
        }
        
        # æ¨¡æ€æ¡†æ ·å¼
        modal_style = {
            'display': 'block',
            'position': 'fixed',
            'zIndex': '9999',
            'left': '0', 'top': '0',
            'width': '100%', 'height': '100%',
            'backgroundColor': 'rgba(0,0,0,0.6)',
            'backdropFilter': 'blur(5px)'
        }
        
        return modal_style, [dcc.Graph(figure=figure, style={'height': '600px'})], point_info


# åˆ›å»ºå…¨å±€å¤„ç†å™¨å®ä¾‹
relative_delay_distribution_handler = RelativeDelayDistributionHandler(None)  # session_manager ä¼šåœ¨æ³¨å†Œæ—¶è®¾ç½®
