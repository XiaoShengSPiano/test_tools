"""
ç€‘å¸ƒå›¾è·³è½¬å¤„ç†å™¨
é‡æ„è‡ª ui/callbacks.py ä¸­çš„ handle_jump_to_waterfall å‡½æ•°
"""

import logging
import traceback
from dash import no_update
from backend.session_manager import SessionManager

logger = logging.getLogger(__name__)


class WaterfallJumpHandler:
    """ç€‘å¸ƒå›¾è·³è½¬å¤„ç†å™¨ç±»"""

    def __init__(self, session_manager: SessionManager):
        self.session_manager = session_manager

    def handle_jump_to_waterfall(self, n_clicks, session_id, point_info):
        """å¤„ç†è·³è½¬åˆ°ç€‘å¸ƒå›¾æŒ‰é’®ç‚¹å‡»"""
        from dash import callback_context

        ctx = callback_context
        if not ctx.triggered:
            return no_update, no_update, no_update, no_update

        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        if trigger_id != 'jump-to-waterfall-btn':
            return no_update, no_update, no_update, no_update

        if not n_clicks or n_clicks == 0:
            return no_update, no_update, no_update, no_update

        if not point_info:
            logger.warning("[WARNING] æ²¡æœ‰å­˜å‚¨çš„æ•°æ®ç‚¹ä¿¡æ¯ï¼Œæ— æ³•è·³è½¬")
            return no_update, no_update, no_update, no_update

        # è·å–æ¥æºå›¾è¡¨IDå’Œå­å›¾ç´¢å¼•
        source_plot_id = point_info.get('source_plot_id', None)
        source_subplot_idx = point_info.get('source_subplot_idx', None)

        # å¦‚æœæ˜¯ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ï¼Œæ„å»ºåŒ…å«å­å›¾ç´¢å¼•çš„å­—å…¸
        if source_plot_id == 'relative-delay-distribution-plot' and source_subplot_idx is not None:
            source_plot_id = {
                'type': 'relative-delay-distribution-plot',
                'index': source_subplot_idx
            }

        backend = self.session_manager.get_backend(session_id)
        if not backend:
            logger.warning("[WARNING] æ²¡æœ‰æ‰¾åˆ°backend")
            return no_update, no_update, no_update, no_update

        try:
            # éªŒè¯å’Œæå–æ•°æ®ç‚¹ä¿¡æ¯
            data_validation = self._validate_point_info(point_info)
            if not data_validation['valid']:
                return no_update, no_update, no_update, no_update

            algorithm_name = data_validation['algorithm_name']
            record_idx = data_validation['record_idx']
            replay_idx = data_validation['replay_idx']
            key_id = data_validation['key_id']
            is_error_table = data_validation['is_error_table']

            logger.info(f"[PROCESS] è·³è½¬åˆ°ç€‘å¸ƒå›¾: ç®—æ³•={algorithm_name}, record_idx={record_idx}, replay_idx={replay_idx}, æŒ‰é”®={key_id}")

            # ç”Ÿæˆç€‘å¸ƒå›¾
            waterfall_fig = self._generate_waterfall_plot(backend)
            if not waterfall_fig:
                return no_update, no_update, no_update, no_update

            # è®¡ç®—æ—¶é—´ä¿¡æ¯
            center_time_ms = self._calculate_center_time_ms(
                point_info, algorithm_name, record_idx, replay_idx,
                key_id, is_error_table, backend
            )

            # æ·»åŠ æ ‡è®°åˆ°ç€‘å¸ƒå›¾
            if center_time_ms is not None and key_id is not None:
                self._add_jump_markers_to_waterfall(
                    waterfall_fig, center_time_ms, key_id, algorithm_name,
                    source_plot_id, backend
                )

            # å…³é—­æ¨¡æ€æ¡†
            modal_style = self._get_modal_close_style()

            # è¿”å›æ›´æ–°åçš„ç€‘å¸ƒå›¾ã€åˆ‡æ¢åˆ°ç€‘å¸ƒå›¾æ ‡ç­¾é¡µã€å…³é—­æ¨¡æ€æ¡†ã€ä¿å­˜æ¥æºå›¾è¡¨ID
            return waterfall_fig, 'waterfall-tab', modal_style, source_plot_id

        except Exception as e:
            logger.error(f"[ERROR] è·³è½¬åˆ°ç€‘å¸ƒå›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return no_update, no_update, no_update, no_update

    def _validate_point_info(self, point_info):
        """éªŒè¯å’Œæå–æ•°æ®ç‚¹ä¿¡æ¯"""
        algorithm_name = point_info.get('algorithm_name')
        record_idx = point_info.get('record_idx')
        replay_idx = point_info.get('replay_idx')
        key_id = point_info.get('key_id')
        source_plot_id = point_info.get('source_plot_id', '')

        # æ£€æŸ¥æ˜¯å¦æ¥è‡ªé”™è¯¯è¡¨æ ¼ï¼ˆä¸¢é”¤/å¤šé”¤ï¼‰
        is_error_table = source_plot_id and 'error-table' in source_plot_id

        if not is_error_table and (record_idx is None or replay_idx is None):
            # éé”™è¯¯è¡¨æ ¼éœ€è¦å®Œæ•´çš„record_idxå’Œreplay_idx
            logger.warning(f"[WARNING] æ•°æ®ç‚¹ä¿¡æ¯ä¸å®Œæ•´: {point_info}")
            return {'valid': False}
        elif is_error_table and record_idx is None and replay_idx is None:
            # é”™è¯¯è¡¨æ ¼è‡³å°‘éœ€è¦ä¸€ä¸ªç´¢å¼•
            logger.warning(f"[WARNING] é”™è¯¯è¡¨æ ¼æ•°æ®ç‚¹ä¿¡æ¯ä¸å®Œæ•´: {point_info}")
            return {'valid': False}

        return {
            'valid': True,
            'algorithm_name': algorithm_name,
            'record_idx': record_idx,
            'replay_idx': replay_idx,
            'key_id': key_id,
            'is_error_table': is_error_table
        }

    def _generate_waterfall_plot(self, backend):
        """ç”Ÿæˆç€‘å¸ƒå›¾"""
        waterfall_fig = backend.generate_waterfall_plot()
        if not waterfall_fig:
            logger.warning(f"[WARNING] ç€‘å¸ƒå›¾ç”Ÿæˆå¤±è´¥")
        return waterfall_fig

    def _calculate_center_time_ms(self, point_info, algorithm_name, record_idx, replay_idx, key_id, is_error_table, backend):
        """è®¡ç®—ä¸­å¿ƒæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰"""
        # ä¼˜å…ˆä½¿ç”¨ point_info ä¸­é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯
        center_time_ms = point_info.get('center_time_ms')

        # å¯¹äºé”™è¯¯è¡¨æ ¼ï¼ˆä¸¢é”¤/å¤šé”¤ï¼‰ï¼Œå¦‚æœå·²ç»æœ‰center_time_msï¼Œç›´æ¥ä½¿ç”¨
        if is_error_table and center_time_ms is not None:
            logger.info(f"[OK] ä½¿ç”¨é”™è¯¯è¡¨æ ¼é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯: center_time_ms={center_time_ms:.1f}ms")
            return center_time_ms

        # å¦‚æœæ²¡æœ‰é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯ï¼Œåˆ™é‡æ–°è®¡ç®—
        if center_time_ms is None:
            try:
                logger.info(f"ğŸ” å¼€å§‹è®¡ç®—è·³è½¬ç‚¹æ—¶é—´: algorithm_name={algorithm_name}, record_idx={record_idx}, replay_idx={replay_idx}, key_id={key_id}")

                if algorithm_name:
                    # å¤šç®—æ³•æ¨¡å¼
                    center_time_ms = self._calculate_time_multi_algorithm(
                        algorithm_name, record_idx, replay_idx, is_error_table, backend
                    )
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    center_time_ms = self._calculate_time_single_algorithm(
                        record_idx, replay_idx, is_error_table, backend
                    )

            except Exception as e:
                logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                logger.error(traceback.format_exc())

        if center_time_ms is not None:
            logger.info(f"[OK] ä½¿ç”¨é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯: center_time_ms={center_time_ms:.1f}ms")

        logger.info(f"ğŸ” æœ€ç»ˆç»“æœ: center_time_ms={center_time_ms}, key_id={key_id}")
        return center_time_ms

    def _calculate_time_multi_algorithm(self, algorithm_name, record_idx, replay_idx, is_error_table, backend):
        """å¤šç®—æ³•æ¨¡å¼ä¸‹çš„æ—¶é—´è®¡ç®—"""
        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms() if backend.multi_algorithm_manager else []
        if len(active_algorithms) <= 1:
            return None

        algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name)
        if not algorithm or not algorithm.analyzer or not algorithm.analyzer.note_matcher:
            return None

        matched_pairs = algorithm.analyzer.matched_pairs
        logger.info(f"ğŸ” å¤šç®—æ³•æ¨¡å¼: æ‰¾åˆ° {len(matched_pairs)} ä¸ªåŒ¹é…å¯¹")

        # é¦–å…ˆå°è¯•ä» matched_pairs è·å–æ—¶é—´
        center_time_ms = self._calculate_from_matched_pairs(matched_pairs, record_idx, replay_idx)

        if center_time_ms is None and is_error_table:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä» initial_valid_data è·å–æ—¶é—´ä¿¡æ¯
            center_time_ms = self._calculate_from_initial_data_multi(
                algorithm, record_idx, replay_idx
            )

        if center_time_ms is None:
            # å¤‡ç”¨æ–¹æ¡ˆ2ï¼šä» offset_data è·å–æ—¶é—´ä¿¡æ¯
            center_time_ms = self._calculate_from_offset_data_multi(
                algorithm, record_idx, replay_idx
            )

        return center_time_ms

    def _calculate_time_single_algorithm(self, record_idx, replay_idx, is_error_table, backend):
        """å•ç®—æ³•æ¨¡å¼ä¸‹çš„æ—¶é—´è®¡ç®—"""
        analyzer = backend._get_current_analyzer()
        if not analyzer or not analyzer.note_matcher:
            return None

        matched_pairs = analyzer.matched_pairs
        logger.info(f"ğŸ” å•ç®—æ³•æ¨¡å¼: æ‰¾åˆ° {len(matched_pairs)} ä¸ªåŒ¹é…å¯¹")

        # é¦–å…ˆå°è¯•ä» matched_pairs è·å–æ—¶é—´
        center_time_ms = self._calculate_from_matched_pairs(matched_pairs, record_idx, replay_idx)

        if center_time_ms is None and is_error_table:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä» initial_valid_data è·å–æ—¶é—´ä¿¡æ¯
            center_time_ms = self._calculate_from_initial_data_single(
                analyzer, record_idx, replay_idx
            )

        if center_time_ms is None:
            # å¤‡ç”¨æ–¹æ¡ˆ2ï¼šä» offset_data è·å–æ—¶é—´ä¿¡æ¯
            center_time_ms = self._calculate_from_offset_data_single(
                analyzer, record_idx, replay_idx
            )

        return center_time_ms

    def _calculate_from_matched_pairs(self, matched_pairs, record_idx, replay_idx):
        """ä»åŒ¹é…å¯¹ä¸­è®¡ç®—æ—¶é—´"""
        for r_idx, p_idx, r_note, p_note in matched_pairs:
            if r_idx == record_idx and p_idx == replay_idx:
                # è®¡ç®—keyonæ—¶é—´
                record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
                replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
                center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
                logger.info(f"[OK] æ‰¾åˆ°åŒ¹é…å¯¹ï¼Œè®¡ç®—å¾—åˆ° center_time_ms={center_time_ms:.1f}ms")
                return center_time_ms
        return None

    def _calculate_from_initial_data_multi(self, algorithm, record_idx, replay_idx):
        """å¤šç®—æ³•æ¨¡å¼ä¸‹ä»åˆå§‹æ•°æ®è®¡ç®—æ—¶é—´"""
        center_time_ms = None

        if record_idx is not None:
            # ä¸¢é”¤ï¼šä»å½•åˆ¶æ•°æ®è·å–æ—¶é—´
            initial_data = getattr(algorithm.analyzer, 'initial_valid_record_data', [])
            if record_idx < len(initial_data):
                note = initial_data[record_idx]
                center_time_ms = self._extract_time_from_note(note)
                if center_time_ms is not None:
                    logger.info(f"[OK] å¤šç®—æ³•æ¨¡å¼(ä¸¢é”¤): ä»å½•åˆ¶æ•°æ®è·å–æ—¶é—´ï¼Œcenter_time_ms={center_time_ms:.1f}ms")

        elif replay_idx is not None:
            # å¤šé”¤ï¼šä»æ’­æ”¾æ•°æ®è·å–æ—¶é—´
            initial_data = getattr(algorithm.analyzer, 'initial_valid_replay_data', [])
            if replay_idx < len(initial_data):
                note = initial_data[replay_idx]
                center_time_ms = self._extract_time_from_note(note)
                if center_time_ms is not None:
                    logger.info(f"[OK] å¤šç®—æ³•æ¨¡å¼(å¤šé”¤): ä»æ’­æ”¾æ•°æ®è·å–æ—¶é—´ï¼Œcenter_time_ms={center_time_ms:.1f}ms")

        return center_time_ms

    def _calculate_from_initial_data_single(self, analyzer, record_idx, replay_idx):
        """å•ç®—æ³•æ¨¡å¼ä¸‹ä»åˆå§‹æ•°æ®è®¡ç®—æ—¶é—´"""
        center_time_ms = None

        if record_idx is not None:
            # ä¸¢é”¤ï¼šä»å½•åˆ¶æ•°æ®è·å–æ—¶é—´
            initial_data = getattr(analyzer, 'initial_valid_record_data', [])
            if record_idx < len(initial_data):
                note = initial_data[record_idx]
                center_time_ms = self._extract_time_from_note(note)
                if center_time_ms is not None:
                    logger.info(f"[OK] å•ç®—æ³•æ¨¡å¼(ä¸¢é”¤): ä»å½•åˆ¶æ•°æ®è·å–æ—¶é—´ï¼Œcenter_time_ms={center_time_ms:.1f}ms")

        elif replay_idx is not None:
            # å¤šé”¤ï¼šä»æ’­æ”¾æ•°æ®è·å–æ—¶é—´
            initial_data = getattr(analyzer, 'initial_valid_replay_data', [])
            if replay_idx < len(initial_data):
                note = initial_data[replay_idx]
                center_time_ms = self._extract_time_from_note(note)
                if center_time_ms is not None:
                    logger.info(f"[OK] å•ç®—æ³•æ¨¡å¼(å¤šé”¤): ä»æ’­æ”¾æ•°æ®è·å–æ—¶é—´ï¼Œcenter_time_ms={center_time_ms:.1f}ms")

        return center_time_ms

    def _extract_time_from_note(self, note):
        """ä»éŸ³ç¬¦å¯¹è±¡ä¸­æå–æ—¶é—´ä¿¡æ¯"""
        if hasattr(note, 'after_touch') and not note.after_touch.empty:
            return note.key_on_ms
        elif hasattr(note, 'hammers') and not note.hammers.empty:
            return (note.hammers.index[0] + note.offset) / 10.0
        elif hasattr(note, 'offset'):
            return note.offset / 10.0
        return None

    def _calculate_from_offset_data_multi(self, algorithm, record_idx, replay_idx):
        """å¤šç®—æ³•æ¨¡å¼ä¸‹ä»åç§»æ•°æ®è®¡ç®—æ—¶é—´"""
        if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
            return None

        offset_data = algorithm.analyzer.note_matcher.get_offset_alignment_data()
        if not offset_data:
            return None

        for item in offset_data:
            if item.get('record_index') == record_idx and item.get('replay_index') == replay_idx:
                record_keyon = item.get('record_keyon', 0)
                replay_keyon = item.get('replay_keyon', 0)
                if record_keyon and replay_keyon:
                    center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                    logger.info(f"[OK] å¤šç®—æ³•æ¨¡å¼: ä» offset_data è·å–æ—¶é—´ï¼Œcenter_time_ms={center_time_ms:.1f}ms")
                    return center_time_ms
        return None

    def _calculate_from_offset_data_single(self, analyzer, record_idx, replay_idx):
        """å•ç®—æ³•æ¨¡å¼ä¸‹ä»åç§»æ•°æ®è®¡ç®—æ—¶é—´"""
        if not analyzer.note_matcher:
            return None

        offset_data = analyzer.note_matcher.get_offset_alignment_data()
        if not offset_data:
            return None

        for item in offset_data:
            if item.get('record_index') == record_idx and item.get('replay_index') == replay_idx:
                record_keyon = item.get('record_keyon', 0)
                replay_keyon = item.get('replay_keyon', 0)
                if record_keyon and replay_keyon:
                    center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                    logger.info(f"[OK] å•ç®—æ³•æ¨¡å¼: ä» offset_data è·å–æ—¶é—´ï¼Œcenter_time_ms={center_time_ms:.1f}ms")
                    return center_time_ms
        return None

    def _add_jump_markers_to_waterfall(self, waterfall_fig, center_time_ms, key_id, algorithm_name, source_plot_id, backend):
        """åœ¨ç€‘å¸ƒå›¾ä¸­æ·»åŠ è·³è½¬æ ‡è®°"""
        try:
            import plotly.graph_objects as go
        except ImportError:
            logger.warning("[WARNING] æ— æ³•å¯¼å…¥ plotly.graph_objectsï¼Œè·³è¿‡æ·»åŠ æ ‡è®°")
            return

        # è®¡ç®—æ ‡è®°çš„yä½ç½®
        marker_y = self._calculate_marker_y_position(key_id, algorithm_name, source_plot_id, backend)

        logger.info(f"ğŸ” æœ€ç»ˆæ ‡è®°ä½ç½®: x={center_time_ms:.2f}ms, y={marker_y:.2f}, key_id={key_id}")

        # æ·»åŠ å‚ç›´å‚è€ƒçº¿æ ‡è®°è·³è½¬çš„æ•°æ®ç‚¹
        self._add_vertical_reference_line(waterfall_fig, center_time_ms, key_id, algorithm_name)

        # åœ¨æŒ‰é”®ä½ç½®æ·»åŠ ä¸€ä¸ªé†’ç›®çš„æ ‡è®°ç‚¹
        self._add_highlight_marker(waterfall_fig, center_time_ms, marker_y, key_id, algorithm_name)

        logger.info(f"[OK] å·²åœ¨ç€‘å¸ƒå›¾ä¸­æ·»åŠ è·³è½¬æ ‡è®°: æŒ‰é”®={key_id}, æ—¶é—´={center_time_ms:.1f}ms, yä½ç½®={marker_y:.1f}")

    def _calculate_marker_y_position(self, key_id, algorithm_name, source_plot_id, backend):
        """è®¡ç®—æ ‡è®°çš„Yè½´ä½ç½®"""
        try:
            marker_y = float(key_id)
            logger.info(f"ğŸ” åˆå§‹marker_y={marker_y} (key_id={key_id})")
        except (ValueError, TypeError):
            logger.warning(f"[WARNING] æ— æ³•è½¬æ¢key_idä¸ºfloat: {key_id}")
            marker_y = 0.0

        # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯è¡¨æ ¼ï¼ˆä¸¢é”¤/å¤šé”¤ï¼‰
        is_error_table = source_plot_id and 'error-table' in str(source_plot_id)
        logger.info(f"ğŸ” is_error_table={is_error_table}, source_plot_id={source_plot_id}")

        if is_error_table:
            # é”™è¯¯è¡¨æ ¼ï¼šæ ¹æ®è¡¨æ ¼ç±»å‹å†³å®šæ˜¯å¦æ·»åŠ 0.2åç§»
            if source_plot_id == 'error-table-multi' or (isinstance(source_plot_id, str) and 'error-table-multi' in source_plot_id):
                # å¤šé”¤ï¼šreplayç±»å‹ï¼Œéœ€è¦æ·»åŠ 0.2åç§»
                marker_y += 0.2
                logger.info(f"ğŸ” å¤šé”¤ï¼šæ·»åŠ 0.2åç§»ï¼Œmarker_y={marker_y}")
            else:
                # ä¸¢é”¤ï¼šrecordç±»å‹ï¼Œä¸éœ€è¦æ·»åŠ 0.2åç§»
                logger.info(f"ğŸ” ä¸¢é”¤ï¼šä¸æ·»åŠ 0.2åç§»ï¼Œmarker_y={marker_y}")

        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms() if backend.multi_algorithm_manager else []
        if algorithm_name and len(active_algorithms) > 1:
            # å¤šç®—æ³•æ¨¡å¼ï¼šéœ€è¦æ‰¾åˆ°è¯¥ç®—æ³•å¯¹åº”çš„yåç§»
            marker_y = self._apply_algorithm_y_offset(marker_y, algorithm_name, backend)
        else:
            logger.info(f"ğŸ” å•ç®—æ³•æ¨¡å¼æˆ–æ— ç®—æ³•åç§°ï¼Œmarker_y={marker_y}")

        return marker_y

    def _apply_algorithm_y_offset(self, marker_y, algorithm_name, backend):
        """åº”ç”¨å¤šç®—æ³•æ¨¡å¼çš„Yè½´åç§»"""
        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
        algorithm_y_offset = 0
        algorithm_y_range = 100  # æ¯ä¸ªç®—æ³•åç§»100ä¸ªå•ä½
        for idx, alg in enumerate(active_algorithms):
            if alg.metadata.algorithm_name == algorithm_name:
                algorithm_y_offset = idx * algorithm_y_range
                break
        marker_y = marker_y + algorithm_y_offset
        logger.info(f"ğŸ” å¤šç®—æ³•æ¨¡å¼ï¼šæ·»åŠ algorithm_y_offset={algorithm_y_offset}ï¼Œæœ€ç»ˆmarker_y={marker_y}")
        return marker_y

    def _add_vertical_reference_line(self, waterfall_fig, center_time_ms, key_id, algorithm_name):
        """æ·»åŠ å‚ç›´å‚è€ƒçº¿"""
        waterfall_fig.add_vline(
            x=center_time_ms,
            line_dash="dash",
            line_color="red",
            line_width=4,
            opacity=0.9,
            annotation_text=f"è·³è½¬ç‚¹: æŒ‰é”® {key_id}" + (f" (ç®—æ³•: {algorithm_name})" if algorithm_name else ""),
            annotation_position="top",
            annotation=dict(
                font=dict(size=16, color="red", family="Arial Black"),
                bgcolor="rgba(255, 255, 255, 0.9)",
                bordercolor="red",
                borderwidth=2,
                borderpad=4
            )
        )

    def _add_highlight_marker(self, waterfall_fig, center_time_ms, marker_y, key_id, algorithm_name):
        """æ·»åŠ é«˜äº®æ ‡è®°ç‚¹"""
        import plotly.graph_objects as go

        waterfall_fig.add_trace(go.Scatter(
            x=[center_time_ms],
            y=[marker_y],
            mode='markers+text',
            marker=dict(
                size=25,
                color='red',
                symbol='star',
                line=dict(width=3, color='white'),
                opacity=0.9
            ),
            text=[f"æŒ‰é”® {key_id}"],
            textposition="top center",
            textfont=dict(size=16, color="red", family="Arial Black", weight="bold"),
            name='è·³è½¬æ ‡è®°',
            showlegend=False,
            hovertemplate=f'<b>[TARGET] è·³è½¬ç‚¹</b><br>æŒ‰é”®: {key_id}<br>æ—¶é—´: {center_time_ms:.1f}ms' + (f'<br>ç®—æ³•: {algorithm_name}' if algorithm_name else '') + '<extra></extra>'
        ))

    def _get_modal_close_style(self):
        """è·å–å…³é—­æ¨¡æ€æ¡†çš„æ ·å¼"""
        return {
            'display': 'none',
            'position': 'fixed',
            'zIndex': '9999',
            'left': '0',
            'top': '0',
            'width': '100%',
            'height': '100%',
            'backgroundColor': 'rgba(0,0,0,0.6)',
            'backdropFilter': 'blur(5px)'
        }
