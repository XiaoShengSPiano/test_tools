"""
å»¶è¿Ÿå€¼ç‚¹å‡»å¤„ç†å™¨
é‡æ„è‡ª ui/callbacks.py ä¸­çš„ handle_delay_value_click å‡½æ•°
"""

import logging
import ast
from typing import Dict, List, Optional, Tuple, Any
from dash import no_update, dcc
import dash
from dash._callback_context import CallbackContext

logger = logging.getLogger(__name__)


class DelayValueClickHandler:
    """å»¶è¿Ÿå€¼ç‚¹å‡»å¤„ç†å™¨ç±»"""

    def __init__(self, session_manager=None):
        self.session_manager = session_manager

    def set_session_manager(self, session_manager):
        """è®¾ç½® session_managerï¼ˆç”¨äºå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
        self.session_manager = session_manager

    def handle_delay_value_click(self, max_clicks_list, min_clicks_list, close_modal_clicks, close_btn_clicks,
                                max_ids_list, min_ids_list, session_id, current_style):
        """å¤„ç†æœ€å¤§/æœ€å°å»¶è¿Ÿå­—æ®µç‚¹å‡»ï¼Œæ˜¾ç¤ºå¯¹åº”æŒ‰é”®çš„æ›²çº¿å¯¹æ¯”å›¾"""
        try:
            logger.info("[START] handle_delay_value_click å›è°ƒè¢«è§¦å‘")

            # æ£€æµ‹è§¦å‘æº
            ctx = dash.callback_context
            if not ctx.triggered:
                logger.info("[DEBUG] æ²¡æœ‰è§¦å‘äº‹ä»¶")
                return current_style, [], None

            # å¤„ç†è§¦å‘æ£€æµ‹
            trigger_result = self._handle_trigger_detection(ctx, max_clicks_list, min_clicks_list)
            if trigger_result.get('is_close'):
                logger.info("[DEBUG] æ£€æµ‹åˆ°å…³é—­æŒ‰é’®ç‚¹å‡»")
                return trigger_result['modal_style'], [], None
            if trigger_result.get('should_skip'):
                logger.info("[DEBUG] è·³è¿‡å¤„ç†ï¼ˆå¯èƒ½æ˜¯å¸ƒå±€æ›´æ–°ï¼‰")
                return current_style, [], None

            # è§£æè§¦å‘ä¿¡æ¯
            parse_result = self._parse_trigger_info(ctx, max_clicks_list, min_clicks_list, max_ids_list, min_ids_list)
            if not parse_result['valid']:
                logger.error("[ERROR] è§£æè§¦å‘ä¿¡æ¯å¤±è´¥")
                return current_style, [], None

            delay_type = parse_result['delay_type']
            algorithm_name = parse_result['algorithm_name']
            logger.info(f"[DEBUG] è§£æç»“æœ: delay_type={delay_type}, algorithm_name={algorithm_name}")

            # è·å–åç«¯
            backend = self.session_manager.get_backend(session_id)
            if not backend:
                logger.warning("[WARNING] backendä¸ºç©º")
                return current_style, [], None

            # è·å–éŸ³ç¬¦æ•°æ®
            logger.info("[DEBUG] å¼€å§‹è·å–éŸ³ç¬¦æ•°æ®")
            notes_result = self._get_notes_data(backend, algorithm_name, delay_type)
            if not notes_result['valid']:
                logger.error("[ERROR] è·å–éŸ³ç¬¦æ•°æ®å¤±è´¥")
                return current_style, [], None

            record_note, replay_note, record_index, replay_index = notes_result['notes']
            logger.info(f"[DEBUG] è·å–åˆ°éŸ³ç¬¦æ•°æ®: record_index={record_index}, replay_index={replay_index}")

            # æŸ¥æ‰¾å…¶ä»–ç®—æ³•çš„åŒ¹é…éŸ³ç¬¦
            logger.info("[DEBUG] å¼€å§‹æŸ¥æ‰¾å…¶ä»–ç®—æ³•çš„åŒ¹é…éŸ³ç¬¦")
            other_notes_result = self._find_other_algorithm_notes(backend, algorithm_name, record_note)
            logger.info(f"[DEBUG] æ‰¾åˆ° {len(other_notes_result['other_algorithm_notes'])} ä¸ªå…¶ä»–ç®—æ³•çš„åŒ¹é…éŸ³ç¬¦")

            # è®¡ç®—å¹³å‡å»¶æ—¶
            logger.info("[DEBUG] å¼€å§‹è®¡ç®—å¹³å‡å»¶æ—¶")
            mean_delays_result = self._calculate_mean_delays(backend, algorithm_name)
            logger.info(f"[DEBUG] å¹³å‡å»¶æ—¶è®¡ç®—å®Œæˆ: {mean_delays_result['mean_delays']}")

            # ç”Ÿæˆå›¾è¡¨å¹¶è¿”å›
            logger.info("[DEBUG] å¼€å§‹ç”Ÿæˆå›¾è¡¨")
            chart_result = self._generate_chart_and_return(
                record_note, replay_note, algorithm_name, delay_type,
                other_notes_result['other_algorithm_notes'], mean_delays_result['mean_delays'],
                record_index, replay_index
            )

            logger.info("[SUCCESS] å»¶è¿Ÿå€¼ç‚¹å‡»å¤„ç†å®Œæˆ")
            return chart_result['modal_style'], chart_result['rendered_row'], chart_result['clicked_point_info']

        except Exception as e:
            logger.error(f"[ERROR] å¤„ç†å»¶è¿Ÿå­—æ®µç‚¹å‡»å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return current_style, [], None

    def _handle_trigger_detection(self, ctx: CallbackContext, max_clicks_list, min_clicks_list) -> Dict[str, Any]:
        """å¤„ç†è§¦å‘æºæ£€æµ‹"""
        trigger_id = ctx.triggered[0]['prop_id']
        trigger_value = ctx.triggered[0].get('value')
        logger.info(f"ğŸ” è§¦å‘ID: {trigger_id}, è§¦å‘å€¼: {trigger_value}")

        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯å…³é—­æŒ‰é’®çš„ç‚¹å‡»
        if trigger_id in ['close-key-curves-modal.n_clicks', 'close-key-curves-modal-btn.n_clicks']:
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return {'is_close': True, 'modal_style': modal_style}

        # å¯¹äºæœ€å¤§/æœ€å°å»¶è¿Ÿå­—æ®µçš„ç‚¹å‡»ï¼Œéœ€è¦ç¡®ä¿æ˜¯çœŸæ­£çš„ç”¨æˆ·ç‚¹å‡»
        has_real_click = self._check_real_clicks(max_clicks_list, min_clicks_list)

        if not has_real_click:
            logger.info(f"[WARNING] æ²¡æœ‰æ£€æµ‹åˆ°çœŸæ­£çš„ç”¨æˆ·ç‚¹å‡»ï¼ˆå¯èƒ½æ˜¯å¸ƒå±€æ›´æ–°ï¼‰ï¼Œè·³è¿‡å¤„ç†: trigger_id={trigger_id}")
            return {'should_skip': True}

        return {'continue': True}

    def _check_real_clicks(self, max_clicks_list, min_clicks_list) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰çœŸæ­£çš„ç”¨æˆ·ç‚¹å‡»"""
        # æ£€æŸ¥max_clicks_listä¸­æ˜¯å¦æœ‰ä»»ä½•å€¼>0ï¼ˆçœŸæ­£çš„ç‚¹å‡»ï¼‰
        if max_clicks_list:
            for clicks in max_clicks_list:
                if clicks is not None and clicks > 0:
                    return True

        # æ£€æŸ¥min_clicks_listä¸­æ˜¯å¦æœ‰ä»»ä½•å€¼>0ï¼ˆçœŸæ­£çš„ç‚¹å‡»ï¼‰
        if min_clicks_list:
            for clicks in min_clicks_list:
                if clicks is not None and clicks > 0:
                    return True

        return False

    def _parse_trigger_info(self, ctx, max_clicks_list, min_clicks_list, max_ids_list, min_ids_list) -> Dict[str, Any]:
        """è§£æè§¦å‘ä¿¡æ¯ï¼Œæå–å»¶è¿Ÿç±»å‹å’Œç®—æ³•åç§°"""
        # ä»triggeredä¿¡æ¯ä¸­æå–è¢«è§¦å‘çš„ç»„ä»¶ID
        triggered_prop = ctx.triggered[0]
        prop_id_str = triggered_prop['prop_id']

        delay_type = None
        algorithm_name = None

        try:
            # ä¸»è¦è§£ææ–¹æ³•ï¼šä»prop_idä¸­è§£æ
            if 'max-delay-value' in prop_id_str:
                delay_type = 'max'
                algorithm_name = self._extract_algorithm_from_prop_id(prop_id_str)
                if algorithm_name:
                    logger.info(f"[OK] ä»prop_idè§£æå¾—åˆ°æœ€å¤§å»¶è¿Ÿç‚¹å‡»: ç®—æ³•={algorithm_name}")
            elif 'min-delay-value' in prop_id_str:
                delay_type = 'min'
                algorithm_name = self._extract_algorithm_from_prop_id(prop_id_str)
                if algorithm_name:
                    logger.info(f"[OK] ä»prop_idè§£æå¾—åˆ°æœ€å°å»¶è¿Ÿç‚¹å‡»: ç®—æ³•={algorithm_name}")

            # å¦‚æœä¸Šé¢çš„æ–¹æ³•æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
            if not delay_type or not algorithm_name:
                logger.warning(f"[WARNING] ä¸»è¦è§£ææ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                result = self._parse_trigger_info_fallback(max_clicks_list, min_clicks_list, max_ids_list, min_ids_list)
                delay_type = result.get('delay_type')
                algorithm_name = result.get('algorithm_name')

        except Exception as e:
            logger.warning(f"[WARNING] è§£æè§¦å‘IDå¤±è´¥: {e}, trigger_id={prop_id_str}")

        if not delay_type or not algorithm_name:
            logger.warning(f"[WARNING] æ— æ³•è§£æå»¶è¿Ÿç±»å‹æˆ–ç®—æ³•åç§°: prop_id={prop_id_str}, delay_type={delay_type}, algorithm_name={algorithm_name}")
            return {'valid': False}

        logger.info(f"[STATS] å»¶è¿Ÿç±»å‹: {delay_type}, ç®—æ³•åç§°: {algorithm_name}")
        return {
            'valid': True,
            'delay_type': delay_type,
            'algorithm_name': algorithm_name
        }

    def _extract_algorithm_from_prop_id(self, prop_id_str) -> Optional[str]:
        """ä»prop_idä¸­æå–ç®—æ³•åç§°"""
        try:
            # prop_idæ ¼å¼: {"type": "max-delay-value", "algorithm": "xxx"}.n_clicks
            # æå–å­—å…¸éƒ¨åˆ†
            dict_str = prop_id_str.split('.')[0]  # å»æ‰.n_clickséƒ¨åˆ†
            id_dict = ast.literal_eval(dict_str)
            return id_dict.get('algorithm')
        except Exception as e:
            logger.warning(f"[WARNING] è§£æprop_idå¤±è´¥: {prop_id_str}, é”™è¯¯: {e}")
            return None

    def _parse_trigger_info_fallback(self, max_clicks_list, min_clicks_list, max_ids_list, min_ids_list) -> Dict[str, Any]:
        """å¤‡ç”¨æ–¹æ³•ï¼šé€šè¿‡æ£€æŸ¥clicksåˆ—è¡¨æ¥è§£æè§¦å‘ä¿¡æ¯"""
        result = {}

        # æ£€æŸ¥max_clicks_listä¸­æ˜¯å¦æœ‰ç‚¹å‡»
        if max_clicks_list:
            for i, clicks in enumerate(max_clicks_list):
                if clicks is not None and clicks > 0:
                    if max_ids_list and i < len(max_ids_list):
                        max_id = max_ids_list[i]
                        if max_id and isinstance(max_id, dict):
                            result['algorithm_name'] = max_id.get('algorithm')
                            result['delay_type'] = 'max'
                            logger.info(f"[OK] å¤‡ç”¨æ–¹æ³•ï¼šæ£€æµ‹åˆ°æœ€å¤§å»¶è¿Ÿç‚¹å‡»: ç®—æ³•={result['algorithm_name']}, clicks={clicks}")
                            break

        # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œæ£€æŸ¥min_clicks_list
        if not result.get('delay_type') and min_clicks_list:
            for i, clicks in enumerate(min_clicks_list):
                if clicks is not None and clicks > 0:
                    if min_ids_list and i < len(min_ids_list):
                        min_id = min_ids_list[i]
                        if min_id and isinstance(min_id, dict):
                            result['algorithm_name'] = min_id.get('algorithm')
                            result['delay_type'] = 'min'
                            logger.info(f"[OK] å¤‡ç”¨æ–¹æ³•ï¼šæ£€æµ‹åˆ°æœ€å°å»¶è¿Ÿç‚¹å‡»: ç®—æ³•={result['algorithm_name']}, clicks={clicks}")
                            break

        return result

    def _get_notes_data(self, backend, algorithm_name, delay_type) -> Dict[str, Any]:
        """è·å–å¯¹åº”å»¶è¿Ÿç±»å‹çš„éŸ³ç¬¦æ•°æ®"""
        try:
            logger.info(f"[DEBUG] è°ƒç”¨ backend.get_notes_by_delay_type({algorithm_name}, {delay_type})")
            # è·å–å¯¹åº”å»¶è¿Ÿç±»å‹çš„éŸ³ç¬¦
            notes = backend.get_notes_by_delay_type(algorithm_name, delay_type)
            if notes is None:
                logger.warning(f"[WARNING] æ— æ³•è·å–{delay_type}å»¶è¿Ÿå¯¹åº”çš„éŸ³ç¬¦")
                return {'valid': False}

            logger.info(f"[DEBUG] æˆåŠŸè·å–éŸ³ç¬¦æ•°æ®: {type(notes)}")
            if isinstance(notes, tuple) and len(notes) == 4:
                logger.info(f"[DEBUG] éŸ³ç¬¦æ•°æ®åŒ…å«: record_note={type(notes[0])}, replay_note={type(notes[1])}, record_index={notes[2]}, replay_index={notes[3]}")

            return {
                'valid': True,
                'notes': notes
            }

        except Exception as e:
            logger.error(f"[ERROR] è·å–éŸ³ç¬¦æ•°æ®å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {'valid': False}

    def _find_other_algorithm_notes(self, backend, algorithm_name, record_note) -> Dict[str, Any]:
        """æŸ¥æ‰¾å…¶ä»–ç®—æ³•ä¸­åŒ¹é…çš„éŸ³ç¬¦"""
        other_algorithm_notes = []  # [(algorithm_name, play_note), ...]

        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms() if backend.multi_algorithm_manager else []
        if len(active_algorithms) > 1:
            active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
            for alg in active_algorithms:
                if alg.metadata.algorithm_name == algorithm_name:
                    continue  # è·³è¿‡å½“å‰ç®—æ³•ï¼ˆå·²ç»ç»˜åˆ¶ï¼‰

                if not alg.analyzer or not hasattr(alg.analyzer, 'matched_pairs'):
                    continue

                matched_pairs = alg.analyzer.matched_pairs
                # æŸ¥æ‰¾åŒ¹é…åˆ°åŒä¸€ä¸ªrecord_noteçš„æ’­æ”¾éŸ³ç¬¦
                for r_idx, p_idx, r_note, p_note in matched_pairs:
                    if r_note is record_note:  # ä½¿ç”¨isæ¯”è¾ƒå¯¹è±¡å¼•ç”¨
                        other_algorithm_notes.append((alg.metadata.algorithm_name, p_note))
                        logger.info(f"[OK] æ‰¾åˆ°ç®—æ³• '{alg.metadata.algorithm_name}' çš„åŒ¹é…æ’­æ”¾éŸ³ç¬¦")
                        break

        return {'other_algorithm_notes': other_algorithm_notes}

    def _calculate_mean_delays(self, backend, algorithm_name) -> Dict[str, Any]:
        """è·å–å¹³å‡å»¶æ—¶ - ç›´æ¥ä»å·²è®¡ç®—çš„ç»Ÿè®¡æ•°æ®ä¸­è·å–"""
        mean_delays = {}

        # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ä»ç®—æ³•å¯¹è±¡çš„ç»Ÿè®¡æ•°æ®ä¸­è·å–
        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms() if backend.multi_algorithm_manager else []
        if len(active_algorithms) > 1:
            active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
            target_algorithm = None
            for alg in active_algorithms:
                if alg.metadata.algorithm_name == algorithm_name:
                    target_algorithm = alg
                    break

            if target_algorithm:
                # ç›´æ¥ä»å·²è®¡ç®—çš„ç»Ÿè®¡æ•°æ®ä¸­è·å–å¹³å‡å»¶æ—¶
                statistics = target_algorithm.get_statistics()
                mean_error_0_1ms = statistics.get('mean_error', 0.0)
                mean_delays[algorithm_name] = mean_error_0_1ms / 10.0  # è½¬æ¢ä¸ºmså•ä½
                logger.info(f"[OK] ä»ç»Ÿè®¡æ•°æ®è·å–å¹³å‡å»¶æ—¶: {mean_delays[algorithm_name]:.2f}ms")
            else:
                logger.warning(f"[WARNING] æœªæ‰¾åˆ°ç®—æ³• {algorithm_name}ï¼Œä½¿ç”¨é»˜è®¤å¹³å‡å»¶æ—¶0")
                mean_delays[algorithm_name] = 0.0
        else:
            # å•ç®—æ³•æ¨¡å¼ç›´æ¥ä»backendè·å–
            analyzer = backend._get_current_analyzer()
            if analyzer:
                mean_error_0_1ms = analyzer.get_mean_error()
                mean_delays[algorithm_name] = mean_error_0_1ms / 10.0
                logger.info(f"[OK] ä»å•ç®—æ³•åˆ†æå™¨è·å–å¹³å‡å»¶æ—¶: {mean_delays[algorithm_name]:.2f}ms")
            else:
                logger.warning("[WARNING] å•ç®—æ³•æ¨¡å¼æ— åˆ†æå™¨ï¼Œä½¿ç”¨é»˜è®¤å¹³å‡å»¶æ—¶0")
                mean_delays[algorithm_name] = 0.0

        return {'mean_delays': mean_delays}

    def _generate_chart_and_return(self, record_note, replay_note, algorithm_name, delay_type,
                                  other_algorithm_notes, mean_delays, record_index, replay_index) -> Dict[str, Any]:
        """ç”Ÿæˆå¯¹æ¯”æ›²çº¿å›¾å¹¶å‡†å¤‡è¿”å›æ•°æ®"""
        try:
            

            # ç”Ÿæˆå¯¹æ¯”æ›²çº¿ï¼ˆåŒ…å«å…¶ä»–ç®—æ³•çš„æ’­æ”¾æ›²çº¿å’Œå¹³å‡å»¶æ—¶åç§»ï¼‰
            import spmid
            detail_figure_combined = spmid.plot_note_comparison_plotly(
                record_note,
                replay_note,
                algorithm_name=algorithm_name,
                other_algorithm_notes=other_algorithm_notes,  # ä¼ é€’å…¶ä»–ç®—æ³•çš„æ’­æ”¾éŸ³ç¬¦
                mean_delays=mean_delays
            )

            if not detail_figure_combined:
                logger.error("[ERROR] æ›²çº¿ç”Ÿæˆå¤±è´¥ - spmid.plot_note_comparison_plotly è¿”å› None")
                return {'modal_style': {'display': 'none'}, 'rendered_row': [], 'clicked_point_info': None}

            logger.info(f"[DEBUG] å›¾è¡¨ç”ŸæˆæˆåŠŸ: {type(detail_figure_combined)}")

            # æ˜¾ç¤ºæ¨¡æ€æ¡†
            modal_style = {
                'display': 'block',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }

            rendered_row = dcc.Graph(figure=detail_figure_combined, style={'height': '600px'})

            # è®¾ç½®ç‚¹å‡»ç‚¹ä¿¡æ¯ï¼Œç”¨äºè·³è½¬åˆ°ç€‘å¸ƒå›¾
            key_id = getattr(record_note, 'id', 'N/A') if record_note else 'N/A'
            clicked_point_info = {
                'algorithm_name': algorithm_name,
                'record_idx': record_index,
                'replay_idx': replay_index,
                'key_id': key_id,
                'source_plot_id': 'delay-value-click',  # æ ‡è¯†æ¥æºæ˜¯å»¶è¿Ÿå€¼ç‚¹å‡»
                'delay_type': delay_type
            }

            delay_type_name = "æœ€å¤§" if delay_type == 'max' else "æœ€å°"
            logger.info(f"[OK] {delay_type_name}å»¶è¿Ÿå­—æ®µç‚¹å‡»å¤„ç†æˆåŠŸï¼Œç®—æ³•: {algorithm_name}, æŒ‰é”®ID: {key_id}")

            return {
                'modal_style': modal_style,
                'rendered_row': [rendered_row],
                'clicked_point_info': clicked_point_info
            }

        except Exception as e:
            logger.error(f"[ERROR] ç”Ÿæˆå›¾è¡¨å¤±è´¥: {e}")
            return {'modal_style': {'display': 'none'}, 'rendered_row': [], 'clicked_point_info': None}


# åˆ›å»ºå…¨å±€å¤„ç†å™¨å®ä¾‹
delay_value_click_handler = DelayValueClickHandler(None)  # session_manager ä¼šåœ¨æ³¨å†Œæ—¶è®¾ç½®
