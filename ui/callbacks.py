"""
å›è°ƒå‡½æ•°æ¨¡å— - å¤„ç†Dashåº”ç”¨çš„æ‰€æœ‰å›è°ƒé€»è¾‘
åŒ…å«æ–‡ä»¶ä¸Šä¼ ã€å†å²è®°å½•è¡¨æ ¼äº¤äº’ç­‰å›è°ƒå‡½æ•°
"""
import base64
import json
import time
import traceback
import uuid
import math

from typing import Dict, Optional, Union, TypedDict, Tuple, List, Any
from collections import defaultdict

import pandas as pd
import numpy as np

# SPMIDå¯¼å…¥
from spmid.spmid_analyzer import SPMIDAnalyzer


from dash import html, no_update
from dash._callback import NoUpdate
            
import dash
import dash.dependencies
import dash.dcc as dcc
import dash_bootstrap_components as dbc
from dash import Input, Output, State, ALL, callback_context, dcc, dash_table
from dash._callback_context import CallbackContext
from datetime import datetime

import plotly.graph_objects as go
from plotly.graph_objects import Figure

from scipy import stats
from ui.layout_components import create_report_layout, empty_figure, create_multi_algorithm_upload_area, create_multi_algorithm_management_area
from backend.session_manager import SessionManager
from ui.ui_processor import UIProcessor
from ui.multi_file_upload_handler import MultiFileUploadHandler
from ui.waterfall_jump_handler import WaterfallJumpHandler
from ui.delay_time_series_handler import DelayTimeSeriesHandler
from ui.relative_delay_distribution_handler import RelativeDelayDistributionHandler
from grade_detail_callbacks import register_all_callbacks
from utils.logger import Logger
# åç«¯ç±»å‹å¯¼å…¥
from backend.piano_analysis_backend import PianoAnalysisBackend



logger = Logger.get_logger()

# è‡ªå®šä¹‰ç±»å‹å®šä¹‰
class VelocityDataItem(TypedDict):
    """é”¤é€Ÿæ•°æ®é¡¹çš„ç±»å‹å®šä¹‰"""
    algorithm_name: str
    display_name: str
    filename: str  # æ·»åŠ æ–‡ä»¶åä»¥åŒºåˆ†åŒç§ç®—æ³•çš„ä¸åŒæ–‡ä»¶
    key_id: int
    record_index: int  # å½•åˆ¶éŸ³ç¬¦åœ¨matched_pairsä¸­çš„ç´¢å¼•
    replay_index: int  # æ’­æ”¾éŸ³ç¬¦åœ¨matched_pairsä¸­çš„ç´¢å¼•
    record_velocity: float
    replay_velocity: float
    velocity_diff: float
    record_hammer_time_ms: float  # å½•åˆ¶ç¬¬ä¸€ä¸ªé”¤å­æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    replay_hammer_time_ms: float  # æ’­æ”¾ç¬¬ä¸€ä¸ªé”¤å­æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰

class AlgorithmMetadata:
    """ç®—æ³•å…ƒæ•°æ®çš„ç±»å‹å®šä¹‰"""
    algorithm_name: str
    display_name: str
    filename: str

class OffsetAlignmentDataItem(TypedDict):
    """åç§»å¯¹é½æ•°æ®é¡¹çš„ç±»å‹å®šä¹‰"""
    record_index: int
    replay_index: int
    key_id: int
    record_keyon: float
    replay_keyon: float
    keyon_offset: float
    record_keyoff: float
    replay_keyoff: float
    duration_offset: float
    average_offset: float
    record_duration: float
    replay_duration: float
    duration_diff: float

class OffsetAlignmentTableItem(TypedDict):
    """åç§»å¯¹é½è¡¨æ ¼æ•°æ®é¡¹çš„ç±»å‹å®šä¹‰"""
    algorithm_name: str
    key_id: Union[int, str]
    count: int
    median: Union[float, str]
    mean: Union[float, str]
    std: Union[float, str]
    variance: Union[float, str]
    min: Union[float, str]
    max: Union[float, str]
    range: Union[float, str]
    status: str

class SPMIDNote:
    """SPMIDéŸ³ç¬¦å¯¹è±¡çš„ç±»å‹å®šä¹‰"""
    id: int
    hammers: pd.Series  # é”¤å‡»æ•°æ®ï¼Œpandas Serieså¯¹è±¡ï¼Œç´¢å¼•ä¸ºæ—¶é—´æˆ³

class ZScoreClickData(TypedDict):
    """Z-Scoreæ•£ç‚¹å›¾ç‚¹å‡»æ•°æ®çš„ç±»å‹å®šä¹‰"""
    record_index: int
    replay_index: int
    key_id: Optional[int]
    algorithm_name: str

class AlgorithmInstance:
    """ç®—æ³•å®ä¾‹çš„ç±»å‹å®šä¹‰"""
    metadata: AlgorithmMetadata
    analyzer: Optional[SPMIDAnalyzer]  # SPMIDåˆ†æå™¨å®ä¾‹

    def is_ready(self) -> bool:
        """æ£€æŸ¥ç®—æ³•æ˜¯å¦å°±ç»ª"""
        pass

# çŠ¶æ€å­—å…¸ç±»å‹å®šä¹‰
class StateDict(TypedDict, total=False):
    """çŠ¶æ€å­—å…¸ç±»å‹å®šä¹‰"""
    has_upload: bool
    upload_content: Optional[str]
    filename: Optional[str]
    has_history: bool
    history_id: Optional[str]
    last_upload_content: Optional[str]
    last_history_id: Optional[str]

# æ–‡ä»¶ä¸Šä¼ ç»“æœæ•°æ®ç±»å‹å®šä¹‰
class UploadResultData(TypedDict):
    """æ–‡ä»¶ä¸Šä¼ æˆåŠŸæ—¶çš„ç»“æœæ•°æ®å­—å…¸"""
    filename: str
    record_count: int
    replay_count: int
    history_id: str

def _create_empty_figure_for_callback(title: str) -> Figure:
    """åˆ›å»ºç”¨äºå›è°ƒçš„ç©ºPlotly figureå¯¹è±¡"""
    fig = go.Figure()
    fig.add_annotation(
        x=0.5,
        y=0.5,
        xref="paper",
        yref="paper",
        text=title,
        showarrow=False,
        font=dict(size=16, color="gray"),
        align="center"
    )

    fig.update_layout(
        title=title,
        xaxis=dict(visible=False),
        yaxis=dict(visible=False),
        height=600,
        template='plotly_white',
        showlegend=False
    )

    return fig


def _detect_trigger_source(ctx: CallbackContext, backend: Optional[PianoAnalysisBackend],
                          contents: Optional[str], filename: Optional[str], history_id: Optional[str]) -> str:
    """
    æ£€æµ‹ç”¨æˆ·æ“ä½œçš„è§¦å‘æºï¼Œç¡®å®šéœ€è¦æ‰§è¡Œçš„å¤„ç†é€»è¾‘
    
    è§¦å‘æºä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š
    1. æ–°æ–‡ä»¶ä¸Šä¼  - æœ€é«˜ä¼˜å…ˆçº§ï¼Œä¼šé‡æ–°åŠ è½½æ•°æ®
    2. å†å²è®°å½•é€‰æ‹© - ä¸­ç­‰ä¼˜å…ˆçº§ï¼Œä¼šåˆ‡æ¢æ•°æ®æº
    3. æŒ‰é’®ç‚¹å‡» - æœ€ä½ä¼˜å…ˆçº§ï¼ŒåŸºäºå½“å‰æ•°æ®ç”Ÿæˆè§†å›¾
    
    Args:
        ctx: Dashå›è°ƒä¸Šä¸‹æ–‡ï¼ŒåŒ…å«è§¦å‘ä¿¡æ¯
        backend: åç«¯å®ä¾‹ï¼Œç”¨äºçŠ¶æ€ç®¡ç†
        contents: ä¸Šä¼ æ–‡ä»¶çš„å†…å®¹ï¼ˆbase64ç¼–ç ï¼‰
        filename: ä¸Šä¼ æ–‡ä»¶çš„æ–‡ä»¶å
        history_id: é€‰æ‹©çš„å†å²è®°å½•ID
        
    Returns:
        str: è§¦å‘æºç±»å‹ ('upload', 'history', 'waterfall', 'report', 'skip')
             - 'upload': æ–°æ–‡ä»¶ä¸Šä¼ 
             - 'history': å†å²è®°å½•é€‰æ‹©
             - 'waterfall': ç€‘å¸ƒå›¾æŒ‰é’®ç‚¹å‡»
             - 'report': æŠ¥å‘ŠæŒ‰é’®ç‚¹å‡»
             - 'skip': è·³è¿‡å¤„ç†ï¼ˆé‡å¤æ“ä½œï¼‰
    """
    # è·å–å½“å‰çŠ¶æ€ä¿¡æ¯
    current_time = time.time()
    current_state = _get_current_state(contents, filename, history_id)
    previous_state = _get_previous_state(backend)
    
    # ä»å›è°ƒä¸Šä¸‹æ–‡æ£€æµ‹è§¦å‘æº
    trigger_source = _detect_trigger_from_context(ctx, current_state, previous_state, backend, current_time)
    
    # å¦‚æœæ— æ³•ä»ä¸Šä¸‹æ–‡ç¡®å®šï¼Œåˆ™åŸºäºçŠ¶æ€å˜åŒ–æ™ºèƒ½åˆ¤æ–­
    if not trigger_source:
        trigger_source = _detect_trigger_from_state_change(current_state, previous_state, backend, current_time)
    
    # è®°å½•æœ€ç»ˆç»“æœ
    data_source = getattr(backend, '_data_source', 'none') if backend else 'none'
    logger.info(f"ğŸ” æœ€ç»ˆç¡®å®šè§¦å‘æº: {trigger_source}, å½“å‰æ•°æ®æº: {data_source}")
    return trigger_source

def _get_current_state(contents: Optional[str], filename: Optional[str], history_id: Optional[str]) -> StateDict:
    """è·å–å½“å‰çŠ¶æ€ä¿¡æ¯"""
    return {
        'has_upload': bool(contents and filename),
        'has_history': history_id is not None,
        'upload_content': contents,
        'filename': filename,
        'history_id': history_id
    }

def _get_previous_state(backend: Optional[PianoAnalysisBackend]) -> StateDict:
    """è·å–ä¸Šæ¬¡çš„çŠ¶æ€ä¿¡æ¯"""
    if not backend:
        return {
            'last_upload_content': None,
            'last_history_id': None
        }
    
    return {
        'last_upload_content': getattr(backend, '_last_upload_content', None),
        'last_history_id': getattr(backend, '_last_selected_history_id', None)
    }

def _detect_trigger_from_context(ctx: CallbackContext, current_state: StateDict, previous_state: StateDict,
                               backend: PianoAnalysisBackend, current_time: float) -> Optional[str]:
    """ä»å›è°ƒä¸Šä¸‹æ–‡æ£€æµ‹è§¦å‘æº"""
    if not ctx.triggered:
        return None
    
    recent_trigger = ctx.triggered[0]['prop_id']
    
    # æ£€æŸ¥å†å²è®°å½•é€‰æ‹©è§¦å‘
    if 'history-dropdown' in recent_trigger:
        return _handle_history_trigger(current_state, previous_state, backend, current_time)
    
    return None

def _handle_upload_trigger(current_state: StateDict, previous_state: StateDict,
                          backend: PianoAnalysisBackend, current_time: float) -> Optional[str]:
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ è§¦å‘ - å…è®¸é‡å¤ä¸Šä¼ ç›¸åŒæ–‡ä»¶ä»¥è¿›è¡Œä¸€è‡´æ€§éªŒè¯"""
    # æ³¨æ„ï¼šHTMLæ–‡ä»¶è¾“å…¥åœ¨é€‰æ‹©ç›¸åŒæ–‡ä»¶æ—¶ä¸ä¼šè§¦å‘changeäº‹ä»¶
    # æ‰€ä»¥æˆ‘ä»¬ä¸ä¾èµ–current_state['has_upload']ï¼Œè€Œæ˜¯åªè¦è§¦å‘äº†å›è°ƒå°±å¤„ç†

    # è®°å½•ä¸Šä¼ å°è¯•ï¼Œæ— è®ºæ˜¯å¦æœ‰æ–°å†…å®¹
    filename = current_state.get('filename', 'unknown')
    logger.info(f"[UPLOAD] æ–‡ä»¶ä¸Šä¼ å›è°ƒè¢«è§¦å‘: {filename}")

    # æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤éªŒè¯ï¼ˆä½¿ç”¨ç›¸åŒæ–‡ä»¶ï¼‰
    is_repeat_verification = False
    upload_content = current_state.get('upload_content')

    if not upload_content:
        # æ²¡æœ‰æ–°å†…å®¹ï¼Œä½¿ç”¨ä¸Šæ¬¡çš„å†…å®¹ï¼ˆé‡å¤éªŒè¯åœºæ™¯ï¼‰
        upload_content = previous_state.get('last_upload_content')
        if upload_content:
            is_repeat_verification = True
            logger.info(f"ğŸ”„ æ£€æµ‹åˆ°é‡å¤éªŒè¯è¯·æ±‚ï¼šä½¿ç”¨ç›¸åŒæ–‡ä»¶é‡æ–°å¤„ç†")
            logger.info(f"ğŸ¯ è¿™å°†æ˜¯æ•°æ®ä¸€è‡´æ€§éªŒè¯çš„ç¬¬ {getattr(backend, '_analysis_count', 0) + 1} æ¬¡åˆ†æ")
        else:
            logger.warning(f"[UPLOAD] æ²¡æœ‰å¯ç”¨çš„æ–‡ä»¶å†…å®¹")
            return None
    else:
        logger.info(f"ğŸ“ æ–°æ–‡ä»¶ä¸Šä¼ : {filename}")

    # è®°å½•éªŒè¯çŠ¶æ€
    if is_repeat_verification:
        backend._is_repeat_verification = True
    else:
        backend._is_repeat_verification = False

    _update_upload_state(backend, upload_content, current_time, filename)
    return 'upload'

def _handle_history_trigger(current_state: StateDict, previous_state: StateDict,
                           backend: PianoAnalysisBackend, current_time: float) -> Optional[str]:
    """å¤„ç†å†å²è®°å½•é€‰æ‹©è§¦å‘"""
    if not current_state['has_history']:
        return None
    
    # æ£€æŸ¥å†å²è®°å½•é€‰æ‹©æ˜¯å¦å‘ç”Ÿå˜åŒ–
    if current_state['history_id'] != previous_state['last_history_id']:
        _update_history_state(backend, current_state['history_id'], current_time)
        logger.info(f"[PROCESS] æ£€æµ‹åˆ°å†å²è®°å½•é€‰æ‹©å˜åŒ–: {current_state['history_id']}")
        return 'history'
    else:
        logger.warning("[WARNING] å†å²è®°å½•é€‰æ‹©æœªå˜åŒ–ï¼Œè·³è¿‡é‡å¤å¤„ç†")
        return 'skip'

def _detect_trigger_from_state_change(current_state: StateDict, previous_state: StateDict,
                                     backend: PianoAnalysisBackend, current_time: float) -> Optional[str]:
    """åŸºäºçŠ¶æ€å˜åŒ–æ™ºèƒ½æ£€æµ‹è§¦å‘æº"""
    # æ–‡ä»¶ä¸Šä¼ ç°åœ¨ç”±ç»Ÿä¸€ç®¡ç†å™¨å¤„ç†ï¼Œè¿™é‡Œåªå¤„ç†å†å²è®°å½•
    if (current_state['has_history'] and
          current_state['history_id'] != previous_state['last_history_id']):
        _update_history_state(backend, current_state['history_id'], current_time)
        logger.info(f"[PROCESS] æ™ºèƒ½æ£€æµ‹åˆ°å†å²è®°å½•é€‰æ‹©: {current_state['history_id']}")
        return 'history'
    
    return None

def _update_upload_state(backend: PianoAnalysisBackend, upload_content: str, current_time: float, filename: str = None) -> None:
    """æ›´æ–°æ–‡ä»¶ä¸Šä¼ çŠ¶æ€"""
    backend._last_upload_content = upload_content
    backend._last_upload_filename = filename or getattr(backend, '_last_upload_filename', 'unknown')
    backend._last_upload_time = current_time
    backend._data_source = 'upload'

def _update_history_state(backend: PianoAnalysisBackend, history_id: str, current_time: float) -> None:
    """æ›´æ–°å†å²è®°å½•é€‰æ‹©çŠ¶æ€"""
    backend._last_selected_history_id = history_id
    backend._last_history_time = current_time
    backend._data_source = 'history'


def _process_file_upload_result(success: bool, result_data: Optional[UploadResultData], 
                                error_msg: Optional[str], filename: Optional[str]) -> Tuple[Optional[html.Div], Optional[html.Div]]:
    """
    å¤„ç†æ–‡ä»¶ä¸Šä¼ ç»“æœå¹¶ç”ŸæˆUIå†…å®¹
    
    Args:
        success: æ–‡ä»¶ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        result_data: æˆåŠŸæ—¶çš„ç»“æœæ•°æ®å­—å…¸ï¼ŒåŒ…å«filenameã€record_countã€replay_countã€history_id
        error_msg: å¤±è´¥æ—¶çš„é”™è¯¯ä¿¡æ¯
        filename: ä¸Šä¼ çš„æ–‡ä»¶å
        
    Returns:
        Tuple[Optional[html.Div], Optional[html.Div]]: 
            - ç¬¬ä¸€ä¸ªå…ƒç´ ï¼šæˆåŠŸæ—¶çš„ä¿¡æ¯å†…å®¹ï¼ˆhtml.Divï¼‰ï¼Œå¤±è´¥æ—¶ä¸ºNone
            - ç¬¬äºŒä¸ªå…ƒç´ ï¼šå¤±è´¥æ—¶çš„é”™è¯¯å†…å®¹ï¼ˆhtml.Divï¼‰ï¼ŒæˆåŠŸæ—¶ä¸ºNone
    """
    ui_processor = UIProcessor()

    if success:
        info_content = ui_processor.create_upload_success_content(result_data)
        error_content = None
    else:
        info_content = None
        error_content = ui_processor.create_upload_error_content(filename, error_msg)

    return info_content, error_content

def _handle_upload_error(error_msg, error_content):
    """å¤„ç†ä¸Šä¼ é”™è¯¯æƒ…å†µ"""
    if error_content:
        if error_msg and ("è½¨é“" in error_msg or "track" in error_msg.lower() or "SPMIDæ–‡ä»¶åªåŒ…å«" in error_msg):
            fig = _create_empty_figure_for_callback("[ERROR] SPMIDæ–‡ä»¶åªåŒ…å« 1 ä¸ªè½¨é“ï¼Œéœ€è¦è‡³å°‘2ä¸ªè½¨é“ï¼ˆå½•åˆ¶+æ’­æ”¾ï¼‰æ‰èƒ½è¿›è¡Œåˆ†æ")
        else:
            fig = _create_empty_figure_for_callback("æ–‡ä»¶ç±»å‹ä¸ç¬¦")
        # é¡ºåº: fig, report, history_options, time_min, time_max, time_value, time_status
        return fig, error_content, no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
    else:
        fig = _create_empty_figure_for_callback("æ–‡ä»¶ä¸Šä¼ å¤±è´¥")
        error_div = html.Div([
            html.H4("æ–‡ä»¶ä¸Šä¼ å¤±è´¥", className="text-center text-danger"),
            html.P("è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æˆ–è”ç³»ç®¡ç†å‘˜ã€‚", className="text-center")
        ])
        return fig, error_div, no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"

def _handle_history_selection(history_id, backend):
    """å¤„ç†å†å²è®°å½•é€‰æ‹©æ“ä½œ"""
    logger.info(f"[PROCESS] åŠ è½½å†å²è®°å½•: {history_id}")
    
    # ä½¿ç”¨HistoryManagerå¤„ç†å†å²è®°å½•é€‰æ‹©ï¼ˆåŒ…å«çŠ¶æ€åˆå§‹åŒ–ï¼‰
    success, result_data, error_msg = backend.history_manager.process_history_selection(history_id, backend)
    
    # ä½¿ç”¨UIProcessorç”ŸæˆUIå†…å®¹
    ui_processor = UIProcessor()

    if success:
        if result_data['has_file_content']:
            # æ‰§è¡Œæ•°æ®åˆ†æ
            backend._perform_error_analysis()
            
            # è‡ªåŠ¨ç”Ÿæˆç€‘å¸ƒå›¾å’ŒæŠ¥å‘Š
            waterfall_fig = backend.generate_waterfall_plot()
            report_content = ui_processor.generate_history_report(backend, result_data['filename'], result_data['history_id'])
        else:
            # æ²¡æœ‰æ–‡ä»¶å†…å®¹ï¼Œåªæ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
            waterfall_fig = ui_processor.create_empty_figure("å†å²è®°å½•æ— æ–‡ä»¶å†…å®¹")
            report_content = ui_processor.create_history_basic_info_content(result_data)
    else:
        waterfall_fig = ui_processor.create_empty_figure("å†å²è®°å½•åŠ è½½å¤±è´¥")
        report_content = ui_processor.create_error_content("å†å²è®°å½•åŠ è½½å¤±è´¥", error_msg)
    
    if waterfall_fig and report_content:
        logger.info("[OK] å†å²è®°å½•åŠ è½½å®Œæˆï¼Œè¿”å›ç€‘å¸ƒå›¾å’ŒæŠ¥å‘Š")
        
        # è·å–é”®IDç­›é€‰ç›¸å…³æ•°æ®
        available_keys = backend.get_available_keys()
        key_options = [{'label': f'é”®ä½ {key_id}', 'value': key_id} for key_id in available_keys]
        key_status = backend.get_key_filter_status()
        
        # å°†key_statusè½¬æ¢ä¸ºå¯æ¸²æŸ“çš„å­—ç¬¦ä¸²
        if key_status['enabled']:
            key_status_text = f"å·²ç­›é€‰ {len(key_status['filtered_keys'])} ä¸ªé”®ä½ (å…± {key_status['total_available_keys']} ä¸ª)"
        else:
            key_status_text = f"æ˜¾ç¤ºå…¨éƒ¨ {key_status['total_available_keys']} ä¸ªé”®ä½"
        
        # å®Œå…¨é¿å…æ›´æ–°æ»‘å—å±æ€§ï¼Œé˜²æ­¢æ— é™é€’å½’
        time_status = backend.get_time_filter_status()
        
        # å°†time_statusè½¬æ¢ä¸ºå¯æ¸²æŸ“çš„å­—ç¬¦ä¸²
        if time_status['enabled']:
            time_status_text = f"æ—¶é—´èŒƒå›´: {time_status['start_time']:.2f}s - {time_status['end_time']:.2f}s (æ—¶é•¿: {time_status['duration']:.2f}s)"
        else:
            time_status_text = "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
        
        # å†å²è®°å½•æƒ…å†µä¸‹ï¼Œå½“å‰ç­›é€‰å€¼å–åç«¯å·²è®¾ç½®çš„filtered_keys
        kstatus = backend.get_key_filter_status()
        current_value = kstatus.get('filtered_keys', []) if kstatus else []
        return waterfall_fig, report_content, no_update, key_options, key_status_text, current_value, no_update, no_update, no_update, time_status_text
    else:
        logger.error("[ERROR] å†å²è®°å½•åŠ è½½å¤±è´¥")
        empty_fig = _create_empty_figure_for_callback("å†å²è®°å½•åŠ è½½å¤±è´¥")
        error_content = html.Div([
            html.H4("å†å²è®°å½•åŠ è½½å¤±è´¥", className="text-center text-danger"),
            html.P("è¯·å°è¯•é€‰æ‹©å…¶ä»–å†å²è®°å½•", className="text-center")
        ])
        return empty_fig, error_content, no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´", no_update


def _handle_waterfall_button(backend):
    """å¤„ç†ç€‘å¸ƒå›¾æŒ‰é’®ç‚¹å‡»"""
    current_data_source = getattr(backend, '_data_source', 'none') if backend else 'none'
    logger.info(f"[PROCESS] ç”Ÿæˆç€‘å¸ƒå›¾ï¼ˆæ•°æ®æº: {current_data_source}ï¼‰")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²åŠ è½½çš„æ•°æ® - æ”¹ä¸ºæ£€æŸ¥æ›´åŸºæœ¬çš„æ•°æ®çŠ¶æ€
    has_data = (backend.analyzer and 
                (backend.plot_generator.valid_record_data or backend.plot_generator.valid_replay_data or
                 (hasattr(backend.analyzer, 'valid_record_data') and backend.analyzer.valid_record_data) or
                 (hasattr(backend.analyzer, 'valid_replay_data') and backend.analyzer.valid_replay_data)))
    
    if has_data:
        fig = backend.generate_waterfall_plot()
        
        # è·å–å®é™…çš„æ—¶é—´èŒƒå›´å¹¶æ›´æ–°æ»‘åŠ¨æ¡
        try:
            time_range = backend.get_time_range()
            time_min, time_max = time_range
            
            # ç¡®ä¿æ—¶é—´èŒƒå›´æ˜¯æœ‰æ•ˆçš„
            if isinstance(time_min, (int, float)) and isinstance(time_max, (int, float)) and time_min < time_max:
                # åˆ›å»ºåˆç†çš„æ ‡è®°ç‚¹
                range_size = time_max - time_min
                if range_size <= 1000:
                    step = max(1, range_size // 5)
                elif range_size <= 10000:
                    step = max(10, range_size // 10)
                else:
                    step = max(100, range_size // 20)
                
                marks = {}
                for i in range(int(time_min), int(time_max) + 1, step):
                    if i == time_min or i == time_max or (i - time_min) % (step * 2) == 0:
                        marks[i] = str(i)
                
                logger.info(f"â° ç€‘å¸ƒå›¾æŒ‰é’®æ›´æ–°æ»‘åŠ¨æ¡: min={time_min}, max={time_max}, èŒƒå›´={range_size}")
                # key_value ä¸åœ¨æ­¤å›è°ƒä¸­æ›´æ–°
                return fig, no_update, no_update, time_min, time_max, [time_min, time_max], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
            else:
                logger.warning(f"[WARNING] æ—¶é—´èŒƒå›´æ— æ•ˆ: {time_range}")
                return fig, no_update, no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
        except Exception as e:
            logger.error(f"[ERROR] è·å–æ—¶é—´èŒƒå›´å¤±è´¥: {e}")
            return fig, no_update, no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´", no_update
    else:
        if current_data_source == 'history':
            empty_fig = _create_empty_figure_for_callback("è¯·é€‰æ‹©å†å²è®°å½•æˆ–ä¸Šä¼ æ–°æ–‡ä»¶")
        else:
            empty_fig = _create_empty_figure_for_callback("è¯·å…ˆä¸Šä¼ SPMIDæ–‡ä»¶")
            return empty_fig, no_update, no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"


def register_callbacks(app, session_manager: SessionManager, history_manager):
    """æ³¨å†Œæ‰€æœ‰å›è°ƒå‡½æ•°"""

    # åˆ›å»ºç€‘å¸ƒå›¾è·³è½¬å¤„ç†å™¨å®ä¾‹
    waterfall_jump_handler = WaterfallJumpHandler(session_manager)

    # åˆ›å»ºå»¶æ—¶æ—¶é—´åºåˆ—å›¾å¤„ç†å™¨å®ä¾‹
    delay_time_series_handler = DelayTimeSeriesHandler(session_manager)

    # åˆ›å»ºç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å¤„ç†å™¨å®ä¾‹
    relative_delay_distribution_handler = RelativeDelayDistributionHandler(session_manager)

    # åˆå§‹åŒ–å›è°ƒï¼šè‡ªåŠ¨å¯ç”¨å¤šç®—æ³•æ¨¡å¼
    @app.callback(
        Output('session-id', 'data'),
        Input('session-id', 'data'),
        prevent_initial_call=False
    )
    def init_session_and_enable_multi_algorithm(session_data):
        """åˆå§‹åŒ–ä¼šè¯IDå¹¶è‡ªåŠ¨å¯ç”¨å¤šç®—æ³•æ¨¡å¼"""
        if session_data is None:
            session_id = str(uuid.uuid4())
        else:
            session_id = session_data
        
        # å¤šç®—æ³•æ¨¡å¼å§‹ç»ˆå¯ç”¨
        session_id, backend = session_manager.get_or_create_backend(session_id)
        if backend:
            # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
            if not backend.multi_algorithm_manager:
                backend._ensure_multi_algorithm_manager()
            logger.info("[OK] å¤šç®—æ³•æ¨¡å¼å·²å°±ç»ª")
        
        return session_id

    # æ·»åŠ æ—¶é—´æ»‘å—åˆå§‹åŒ–å›è°ƒ - å½“æ•°æ®åŠ è½½å®Œæˆåè‡ªåŠ¨è®¾ç½®åˆç†çš„æ—¶é—´èŒƒå›´
    @app.callback(
        [Output('time-filter-slider', 'min', allow_duplicate=True),
         Output('time-filter-slider', 'max', allow_duplicate=True),
         Output('time-filter-slider', 'value', allow_duplicate=True),
         Output('time-filter-slider', 'marks', allow_duplicate=True)],
        Input('report-content', 'children'),
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def initialize_time_slider_on_data_load(report_content, session_id):
        """å½“æ•°æ®åŠ è½½å®Œæˆååˆå§‹åŒ–æ—¶é—´æ»‘å—"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update, no_update, no_update
        
        # åªæœ‰å½“æœ‰åˆ†ææ•°æ®æ—¶æ‰æ›´æ–°æ»‘å—
        if not hasattr(backend, 'all_error_notes') or not backend.all_error_notes:
            return no_update, no_update, no_update, no_update
        
        try:
            # è·å–å®é™…çš„æ—¶é—´èŒƒå›´
            time_range = backend.get_time_range()
            time_min, time_max = time_range
            
            # ç¡®ä¿æ—¶é—´èŒƒå›´æ˜¯æœ‰æ•ˆçš„
            if not isinstance(time_min, (int, float)) or not isinstance(time_max, (int, float)):
                return no_update, no_update, no_update, no_update
            
            if time_min >= time_max:
                return no_update, no_update, no_update, no_update
            
            # è½¬æ¢ä¸ºæ•´æ•°ï¼Œé¿å…æ»‘å—ç²¾åº¦é—®é¢˜
            time_min, time_max = int(time_min), int(time_max)
            
            # åˆ›å»ºåˆç†çš„æ ‡è®°ç‚¹
            range_size = time_max - time_min
            if range_size <= 1000:
                step = max(1, range_size // 5)
            elif range_size <= 10000:
                step = max(10, range_size // 10)
            else:
                step = max(100, range_size // 20)
            
            marks = {}
            for i in range(time_min, time_max + 1, step):
                if i == time_min or i == time_max or (i - time_min) % (step * 2) == 0:
                    marks[i] = str(i)
            
            logger.info(f"â° åˆå§‹åŒ–æ—¶é—´æ»‘å—: min={time_min}, max={time_max}, èŒƒå›´={range_size}")
            
            return time_min, time_max, [time_min, time_max], marks
            
        except Exception as e:
            logger.warning(f"[WARNING] åˆå§‹åŒ–æ—¶é—´æ»‘å—å¤±è´¥: {e}")
            return no_update, no_update, no_update, no_update

    # æ·»åŠ åˆå§‹åŒ–å†å²è®°å½•ä¸‹æ‹‰èœå•çš„å›è°ƒ - åªåœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–ä¸€æ¬¡
    @app.callback(
        [Output('history-dropdown', 'options', allow_duplicate=True),
         Output('history-dropdown', 'value', allow_duplicate=True)],
        Input('session-id', 'data'),
        prevent_initial_call='initial_duplicate'  # ä¿®å¤ï¼šä½¿ç”¨ initial_duplicate å…è®¸åˆå§‹è°ƒç”¨å’Œé‡å¤è¾“å‡º
    )
    def initialize_history_dropdown(session_id):
        """åˆå§‹åŒ–å†å²è®°å½•ä¸‹æ‹‰æ¡†é€‰é¡¹ - åªåœ¨ä¼šè¯åˆå§‹åŒ–æ—¶è°ƒç”¨ä¸€æ¬¡"""
        # æ£€æŸ¥æ˜¯å¦å·²ç»åˆå§‹åŒ–è¿‡
        if hasattr(initialize_history_dropdown, '_initialized'):
            return no_update, no_update
        
        try:
            # æ£€æŸ¥æ•°æ®åº“åŠŸèƒ½æ˜¯å¦å·²ç¦ç”¨
            if hasattr(history_manager, 'disable_database') and history_manager.disable_database:
                disabled_option = {
                    'label': 'âš ï¸ æ•°æ®åº“åŠŸèƒ½å·²ç¦ç”¨',
                    'value': 'disabled',
                    'disabled': True
                }
                initialize_history_dropdown._initialized = True
                return [disabled_option], None

            # è·å–å†å²è®°å½•åˆ—è¡¨
            history_list = history_manager.get_history_list(limit=100)

            if not history_list:
                initialize_history_dropdown._initialized = True
                return [], None

            # è½¬æ¢ä¸ºä¸‹æ‹‰æ¡†é€‰é¡¹æ ¼å¼
            options = []
            for record in history_list:
                label = f"{record['filename']} ({record['timestamp'][:19] if record['timestamp'] else 'æœªçŸ¥æ—¶é—´'}) - å¤šé”¤:{record['multi_hammers']} ä¸¢é”¤:{record['drop_hammers']}"
                options.append({
                    'label': label,
                    'value': record['id']
                })

            logger.info(f"[OK] åˆå§‹åŒ–å†å²è®°å½•ä¸‹æ‹‰èœå•ï¼Œæ‰¾åˆ° {len(options)} æ¡è®°å½•")
            initialize_history_dropdown._initialized = True
            return options, None  # è¿”å›é€‰é¡¹åˆ—è¡¨ï¼Œä½†ä¸é¢„é€‰ä»»ä½•é¡¹

        except Exception as e:
            logger.error(f"[ERROR] åˆå§‹åŒ–å†å²è®°å½•ä¸‹æ‹‰æ¡†å¤±è´¥: {e}")
            initialize_history_dropdown._initialized = True
            return [], None

    @app.callback(
        Output('history-dropdown', 'options', allow_duplicate=True),
        [Input('history-search', 'value'),
         Input('session-id', 'data')],
        prevent_initial_call=True  # ä¿®æ”¹ä¸ºTrueï¼Œé˜²æ­¢åˆå§‹åŒ–æ—¶é‡å¤è°ƒç”¨
    )
    def update_history_dropdown_search(search_value, session_id):
        """æ›´æ–°å†å²è®°å½•ä¸‹æ‹‰æ¡†é€‰é¡¹ - ä»…æœç´¢è§¦å‘"""
        try:
            # æ£€æŸ¥æ•°æ®åº“åŠŸèƒ½æ˜¯å¦å·²ç¦ç”¨
            if hasattr(history_manager, 'disable_database') and history_manager.disable_database:
                return [{
                    'label': 'âš ï¸ æ•°æ®åº“åŠŸèƒ½å·²ç¦ç”¨',
                    'value': 'disabled',
                    'disabled': True
                }]

            # è·å–å†å²è®°å½•åˆ—è¡¨
            history_list = history_manager.get_history_list(limit=100)

            if not history_list:
                return []

            # è½¬æ¢ä¸ºä¸‹æ‹‰æ¡†é€‰é¡¹æ ¼å¼
            options = []
            for record in history_list:
                label = f"{record['filename']} ({record['timestamp'][:19] if record['timestamp'] else 'æœªçŸ¥æ—¶é—´'}) - å¤šé”¤:{record['multi_hammers']} ä¸¢é”¤:{record['drop_hammers']}"

                # å¦‚æœæœ‰æœç´¢å€¼ï¼Œåˆ™è¿‡æ»¤é€‰é¡¹
                if search_value and search_value.lower() not in label.lower():
                    continue

                options.append({
                    'label': label,
                    'value': record['id']
                })

            return options

        except Exception as e:
            logger.error(f"[ERROR] æ›´æ–°å†å²è®°å½•ä¸‹æ‹‰æ¡†å¤±è´¥: {e}")
            return []


    def _validate_zscore_click_data(zscore_scatter_clickData: Dict[str, Any], backend: PianoAnalysisBackend) -> Optional[Dict[str, Any]]:
        """
        éªŒè¯Z-Scoreæ•£ç‚¹å›¾ç‚¹å‡»æ•°æ®

        Args:
            zscore_scatter_clickData: ç‚¹å‡»æ•°æ®
            backend: åç«¯å®ä¾‹

        Returns:
            Optional[Dict[str, Any]]: éªŒè¯é€šè¿‡çš„ç‚¹å‡»ç‚¹æ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        if 'points' not in zscore_scatter_clickData or len(zscore_scatter_clickData['points']) == 0:
            logger.warning("[WARNING] Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - zscore_scatter_clickDataæ— æ•ˆæˆ–æ²¡æœ‰points")
            return None

        point = zscore_scatter_clickData['points'][0]
        logger.info(f"ğŸ” Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - ç‚¹å‡»ç‚¹æ•°æ®: {point}")

        if not point.get('customdata'):
            logger.warning("[WARNING] Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - ç‚¹æ²¡æœ‰customdata")
            return None

        return point

    def _extract_zscore_customdata(raw_customdata: Any) -> Optional[ZScoreClickData]:
        """
        æå–å’ŒéªŒè¯Z-Scoreæ•£ç‚¹å›¾çš„customdata

        Args:
            raw_customdata: åŸå§‹customdata

        Returns:
            Optional[ZScoreClickData]: æå–çš„ç‚¹å‡»æ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        logger.info(f"ğŸ” Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - raw_customdataç±»å‹: {type(raw_customdata)}, å€¼: {raw_customdata}")

        if isinstance(raw_customdata, list) and len(raw_customdata) > 0:
            customdata = raw_customdata[0] if isinstance(raw_customdata[0], list) else raw_customdata
        else:
            customdata = raw_customdata

        if not isinstance(customdata, list):
            logger.warning(f"[WARNING] Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - customdataä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(customdata)}, å€¼: {customdata}")
            return None

        logger.info(f"ğŸ” Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - customdata: {customdata}, é•¿åº¦: {len(customdata)}")

        if len(customdata) < 5:
            logger.warning(f"[WARNING] Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - customdataé•¿åº¦ä¸è¶³: {len(customdata)}")
            return None

        # Z-Scoreæ•£ç‚¹å›¾çš„customdataæ ¼å¼: [record_index, replay_index, key_id_int, delay_ms, algorithm_name]
        record_index = customdata[0]
        replay_index = customdata[1]
        key_id = customdata[2] if len(customdata) > 2 else None
        algorithm_name = customdata[4]

        logger.info(f"ğŸ–±ï¸ Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»: ç®—æ³•={algorithm_name}, record_index={record_index}, replay_index={replay_index}, key_id={key_id}")

        return {
            'record_index': record_index,
            'replay_index': replay_index,
            'key_id': key_id,
            'algorithm_name': algorithm_name
        }

    def _get_algorithm_for_zscore(backend: PianoAnalysisBackend, algorithm_name: str) -> Optional[Any]:
        """
        è·å–Z-Scoreåˆ†æçš„ç®—æ³•å®ä¾‹

        Args:
            backend: åç«¯å®ä¾‹
            algorithm_name: ç®—æ³•åç§°

        Returns:
            Optional[Any]: ç®—æ³•å®ä¾‹ï¼Œè·å–å¤±è´¥è¿”å›None
        """
        if not algorithm_name or not backend.multi_algorithm_mode or not backend.multi_algorithm_manager:
            return None

        algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name)
        if not algorithm or not algorithm.analyzer or not algorithm.analyzer.note_matcher:
            return None

        return algorithm

    def _get_time_from_offset_data(note_matcher: Any, record_index: int, replay_index: int) -> Optional[Tuple[float, float]]:
        """
        ä»é¢„è®¡ç®—çš„offset_dataä¸­è·å–æ—¶é—´ä¿¡æ¯

        Args:
            note_matcher: éŸ³ç¬¦åŒ¹é…å™¨å®ä¾‹
            record_index: å½•åˆ¶éŸ³ç¬¦ç´¢å¼•
            replay_index: æ’­æ”¾éŸ³ç¬¦ç´¢å¼•

        Returns:
            Optional[Tuple[float, float]]: (record_keyon, replay_keyon)ï¼Œè·å–å¤±è´¥è¿”å›None
        """
        try:
            offset_data = note_matcher.get_offset_alignment_data()
            if not offset_data:
                return None

            for item in offset_data:
                if item.get('record_index') == record_index and item.get('replay_index') == replay_index:
                    record_keyon = item.get('record_keyon', 0)
                    replay_keyon = item.get('replay_keyon', 0)
                    if record_keyon and replay_keyon:
                        return record_keyon, replay_keyon
            return None
        except Exception:
            return None

    def _calculate_time_from_notes(matched_pairs: List, record_index: int, replay_index: int) -> Optional[Tuple[float, float]]:
        """
        ä»matched_pairsä¸­çš„éŸ³ç¬¦ç›´æ¥è®¡ç®—æ—¶é—´ä¿¡æ¯

        Args:
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨
            record_index: å½•åˆ¶éŸ³ç¬¦ç´¢å¼•
            replay_index: æ’­æ”¾éŸ³ç¬¦ç´¢å¼•

        Returns:
            Optional[Tuple[float, float]]: (record_keyon, replay_keyon)ï¼Œè®¡ç®—å¤±è´¥è¿”å›None
        """
        try:
            for r_idx, p_idx, r_note, p_note in matched_pairs:
                if r_idx == record_index and p_idx == replay_index:
                    record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
                    replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
                    return record_keyon, replay_keyon
            return None
        except Exception:
            return None

    def _calculate_center_time_ms(record_keyon: float, replay_keyon: float) -> float:
        """
        è®¡ç®—ä¸­å¿ƒæ—¶é—´å¹¶è½¬æ¢ä¸ºæ¯«ç§’

        Args:
            record_keyon: å½•åˆ¶éŸ³ç¬¦å¼€å§‹æ—¶é—´ï¼ˆ0.1mså•ä½ï¼‰
            replay_keyon: æ’­æ”¾éŸ³ç¬¦å¼€å§‹æ—¶é—´ï¼ˆ0.1mså•ä½ï¼‰

        Returns:
            float: ä¸­å¿ƒæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        """
        return ((record_keyon + replay_keyon) / 2.0) / 10.0

    def _calculate_zscore_center_time(backend: PianoAnalysisBackend, click_data: ZScoreClickData) -> Optional[float]:
        """
        è®¡ç®—Z-Scoreæ•£ç‚¹å›¾ç‚¹å‡»çš„ä¸­å¿ƒæ—¶é—´

        Args:
            backend: åç«¯å®ä¾‹
            click_data: ç‚¹å‡»æ•°æ®

        Returns:
            Optional[float]: ä¸­å¿ƒæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ï¼Œè®¡ç®—å¤±è´¥è¿”å›None
        """
        try:
            # è·å–ç®—æ³•å®ä¾‹
            algorithm = _get_algorithm_for_zscore(backend, click_data['algorithm_name'])
            if not algorithm:
                return None

            record_index = click_data['record_index']
            replay_index = click_data['replay_index']

            # ä¼˜å…ˆä»é¢„è®¡ç®—çš„ offset_data ä¸­è·å–æ—¶é—´ä¿¡æ¯
            keyon_times = _get_time_from_offset_data(algorithm.analyzer.note_matcher, record_index, replay_index)
            if keyon_times:
                record_keyon, replay_keyon = keyon_times
                return _calculate_center_time_ms(record_keyon, replay_keyon)

            # å¦‚æœ offset_data ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œé™çº§åˆ°ç›´æ¥ä»éŸ³ç¬¦è®¡ç®—
            keyon_times = _calculate_time_from_notes(algorithm.analyzer.matched_pairs, record_index, replay_index)
            if keyon_times:
                record_keyon, replay_keyon = keyon_times
                return _calculate_center_time_ms(record_keyon, replay_keyon)

            return None

        except Exception as e:
            logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def _generate_zscore_detail_plots(backend: PianoAnalysisBackend, click_data: ZScoreClickData) -> Tuple[Any, Any, Any]:
        """
        ç”ŸæˆZ-Scoreæ•£ç‚¹å›¾ç‚¹å‡»çš„è¯¦ç»†æ›²çº¿å›¾

        Args:
            backend: åç«¯å®ä¾‹
            click_data: ç‚¹å‡»æ•°æ®

        Returns:
            Tuple[Any, Any, Any]: (å½•åˆ¶å›¾, æ’­æ”¾å›¾, å¯¹æ¯”å›¾)
        """
        detail_figure1, detail_figure2, detail_figure_combined = backend.generate_multi_algorithm_scatter_detail_plot_by_indices(
            algorithm_name=click_data['algorithm_name'],
            record_index=click_data['record_index'],
            replay_index=click_data['replay_index']
        )

        logger.info(f"ğŸ” Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - å›¾è¡¨ç”Ÿæˆç»“æœ: figure1={detail_figure1 is not None}, figure2={detail_figure2 is not None}, figure_combined={detail_figure_combined is not None}")

        return detail_figure1, detail_figure2, detail_figure_combined

    def _create_zscore_modal_response(detail_figure_combined: Any, point_info: Dict[str, Any]) -> Tuple[Dict[str, Any], Any, Dict[str, Any]]:
        """
        åˆ›å»ºZ-Scoreæ•£ç‚¹å›¾çš„æ¨¡æ€æ¡†å“åº”

        Args:
            detail_figure_combined: å¯¹æ¯”æ›²çº¿å›¾
            point_info: ç‚¹ä¿¡æ¯

        Returns:
            Tuple[Dict[str, Any], Any, Dict[str, Any]]: (æ¨¡æ€æ¡†æ ·å¼, å›¾è¡¨ç»„ä»¶, ç‚¹ä¿¡æ¯)
        """
        modal_style = {
            'display': 'block',
            'position': 'fixed',
            'zIndex': '9999',
            'left': '0',
            'top': '0',
            'width': '100%',
            'height': '100%',
            'backgroundColor': 'rgba(0,0,0,0.6)',
            'backdropFilter': 'blur(5px)'
        }

        logger.info("[OK] Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - è¿”å›æ¨¡æ€æ¡†å’Œå›¾è¡¨")
        return modal_style, dcc.Graph(figure=detail_figure_combined, style={'height': '600px'}), point_info

    def _handle_zscore_modal_close() -> Tuple[Dict[str, Any], List[Any], NoUpdate]:
        """å¤„ç†Z-Scoreæ¨¡æ€æ¡†å…³é—­é€»è¾‘"""
        logger.info("[OK] å…³é—­æŒ‰é”®æ›²çº¿å¯¹æ¯”æ¨¡æ€æ¡†")
        modal_style = {
            'display': 'none',
            'position': 'fixed',
            'zIndex': '9999',
            'left': '0',
            'top': '0',
            'width': '100%',
            'height': '100%',
            'backgroundColor': 'rgba(0,0,0,0.6)',
            'backdropFilter': 'blur(5px)'
        }
        return modal_style, [], no_update

    def _handle_zscore_plot_click(zscore_scatter_clickData: Optional[Dict[str, Any]], session_id: str, current_style: Dict[str, Any], source_plot_id: str = 'key-delay-zscore-scatter-plot') -> Tuple[Dict[str, Any], List[Any], Union[Dict[str, Any], NoUpdate]]:
        """å¤„ç†Z-Scoreæ•£ç‚¹å›¾ç‚¹å‡»çš„ä¸»è¦é€»è¾‘"""
        logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒè¢«è§¦å‘ - source_plot_id: {source_plot_id}, clickData: {zscore_scatter_clickData is not None}")

        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("[WARNING] æ²¡æœ‰æ‰¾åˆ°backend")
            return current_style, [], no_update

        # éªŒè¯ç‚¹å‡»æ•°æ®
        point = _validate_zscore_click_data(zscore_scatter_clickData, backend)
        if not point:
            return current_style, [], no_update

        # æå–customdata
        click_data = _extract_zscore_customdata(point['customdata'])
        if not click_data:
            return current_style, [], no_update

        # è®¡ç®—ä¸­å¿ƒæ—¶é—´
        center_time_ms = _calculate_zscore_center_time(backend, click_data)

        # å­˜å‚¨å½“å‰ç‚¹å‡»çš„æ•°æ®ç‚¹ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æŒ‰é’®
        point_info = {
            'algorithm_name': click_data['algorithm_name'],
            'record_idx': click_data['record_index'],
            'replay_idx': click_data['replay_index'],
            'key_id': click_data['key_id'],
            'source_plot_id': source_plot_id,  # è®°å½•æ¥æºå›¾è¡¨ID
            'center_time_ms': center_time_ms  # é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯
        }

        # ç”Ÿæˆè¯¦ç»†æ›²çº¿å›¾
        detail_figure1, detail_figure2, detail_figure_combined = _generate_zscore_detail_plots(backend, click_data)

        # æ£€æŸ¥å›¾è¡¨ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        if detail_figure1 and detail_figure2 and detail_figure_combined:
            modal_style, graph_component, point_info_response = _create_zscore_modal_response(detail_figure_combined, point_info)
            return modal_style, graph_component, point_info_response
        else:
            logger.warning("[WARNING] Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼Œéƒ¨åˆ†å›¾è¡¨ä¸ºNone")
            return current_style, [], no_update

    # Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True),
         Output('key-delay-zscore-scatter-plot', 'clickData', allow_duplicate=True)],
        [Input('key-delay-zscore-scatter-plot', 'clickData'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_zscore_scatter_click(zscore_scatter_clickData, close_modal_clicks, close_btn_clicks, session_id, current_style):
        """å¤„ç†Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»ï¼Œæ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾"""
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            logger.debug("[WARNING] Z-Scoreæ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒï¼šæ²¡æœ‰è§¦å‘æº")
            return current_style, [], no_update, no_update

        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"[PROCESS] Z-Scoreæ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")

        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            result = _handle_zscore_modal_close()
            return result[0], result[1], result[2], None

        # å¦‚æœæ˜¯Z-Scoreæ•£ç‚¹å›¾ç‚¹å‡»
        if trigger_id == 'key-delay-zscore-scatter-plot' and zscore_scatter_clickData:
            result = _handle_zscore_plot_click(zscore_scatter_clickData, session_id, current_style, 'key-delay-zscore-scatter-plot')
            return result[0], result[1], result[2], no_update

        # å…¶ä»–æƒ…å†µï¼Œè¿”å›é»˜è®¤å€¼
        return current_style, [], no_update, no_update

    # æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True),
         Output('key-delay-scatter-plot', 'clickData', allow_duplicate=True)],
        [Input('key-delay-scatter-plot', 'clickData'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_key_delay_scatter_click(scatter_clickData, close_modal_clicks, close_btn_clicks, session_id, current_style):
        """å¤„ç†æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ç‚¹å‡»ï¼Œæ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾"""
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            logger.debug("[WARNING] æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒï¼šæ²¡æœ‰è§¦å‘æº")
            return current_style, [], no_update, no_update

        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"[PROCESS] æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")

        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            result = _handle_zscore_modal_close()
            return result[0], result[1], result[2], None

        # å¦‚æœæ˜¯æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ç‚¹å‡»
        if trigger_id == 'key-delay-scatter-plot' and scatter_clickData:
            # å¤ç”¨ Z-Score å›¾è¡¨çš„ç‚¹å‡»å¤„ç†é€»è¾‘ï¼Œå› ä¸º customdata æ ¼å¼åº”è¯¥æ˜¯ä¸€æ ·çš„
            result = _handle_zscore_plot_click(scatter_clickData, session_id, current_style, 'key-delay-scatter-plot')
            return result[0], result[1], result[2], no_update

        # å…¶ä»–æƒ…å†µï¼Œè¿”å›é»˜è®¤å€¼
        return current_style, [], no_update, no_update

    # æ—¶é—´è½´ç­›é€‰å›è°ƒå‡½æ•°
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('time-filter-status', 'children', allow_duplicate=True),
         Output('time-filter-slider', 'value', allow_duplicate=True)],
        [Input('btn-apply-time-filter', 'n_clicks'),
         Input('btn-reset-time-filter', 'n_clicks')],
        [State('session-id', 'data'),
         State('time-filter-slider', 'value')],
        prevent_initial_call=True
    )
    def handle_time_filter(apply_clicks, reset_clicks, session_id, time_range):
        """å¤„ç†æ—¶é—´è½´ç­›é€‰"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update, no_update
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        if not hasattr(backend, 'all_error_notes') or not backend.all_error_notes:
            logger.warning("[WARNING] æ²¡æœ‰åˆ†ææ•°æ®ï¼Œæ— æ³•åº”ç”¨æ—¶é—´ç­›é€‰")
            return no_update, no_update, no_update
        
        # è·å–è§¦å‘ä¸Šä¸‹æ–‡
        ctx = callback_context
        if not ctx.triggered:
            return no_update, no_update, no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"â° æ—¶é—´ç­›é€‰è§¦å‘å™¨: {trigger_id}")
        
        # è·å–åŸå§‹æ—¶é—´èŒƒå›´ï¼ˆç”¨äºé‡ç½®ï¼‰
        original_time_range = backend.get_time_range()
        original_min, original_max = original_time_range
        slider_value = no_update
        
        # å¤„ç†"é‡ç½®æ—¶é—´èŒƒå›´"æŒ‰é’®
        if trigger_id == 'btn-reset-time-filter' and reset_clicks and reset_clicks > 0:
            backend.set_time_filter(None)
            logger.info("â° é‡ç½®æ—¶é—´èŒƒå›´ç­›é€‰")
            # é‡ç½®æ»‘å—åˆ°åŸå§‹èŒƒå›´
            slider_value = [int(original_min), int(original_max)]
            logger.info(f"â° é‡ç½®æ»‘å—åˆ°åŸå§‹èŒƒå›´: {slider_value}")
            
        # å¤„ç†"åº”ç”¨æ—¶é—´ç­›é€‰"æŒ‰é’®
        elif trigger_id == 'btn-apply-time-filter' and apply_clicks and apply_clicks > 0:
            if time_range and len(time_range) == 2 and time_range[0] != time_range[1]:
                # éªŒè¯æ—¶é—´èŒƒå›´çš„åˆç†æ€§
                start_time, end_time = time_range
                if start_time < end_time:
                    backend.set_time_filter(time_range)
                    logger.info(f"â° åº”ç”¨æ—¶é—´è½´ç­›é€‰: {time_range}")
                    # ä¿æŒå½“å‰æ»‘å—å€¼
                    slider_value = no_update
                else:
                    logger.warning(f"[WARNING] æ—¶é—´èŒƒå›´æ— æ•ˆ: {time_range}")
                    backend.set_time_filter(None)
                    # é‡ç½®æ»‘å—åˆ°åŸå§‹èŒƒå›´
                    slider_value = [int(original_min), int(original_max)]
            else:
                backend.set_time_filter(None)
                logger.info("â° æ¸…é™¤æ—¶é—´è½´ç­›é€‰ï¼ˆæ— æ•ˆèŒƒå›´ï¼‰")
                # é‡ç½®æ»‘å—åˆ°åŸå§‹èŒƒå›´
                slider_value = [int(original_min), int(original_max)]
        else:
            logger.warning(f"[WARNING] æœªè¯†åˆ«çš„æ—¶é—´ç­›é€‰è§¦å‘å™¨: {trigger_id}")
            return no_update, no_update, no_update
        
        try:
            # é‡æ–°ç”Ÿæˆç€‘å¸ƒå›¾
            fig = backend.generate_waterfall_plot()
            time_status = backend.get_time_filter_status()
            
            # å°†time_statusè½¬æ¢ä¸ºå¯æ¸²æŸ“çš„å­—ç¬¦ä¸²
            if time_status['enabled']:
                time_status_text = f"æ—¶é—´èŒƒå›´: {time_status['start_time']:.2f}s - {time_status['end_time']:.2f}s (æ—¶é•¿: {time_status['duration']:.2f}s)"
            else:
                time_status_text = "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
            
            logger.info(f"â° æ—¶é—´è½´ç­›é€‰çŠ¶æ€: {time_status}")
            
            return fig, time_status_text, slider_value
        except Exception as e:
            logger.error(f"[ERROR] æ—¶é—´ç­›é€‰åç”Ÿæˆç€‘å¸ƒå›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            
            # è¿”å›é”™è¯¯æç¤ºå›¾
            error_fig = _create_empty_figure_for_callback(f"æ—¶é—´ç­›é€‰å¤±è´¥: {str(e)}")
            return error_fig, "æ—¶é—´ç­›é€‰å‡ºé”™ï¼Œè¯·é‡è¯•", no_update


    # æ—¶é—´èŒƒå›´è¾“å…¥ç¡®è®¤å›è°ƒå‡½æ•°
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('time-range-input-status', 'children', allow_duplicate=True),
         Output('time-filter-slider', 'min', allow_duplicate=True),
         Output('time-filter-slider', 'max', allow_duplicate=True),
         Output('time-filter-slider', 'value', allow_duplicate=True),
         Output('time-filter-slider', 'marks', allow_duplicate=True)],
        [Input('btn-confirm-time-range', 'n_clicks')],
        [State('session-id', 'data'),
         State('time-range-start-input', 'value'),
         State('time-range-end-input', 'value')],
        prevent_initial_call=True
    )
    def handle_time_range_input_confirmation(n_clicks, session_id, start_time, end_time):
        """å¤„ç†æ—¶é—´èŒƒå›´è¾“å…¥ç¡®è®¤"""
        logger.info(f"[PROCESS] æ—¶é—´èŒƒå›´è¾“å…¥ç¡®è®¤å›è°ƒè¢«è§¦å‘: n_clicks={n_clicks}, start_time={start_time}, end_time={end_time}")
        
        if not n_clicks or n_clicks <= 0:
            logger.info("[WARNING] æŒ‰é’®æœªç‚¹å‡»ï¼Œè·³è¿‡å¤„ç†")
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("[WARNING] æ— æ•ˆçš„ä¼šè¯ID")
            return no_update, "æ— æ•ˆçš„ä¼šè¯ID", no_update, no_update, no_update, no_update
        
        if start_time is None or end_time is None:
            logger.warning("[WARNING] æ—¶é—´èŒƒå›´è¾“å…¥ä¸ºç©º")
            return no_update, "è¯·è¾“å…¥æœ‰æ•ˆçš„æ—¶é—´èŒƒå›´", no_update, no_update, no_update, no_update
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            logger.info(f"[PROCESS] è°ƒç”¨åç«¯æ›´æ–°æ—¶é—´èŒƒå›´: start_time={start_time}, end_time={end_time}")
            # è°ƒç”¨åç«¯æ–¹æ³•æ›´æ–°æ—¶é—´èŒƒå›´
            success, message = backend.update_time_range_from_input(start_time, end_time)
            
            if success:
                logger.info(f"[OK] åç«¯æ—¶é—´èŒƒå›´æ›´æ–°æˆåŠŸ: {message}")
                # é‡æ–°ç”Ÿæˆç€‘å¸ƒå›¾ï¼ˆä½¿ç”¨æ–°çš„æ—¶é—´èŒƒå›´ï¼‰
                fig = backend.generate_waterfall_plot()
                
                # æ›´æ–°æ»‘åŠ¨æ¡çš„èŒƒå›´å’Œå½“å‰å€¼
                new_min = int(start_time)
                new_max = int(end_time)
                new_value = [new_min, new_max]
                
                # åˆ›å»ºæ–°çš„æ ‡è®°ç‚¹
                range_size = new_max - new_min
                if range_size <= 1000:
                    step = max(1, range_size // 5)
                elif range_size <= 10000:
                    step = max(10, range_size // 10)
                else:
                    step = max(100, range_size // 20)
                
                new_marks = {}
                for i in range(new_min, new_max + 1, step):
                    if i == new_min or i == new_max or (i - new_min) % (step * 2) == 0:
                        new_marks[i] = str(i)
                
                logger.info(f"[OK] æ—¶é—´èŒƒå›´æ›´æ–°æˆåŠŸ: {message}")
                logger.info(f"â° æ›´æ–°æ»‘åŠ¨æ¡èŒƒå›´: min={new_min}, max={new_max}, value={new_value}")
                logger.info(f"â° æ–°æ ‡è®°ç‚¹: {new_marks}")
                status_message = f"[OK] {message}"
                status_style = {'color': '#28a745', 'fontWeight': 'bold'}
                
                return fig, html.Span(status_message, style=status_style), new_min, new_max, new_value, new_marks
            else:
                logger.warning(f"[WARNING] æ—¶é—´èŒƒå›´æ›´æ–°å¤±è´¥: {message}")
                status_message = f"[ERROR] {message}"
                status_style = {'color': '#dc3545', 'fontWeight': 'bold'}
                
                return no_update, html.Span(status_message, style=status_style), no_update, no_update, no_update, no_update
                
        except Exception as e:
            logger.error(f"[ERROR] æ—¶é—´èŒƒå›´è¾“å…¥ç¡®è®¤å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            
            error_message = f"[ERROR] æ—¶é—´èŒƒå›´æ›´æ–°å¤±è´¥: {str(e)}"
            error_style = {'color': '#dc3545', 'fontWeight': 'bold'}
            
            return no_update, html.Span(error_message, style=error_style), no_update, no_update, no_update, no_update


    # é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´å›è°ƒå‡½æ•°
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('time-range-input-status', 'children', allow_duplicate=True),
         Output('time-filter-slider', 'min', allow_duplicate=True),
         Output('time-filter-slider', 'max', allow_duplicate=True),
         Output('time-filter-slider', 'value', allow_duplicate=True),
         Output('time-filter-slider', 'marks', allow_duplicate=True)],
        [Input('btn-reset-display-time-range', 'n_clicks')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_reset_display_time_range(n_clicks, session_id):
        """å¤„ç†é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´"""
        if not n_clicks or n_clicks <= 0:
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("[WARNING] æ— æ•ˆçš„ä¼šè¯ID")
            return no_update, "æ— æ•ˆçš„ä¼šè¯ID", no_update, no_update, no_update, no_update
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´
            backend.reset_display_time_range()
            
            # é‡æ–°ç”Ÿæˆç€‘å¸ƒå›¾
            fig = backend.generate_waterfall_plot()
            
            # è·å–åŸå§‹æ•°æ®æ—¶é—´èŒƒå›´å¹¶é‡ç½®æ»‘åŠ¨æ¡åˆ°åŸå§‹èŒƒå›´
            original_min, original_max = backend.get_time_range()
            new_value = [int(original_min), int(original_max)]
            
            logger.info("[OK] æ˜¾ç¤ºæ—¶é—´èŒƒå›´é‡ç½®æˆåŠŸ")
            status_message = "[OK] æ˜¾ç¤ºæ—¶é—´èŒƒå›´å·²é‡ç½®åˆ°åŸå§‹æ•°æ®èŒƒå›´"
            status_style = {'color': '#28a745', 'fontWeight': 'bold'}
            
            return fig, html.Span(status_message, style=status_style), no_update, no_update, new_value, no_update
                
        except Exception as e:
            logger.error(f"[ERROR] é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            
            error_message = f"[ERROR] é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´å¤±è´¥: {str(e)}"
            error_style = {'color': '#dc3545', 'fontWeight': 'bold'}
            
            return no_update, html.Span(error_message, style=error_style), no_update, no_update, no_update, no_update

    # åç§»å¯¹é½åˆ†æ - é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('offset-alignment-plot', 'children', allow_duplicate=True),
        Output('offset-alignment-table', 'data', allow_duplicate=True),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def auto_generate_alignment_on_load(report_content, session_id):
        """æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶ï¼Œè‡ªåŠ¨ç”Ÿæˆåç§»å¯¹é½æŸ±çŠ¶å›¾ä¸è¡¨æ ¼"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
            active_algorithms = backend.get_active_algorithms()
            if not active_algorithms:
                logger.warning("[WARNING] æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆåç§»å¯¹é½åˆ†æ")
                empty = backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
                return [dcc.Graph(figure=empty)], []
            
            result = backend.generate_offset_alignment_plot()
            table_data = backend.get_offset_alignment_data()
            
            children = []
            if isinstance(result, list):
                # å¤šå›¾æ¨¡å¼ï¼šè¿”å›å¤šä¸ªç‹¬ç«‹çš„å›¾è¡¨
                for item in result:
                    fig = item.get('figure')
                    
                    # åˆ›å»ºå•ä¸ªå›¾è¡¨çš„å®¹å™¨
                    children.append(html.Div([
                        dcc.Graph(
                            figure=fig,
                            style={'height': '500px'},
                            config={'displayModeBar': True}
                        )
                    ], className="mb-4", style={'border': '1px solid #eee', 'padding': '10px', 'borderRadius': '5px', 'backgroundColor': 'white', 'boxShadow': '0 1px 3px rgba(0,0,0,0.1)'}))
            else:
                # å•å›¾æ¨¡å¼ (Legacy)ï¼šè¿”å›å•ä¸ªå›¾è¡¨
                children.append(dcc.Graph(
                    figure=result,
                    style={'height': '800px'}
                ))
            
            logger.info("[OK] åç§»å¯¹é½åˆ†æï¼ˆè‡ªåŠ¨ï¼‰ç”ŸæˆæˆåŠŸ")
            return children, table_data
            
        except Exception as e:
            logger.error(f"[ERROR] è‡ªåŠ¨ç”Ÿæˆåç§»å¯¹é½åˆ†æå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            empty = backend.plot_generator._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
            return [dcc.Graph(figure=empty)], no_update

    # æ›´æ–°æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾çš„æ›²å­é€‰æ‹©å™¨é€‰é¡¹
    @app.callback(
        [Output({'type': 'key-delay-scatter-algorithm-selector', 'index': ALL}, 'options'),
         Output({'type': 'key-delay-scatter-algorithm-selector', 'index': ALL}, 'value')],
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def update_key_delay_scatter_algorithm_selector(report_content, session_id):
        backend = session_manager.get_backend(session_id)
        if not backend or not hasattr(backend, 'multi_algorithm_manager'):
            return [], []
            
        try:
            active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
            if not active_algorithms:
                return [], []
            
            options = []
            values = []
            for alg in active_algorithms:
                unique_name = alg.metadata.algorithm_name  # unique_algorithm_name
                display_name = alg.metadata.display_name    # ç”¨æˆ·è¾“å…¥çš„ç®—æ³•å
                filename = alg.metadata.filename            # åŸå§‹æ–‡ä»¶å

                # åˆ›å»ºæ›´å…·æè¿°æ€§çš„æ ‡ç­¾ï¼šç®—æ³•å (æ–‡ä»¶å)
                # ä¾‹å¦‚ï¼špid (11-21-éŸ³é˜¶æµ‹è¯•pid.spmid)
                descriptive_label = f"{display_name} ({filename})"
                options.append({'label': descriptive_label, 'value': unique_name})
                values.append(unique_name)
            
            # è¿”å›åˆ—è¡¨ä»¥åŒ¹é… Pattern Matching Output
            return [options], [values]
            
        except Exception as e:
            logger.error(f"[ERROR] æ›´æ–°æ›²å­é€‰æ‹©å™¨å¤±è´¥: {e}")
            return [], []

    # ç»Ÿä¸€çš„æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾å›è°ƒå‡½æ•° - æ ¹æ®è§¦å‘æºå’Œæ¨¡å¼æ™ºèƒ½å“åº”
    @app.callback(
        Output('key-delay-scatter-plot', 'figure'),
        [Input('report-content', 'children'),
         Input({'type': 'key-delay-scatter-common-keys-only', 'index': ALL}, 'value'),
         Input({'type': 'key-delay-scatter-algorithm-selector', 'index': ALL}, 'value')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_key_delay_scatter_plot_unified(report_content, common_keys_filter_values, algorithm_selector_values, session_id):
        """ç»Ÿä¸€çš„æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾å›è°ƒå‡½æ•° - æ ¹æ®è§¦å‘æºå’Œå½“å‰æ¨¡å¼æ™ºèƒ½å“åº”"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update

        # è§£æ Pattern Matching Inputs
        # å¦‚æœç»„ä»¶ä¸å­˜åœ¨ï¼Œåˆ—è¡¨ä¸ºç©ºï¼›å¦‚æœå­˜åœ¨ï¼Œåˆ—è¡¨åŒ…å«ä¸€ä¸ªå€¼
        common_keys_filter = common_keys_filter_values[0] if common_keys_filter_values else False
        algorithm_selector = algorithm_selector_values[0] if algorithm_selector_values else []

        # è·å–å›è°ƒä¸Šä¸‹æ–‡ï¼Œåˆ¤æ–­è§¦å‘æº
        ctx = dash.callback_context
        if not ctx.triggered:
            return no_update

        triggered_id_str = ctx.triggered[0]['prop_id'].split('.')[0]
        
        # è§£æè§¦å‘æºIDç±»å‹
        triggered_type = None
        if '{' in triggered_id_str:
            try:
                # ç®€å•åˆ¤æ–­æ˜¯å¦ä¸ºæˆ‘ä»¬çš„ç­›é€‰ç»„ä»¶
                if 'key-delay-scatter-common-keys-only' in triggered_id_str:
                    triggered_type = 'filter_change'
                elif 'key-delay-scatter-algorithm-selector' in triggered_id_str:
                    triggered_type = 'filter_change'
                else:
                    triggered_type = 'other'
            except:
                triggered_type = 'other'
        else:
            triggered_type = 'report-content' if triggered_id_str == 'report-content' else 'other'

        try:
            # åˆ¤æ–­å½“å‰æ˜¯å•ç®—æ³•æ¨¡å¼è¿˜æ˜¯å¤šç®—æ³•æ¨¡å¼
            is_multi_algorithm_mode = hasattr(backend, 'multi_algorithm_mode') and backend.multi_algorithm_mode
            has_analyzer = bool(backend.analyzer)

            # å•ç®—æ³•æ¨¡å¼ï¼šåªå“åº” report-content å˜åŒ–
            if not is_multi_algorithm_mode and has_analyzer:
                if triggered_type == 'report-content':
                    fig = backend.generate_key_delay_scatter_plot(
                        only_common_keys=False,
                        selected_algorithm_names=[]
                    )
                    logger.info("[OK] å•ç®—æ³•æ¨¡å¼æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸ")
                    return fig
                else:
                    # å•ç®—æ³•æ¨¡å¼ä¸å“åº”ç­›é€‰æ§ä»¶å˜åŒ–
                    return no_update

            # å¤šç®—æ³•æ¨¡å¼ï¼šå“åº”æ‰€æœ‰å˜åŒ–
            elif is_multi_algorithm_mode:
                # å¤„ç†ç­›é€‰æ§ä»¶å€¼
                only_common_keys = bool(common_keys_filter) if common_keys_filter is not None else False
                selected_algorithms = algorithm_selector if algorithm_selector is not None else []

                fig = backend.generate_key_delay_scatter_plot(
                    only_common_keys=only_common_keys,
                    selected_algorithm_names=selected_algorithms
                )

                if triggered_type == 'report-content':
                    logger.info("[OK] å¤šç®—æ³•æ¨¡å¼æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾æ•°æ®åŠ è½½æˆåŠŸ")
                else:
                    logger.info("[OK] å¤šç®—æ³•æ¨¡å¼æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ç­›é€‰æ›´æ–°æˆåŠŸ")
                return fig

            # å…¶ä»–æƒ…å†µï¼šæ— åˆ†æå™¨ï¼Œä¸å“åº”
            else:
                logger.warning("[WARNING] æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æå™¨ï¼Œæ— æ³•ç”ŸæˆæŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾")
                return no_update

        except Exception as e:
            error_msg = f"æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(f"[ERROR] {error_msg}")
            logger.error(traceback.format_exc())

            if backend:
                empty = backend.plot_generator._create_empty_plot(error_msg)
                return empty
            else:
                return no_update

    # æŒ‰é”®ä¸å»¶æ—¶Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾è‡ªåŠ¨ç”Ÿæˆå›è°ƒå‡½æ•° - å½“æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('key-delay-zscore-scatter-plot', 'figure'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_scatter_plot(report_content, session_id):
        """å¤„ç†æŒ‰é”®ä¸å»¶æ—¶Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†ææ•°æ®
            if not backend.analyzer and not (hasattr(backend, 'multi_algorithm_mode') and backend.multi_algorithm_mode):
                logger.warning("[WARNING] æ²¡æœ‰åˆ†æå™¨ï¼Œæ— æ³•ç”ŸæˆZ-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾")
                empty = backend.plot_generator._create_empty_plot("æ²¡æœ‰åˆ†æå™¨")
                return empty
            
            # ç”ŸæˆZ-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾
            zscore_fig = backend.generate_key_delay_zscore_scatter_plot()
            
            # éªŒè¯Z-Scoreå›¾è¡¨æ˜¯å¦æ­£ç¡®ç”Ÿæˆ
            if zscore_fig and hasattr(zscore_fig, 'data') and len(zscore_fig.data) > 0:
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹çš„yå€¼æ˜¯å¦æ˜¯Z-Scoreï¼ˆåº”è¯¥åœ¨-3åˆ°3ä¹‹é—´ï¼Œè€Œä¸æ˜¯åŸå§‹çš„å»¶æ—¶å€¼ï¼‰
                first_trace = zscore_fig.data[0]
                if hasattr(first_trace, 'y') and len(first_trace.y) > 0:
                    first_y = first_trace.y[0] if hasattr(first_trace.y, '__getitem__') else first_trace.y
                    logger.info(f"ğŸ” Z-Scoreå›¾è¡¨éªŒè¯: ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹çš„yå€¼={first_y} (åº”è¯¥æ˜¯Z-Scoreå€¼ï¼Œé€šå¸¸åœ¨-3åˆ°3ä¹‹é—´)")
            
            logger.info("[OK] æŒ‰é”®ä¸å»¶æ—¶Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸ")
            return zscore_fig
            
        except Exception as e:
            logger.error(f"[ERROR] ç”ŸæˆZ-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            empty = backend.plot_generator._create_empty_plot(f"ç”ŸæˆZ-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾å¤±è´¥: {str(e)}")
            return empty


    # é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾è‡ªåŠ¨ç”Ÿæˆå›è°ƒå‡½æ•° - å½“æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('hammer-velocity-delay-scatter-plot', 'figure'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_hammer_velocity_scatter_plot(report_content, session_id):
        """å¤„ç†é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
            active_algorithms = backend.get_active_algorithms()
            if not active_algorithms:
                logger.warning("[WARNING] æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆæ•£ç‚¹å›¾")
                return backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
            # ç”Ÿæˆé”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾
            fig = backend.generate_hammer_velocity_delay_scatter_plot()
            
            logger.info("[OK] é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸ")
            return fig
            
        except Exception as e:
            logger.error(f"[ERROR] ç”Ÿæˆæ•£ç‚¹å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            
            return backend.plot_generator._create_empty_plot(f"ç”Ÿæˆæ•£ç‚¹å›¾å¤±è´¥: {str(e)}")

    # é”¤é€Ÿå¯¹æ¯”å›¾è‡ªåŠ¨ç”Ÿæˆå›è°ƒå‡½æ•° - å½“æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('hammer-velocity-comparison-plot', 'figure'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_hammer_velocity_comparison_plot(report_content: html.Div, session_id: str) -> Figure:
        """
        å¤„ç†é”¤é€Ÿå¯¹æ¯”å›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘

        è¯¥å‡½æ•°ç”Ÿæˆä¸€ä¸ªæ•£ç‚¹å›¾ï¼Œæ˜¾ç¤ºä¸åŒç®—æ³•ï¼ˆæ›²å­ï¼‰ä¸‹å„æŒ‰é”®çš„é”¤é€Ÿå·®å€¼å¯¹æ¯”ã€‚
        æ¨ªè½´ä¸ºæŒ‰é”®IDï¼Œçºµè½´ä¸ºé”¤é€Ÿå·®å€¼ï¼ˆæ’­æ”¾é”¤é€Ÿ - å½•åˆ¶é”¤é€Ÿï¼‰ã€‚
        æ¯ä¸ªæ•°æ®ç‚¹ä»£è¡¨ä¸€ä¸ªå…·ä½“çš„æŒ‰é”®-ç®—æ³•ç»„åˆï¼Œé¢œè‰²åŒºåˆ†ä¸åŒç®—æ³•ã€‚

        Args:
            report_content: æŠ¥å‘Šå†…å®¹ï¼ˆè§¦å‘å™¨ï¼‰
            session_id: ä¼šè¯IDï¼Œç”¨äºè·å–åç«¯å®ä¾‹

        Returns:
            plotlyå›¾è¡¨å¯¹è±¡æˆ–ç©ºå›¾è¡¨ï¼ˆå½“æ— æ•°æ®æˆ–é”™è¯¯æ—¶ï¼‰
        """
        backend = session_manager.get_backend(session_id)
        if not backend:
            return go.Figure()  # è¿”å›ç©ºå›¾è¡¨è€Œä¸æ˜¯ no_update

        try:
            # éªŒè¯ç¯å¢ƒæ¡ä»¶
            if not _validate_velocity_comparison_prerequisites(backend):
                return go.Figure()  # è¿”å›ç©ºå›¾è¡¨

            # æ”¶é›†é”¤é€Ÿæ•°æ®
            velocity_data = _collect_velocity_comparison_data(backend)
            if not velocity_data:
                return go.Figure()  # è¿”å›ç©ºå›¾è¡¨

            # ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
            fig = _create_velocity_comparison_plot(velocity_data)
            return fig.figure if hasattr(fig, 'figure') else fig

        except Exception as e:
            logger.error(f"[ERROR] ç”Ÿæˆé”¤é€Ÿå¯¹æ¯”å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return go.Figure()  # è¿”å›ç©ºå›¾è¡¨

    def _validate_velocity_comparison_prerequisites(backend: PianoAnalysisBackend) -> bool:
        """
        éªŒè¯ç”Ÿæˆé”¤é€Ÿå¯¹æ¯”å›¾çš„å¿…è¦å‰ææ¡ä»¶

        Args:
            backend: åç«¯å®ä¾‹

        Returns:
            bool: æ˜¯å¦æ»¡è¶³ç”Ÿæˆæ¡ä»¶
        """
        if not backend.multi_algorithm_mode or not backend.multi_algorithm_manager:
            logger.warning("[WARNING] æœªå¯ç”¨å¤šç®—æ³•æ¨¡å¼ï¼Œæ— æ³•ç”Ÿæˆé”¤é€Ÿå¯¹æ¯”å›¾")
            return False

        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
        if not active_algorithms:
            logger.warning("[WARNING] æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆé”¤é€Ÿå¯¹æ¯”å›¾")
            return False

        return True

    def _collect_velocity_comparison_data(backend: PianoAnalysisBackend) -> List[VelocityDataItem]:
        """
        ä»æ‰€æœ‰æ¿€æ´»ç®—æ³•ä¸­æ”¶é›†é”¤é€Ÿå¯¹æ¯”æ•°æ®

        éå†æ¯ä¸ªç®—æ³•ï¼Œæå–åŒ¹é…å¯¹ä¸­çš„é”¤é€Ÿä¿¡æ¯ï¼Œè®¡ç®—å·®å€¼ã€‚

        Args:
            backend: åç«¯å®ä¾‹

        Returns:
            List[VelocityDataItem]: é”¤é€Ÿæ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«å®Œæ•´çš„é”¤é€Ÿä¿¡æ¯
        """
        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
        all_velocity_data = []

        logger.info(f"[DEBUG] å¼€å§‹æ”¶é›†é”¤é€Ÿå¯¹æ¯”æ•°æ®ï¼Œæ¿€æ´»ç®—æ³•æ•°é‡: {len(active_algorithms)}")

        for algorithm in active_algorithms:
            if not algorithm.is_ready():
                logger.info(f"[DEBUG] ç®—æ³• {algorithm.metadata.algorithm_name} æœªå°±ç»ªï¼Œè·³è¿‡")
                continue

            logger.info(f"[DEBUG] å¤„ç†ç®—æ³•: {algorithm.metadata.algorithm_name} ({algorithm.metadata.display_name})")

            # ä»å•ä¸ªç®—æ³•æå–æ•°æ®
            algorithm_velocity_data = _extract_single_algorithm_velocity_data(algorithm)
            logger.info(f"[DEBUG] ç®—æ³• {algorithm.metadata.algorithm_name} æå–åˆ° {len(algorithm_velocity_data)} ä¸ªé”¤é€Ÿæ•°æ®ç‚¹")
            all_velocity_data.extend(algorithm_velocity_data)

        logger.info(f"[DEBUG] æ€»å…±æ”¶é›†åˆ° {len(all_velocity_data)} ä¸ªé”¤é€Ÿæ•°æ®ç‚¹")
        return all_velocity_data

    def _extract_single_algorithm_velocity_data(algorithm: AlgorithmInstance) -> List[VelocityDataItem]:
        """
        ä»å•ä¸ªç®—æ³•ä¸­æå–é”¤é€Ÿæ•°æ®

        Args:
            algorithm: ç®—æ³•å®ä¾‹

        Returns:
            List[VelocityDataItem]: è¯¥ç®—æ³•çš„é”¤é€Ÿæ•°æ®åˆ—è¡¨
        """
        velocity_data = []

        # æ£€æŸ¥ç®—æ³•æ˜¯å¦æœ‰å¿…è¦çš„åˆ†æå™¨
        if not (algorithm.analyzer and algorithm.analyzer.note_matcher):
            logger.warning(f"[WARNING] ç®—æ³• {algorithm.metadata.algorithm_name} ç¼ºå°‘å¿…è¦çš„åˆ†æå™¨æˆ–éŸ³ç¬¦åŒ¹é…å™¨")
            return velocity_data

        # è·å–åŒ¹é…å¯¹å’Œåç§»æ•°æ®
        matched_pairs = algorithm.analyzer.note_matcher.get_matched_pairs()
        offset_data = algorithm.analyzer.note_matcher.get_offset_alignment_data()

        logger.info(f"[DEBUG] ç®—æ³• {algorithm.metadata.algorithm_name}: åŒ¹é…å¯¹æ•°é‡={len(matched_pairs) if matched_pairs else 0}, åç§»æ•°æ®æ•°é‡={len(offset_data) if offset_data else 0}")

        if not (matched_pairs and offset_data):
            logger.warning(f"[WARNING] ç®—æ³• {algorithm.metadata.algorithm_name} ç¼ºå°‘åŒ¹é…å¯¹æˆ–åç§»æ•°æ®")
            return velocity_data

        # åˆ›å»ºåç§»æ•°æ®çš„å¿«é€ŸæŸ¥æ‰¾æ˜ å°„
        offset_map = _create_velocity_offset_map(offset_data)

        # éå†åŒ¹é…å¯¹ï¼Œæå–é”¤é€Ÿæ•°æ®
        valid_count = 0
        for record_idx, replay_idx, record_note, replay_note in matched_pairs:
            velocity_item = _extract_velocity_data_from_pair(
                record_idx, replay_idx, record_note, replay_note,
                offset_map, algorithm
            )
            if velocity_item:
                velocity_data.append(velocity_item)
                valid_count += 1

        logger.info(f"[DEBUG] ç®—æ³• {algorithm.metadata.algorithm_name}: ä» {len(matched_pairs)} ä¸ªåŒ¹é…å¯¹ä¸­æå–åˆ° {valid_count} ä¸ªæœ‰æ•ˆé”¤é€Ÿæ•°æ®ç‚¹")
        return velocity_data

    def _create_velocity_offset_map(offset_data: List[OffsetAlignmentDataItem]) -> Dict[Tuple[int, int], OffsetAlignmentDataItem]:
        """
        åˆ›å»ºåç§»æ•°æ®çš„å¿«é€ŸæŸ¥æ‰¾æ˜ å°„

        Args:
            offset_data: åç§»æ•°æ®åˆ—è¡¨

        Returns:
            Dict[Tuple[int, int], OffsetAlignmentDataItem]: (record_idx, replay_idx) -> offset_item çš„æ˜ å°„
        """
        offset_map = {}
        for item in offset_data:
            record_idx = item.get('record_index')
            replay_idx = item.get('replay_index')
            if record_idx is not None and replay_idx is not None:
                offset_map[(record_idx, replay_idx)] = item
        return offset_map

    def _extract_velocity_data_from_pair(record_idx: int, replay_idx: int, record_note: SPMIDNote, replay_note: SPMIDNote, offset_map: Dict[Tuple[int, int], OffsetAlignmentDataItem], algorithm: AlgorithmInstance) -> Optional[VelocityDataItem]:
        """
        ä»å•ä¸ªåŒ¹é…å¯¹ä¸­æå–é”¤é€Ÿæ•°æ®

        Args:
            record_idx: å½•åˆ¶ç´¢å¼•
            replay_idx: æ’­æ”¾ç´¢å¼•
            record_note: å½•åˆ¶éŸ³ç¬¦
            replay_note: æ’­æ”¾éŸ³ç¬¦
            offset_map: åç§»æ•°æ®æ˜ å°„
            algorithm: ç®—æ³•å®ä¾‹

        Returns:
            Optional[VelocityDataItem]: é”¤é€Ÿæ•°æ®é¡¹ï¼ŒåŒ…å«å·®å€¼è®¡ç®—ï¼Œå¦‚æœæå–å¤±è´¥åˆ™è¿”å›None
        """
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¯¹åº”çš„åç§»æ•°æ®
        if (record_idx, replay_idx) not in offset_map:
            return None

        # æå–é”¤é€Ÿå€¼
        record_velocity = _get_velocity_from_note(record_note, 'record')
        replay_velocity = _get_velocity_from_note(replay_note, 'replay')


        # è®¡ç®—å½•åˆ¶ç¬¬ä¸€ä¸ªé”¤å­æ—¶é—´
        record_hammer_time_ms = 0.0
        try:
            if hasattr(record_note, 'hammers') and record_note.hammers is not None and not record_note.hammers.empty:
                record_hammer_time_ms = (record_note.hammers.index[0] + record_note.offset) / 10.0
        except Exception:
            record_hammer_time_ms = getattr(record_note, 'offset', 0) / 10.0

        # è®¡ç®—æ’­æ”¾ç¬¬ä¸€ä¸ªé”¤å­æ—¶é—´
        replay_hammer_time_ms = 0.0
        try:
            if hasattr(replay_note, 'hammers') and replay_note.hammers is not None and not replay_note.hammers.empty:
                replay_hammer_time_ms = (replay_note.hammers.index[0] + replay_note.offset) / 10.0
        except Exception:
            replay_hammer_time_ms = getattr(replay_note, 'offset', 0) / 10.0

        # åªæœ‰å½“ä¸¤ä¸ªé”¤é€Ÿéƒ½æœ‰æ•ˆæ—¶æ‰è¿”å›æ•°æ®
        if record_velocity is not None and replay_velocity is not None:

            filename_display = algorithm.metadata.filename
            # å°è¯•ä»display_nameä¸­æå–æ›´å‹å¥½çš„æ–‡ä»¶åï¼ˆå¦‚æœdisplay_nameåŒ…å«æ–‡ä»¶åï¼‰
            # è¿™é‡Œç®€å•å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨display_nameä½œä¸ºä¸»è¦æ ‡è¯†ï¼Œfilenameä½œä¸ºè¾…åŠ©
            
            return {
                'algorithm_name': algorithm.metadata.algorithm_name,
                'display_name': algorithm.metadata.display_name,
                'filename': algorithm.metadata.filename,
                'key_id': record_note.id,
                'record_index': record_idx,  # æ·»åŠ å½•åˆ¶éŸ³ç¬¦ç´¢å¼•
                'replay_index': replay_idx,  # æ·»åŠ æ’­æ”¾éŸ³ç¬¦ç´¢å¼•
                'record_velocity': record_velocity,
                'replay_velocity': replay_velocity,
                'velocity_diff': replay_velocity - record_velocity,
                'record_hammer_time_ms': record_hammer_time_ms,
                'replay_hammer_time_ms': replay_hammer_time_ms
            }

        return None

    def _get_velocity_from_note(note: SPMIDNote, note_type: str) -> Optional[float]:
        """
        ä»éŸ³ç¬¦ä¸­å®‰å…¨åœ°æå–é”¤é€Ÿå€¼

        Args:
            note: éŸ³ç¬¦å¯¹è±¡
            note_type: éŸ³ç¬¦ç±»å‹æè¿°ï¼ˆç”¨äºæ—¥å¿—ï¼‰

        Returns:
            Optional[float]: é”¤é€Ÿå€¼ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
        """
        try:
            if not hasattr(note, 'hammers'):
                logger.debug(f"æå–{note_type}é”¤é€Ÿå¤±è´¥: éŸ³ç¬¦æ²¡æœ‰hammerså±æ€§")
                return None

            hammers = getattr(note, 'hammers', None)
            if hammers is None:
                logger.debug(f"æå–{note_type}é”¤é€Ÿå¤±è´¥: hammerså±æ€§ä¸ºNone")
                return None

            # å¯¹äºpandas Seriesï¼Œä½¿ç”¨emptyå±æ€§æ£€æŸ¥æ˜¯å¦ä¸ºç©º
            if hasattr(hammers, 'empty'):
                if hammers.empty:
                    logger.debug(f"æå–{note_type}é”¤é€Ÿå¤±è´¥: hammers Seriesä¸ºç©º")
                    return None
                try:
                    first_value = hammers.values[0] if hasattr(hammers, 'values') else hammers[0]
                    # æ£€æŸ¥å€¼æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯NaNæˆ–Noneï¼‰
                    if pd.isna(first_value) or first_value is None:
                        logger.debug(f"æå–{note_type}é”¤é€Ÿå¤±è´¥: ç¬¬ä¸€ä¸ªé”¤é€Ÿå€¼ä¸ºæ— æ•ˆå€¼ {first_value}")
                        return None
                    return first_value
                except (IndexError, KeyError, TypeError) as e:
                    logger.debug(f"æå–{note_type}é”¤é€Ÿå¤±è´¥: è®¿é—®ç¬¬ä¸€ä¸ªå€¼æ—¶å‡ºé”™ {e}")
                    return None
            # å¯¹äºå…¶ä»–åºåˆ—ç±»å‹ï¼Œä½¿ç”¨len()æ£€æŸ¥
            elif hasattr(hammers, '__len__'):
                if len(hammers) == 0:
                    logger.debug(f"æå–{note_type}é”¤é€Ÿå¤±è´¥: hammersåºåˆ—ä¸ºç©º")
                    return None
                try:
                    first_value = hammers.values[0] if hasattr(hammers, 'values') else hammers[0]
                    # æ£€æŸ¥å€¼æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯NaNæˆ–Noneï¼‰
                    if pd.isna(first_value) or first_value is None:
                        logger.debug(f"æå–{note_type}é”¤é€Ÿå¤±è´¥: ç¬¬ä¸€ä¸ªé”¤é€Ÿå€¼ä¸ºæ— æ•ˆå€¼ {first_value}")
                        return None
                    return first_value
                except (IndexError, KeyError, TypeError) as e:
                    logger.debug(f"æå–{note_type}é”¤é€Ÿå¤±è´¥: è®¿é—®ç¬¬ä¸€ä¸ªå€¼æ—¶å‡ºé”™ {e}")
                    return None
            else:
                logger.debug(f"æå–{note_type}é”¤é€Ÿå¤±è´¥: hammersä¸æ˜¯å¯è¿­ä»£å¯¹è±¡")
                return None

        except (AttributeError, IndexError, KeyError, TypeError) as e:
            logger.debug(f"æå–{note_type}é”¤é€Ÿå¤±è´¥: {e}")
        return None

    def _create_velocity_comparison_plot(velocity_data: List[VelocityDataItem]) -> Figure:
        """
        åˆ›å»ºé”¤é€Ÿå¯¹æ¯”æ•£ç‚¹å›¾

        Args:
            velocity_data: é”¤é€Ÿæ•°æ®åˆ—è¡¨

        Returns:
            Figure: é…ç½®å®Œæ•´çš„å›¾è¡¨å¯¹è±¡
        """
        logger.info(f"[DEBUG] å¼€å§‹åˆ›å»ºé”¤é€Ÿå¯¹æ¯”å›¾ï¼Œè¾“å…¥æ•°æ®ç‚¹æ•°é‡: {len(velocity_data)}")

        if not velocity_data:
            logger.warning("[WARNING] æ²¡æœ‰é”¤é€Ÿæ•°æ®ï¼Œåˆ›å»ºç©ºå›¾è¡¨")
            return go.Figure()

        velocity_fig = go.Figure()

        # å®šä¹‰é¢œè‰²æ–¹æ¡ˆ
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f']

        # ä¸ºæ¯ä¸ªç®—æ³•+æ–‡ä»¶ç»„åˆåˆ†é…é¢œè‰²å¹¶æ·»åŠ æ•£ç‚¹
        # åˆ›å»ºç®—æ³•+æ–‡ä»¶çš„å”¯ä¸€æ ‡è¯†ç¬¦
        # ä½¿ç”¨ filename æ¥åŒºåˆ†åŒç§ç®—æ³•çš„ä¸åŒæ–‡ä»¶
        unique_algorithm_files = list(set(f"{item['display_name']} - {item['filename']}" for item in velocity_data))

        logger.info(f"[DEBUG] å‘ç° {len(unique_algorithm_files)} ä¸ªä¸åŒçš„ç®—æ³•+æ–‡ä»¶ç»„åˆ: {unique_algorithm_files}")

        for i, algorithm_file in enumerate(unique_algorithm_files):
            color = colors[i % len(colors)]
            # æ ¹æ® display_name å’Œ filename ç»„åˆæ¥ç­›é€‰æ•°æ®
            algorithm_file_data = [item for item in velocity_data if f"{item['display_name']} - {item['filename']}" == algorithm_file]

            logger.info(f"[DEBUG] ç®—æ³•æ–‡ä»¶ '{algorithm_file}' æœ‰ {len(algorithm_file_data)} ä¸ªæ•°æ®ç‚¹")

            if algorithm_file_data:
                # å‡†å¤‡å›¾è¡¨æ•°æ®
                plot_data = _prepare_velocity_plot_data(algorithm_file_data)

                logger.info(f"[DEBUG] æ·»åŠ trace: {algorithm_file}, æ•°æ®ç‚¹æ•°é‡: {len(plot_data['x_values'])}")

                # ä»algorithm_fileä¸­æå–display_nameä½œä¸ºå›¾æ³¨åç§°
                display_name = algorithm_file.split(' - ')[0] if ' - ' in algorithm_file else algorithm_file

                # æ·»åŠ æ•£ç‚¹ç³»åˆ—
                trace = go.Scatter(
                    x=plot_data['x_values'],
                    y=plot_data['y_values'],
                    mode='markers',
                    name=display_name,
                    marker=dict(
                        color=color,
                        size=8,
                        opacity=0.8,
                        line=dict(width=1, color='white')
                    ),
                    text=plot_data['hover_texts'],
                    customdata=plot_data['custom_data'],  # æ·»åŠ è‡ªå®šä¹‰æ•°æ®ç”¨äºç‚¹å‡»å›è°ƒ
                    hovertemplate='%{text}<extra></extra>',
                    showlegend=True  # ç¡®ä¿æ˜¾ç¤ºåœ¨å›¾æ³¨ä¸­
                )
                velocity_fig.add_trace(trace)
                logger.info(f"[DEBUG] å·²æ·»åŠ trace '{display_name}' åˆ°å›¾è¡¨ï¼ŒåŒ…å« {len(plot_data['x_values'])} ä¸ªæ•°æ®ç‚¹")

        # æ·»åŠ å‚è€ƒçº¿ï¼ˆé›¶å·®å€¼çº¿ï¼‰
        velocity_fig.add_hline(
            y=0,
            line_dash="dash",
            line_color="red",
            opacity=0.7
        )

        # é…ç½®å›¾è¡¨å¸ƒå±€
        velocity_fig.update_layout(
            xaxis_title='æŒ‰é”®ID',
            yaxis_title='é”¤é€Ÿå·®å€¼ (æ’­æ”¾é”¤é€Ÿ - å½•åˆ¶é”¤é€Ÿ)',
            height=500,
            template='plotly_white',
            hovermode='closest',
            showlegend=True,
            legend=dict(
                orientation="h",
                yanchor="top",
                y=1.2,
                xanchor="left",
                x=0.0,
                bgcolor='rgba(255, 255, 255, 0.9)',
                bordercolor='rgba(0, 0, 0, 0.3)',
                borderwidth=1
            ),
            margin=dict(t=100, b=40, l=40, r=40)  # ä¸ºå›¾æ³¨ç•™å‡ºæ›´å¤šä¸Šæ–¹ç©ºé—´
        )

        logger.info("[OK] é”¤é€Ÿå¯¹æ¯”æ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸ")

        return velocity_fig


    def _prepare_velocity_plot_data(algorithm_data: List[VelocityDataItem]) -> Dict[str, Union[List[str], List[float], List[str]]]:
        """
        å‡†å¤‡å•ä¸ªç®—æ³•çš„å›¾è¡¨æ•°æ®æ˜¾ç¤º

        Args:
            algorithm_data: è¯¥ç®—æ³•çš„é”¤é€Ÿæ•°æ®åˆ—è¡¨

        Returns:
            Dict[str, List[Any]]: åŒ…å«x_values, y_values, hover_textsçš„å›¾è¡¨æ•°æ®å­—å…¸
        """
        # æŒ‰key_idå‡åºæ’åº
        sorted_data = sorted(algorithm_data, key=lambda x: x['key_id'])

        x_values = [str(item['key_id']) for item in sorted_data]
        y_values = [item['velocity_diff'] for item in sorted_data]

        # æ„å»ºè¯¦ç»†çš„æ‚¬åœä¿¡æ¯
        hover_texts = []
        custom_data = []
        for item in sorted_data:
            hover_text = (
                f'æŒ‰é”®: {item["key_id"]}<br>'
                f'ç®—æ³•: {item["display_name"]}<br>'
                f'é”¤é€Ÿå·®å€¼: {item["velocity_diff"]:.1f}<br>'
                f'å½•åˆ¶é”¤é€Ÿ: {item["record_velocity"]}<br>'
                f'æ’­æ”¾é”¤é€Ÿ: {item["replay_velocity"]:.1f}<br>'
                f'å½•åˆ¶é”¤å­æ—¶é—´: {item["record_hammer_time_ms"]:.2f} ms<br>'
                f'æ’­æ”¾é”¤å­æ—¶é—´: {item["replay_hammer_time_ms"]:.2f} ms'
            )
            hover_texts.append(hover_text)
            # customdata åŒ…å« [æŒ‰é”®ID, ç®—æ³•åç§°, å½•åˆ¶ç´¢å¼•, æ’­æ”¾ç´¢å¼•] ç”¨äºç‚¹å‡»å›è°ƒ
            custom_data.append([item["key_id"], item["algorithm_name"], item["record_index"], item["replay_index"]])

        return {
            'x_values': x_values,
            'y_values': y_values,
            'hover_texts': hover_texts,
            'custom_data': custom_data
        }
    
    
    def _extract_algorithm_from_customdata(customdata):
        """ä»customdataä¸­æå–ç®—æ³•åç§°"""
        if not customdata or not isinstance(customdata, list) or len(customdata) == 0:
            return None

        try:
            first_point_data = customdata[0]
            if isinstance(first_point_data, list) and len(first_point_data) >= 2:
                return first_point_data[1]
        except (IndexError, TypeError) as e:
            logger.debug(f"[WARNING] æå–ç®—æ³•åç§°æ—¶å‡ºé”™: {e}")
            pass
        return None

    def _check_algorithm_name_match(trace_algorithm_name, target_algorithm_name):
        """æ£€æŸ¥ç®—æ³•åç§°æ˜¯å¦åŒ¹é…ï¼ˆåŒ…æ‹¬æ‹¬å·å¤„ç†ï¼‰"""
        if not trace_algorithm_name or not target_algorithm_name:
            return False

        # ç²¾ç¡®åŒ¹é…
        if trace_algorithm_name == target_algorithm_name:
            return True

        # å¦‚æœç›®æ ‡ç®—æ³•åç§°åŒ…å«æ‹¬å·ï¼Œå°è¯•åŒ¹é…åŸºç¡€åç§°
        # ä¾‹å¦‚ï¼šç®—æ³•A (æ–‡ä»¶å) åº”è¯¥åŒ¹é… ç®—æ³•A
        if '(' in target_algorithm_name:
            base_name = target_algorithm_name.split('(')[0].strip()
            if trace_algorithm_name == base_name:
                return True

        # å¦‚æœtraceç®—æ³•åç§°åŒ…å«æ‹¬å·ï¼Œå°è¯•åŒ¹é…åŸºç¡€åç§°
        if '(' in trace_algorithm_name:
            base_name = trace_algorithm_name.split('(')[0].strip()
            if base_name == target_algorithm_name:
                return True

        return False

    def _check_algorithm_from_legendgroup(legendgroup, algorithm_name):
        """ä»legendgroupæ£€æŸ¥ç®—æ³•åŒ¹é…"""
        if not legendgroup:
            return False

        # ç²¾ç¡®åŒ¹é…
        if legendgroup.startswith(f'data_{algorithm_name}_'):
            return True

        # å¦‚æœç®—æ³•åç§°åŒ…å«æ‹¬å·ï¼Œå°è¯•åŒ¹é…åŸºç¡€åç§°
        if '(' in algorithm_name:
            base_name = algorithm_name.split('(')[0].strip()
            if legendgroup.startswith(f'data_{base_name}_'):
                return True

        return False

    def _check_dict_trace_algorithm(trace, algorithm_name):
        """æ£€æŸ¥dictç±»å‹traceæ˜¯å¦å±äºæŒ‡å®šç®—æ³•"""
        # é¦–å…ˆå°è¯•ä»customdataè·å–
        customdata = trace.get('customdata')
        trace_algorithm_name = _extract_algorithm_from_customdata(customdata)
        if trace_algorithm_name and _check_algorithm_name_match(trace_algorithm_name, algorithm_name):
            return True

        # ç„¶åå°è¯•ä»legendgroupè·å–
        legendgroup = trace.get('legendgroup')
        return _check_algorithm_from_legendgroup(legendgroup, algorithm_name)

    def _check_plotly_trace_algorithm(trace, algorithm_name):
        """æ£€æŸ¥Plotly traceå¯¹è±¡æ˜¯å¦å±äºæŒ‡å®šç®—æ³•"""
        # é¦–å…ˆå°è¯•ä»customdataè·å–
        if hasattr(trace, 'customdata') and trace.customdata:
            trace_algorithm_name = _extract_algorithm_from_customdata(trace.customdata)
            if trace_algorithm_name and _check_algorithm_name_match(trace_algorithm_name, algorithm_name):
                return True

        # ç„¶åå°è¯•ä»legendgroupè·å–
        if hasattr(trace, 'legendgroup') and trace.legendgroup:
            return _check_algorithm_from_legendgroup(trace.legendgroup, algorithm_name)

        return False

    def trace_belongs_to_algorithm(trace, algorithm_name):
        """æ£€æŸ¥traceæ˜¯å¦å±äºæŒ‡å®šçš„ç®—æ³•"""
        if not algorithm_name:
            return False

        # æ ¹æ®traceç±»å‹é€‰æ‹©ä¸åŒçš„æ£€æŸ¥æ–¹æ³•
        if isinstance(trace, dict):
            return _check_dict_trace_algorithm(trace, algorithm_name)
        else:
            return _check_plotly_trace_algorithm(trace, algorithm_name)

    def _prepare_key_force_interaction_figure(trigger_id: str, backend, current_figure):
        """å‡†å¤‡æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾è¡¨å¯¹è±¡"""
        # å¦‚æœæ˜¯report-contentå˜åŒ–ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆå›¾è¡¨
        if trigger_id == 'report-content':
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
            active_algorithms = backend.get_active_algorithms()
            if not active_algorithms:
                logger.warning("[WARNING] æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆäº¤äº’æ•ˆåº”å›¾")
                return backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")

            # é‡æ–°ç”Ÿæˆå›¾è¡¨
            fig = backend.generate_key_force_interaction_plot()
        else:
            # å¦‚æœæ˜¯é€‰æ‹©å˜åŒ–ï¼Œä½¿ç”¨å½“å‰å›¾è¡¨å¹¶æ›´æ–°å¯è§æ€§
            if current_figure and isinstance(current_figure, dict) and 'data' in current_figure:
                # ä»dictåˆ›å»ºFigureï¼Œç¡®ä¿æ‰€æœ‰å±æ€§éƒ½è¢«æ­£ç¡®åŠ è½½
                fig = go.Figure(current_figure)
                # ç¡®ä¿dataæ˜¯traceå¯¹è±¡åˆ—è¡¨ï¼Œè€Œä¸æ˜¯dictåˆ—è¡¨
                if fig.data and isinstance(fig.data[0], dict):
                    # å¦‚æœdataæ˜¯dictåˆ—è¡¨ï¼Œéœ€è¦è½¬æ¢ä¸ºtraceå¯¹è±¡
                    fig_data = []
                    for trace_dict in fig.data:
                        trace_type = trace_dict.get('type', 'scatter')
                        if trace_type == 'scatter':
                            fig_data.append(go.Scatter(trace_dict))
                        else:
                            fig_data.append(trace_dict)
                    fig.data = fig_data
            else:
                active_algorithms = backend.get_active_algorithms()
                if not active_algorithms:
                    return no_update
                fig = backend.generate_key_force_interaction_plot()

        return fig

    def _update_algorithm_control_traces(data_list: List, selected_algorithms: List[str]):
        """æ›´æ–°ç®—æ³•æ§åˆ¶å›¾æ³¨çš„é€æ˜åº¦å’Œå¤§å°"""
        # logger.info(f"[DRAW] å¼€å§‹æ›´æ–°ç®—æ³•æ§åˆ¶å›¾æ³¨: é€‰ä¸­ç®—æ³•={selected_algorithms}")

        for trace_idx, trace in enumerate(data_list):
            # å¤„ç†dictç±»å‹çš„trace
            if isinstance(trace, dict):
                if trace.get('legendgroup') == 'algorithm_control':
                    if 'name' in trace and trace['name']:
                        algorithm_name = trace['name']
                        if 'marker' not in trace:
                            trace['marker'] = {}

                        # é€‰ä¸­æ—¶ï¼šé¢œè‰²å˜æµ“ï¼ˆå®Œå…¨ä¸é€æ˜ï¼‰å¹¶ä¸”å˜å¤§
                        # æœªé€‰ä¸­æ—¶ï¼šé¢œè‰²å˜æ·¡ï¼ˆåŠé€æ˜ï¼‰å¹¶ä¸”å˜å°
                        if algorithm_name in selected_algorithms:
                            trace['marker']['opacity'] = 1.0  # é€‰ä¸­æ—¶å®Œå…¨ä¸é€æ˜ï¼Œé¢œè‰²æ›´æµ“
                            trace['marker']['size'] = 18  # é€‰ä¸­æ—¶æ˜æ˜¾æ›´å¤§
                        else:
                            trace['marker']['opacity'] = 0.4  # æœªé€‰ä¸­æ—¶åŠé€æ˜ï¼Œé¢œè‰²è¾ƒæ·¡
                            trace['marker']['size'] = 12  # æœªé€‰ä¸­æ—¶æ­£å¸¸å¤§å°

                        data_list[trace_idx] = trace
                        logger.info(f"[UPDATE] æ›´æ–°ç®—æ³•æ§åˆ¶å›¾æ³¨ '{algorithm_name}' é€æ˜åº¦: {trace['marker']['opacity']} (é€‰ä¸­: {algorithm_name in selected_algorithms})")
            else:
                # å¤„ç†Plotly traceå¯¹è±¡
                if hasattr(trace, 'legendgroup') and trace.legendgroup == 'algorithm_control':
                    if hasattr(trace, 'name') and trace.name:
                        algorithm_name = trace.name
                        # ç›´æ¥ä¿®æ”¹marker.opacityå’Œsizeå±æ€§ï¼ˆå¯¹è±¡å¼•ç”¨å·²ä¿®æ”¹ï¼Œä¸éœ€è¦é‡æ–°èµ‹å€¼ï¼‰
                        if hasattr(trace, 'marker') and trace.marker is not None:
                            # é€‰ä¸­æ—¶ï¼šé¢œè‰²å˜æµ“ï¼ˆå®Œå…¨ä¸é€æ˜ï¼‰å¹¶ä¸”å˜å¤§
                            # æœªé€‰ä¸­æ—¶ï¼šé¢œè‰²å˜æ·¡ï¼ˆåŠé€æ˜ï¼‰å¹¶ä¸”å˜å°
                            if algorithm_name in selected_algorithms:
                                trace.marker.opacity = 1.0  # é€‰ä¸­æ—¶å®Œå…¨ä¸é€æ˜ï¼Œé¢œè‰²æ›´æµ“
                                trace.marker.size = 18  # é€‰ä¸­æ—¶æ˜æ˜¾æ›´å¤§
                            else:
                                trace.marker.opacity = 0.4  # æœªé€‰ä¸­æ—¶åŠé€æ˜ï¼Œé¢œè‰²è¾ƒæ·¡
                                trace.marker.size = 12  # æœªé€‰ä¸­æ—¶æ­£å¸¸å¤§å°

    def _update_key_control_traces(data_list: List, selected_keys: List[int]):
        """æ›´æ–°æŒ‰é”®æ§åˆ¶å›¾æ³¨çš„é€æ˜åº¦å’Œå¤§å°"""
        logger.info(f"[DRAW] å¼€å§‹æ›´æ–°æŒ‰é”®æ§åˆ¶å›¾æ³¨: é€‰ä¸­æŒ‰é”®={selected_keys}")

        for trace_idx, trace in enumerate(data_list):
            # å¤„ç†dictç±»å‹çš„trace
            if isinstance(trace, dict):
                if trace.get('legendgroup') == 'key_control':
                    if 'name' in trace and trace['name']:
                        key_name = trace['name']
                        # ä»æŒ‰é”®åç§°ä¸­æå–æŒ‰é”®ID
                        import re
                        key_id_match = re.match(r'æŒ‰é”® (\d+)', key_name)
                        if key_id_match:
                            key_id = int(key_id_match.group(1))

                            if 'marker' not in trace:
                                trace['marker'] = {}

                            # é€‰ä¸­æ—¶ï¼šé¢œè‰²å˜æµ“ï¼ˆå®Œå…¨ä¸é€æ˜ï¼‰å¹¶ä¸”å˜å¤§
                            if key_id in selected_keys:
                                trace['marker']['opacity'] = 1.0  # é€‰ä¸­æ—¶å®Œå…¨ä¸é€æ˜ï¼Œé¢œè‰²è¾ƒæµ“
                                trace['marker']['size'] = 16  # é€‰ä¸­æ—¶å˜å¤§
                            else:
                                trace['marker']['opacity'] = 0.4  # æœªé€‰ä¸­æ—¶åŠé€æ˜ï¼Œé¢œè‰²è¾ƒæ·¡
                                trace['marker']['size'] = 14  # æœªé€‰ä¸­æ—¶æ­£å¸¸å¤§å°
                            data_list[trace_idx] = trace
            else:
                # å¤„ç†traceå¯¹è±¡
                if hasattr(trace, 'legendgroup') and trace.legendgroup == 'key_control':
                    if hasattr(trace, 'name') and trace.name:
                        key_name = trace.name
                        # ä»æŒ‰é”®åç§°ä¸­æå–æŒ‰é”®ID
                        import re
                        key_id_match = re.match(r'æŒ‰é”® (\d+)', key_name)
                        if key_id_match:
                            key_id = int(key_id_match.group(1))

                            # é€‰ä¸­æ—¶ï¼šé¢œè‰²å˜æµ“ï¼ˆå®Œå…¨ä¸é€æ˜ï¼‰å¹¶ä¸”å˜å¤§
                            if key_id in selected_keys:
                                trace.marker.opacity = 1.0  # é€‰ä¸­æ—¶å®Œå…¨ä¸é€æ˜ï¼Œé¢œè‰²è¾ƒæµ“
                                trace.marker.size = 16  # é€‰ä¸­æ—¶å˜å¤§
                            else:
                                trace.marker.opacity = 0.4  # æœªé€‰ä¸­æ—¶åŠé€æ˜ï¼Œé¢œè‰²è¾ƒæ·¡
                                trace.marker.size = 14  # æœªé€‰ä¸­æ—¶æ­£å¸¸å¤§å°

    def trace_belongs_to_algorithm_and_key(trace, selected_algorithms: List[str], selected_keys: List[int]) -> bool:
        """æ£€æŸ¥traceæ˜¯å¦å±äºé€‰ä¸­çš„ç®—æ³•å’ŒæŒ‰é”®ï¼ˆå¤šé€‰æ¨¡å¼ï¼‰"""
        # ä»traceçš„customdataä¸­æå–ç®—æ³•å’ŒæŒ‰é”®ä¿¡æ¯
        customdata = None
        if isinstance(trace, dict):
            customdata = trace.get('customdata')
        else:
            customdata = trace.customdata if hasattr(trace, 'customdata') else None

        if not customdata:
            logger.debug("[TRACE] traceæ²¡æœ‰customdata - éšè—")
            return False

        # è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆå¤„ç†numpyæ•°ç»„ã€tupleç­‰ï¼‰
        try:
            if hasattr(customdata, '__iter__') and not isinstance(customdata, str):
                # ç¡®ä¿customdataæ˜¯åˆ—è¡¨æ ¼å¼
                if not isinstance(customdata, list):
                    customdata = list(customdata)
                
                if len(customdata) == 0:
                    logger.debug("[TRACE] customdataä¸ºç©ºåˆ—è¡¨")
                    return False
                
                # è·å–ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹
                first_point = customdata[0]
                
                # è½¬æ¢first_pointä¸ºåˆ—è¡¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if hasattr(first_point, '__iter__') and not isinstance(first_point, str):
                    if not isinstance(first_point, list):
                        first_point = list(first_point)
                    
                    # customdataæ ¼å¼: [key_id, replay_velocity, relative_delay, absolute_delay, algorithm_name, mean_delay]
                    if len(first_point) >= 5:
                        trace_key_id = int(first_point[0])      # ç´¢å¼•0ï¼šæŒ‰é”®ID
                        trace_algorithm = str(first_point[4]) if first_point[4] else ''  # ç´¢å¼•4ï¼šç®—æ³•åç§°

                        # å¦‚æœæ²¡æœ‰é€‰æ‹©ä»»ä½•ç®—æ³•æˆ–æŒ‰é”®ï¼Œåˆ™æ˜¾ç¤ºæ‰€æœ‰
                        if not selected_algorithms and not selected_keys:
                            return True
                        
                        # ç®—æ³•åŒ¹é…é€»è¾‘
                        if selected_algorithms:
                            # å¦‚æœé€‰æ‹©äº†ç®—æ³•ï¼Œtraceçš„algorithmå¿…é¡»åœ¨é€‰ä¸­åˆ—è¡¨ä¸­
                            # ç©ºå­—ç¬¦ä¸²algorithmè¡¨ç¤ºå•ç®—æ³•æ¨¡å¼ï¼Œä¸åŒ¹é…ä»»ä½•å¤šç®—æ³•é€‰æ‹©
                            algorithm_match = bool(trace_algorithm and trace_algorithm in selected_algorithms)
                        else:
                            # å¦‚æœæ²¡æœ‰é€‰æ‹©ä»»ä½•ç®—æ³•ï¼Œæ‰€æœ‰traceéƒ½åŒ¹é…ï¼ˆæ— è®ºalgorithmæ˜¯å¦ä¸ºç©ºï¼‰
                            algorithm_match = True
                        
                        # æŒ‰é”®åŒ¹é…ï¼šå¦‚æœé€‰æ‹©äº†æŒ‰é”®ï¼Œåˆ™å¿…é¡»åŒ¹é…ï¼›å¦åˆ™ä»»ä½•æŒ‰é”®éƒ½å¯ä»¥
                        key_match = True
                        if selected_keys:
                            key_match = trace_key_id in selected_keys
                        
                        # å¿…é¡»åŒæ—¶æ»¡è¶³ç®—æ³•å’ŒæŒ‰é”®æ¡ä»¶ï¼ˆANDé€»è¾‘ï¼‰
                        result = algorithm_match and key_match
                        
                        # è¯¦ç»†æ—¥å¿—
                        if selected_keys and trace_key_id in selected_keys:
                            logger.info(f"[TRACE] â˜… key={trace_key_id}, alg='{trace_algorithm}', selected_algs={selected_algorithms}, selected_keys={selected_keys}, alg_match={algorithm_match}, key_match={key_match}, result={result}")

                        return result
                    else:
                        logger.debug(f"[TRACE] first_pointé•¿åº¦ä¸è¶³: {len(first_point)}, å†…å®¹: {first_point}")
                else:
                    logger.debug(f"[TRACE] first_pointä¸å¯è¿­ä»£, ç±»å‹: {type(first_point)}, å†…å®¹: {first_point}")
            else:
                logger.debug(f"[TRACE] customdataä¸å¯è¿­ä»£, ç±»å‹: {type(customdata)}")
                
        except Exception as e:
            logger.error(f"[TRACE] å¤„ç†customdataæ—¶å‡ºé”™: {e}, ç±»å‹: {type(customdata)}")
            import traceback
            logger.error(traceback.format_exc())
        
        return False

    def _update_data_trace_visibility(data_list: List, selected_algorithms: List[str], selected_keys: List[int], trace_belongs_to_algorithm_and_key):
        """æ›´æ–°æ•°æ®traceçš„å¯è§æ€§"""
        visible_count = 0
        total_data_traces = 0
        
        
        for trace_idx, trace in enumerate(data_list):
            # è·³è¿‡æ§åˆ¶å›¾æ³¨é¡¹
            legendgroup = trace.get('legendgroup') if isinstance(trace, dict) else (trace.legendgroup if hasattr(trace, 'legendgroup') else None)
            if legendgroup in ['algorithm_control', 'key_control']:
                continue

            total_data_traces += 1
            
            # æ•°æ®traceï¼šå¤šé€‰æ¨¡å¼ï¼Œéœ€è¦åŒæ—¶æ»¡è¶³ç®—æ³•å’ŒæŒ‰é”®æ¡ä»¶
            target_visible = trace_belongs_to_algorithm_and_key(trace, selected_algorithms, selected_keys)
            
            if target_visible:
                visible_count += 1
                pass
            else:
                pass

            # æ›´æ–°å¯è§æ€§
            if isinstance(trace, dict):
                trace['visible'] = target_visible
                data_list[trace_idx] = trace
            else:
                trace.visible = target_visible
        

    # æ›´æ–°æŒ‰é”®é€‰æ‹©ä¸‹æ‹‰èœå•çš„é€‰é¡¹
    @app.callback(
        Output('key-force-interaction-key-selector', 'options'),
        [Input('key-force-interaction-plot', 'figure')],
        prevent_initial_call=True
    )
    def update_key_selector_options(figure):
        """æ ¹æ®å›¾è¡¨æ•°æ®æ›´æ–°æŒ‰é”®é€‰æ‹©å™¨çš„é€‰é¡¹"""
        if not figure or 'data' not in figure:
            return []
        
        # æå–æ‰€æœ‰æŒ‰é”®ID
        key_ids = set()
        for trace in figure['data']:
            legendgroup = trace.get('legendgroup', '')
            # åªä»æ•°æ®traceä¸­æå–æŒ‰é”®IDï¼ˆä¸æ˜¯æ§åˆ¶å›¾æ³¨ï¼‰
            if legendgroup and legendgroup.startswith('data_') and '_key_' in legendgroup:
                try:
                    # legendgroupæ ¼å¼ï¼šdata_ç®—æ³•å_key_æŒ‰é”®ID
                    key_part = legendgroup.split('_key_')[1]
                    key_id = int(key_part)
                    key_ids.add(key_id)
                except:
                    pass
        
        # ç”Ÿæˆä¸‹æ‹‰é€‰é¡¹
        options = [{'label': f'æŒ‰é”® {key_id}', 'value': key_id} for key_id in sorted(key_ids)]
        return options
    
    # å½“ä¸‹æ‹‰èœå•é€‰æ‹©æ”¹å˜æ—¶ï¼Œæ›´æ–°selected_keys
    @app.callback(
        Output('key-force-interaction-selected-keys', 'data'),
        [Input('key-force-interaction-key-selector', 'value')],
        prevent_initial_call=True
    )
    def update_selected_keys_from_dropdown(selected_key):
        """å½“ä¸‹æ‹‰èœå•é€‰æ‹©æ”¹å˜æ—¶ï¼Œæ›´æ–°selected_keys"""
        if selected_key is None:
            return []
        return [selected_key]

    # æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾è‡ªåŠ¨ç”Ÿæˆå’Œæ›´æ–°å›è°ƒå‡½æ•°
    @app.callback(
        Output('key-force-interaction-plot', 'figure'),
        [Input('report-content', 'children'),
         Input('key-force-interaction-selected-algorithms', 'data'),
         Input('key-force-interaction-selected-keys', 'data')],
        [State('session-id', 'data'),
         State('key-force-interaction-plot', 'figure')],
        prevent_initial_call=True
    )
    def handle_generate_key_force_interaction_plot(report_content, selected_algorithms, selected_keys, session_id, current_figure):
        """å¤„ç†æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾è‡ªåŠ¨ç”Ÿæˆå’Œæ›´æ–° - æ ¹æ®é€‰ä¸­çš„ç®—æ³•å’ŒæŒ‰é”®æ›´æ–°å¯è§æ€§"""
        ctx = dash.callback_context
        if not ctx.triggered:
            return no_update

        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]

        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update

        try:
            # æ ¹æ®é€‰ä¸­çš„ç®—æ³•å’ŒæŒ‰é”®æ›´æ–°å¯è§æ€§
            selected_algorithms = selected_algorithms or []
            selected_keys = selected_keys or []

            # å‡†å¤‡å›¾è¡¨å¯¹è±¡
            fig = _prepare_key_force_interaction_figure(trigger_id, backend, current_figure)
            if fig is no_update or isinstance(fig, str):  # å¦‚æœæ˜¯ç©ºå›¾æˆ–é”™è¯¯ï¼Œç›´æ¥è¿”å›
                return fig

            # å°†fig.dataè½¬æ¢ä¸ºå¯ä¿®æ”¹çš„list
            data_list = list(fig.data)

            # æ›´æ–°ç®—æ³•æ§åˆ¶å›¾æ³¨çš„é€æ˜åº¦
            _update_algorithm_control_traces(data_list, selected_algorithms)

            # æ›´æ–°æŒ‰é”®æ§åˆ¶å›¾æ³¨çš„é€æ˜åº¦
            _update_key_control_traces(data_list, selected_keys)

            # æ›´æ–°æ•°æ®traceçš„å¯è§æ€§
            _update_data_trace_visibility(data_list, selected_algorithms, selected_keys, trace_belongs_to_algorithm_and_key)

            # å°†ä¿®æ”¹åçš„traceåˆ—è¡¨èµ‹å€¼å›fig.data
            fig.data = data_list

            logger.info(f"[OK] æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾æ›´æ–°æˆåŠŸ (è§¦å‘å™¨: {trigger_id})")
            return fig

        except Exception as e:
            logger.error(f"[ERROR] ç”Ÿæˆ/æ›´æ–°æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return backend.plot_generator._create_empty_plot(f"ç”Ÿæˆäº¤äº’æ•ˆåº”å›¾å¤±è´¥: {str(e)}")

    def _validate_multi_algorithm_analysis(backend):
        """éªŒè¯å¤šç®—æ³•æ¨¡å¼å¹¶è·å–åˆ†æç»“æœ"""
        # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
        if not backend.multi_algorithm_mode or not backend.multi_algorithm_manager:
            logger.warning("[WARNING] æœªå¯ç”¨å¤šç®—æ³•æ¨¡å¼ï¼Œæ— æ³•ç”Ÿæˆç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾")
            return None, html.Div([
                dbc.Alert("æœªå¯ç”¨å¤šç®—æ³•æ¨¡å¼", color="warning")
            ])

        # è·å–åˆ†æç»“æœ
        analysis_result = backend.get_same_algorithm_relative_delay_analysis()
        if analysis_result.get('status') != 'success':
            return None, html.Div([
                dbc.Alert(analysis_result.get('message', 'åˆ†æå¤±è´¥'), color="danger")
            ])

        algorithm_groups = analysis_result.get('algorithm_groups', {})
        if not algorithm_groups:
            return None, html.Div([
                dbc.Alert("æ²¡æœ‰ç®—æ³•ç»„æ•°æ®", color="warning")
            ])

        return analysis_result, None

    def _collect_songs_data(algorithm_groups):
        """æ”¶é›†æ‰€æœ‰éœ€è¦ç»˜åˆ¶çš„æ›²å­ä¿¡æ¯"""
        all_songs = []
        for display_name, group_data in algorithm_groups.items():
            song_data = group_data.get('song_data', [])
            group_relative_delays = group_data.get('relative_delays', [])

            if not group_relative_delays:
                continue

            # æ·»åŠ æ¯ä¸ªæ›²å­
            for song_info in song_data:
                song_relative_delays = song_info.get('relative_delays', [])
                if song_relative_delays:
                    filename_display = song_info.get('filename_display', song_info.get('filename', 'æœªçŸ¥æ–‡ä»¶'))
                    all_songs.append((display_name, filename_display, song_relative_delays, None, song_info))

            # æ·»åŠ æ±‡æ€»
            all_songs.append((display_name, 'æ±‡æ€»', None, group_relative_delays, None))

        return all_songs

    def _create_overall_velocity_plot(algorithm_groups):
        """ç”Ÿæˆæ•´ä½“é”¤é€Ÿå¯¹æ¯”å›¾"""
        try:
            # æ”¶é›†æ‰€æœ‰ç®—æ³•ç»„çš„é”¤é€Ÿæ•°æ®
            all_velocity_data = _collect_velocity_data(algorithm_groups)

            if not all_velocity_data:
                return None

            # æŒ‰æŒ‰é”®IDå’Œç®—æ³•åˆ†ç»„è®¡ç®—å¹³å‡é”¤é€Ÿå·®å€¼
            key_algorithm_stats = _process_velocity_statistics(all_velocity_data)

            # è®¡ç®—æ¯ä¸ªæŒ‰é”®åœ¨æ¯ä¸ªç®—æ³•+æ›²å­ç»„åˆä¸‹çš„å¹³å‡é”¤é€Ÿå·®å€¼
            all_key_ids = sorted(key_algorithm_stats.keys())
            all_algorithm_filenames = sorted(set(item['algorithm_filename'] for item in all_velocity_data))

            plot_data = _prepare_multi_algorithm_velocity_plot_data(key_algorithm_stats, all_algorithm_filenames, all_key_ids)

            # åˆ›å»ºæ•´ä½“é”¤é€Ÿå¯¹æ¯”å›¾
            return _create_velocity_figure(plot_data)

        except Exception as e:
            logger.warning(f"ç”Ÿæˆæ•´ä½“é”¤é€Ÿå¯¹æ¯”å›¾å¤±è´¥: {e}")
            return None

    def _create_velocity_control_panel(plot_data):
        """åˆ›å»ºé”¤é€Ÿå¯¹æ¯”å›¾çš„æ§åˆ¶é¢æ¿"""
        if not plot_data:
            return html.Div("æ— æ•°æ®")

        # æå–æ‰€æœ‰ç®—æ³•+æ›²å­åç§°
        algorithm_filenames = [data['algorithm_filename'] for data in plot_data]

        # åˆ›å»ºé¢œè‰²æ˜ å°„
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']

        # åˆ›å»ºæ§åˆ¶é€‰é¡¹
        control_options = []
        for i, algorithm_filename in enumerate(algorithm_filenames):
            color = colors[i % len(colors)]
            control_options.append({
                'label': html.Div([
                    html.Span('â—', style={'color': color, 'marginRight': '8px', 'fontSize': '12px'}),
                    html.Span(algorithm_filename, style={'fontSize': '12px'})
                ], style={'display': 'flex', 'alignItems': 'center'}),
                'value': algorithm_filename
            })

        return dbc.Checklist(
            id='velocity-plot-legend-control',
            options=control_options,
            value=algorithm_filenames,  # é»˜è®¤å…¨éƒ¨é€‰ä¸­
            inline=False,
            style={'columnCount': 2, 'columnGap': '20px'}  # ä¸¤åˆ—å¸ƒå±€
        )

    def _collect_velocity_data(algorithm_groups):
        """æ”¶é›†æ‰€æœ‰ç®—æ³•ç»„çš„é”¤é€Ÿæ•°æ®"""
        all_velocity_data = []
        for display_name, group_data in algorithm_groups.items():
            song_data = group_data.get('song_data', [])
            for song_info in song_data:
                hammer_velocity_diffs = song_info.get('hammer_velocity_diffs', [])
                filename_display = song_info.get('filename_display', song_info.get('filename', 'æœªçŸ¥æ–‡ä»¶'))
                if hammer_velocity_diffs:
                    for item in hammer_velocity_diffs:
                        all_velocity_data.append({
                            'algorithm': display_name,
                            'filename': filename_display,
                            'algorithm_filename': f'{display_name} - {filename_display}',
                            'key_id': item['key_id'],
                            'velocity_diff': item['velocity_diff'],
                            'record_velocity': item['record_velocity'],
                            'replay_velocity': item['replay_velocity']
                        })
        return all_velocity_data

    def _process_velocity_statistics(all_velocity_data):
        """æŒ‰æŒ‰é”®IDå’Œç®—æ³•+æ›²å­åˆ†ç»„è®¡ç®—å¹³å‡é”¤é€Ÿå·®å€¼"""
        key_algorithm_stats = defaultdict(lambda: defaultdict(list))

        for item in all_velocity_data:
            key_id = item['key_id']
            algorithm_filename = item['algorithm_filename']
            key_algorithm_stats[key_id][algorithm_filename].append(item['velocity_diff'])

        return key_algorithm_stats

    def _prepare_multi_algorithm_velocity_plot_data(key_algorithm_stats, all_algorithm_filenames, all_key_ids):
        """ä¸ºå¤šä¸ªç®—æ³•+æ›²å­ç»„åˆå‡†å¤‡ç»˜å›¾æ•°æ®"""
        plot_data = []

        for algorithm_filename in all_algorithm_filenames:
            x_keys = []
            y_diffs = []
            hover_texts = []

            for key_id in all_key_ids:
                if algorithm_filename in key_algorithm_stats[key_id]:
                    diffs = key_algorithm_stats[key_id][algorithm_filename]
                    avg_diff = np.mean(diffs)
                    x_keys.append(str(key_id))
                    y_diffs.append(avg_diff)

                    # è®¡ç®—å¹³å‡æ’­æ”¾é”¤é€Ÿ
                    record_vel = 100  # é»˜è®¤å½•åˆ¶é”¤é€Ÿ
                    replay_vel = record_vel + avg_diff
                    hover_texts.append(f'æŒ‰é”® {key_id}<br>{algorithm_filename}<br>é”¤é€Ÿå·®å€¼: {avg_diff:.1f}<br>å½•åˆ¶é”¤é€Ÿ: {record_vel}<br>å¹³å‡æ’­æ”¾é”¤é€Ÿ: {replay_vel:.1f}')
                else:
                    x_keys.append(str(key_id))
                    y_diffs.append(0)  # æ²¡æœ‰æ•°æ®æ—¶æ˜¾ç¤º0
                    hover_texts.append(f'æŒ‰é”® {key_id}<br>{algorithm_filename}<br>æ— æ•°æ®')

            if y_diffs:  # åªæœ‰æœ‰æ•°æ®æ—¶æ‰æ·»åŠ 
                plot_data.append({
                    'algorithm_filename': algorithm_filename,
                    'x': x_keys,
                    'y': y_diffs,
                    'hovertext': hover_texts
                })

        return plot_data

    def _create_velocity_figure(plot_data):
        """åˆ›å»ºæ•´ä½“é”¤é€Ÿå¯¹æ¯”å›¾è¡¨"""
        if not plot_data:
            return None

        velocity_fig = go.Figure()

        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
        for i, data in enumerate(plot_data):
            color = colors[i % len(colors)]
            velocity_fig.add_trace(go.Bar(
                x=data['x'],
                y=data['y'],
                name=data['algorithm_filename'],
                marker=dict(color=color, opacity=0.8),
                hovertext=data['hovertext'],
                hovertemplate='%{hovertext}<extra></extra>'
            ))

        # æ·»åŠ é›¶çº¿
        velocity_fig.add_hline(
            y=0,
            line_dash="dash",
            line_color="red",
            opacity=0.7
        )

        velocity_fig.update_layout(
            title='åŒç§ç®—æ³•ä¸åŒæ›²å­çš„é”¤é€Ÿå¯¹æ¯”',
            xaxis_title='æŒ‰é”®ID',
            yaxis_title='é”¤é€Ÿå·®å€¼ (æ’­æ”¾é”¤é€Ÿ - å½•åˆ¶é”¤é€Ÿ)',
            height=500,
            template='plotly_white',
            barmode='group',  # åˆ†ç»„æŸ±çŠ¶å›¾
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1,
                bgcolor='rgba(255, 255, 255, 0.8)',
                bordercolor='rgba(0, 0, 0, 0.2)',
                borderwidth=1
            ),
            showlegend=True
        )

        # åˆ›å»ºæ§åˆ¶é¢æ¿
        control_panel = _create_velocity_control_panel(plot_data)

        # è¿”å›åŒ…å«å›¾è¡¨å’Œæ§åˆ¶é¢æ¿çš„å®¹å™¨
        return html.Div([
            html.Div([
                html.H6("å›¾æ³¨æ§åˆ¶", className="mb-2", style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                control_panel
            ], className="mb-3", style={'backgroundColor': '#f8f9fa', 'padding': '15px', 'borderRadius': '8px', 'border': '1px solid #dee2e6'}),
            dcc.Graph(
                id='overall-hammer-velocity-comparison-plot',
                figure=velocity_fig,
                config={
                    'displayModeBar': True,
                    'displaylogo': False,
                    'modeBarButtonsToRemove': ['pan2d', 'lasso2d', 'select2d'],
                    'modeBarButtonsToAdd': []
                },
                style={'height': '500px'}
            )
        ])

    def _create_subplot_figure(subplot_idx, display_name, filename_display, delays_array, base_color):
        """ä¸ºå•ä¸ªå­å›¾åˆ›å»ºå›¾è¡¨"""
        

        # ç”Ÿæˆå­å›¾æ ‡é¢˜
        if filename_display == 'æ±‡æ€»':
            subplot_title = f'{display_name} (æ±‡æ€»)'
        else:
            subplot_title = f'{display_name} - {filename_display}'

        # è®¡ç®—ç›´æ–¹å›¾æ•°æ®
        hist, bin_edges = np.histogram(delays_array, bins=50, density=False)
        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2

        # ä¸ºæ¯ä¸ªbinåˆ›å»ºcustomdata
        customdata_list = []
        for i, bin_center in enumerate(bin_centers):
            bin_left = bin_edges[i]
            bin_right = bin_edges[i + 1]
            customdata_list.append([
                subplot_idx,
                display_name,
                filename_display,
                bin_center,
                bin_left,
                bin_right
            ])

        # è®¡ç®—å¯†åº¦æ›²çº¿
        bin_width = bin_edges[1] - bin_edges[0]
        try:
            if len(delays_array) < 2 or np.std(delays_array) == 0:
                raise ValueError("Insufficient data or zero variance")
                
            kde = stats.gaussian_kde(delays_array)
            x_density = np.linspace(delays_array.min(), delays_array.max(), 200)
            # ä¿®æ­£ï¼šä¹˜ä»¥bin_width
            y_density = kde(x_density) * len(delays_array) * bin_width
        except:
            # KDEè®¡ç®—å¤±è´¥ï¼ˆå¦‚æ•°æ®ç‚¹å¤ªå°‘æˆ–å…¨ç›¸åŒï¼‰ï¼Œä¸ç»˜åˆ¶æ›²çº¿
            y_density = []
            x_density = []

        # åˆ›å»ºç‹¬ç«‹çš„å›¾è¡¨
        fig = go.Figure()

        # æ·»åŠ ç›´æ–¹å›¾
        fig.add_trace(
            go.Bar(
                x=bin_centers,
                y=hist,
                name='ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒ',
                marker=dict(
                    color=f'rgba({int(base_color[1:3], 16)}, {int(base_color[3:5], 16)}, {int(base_color[5:7], 16)}, 0.6)',
                    line=dict(color=base_color, width=1.5 if filename_display == 'æ±‡æ€»' else 1)
                ),
                opacity=0.7,
                showlegend=False,
                hovertemplate=f'ç›¸å¯¹å»¶æ—¶: %{{x:.2f}} ms<br>é¢‘æ•°: %{{y}}<extra></extra>',
                customdata=customdata_list
            )
        )

        # æ·»åŠ å¯†åº¦æ›²çº¿
        fig.add_trace(
            go.Scatter(
                x=x_density,
                y=y_density,
                mode='lines',
                name='å¯†åº¦æ›²çº¿',
                line=dict(
                    color=base_color,
                    width=3 if filename_display == 'æ±‡æ€»' else 2,
                    dash='dash' if filename_display == 'æ±‡æ€»' else 'solid'
                ),
                showlegend=False,
                hovertemplate=f'ç›¸å¯¹å»¶æ—¶: %{{x:.2f}} ms<br>å¯†åº¦: %{{y:.2f}}<extra></extra>'
            )
        )

        # è®¡ç®—ç»Ÿè®¡é‡
        mean = np.mean(delays_array)
        std = np.std(delays_array)
        median = np.median(delays_array)

        # æ·»åŠ Â±1Ïƒã€Â±2Ïƒã€Â±3ÏƒåŒºé—´
        for sigma, color in [(1, 'rgba(255, 0, 0, 0.08)'), (2, 'rgba(255, 0, 0, 0.12)'), (3, 'rgba(255, 0, 0, 0.15)')]:
            fig.add_vrect(
                x0=mean - sigma * std,
                x1=mean + sigma * std,
                fillcolor=color,
                layer="below",
                line_width=0
            )

        # æ·»åŠ å‡å€¼çº¿
        fig.add_vline(
            x=mean,
            line_dash="dash",
            line_color="green",
            line_width=1.5
        )

        # æ·»åŠ ä¸­ä½æ•°çº¿
        fig.add_vline(
            x=median,
            line_dash="dot",
            line_color="orange",
            line_width=1.5
        )

        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            title=subplot_title,
            xaxis_title='ç›¸å¯¹å»¶æ—¶ (ms)',
            yaxis_title='é¢‘æ•°',
            height=500,
            template='plotly_white',
            showlegend=False
        )

        return fig

    def _create_subplot_velocity_plot(subplot_title, song_info, subplot_idx):
        """ä¸ºå•ä¸ªå­å›¾åˆ›å»ºé”¤é€Ÿå¯¹æ¯”å›¾"""
        

        if not song_info or 'hammer_velocity_diffs' not in song_info:
            return None

        hammer_velocity_diffs = song_info['hammer_velocity_diffs']
        if not hammer_velocity_diffs:
            return None

        # æŒ‰æŒ‰é”®IDåˆ†ç»„è®¡ç®—å¹³å‡é”¤é€Ÿå·®å€¼
        key_velocity_stats = defaultdict(list)

        for item in hammer_velocity_diffs:
            key_id = item['key_id']
            key_velocity_stats[key_id].append(item['velocity_diff'])

        # è®¡ç®—æ¯ä¸ªæŒ‰é”®çš„å¹³å‡é”¤é€Ÿå·®å€¼
        key_avg_diffs = {}
        for key_id, diffs in key_velocity_stats.items():
            key_avg_diffs[key_id] = np.mean(diffs)

        if not key_avg_diffs:
            return None

        # æ’åºæŒ‰é”®ID
        sorted_keys = sorted(key_avg_diffs.keys())
        x_keys = [str(k) for k in sorted_keys]
        y_diffs = [key_avg_diffs[k] for k in sorted_keys]

        # åˆ›å»ºé”¤é€Ÿå¯¹æ¯”å›¾
        velocity_fig = go.Figure()
        velocity_fig.add_trace(go.Bar(
            x=x_keys,
            y=y_diffs,
            name='é”¤é€Ÿå·®å€¼',
            marker=dict(
                color='#ff9800',
                opacity=0.8,
                line=dict(color='#e65100', width=1)
            ),
            hovertemplate='<b>æŒ‰é”® %{x}</b><br>' +
                         'å¹³å‡é”¤é€Ÿå·®å€¼: %{y:.1f}<br>' +
                         '<b>å½•åˆ¶é”¤é€Ÿ: 100</b><br>' +
                         '<b>å¹³å‡æ’­æ”¾é”¤é€Ÿ: %{customdata:.1f}</b><extra></extra>',
            customdata=[100 + diff for diff in y_diffs]  # æ’­æ”¾é”¤é€Ÿ = å½•åˆ¶é”¤é€Ÿ + å·®å€¼
        ))

        # æ·»åŠ é›¶çº¿
        velocity_fig.add_hline(
            y=0,
            line_dash="dash",
            line_color="red",
            opacity=0.7
        )

        velocity_fig.update_layout(
            title=f'{subplot_title} - é”¤é€Ÿå¯¹æ¯”',
            xaxis_title='æŒ‰é”®ID',
            yaxis_title='é”¤é€Ÿå·®å€¼ (æ’­æ”¾é”¤é€Ÿ - å½•åˆ¶é”¤é€Ÿ)',
            height=400,
            template='plotly_white',
            showlegend=False
        )

        return dcc.Graph(
            id={'type': 'hammer-velocity-comparison-plot', 'index': subplot_idx},
            figure=velocity_fig,
            style={'height': '400px', 'marginTop': '20px'}
        )

    def _create_subplot_container(subplot_idx, fig, velocity_plot, display_name, filename_display):
        """åˆ›å»ºå®Œæ•´çš„å­å›¾å®¹å™¨"""
        # åˆ›å»ºå›¾è¡¨å’Œè¡¨æ ¼å®¹å™¨ï¼ˆä½¿ç”¨å­—å…¸å½¢å¼çš„IDä»¥æ”¯æŒPattern Matching Callbacksï¼‰
        plot_id = {'type': 'relative-delay-distribution-plot', 'index': subplot_idx}
        table_id = {'type': 'relative-delay-distribution-table', 'index': subplot_idx}
        title_id = {'type': 'relative-delay-distribution-title', 'index': subplot_idx}
        info_id = {'type': 'relative-delay-distribution-info', 'index': subplot_idx}
        container_id = {'type': 'relative-delay-distribution-container', 'index': subplot_idx}

        # æ·»åŠ ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾
        plot_elements = [
            dcc.Graph(
                id=plot_id,
                figure=fig,
                style={'height': '500px'}
            )
        ]

        # å¦‚æœæœ‰é”¤é€Ÿå¯¹æ¯”å›¾ï¼Œä¹Ÿæ·»åŠ è¿›å»
        if velocity_plot:
            plot_elements.append(velocity_plot)

        return html.Div([
            *plot_elements,
            html.P("ğŸ’¡ æç¤ºï¼šç‚¹å‡»ç›´æ–¹å›¾ä¸­çš„æŸ±çŠ¶å›¾åŒºåŸŸï¼Œå¯æŸ¥çœ‹è¯¥ç›¸å¯¹å»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹è¯¦æƒ…",
                   className="text-muted",
                   style={'fontSize': '12px', 'marginTop': '10px', 'marginBottom': '10px'}),
            html.Div([
                html.Div(id=title_id,
                        style={'marginTop': '15px', 'marginBottom': '10px',
                               'fontSize': '16px', 'fontWeight': 'bold',
                               'color': '#9c27b0', 'padding': '8px 12px',
                               'backgroundColor': '#f3e5f5', 'borderRadius': '4px',
                               'borderLeft': '4px solid #9c27b0', 'display': 'none'}),
                html.Div(id=info_id,
                        style={'marginBottom': '10px', 'fontSize': '14px', 'fontWeight': 'bold', 'color': '#2c3e50', 'display': 'none'}),
                dash_table.DataTable(
                    id=table_id,
                    columns=[
                        {"name": "ç®—æ³•åç§°", "id": "algorithm_name"},
                        {"name": "æŒ‰é”®ID", "id": "key_id"},
                        {"name": "ç›¸å¯¹å»¶æ—¶(ms)", "id": "relative_delay_ms", "type": "numeric", "format": {"specifier": ".2f"}},
                        {"name": "ç»å¯¹å»¶æ—¶(ms)", "id": "absolute_delay_ms", "type": "numeric", "format": {"specifier": ".2f"}},
                        {"name": "å½•åˆ¶ç´¢å¼•", "id": "record_index"},
                        {"name": "æ’­æ”¾ç´¢å¼•", "id": "replay_index"},
                        {"name": "å½•åˆ¶å¼€å§‹(0.1ms)", "id": "record_keyon"},
                        {"name": "æ’­æ”¾å¼€å§‹(0.1ms)", "id": "replay_keyon"},
                        {"name": "æŒç»­æ—¶é—´å·®(0.1ms)", "id": "duration_offset"},
                    ],
                    data=[],
                    page_action='none',
                    style_cell={
                        'textAlign': 'center',
                        'fontSize': '12px',
                        'fontFamily': 'Arial, sans-serif',
                        'padding': '8px',
                        'overflow': 'hidden',
                        'textOverflow': 'ellipsis',
                    },
                    style_header={
                        'backgroundColor': '#f8f9fa',
                        'fontWeight': 'bold',
                        'border': '1px solid #dee2e6',
                        'position': 'sticky',
                        'top': 0,
                        'zIndex': 1
                    },
                    style_data={
                        'whiteSpace': 'normal',
                        'height': 'auto',
                    },
                    style_table={
                        'overflowX': 'auto',
                        'overflowY': 'auto',
                        'maxHeight': '600px',
                    }
                )
            ], style={'display': 'none'}, id=container_id)
        ], className="mb-4", style={'backgroundColor': '#ffffff', 'padding': '20px', 'borderRadius': '8px', 'boxShadow': '0 2px 8px rgba(0,0,0,0.1)'})

    # é”¤é€Ÿå¯¹æ¯”å›¾æ§åˆ¶é¢æ¿å›è°ƒ
    @app.callback(
        Output('overall-hammer-velocity-comparison-plot', 'figure'),
        [Input('velocity-plot-legend-control', 'value')],
        [State('overall-hammer-velocity-comparison-plot', 'figure')],
        prevent_initial_call=True
    )
    def update_velocity_plot_visibility(selected_algorithms, current_figure):
        """æ ¹æ®æ§åˆ¶é¢æ¿çš„é€‰æ‹©æ›´æ–°é”¤é€Ÿå¯¹æ¯”å›¾çš„å¯è§æ€§"""
        if not current_figure or not current_figure.data:
            return current_figure

        # æ›´æ–°æ¯ä¸ªtraceçš„å¯è§æ€§
        for i, trace in enumerate(current_figure.data):
            algorithm_filename = trace.name
            trace.visible = algorithm_filename in selected_algorithms

        return current_figure


    # åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å›è°ƒ - æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('relative-delay-distribution-container', 'children'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_relative_delay_distribution_plot(report_content, session_id):
        """å¤„ç†åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘ï¼Œä¸ºæ¯ä¸ªå­å›¾åˆ›å»ºç‹¬ç«‹çš„å›¾è¡¨å’Œè¡¨æ ¼åŒºåŸŸ"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update

        try:
            # éªŒè¯å¤šç®—æ³•æ¨¡å¼å’Œè·å–åˆ†æç»“æœ
            analysis_result, error_div = _validate_multi_algorithm_analysis(backend)
            if error_div:
                return error_div

            algorithm_groups = analysis_result.get('algorithm_groups', {})

            # æ”¶é›†æ‰€æœ‰éœ€è¦ç»˜åˆ¶çš„æ›²å­ä¿¡æ¯
            all_songs = _collect_songs_data(algorithm_groups)

            if not all_songs:
                return html.Div([
                    dbc.Alert("æ²¡æœ‰æœ‰æ•ˆçš„ç›¸å¯¹å»¶æ—¶æ•°æ®", color="warning")
                ])

            # ç”Ÿæˆæ•´ä½“é”¤é€Ÿå¯¹æ¯”å›¾
            overall_velocity_plot = _create_overall_velocity_plot(algorithm_groups)

            # ä¸ºæ¯ä¸ªå­å›¾åˆ›å»ºç‹¬ç«‹çš„å›¾è¡¨å’Œè¡¨æ ¼åŒºåŸŸ
            children = []
            algorithm_color_map = {}
            color_idx = 0

            # åœ¨æœ€ä¸Šæ–¹æ·»åŠ æ•´ä½“é”¤é€Ÿå¯¹æ¯”å›¾
            if overall_velocity_plot:
                children.append(
                    html.Div([
                        html.H5("æ•´ä½“é”¤é€Ÿå¯¹æ¯”", className="mb-3",
                               style={'color': '#ff9800', 'fontWeight': 'bold', 'textAlign': 'center'}),
                        overall_velocity_plot
                    ], className="mb-4", style={'backgroundColor': '#ffffff', 'padding': '20px', 'borderRadius': '8px', 'boxShadow': '0 2px 8px rgba(0,0,0,0.1)'})
                )

            # é¢œè‰²æ–¹æ¡ˆ
            colors = [
                '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',
                '#9467bd', '#8c564b', '#e377c2', '#7f7f7f'
            ]

            for subplot_idx, (display_name, filename_display, song_relative_delays, group_relative_delays, song_info) in enumerate(all_songs, 1):
                # ç¡®å®šä½¿ç”¨çš„æ•°æ®
                if filename_display == 'æ±‡æ€»':
                    delays_array = np.array(group_relative_delays)
                else:
                    delays_array = np.array(song_relative_delays)

                if len(delays_array) == 0:
                    continue

                # è·å–æˆ–åˆ†é…é¢œè‰²
                if display_name not in algorithm_color_map:
                    algorithm_color_map[display_name] = colors[color_idx % len(colors)]
                    color_idx += 1
                base_color = algorithm_color_map[display_name]

                # ç”Ÿæˆå­å›¾æ ‡é¢˜
                if filename_display == 'æ±‡æ€»':
                    subplot_title = f'{display_name} (æ±‡æ€»)'
                else:
                    subplot_title = f'{display_name} - {filename_display}'

                # åˆ›å»ºå­å›¾å›¾è¡¨
                fig = _create_subplot_figure(subplot_idx, display_name, filename_display, delays_array, base_color)

                # ç”Ÿæˆé”¤é€Ÿå¯¹æ¯”å›¾ï¼ˆä»…å¯¹éæ±‡æ€»çš„æ›²å­ï¼‰
                velocity_plot = None
                if filename_display != 'æ±‡æ€»':
                    velocity_plot = _create_subplot_velocity_plot(subplot_title, song_info, subplot_idx)

                # åˆ›å»ºå®Œæ•´çš„å­å›¾å®¹å™¨
                subplot_container = _create_subplot_container(subplot_idx, fig, velocity_plot, display_name, filename_display)
                children.append(subplot_container)
            
            logger.info("[OK] åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ç”ŸæˆæˆåŠŸ")
            return children
            
        except Exception as e:
            logger.error(f"[ERROR] ç”Ÿæˆç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return html.Div([
                dbc.Alert(f"ç”Ÿæˆå¤±è´¥: {str(e)}", color="danger")
            ])
    
    # åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæŒ‡å®šç›¸å¯¹å»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹è¯¦æƒ…
    # ä½¿ç”¨Pattern Matching Callbackså¤„ç†åŠ¨æ€ç”Ÿæˆçš„å›¾è¡¨ç‚¹å‡»
    @app.callback(
        [Output({'type': 'relative-delay-distribution-table', 'index': dash.dependencies.MATCH}, 'data'),
         Output({'type': 'relative-delay-distribution-table', 'index': dash.dependencies.MATCH}, 'style_table'),
         Output({'type': 'relative-delay-distribution-info', 'index': dash.dependencies.MATCH}, 'children'),
         Output({'type': 'relative-delay-distribution-container', 'index': dash.dependencies.MATCH}, 'style'),
         Output({'type': 'relative-delay-distribution-title', 'index': dash.dependencies.MATCH}, 'children')],
        [Input({'type': 'relative-delay-distribution-plot', 'index': dash.dependencies.MATCH}, 'clickData')],
        [State('session-id', 'data'),
         State({'type': 'relative-delay-distribution-plot', 'index': dash.dependencies.MATCH}, 'id')],
        prevent_initial_call=True
    )
    def handle_relative_delay_distribution_click(click_data, session_id, plot_id):
        """å¤„ç†åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ç‚¹å‡»äº‹ä»¶ï¼Œæ˜¾ç¤ºè¯¥ç›¸å¯¹å»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹è¯¦æƒ…"""
        return relative_delay_distribution_handler.handle_click(click_data, session_id, plot_id)
    
    def _find_target_algorithm_instance(backend, algorithm_name, record_index, replay_index):
        """[Helper] åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹æŸ¥æ‰¾ç›®æ ‡ç®—æ³•å®ä¾‹"""
        if not backend.multi_algorithm_mode or not backend.multi_algorithm_manager:
            return None
            
        all_algorithms = backend.multi_algorithm_manager.get_all_algorithms()
        target_algorithm = None
        
        # 1. é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…ç®—æ³•åç§°
        candidate_algorithms = [alg for alg in all_algorithms if alg.metadata.algorithm_name == algorithm_name]
        logger.info(f"ğŸ” æ‰¾åˆ° {len(candidate_algorithms)} ä¸ªåŒ¹é…ç®—æ³•åç§°çš„ç®—æ³•å®ä¾‹: {algorithm_name}")
        
        # 2. å¦‚æœæœ‰å¤šä¸ªæˆ–åªæœ‰ä¸€ä¸ªå€™é€‰ç®—æ³•ï¼Œé€šè¿‡åŒ¹é…å¯¹è¿›ä¸€æ­¥éªŒè¯
        if candidate_algorithms:
            for alg in candidate_algorithms:
                if alg.analyzer and hasattr(alg.analyzer, 'matched_pairs'):
                    for r_idx, p_idx, _, _ in alg.analyzer.matched_pairs:
                        if r_idx == record_index and p_idx == replay_index:
                            logger.info(f"[OK] é€šè¿‡åŒ¹é…å¯¹æ‰¾åˆ°æ­£ç¡®çš„ç®—æ³•å®ä¾‹: {alg.metadata.algorithm_name}")
                            return alg
                            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…å¯¹ï¼Œä½†åªæœ‰ä¸€ä¸ªå€™é€‰ï¼Œä¸”æ²¡æœ‰åŒ¹é…å¯¹æ•°æ®ï¼ˆå¯èƒ½æœªåˆå§‹åŒ–ï¼‰ï¼Œåˆ™å‹‰å¼ºä½¿ç”¨
            if len(candidate_algorithms) == 1:
                logger.warning(f"[WARNING] åªæœ‰ä¸€ä¸ªå€™é€‰ç®—æ³•ä½†æœªæ‰¾åˆ°æ˜ç¡®åŒ¹é…å¯¹ï¼Œå°è¯•ä½¿ç”¨: {algorithm_name}")
                return candidate_algorithms[0]

        # 3. å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•å…¨å±€æŸ¥æ‰¾ï¼ˆç”¨äºæ±‡æ€»å›¾ç­‰æƒ…å†µï¼‰
        logger.info(f"[WARNING] ç®—æ³•åç§°åŒ¹é…å¤±è´¥ï¼Œå°è¯•åœ¨æ‰€æœ‰ç®—æ³•ä¸­é€šè¿‡ç´¢å¼•æŸ¥æ‰¾")
        for alg in all_algorithms:
            if alg.analyzer and hasattr(alg.analyzer, 'matched_pairs'):
                for r_idx, p_idx, _, _ in alg.analyzer.matched_pairs:
                    if r_idx == record_index and p_idx == replay_index:
                        logger.info(f"[OK] é€šè¿‡åŒ¹é…å¯¹å…¨å±€æ‰¾åˆ°ç®—æ³•å®ä¾‹: {alg.metadata.algorithm_name}")
                        return alg
                        
        return None

    def _get_notes_and_center_time(target_algorithm, record_index, replay_index, key_id):
        """[Helper] è·å–å½•åˆ¶/æ’­æ”¾éŸ³ç¬¦å¯¹è±¡åŠä¸­å¿ƒæ—¶é—´"""
        record_note = None
        replay_note = None
        center_time_ms = None
        
        if not target_algorithm or not target_algorithm.analyzer:
            return None, None, None

        # 1. å°è¯•ä» matched_pairs è·å–
        matched_pairs = getattr(target_algorithm.analyzer, 'matched_pairs', [])
        found_pair = False
        
        if matched_pairs:
            for r_idx, p_idx, r_note, p_note in matched_pairs:
                if r_idx == record_index and p_idx == replay_index:
                    if key_id is not None and r_note.id != key_id:
                        continue
                        
                    record_note = r_note
                    replay_note = p_note
                    found_pair = True
                    
                    # è®¡ç®—keyonæ—¶é—´
                    r_offset = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
                    p_offset = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
                    center_time_ms = ((r_offset + p_offset) / 2.0) / 10.0
                    break
        
        # 2. å¦‚æœ matched_pairs å¤±è´¥ï¼Œå°è¯•ä» offset_data è·å–ï¼ˆå¤‡ç”¨ï¼‰
        if not found_pair and target_algorithm.analyzer.note_matcher:
            try:
                offset_data = target_algorithm.analyzer.note_matcher.get_offset_alignment_data()
                for item in offset_data or []:
                    if item.get('record_index') == record_index and item.get('replay_index') == replay_index:
                        r_keyon = item.get('record_keyon', 0)
                        p_keyon = item.get('replay_keyon', 0)
                        if r_keyon and p_keyon:
                            center_time_ms = ((r_keyon + p_keyon) / 2.0) / 10.0
                            logger.info(f"[OK] ä»offset_dataè·å–æ—¶é—´ä¿¡æ¯: {center_time_ms:.1f}ms")
                            
                            # å†æ¬¡å°è¯•åœ¨ matched_pairs ä¸­æ‰¾éŸ³ç¬¦å¯¹è±¡ï¼ˆå¯èƒ½ä¹‹å‰key_idè¿‡æ»¤å¤ªä¸¥ï¼Ÿï¼‰
                            for r_idx, p_idx, r_note, p_note in matched_pairs:
                                if r_idx == record_index and p_idx == replay_index:
                                    record_note, replay_note = r_note, p_note
                                    found_pair = True
                                    break
                            break
            except Exception as e:
                logger.warning(f"[WARNING] ä»offset_dataè·å–ä¿¡æ¯å¤±è´¥: {e}")

        return record_note, replay_note, center_time_ms
    
    # åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾è¯¦æƒ…è¡¨æ ¼ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºå½•åˆ¶ä¸æ’­æ”¾å¯¹æ¯”æ›²çº¿
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True)],
        [Input({'type': 'relative-delay-distribution-table', 'index': dash.dependencies.ALL}, 'active_cell'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State({'type': 'relative-delay-distribution-table', 'index': dash.dependencies.ALL}, 'data'),
         State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_relative_delay_distribution_table_click(active_cells, close_modal_clicks, close_btn_clicks, table_data_list, session_id, current_style):
        """å¤„ç†åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾è¯¦æƒ…è¡¨æ ¼ç‚¹å‡»ï¼Œæ˜¾ç¤ºå½•åˆ¶ä¸æ’­æ”¾å¯¹æ¯”æ›²çº¿ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾"""
        # 1. æ£€æµ‹è§¦å‘æºä¸å…³é—­æ“ä½œ
        ctx = callback_context
        if not ctx.triggered:
            return current_style, [], no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            return {'display': 'none'}, [], no_update
            
        # 2. è·å– Backend
        backend = session_manager.get_backend(session_id)
        if not backend:
            return current_style, [], no_update
        
        # 3. è·å–è§¦å‘çš„è¡¨æ ¼è¡Œæ•°æ®
        try:
            triggered_table_idx = next((i for i, cell in enumerate(active_cells) if cell), None)
            if triggered_table_idx is None or triggered_table_idx >= len(table_data_list):
                return current_style, [], no_update

            table_data = table_data_list[triggered_table_idx]
            active_cell = active_cells[triggered_table_idx]

            if not active_cell or not table_data:
                return current_style, [], no_update

            row_data = table_data[active_cell.get('row')]
            record_index = int(row_data.get('record_index'))
            replay_index = int(row_data.get('replay_index'))
            key_id = int(row_data.get('key_id')) if row_data.get('key_id') != 'N/A' else None
            algorithm_name = row_data.get('algorithm_name')
            
            logger.info(f"[STATS] ç‚¹å‡»è¡Œ: rec={record_index}, rep={replay_index}, key={key_id}, alg={algorithm_name}")

            # 4. æŸ¥æ‰¾ç›®æ ‡ç®—æ³•å®ä¾‹
            if backend.multi_algorithm_mode:
                target_algorithm = _find_target_algorithm_instance(backend, algorithm_name, record_index, replay_index)
                if not target_algorithm:
                    logger.warning(f"[WARNING] æœªæ‰¾åˆ°åŒ¹é…ç®—æ³•: {algorithm_name}")
                    return current_style, [], no_update
                final_algorithm_name = target_algorithm.metadata.algorithm_name
            else:
                logger.warning("[WARNING] éå¤šç®—æ³•æ¨¡å¼æˆ–æ— æ•ˆè°ƒç”¨")
                return current_style, [], no_update
            
            # 5. è·å–éŸ³ç¬¦æ•°æ®ä¸æ—¶é—´
            record_note, replay_note, center_time_ms = _get_notes_and_center_time(target_algorithm, record_index, replay_index, key_id)
            
            if not record_note or not replay_note:
                logger.error("[ERROR] æ— æ³•è·å–éŸ³ç¬¦å¯¹è±¡")
                # å¦‚æœæœ‰center_time_msä½†æ²¡éŸ³ç¬¦ï¼Œä¹Ÿå¯ä»¥ç»§ç»­å—ï¼Ÿç›®å‰é€»è¾‘ä¼¼ä¹éœ€è¦éŸ³ç¬¦æ¥ç”»å›¾
                if center_time_ms is None:
                    return current_style, [], no_update

            # 6. ç”Ÿæˆå¯¹æ¯”æ›²çº¿å›¾
            mean_delay = 0.0
            if target_algorithm.analyzer:
                mean_delay = target_algorithm.analyzer.get_mean_error() / 10.0

            import spmid
            detail_figure = spmid.plot_note_comparison_plotly(
                record_note, 
                replay_note, 
                algorithm_name=final_algorithm_name,
                other_algorithm_notes=[],
                mean_delays={final_algorithm_name: mean_delay}
            )
            
            if not detail_figure:
                return current_style, [], no_update
            
            # 7. æ„å»ºè¿”å›æ•°æ®
            source_subplot_idx = triggered_table_idx + 1 # å‡è®¾ç´¢å¼•+1
            point_info = {
                'algorithm_name': final_algorithm_name,
                'record_idx': record_index,
                'replay_idx': replay_index,
                'key_id': key_id,
                'source_plot_id': 'relative-delay-distribution-plot',
                'source_subplot_idx': source_subplot_idx,
                'center_time_ms': center_time_ms
            }
            
            modal_style = {
                'display': 'block',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0', 'top': '0',
                'width': '100%', 'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            
            return modal_style, [dcc.Graph(figure=detail_figure, style={'height': '600px'})], point_info

        except Exception as e:
            logger.error(f"[ERROR] å¤„ç†è¡¨æ ¼ç‚¹å‡»å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
        return current_style, [], no_update

    # å»¶æ—¶æ—¶é—´åºåˆ—å›¾å›è°ƒ - æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('delay-time-series-plot', 'figure'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_delay_time_series(report_content, session_id):
        """å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update

        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
            active_algorithms = backend.get_active_algorithms()
            if not active_algorithms:
                logger.warning("[WARNING] æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆå»¶æ—¶æ—¶é—´åºåˆ—å›¾")
                empty_plot = backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
                return empty_plot

            result = backend.generate_delay_time_series_plot()

            # æ£€æŸ¥è¿”å›çš„æ˜¯å¦æ˜¯å­—å…¸ï¼ˆä¸¤ä¸ªå›¾è¡¨ï¼‰è¿˜æ˜¯å•ä¸ªå›¾è¡¨
            if isinstance(result, dict) and 'raw_delay_plot' in result and 'relative_delay_plot' in result:
                logger.info("[OK] å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç”ŸæˆæˆåŠŸï¼ˆåˆ†ç¦»æ¨¡å¼ï¼‰")
                # åœ¨å½“å‰å¸ƒå±€ä¸­ï¼Œæˆ‘ä»¬åªæœ‰ä¸€ä¸ªå›¾è¡¨ç»„ä»¶ï¼Œåˆå¹¶ä¸¤ä¸ªå›¾è¡¨æˆ–é€‰æ‹©ä¸€ä¸ª
                # è¿™é‡Œé€‰æ‹©ç›¸å¯¹å»¶æ—¶å›¾ä½œä¸ºä¸»è¦æ˜¾ç¤º
                return result['relative_delay_plot']
            else:
                # å•ä¸ªå›¾è¡¨æ¨¡å¼
                logger.info("[OK] å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç”ŸæˆæˆåŠŸï¼ˆå•ä¸ªå›¾è¡¨æ¨¡å¼ï¼‰")
                return result

        except Exception as e:
            logger.error(f"[ERROR] ç”Ÿæˆå»¶æ—¶æ—¶é—´åºåˆ—å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            empty_plot = backend.plot_generator._create_empty_plot(f"ç”Ÿæˆæ—¶é—´åºåˆ—å›¾å¤±è´¥: {str(e)}")
            return empty_plot
    
    # å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»å›è°ƒ - åªå¤„ç†å…³é—­æŒ‰é’®ï¼ˆå•ç®—æ³•æ¨¡å¼ï¼‰
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True)],
        [Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_delay_time_series_click(close_modal_clicks, close_btn_clicks, current_style):
        """å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»ï¼Œæ˜¾ç¤ºéŸ³ç¬¦åˆ†ææ›²çº¿ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾"""
        """å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾æ¨¡æ€æ¡†çš„å…³é—­æŒ‰é’®ï¼ˆå•ç®—æ³•æ¨¡å¼ï¼‰"""
        logger.info("[START] handle_delay_time_series_click å…³é—­æŒ‰é’®å›è°ƒè¢«è§¦å‘")

        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            return current_style, [], no_update

        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"ğŸ” è§¦å‘ID: {trigger_id}")

        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, [], no_update

        return current_style, [], no_update

    # å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»å›è°ƒ - å¤šç®—æ³•æ¨¡å¼ï¼ˆä»…ç›‘å¬ delay-time-series-plotï¼‰
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True),
         Output('delay-time-series-plot', 'clickData', allow_duplicate=True)],
        [Input('delay-time-series-plot', 'clickData'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
#     def handle_delay_time_series_click_multi(delay_click_data, close_modal_clicks, close_btn_clicks, session_id, current_style):
#         """å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»ï¼ˆå¤šç®—æ³•æ¨¡å¼ï¼‰ï¼Œæ˜¾ç¤ºéŸ³ç¬¦åˆ†ææ›²çº¿ï¼ˆæ‚¬æµ®çª—ï¼‰"""
        # æ£€æµ‹è§¦å‘æº
#         ctx = callback_context
#         if not ctx.triggered:
#             return current_style, [], no_update, no_update

#         trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
#         logger.info(f"ğŸ” è§¦å‘ID: {trigger_id}")

        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
#         if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
#             modal_style = {
#                 'display': 'none',
#                 'position': 'fixed',
#                 'zIndex': '9999',
#                 'left': '0',
#                 'top': '0',
#                 'width': '100%',
#                 'height': '100%',
#                 'backgroundColor': 'rgba(0,0,0,0.6)',
#                 'backdropFilter': 'blur(5px)'
#             }
#             return modal_style, [], no_update, no_update

        # åªæœ‰åœ¨ç‚¹å‡»äº† delay-time-series-plot æ—¶æ‰å¤„ç†
#         if trigger_id != 'delay-time-series-plot' or not delay_click_data:
#             return current_style, [], no_update, no_update

#         logger.info(f"[TARGET] æ£€æµ‹åˆ°{trigger_id}ç‚¹å‡»")

#         backend = session_manager.get_backend(session_id)
#         if not backend:
#             logger.warning("[WARNING] backendä¸ºç©º")
#             return current_style, [], no_update, no_update

#         try:
#             if 'points' not in click_data or len(click_data['points']) == 0:
#                 logger.warning("[WARNING] clickDataä¸­æ²¡æœ‰points")
#                 return current_style, [], no_update, no_update

#             point = click_data['points'][0]
#             if not point.get('customdata'):
#                 logger.warning("[WARNING] pointä¸­æ²¡æœ‰customdata")
#                 return current_style, [], no_update, no_update

            # æå–customdata: [key_id, record_index, replay_index] æˆ– [key_id, record_index, replay_index, algorithm_name, ...]
            # å¤šç®—æ³•æ¨¡å¼å¯èƒ½åŒ…å«æ›´å¤šä¿¡æ¯: [key_id, record_index, replay_index, algorithm_name, delay, mean_delay, replay_time, record_time]
#             customdata = point['customdata']
#             logger.info(f"[DATA] customdata: {customdata}")

#             if not isinstance(customdata, list) or len(customdata) < 3:
#                 logger.warning(f"[WARNING] customdataæ ¼å¼é”™è¯¯: {customdata}")
#                 return current_style, [], no_update, no_update
                
#                 key_id = customdata[0]
#                 record_index = customdata[1]
#                 replay_index = customdata[2]
#                 algorithm_name = customdata[3] if len(customdata) > 3 else None
                
#                 logger.info(f"[STATS] æå–çš„æ•°æ®: key_id={key_id}, record_index={record_index}, replay_index={replay_index}, algorithm_name={algorithm_name}")
                
                # è·å–ç®—æ³•å¯¹è±¡å’ŒåŒ¹é…å¯¹
#                 record_note = None
#                 replay_note = None
#                 final_algorithm_name = None
                
                # è®¡ç®—æ—¶é—´ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æ—¶ç›´æ¥ä½¿ç”¨
#                 center_time_ms = None
                
#                 if backend.multi_algorithm_mode and backend.multi_algorithm_manager and algorithm_name:
                    # å¤šç®—æ³•æ¨¡å¼
#                     algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name)
#                     if not algorithm or not algorithm.analyzer:
#                         logger.warning(f"[WARNING] ç®—æ³• '{algorithm_name}' ä¸å­˜åœ¨æˆ–analyzerä¸ºç©º")
#                         return current_style, [], no_update
                    
                    # è·å–matched_pairs
#                     matched_pairs = algorithm.analyzer.matched_pairs if hasattr(algorithm.analyzer, 'matched_pairs') else []
                    
                    # åœ¨matched_pairsä¸­æŸ¥æ‰¾åŒ¹é…å¯¹
#                     for r_idx, p_idx, r_note, p_note in matched_pairs:
#                         if r_idx == record_index and p_idx == replay_index:
#                             record_note = r_note
#                             replay_note = p_note
#                             final_algorithm_name = algorithm_name
#                             logger.info(f"[OK] åœ¨å¤šç®—æ³•æ¨¡å¼ä¸­æ‰¾åˆ°åŒ¹é…å¯¹")
                            
                            # è®¡ç®—keyonæ—¶é—´
#                             try:
#                                 record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
#                                 replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
#                                 center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
#                             except Exception as e:
#                                 logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                                # å¤‡ç”¨æ–¹æ¡ˆï¼šä» customdata è·å–æ—¶é—´ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
#                                 if len(customdata) >= 7:
#                                     record_time = customdata[7] if len(customdata) > 7 else None
#                                     replay_time = customdata[6] if len(customdata) > 6 else None
#                                     if record_time is not None and replay_time is not None:
#                                         center_time_ms = ((record_time + replay_time) / 2.0) / 10.0
                            
#                             break
                    
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šä» offset_data è·å–
#                     if center_time_ms is None and algorithm.analyzer.note_matcher:
#                         try:
#                             offset_data = algorithm.analyzer.note_matcher.get_offset_alignment_data()
#                             if offset_data:
#                                 for item in offset_data:
#                                     if item.get('record_index') == record_index and item.get('replay_index') == replay_index:
#                                         record_keyon = item.get('record_keyon', 0)
#                                         replay_keyon = item.get('replay_keyon', 0)
#                                         if record_keyon and replay_keyon:
#                                             center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
#                                             break
#                         except Exception as e:
#                             logger.warning(f"[WARNING] ä»offset_dataè·å–æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
#                 else:
                    # å•ç®—æ³•æ¨¡å¼
#                     if not backend.analyzer or not backend.analyzer.note_matcher:
#                         logger.warning("[WARNING] analyzeræˆ–note_matcherä¸ºç©º")
#                         return current_style, [], no_update, no_update
                    
#                     matched_pairs = backend.analyzer.matched_pairs if hasattr(backend.analyzer, 'matched_pairs') else []
                    
                    # åœ¨matched_pairsä¸­æŸ¥æ‰¾åŒ¹é…å¯¹
#                     for r_idx, p_idx, r_note, p_note in matched_pairs:
#                         if r_idx == record_index and p_idx == replay_index:
#                             record_note = r_note
#                             replay_note = p_note
#                             final_algorithm_name = None
#                             logger.info(f"[OK] åœ¨å•ç®—æ³•æ¨¡å¼ä¸­æ‰¾åˆ°åŒ¹é…å¯¹")
                            
                            # è®¡ç®—keyonæ—¶é—´
#                             try:
#                                 record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
#                                 replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
#                                 center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
#                             except Exception as e:
#                                 logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                            
#                             break
                    
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šä» offset_data è·å–
#                     if center_time_ms is None:
#                         try:
#                             offset_data = backend.analyzer.note_matcher.get_offset_alignment_data()
#                             if offset_data:
#                                 for item in offset_data:
#                                     if item.get('record_index') == record_index and item.get('replay_index') == replay_index:
#                                         record_keyon = item.get('record_keyon', 0)
#                                         replay_keyon = item.get('replay_keyon', 0)
#                                         if record_keyon and replay_keyon:
#                                             center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
#                                             break
#                         except Exception as e:
#                             logger.warning(f"[WARNING] ä»offset_dataè·å–æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                
#                 if not record_note or not replay_note:
#                     logger.warning("[WARNING] æœªæ‰¾åˆ°åŒ¹é…å¯¹")
#                     return current_style, [], no_update, no_update, no_update
                
                # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ç®—æ³•ä¸­åŒ¹é…åˆ°åŒä¸€ä¸ªå½•åˆ¶éŸ³ç¬¦çš„æ’­æ”¾éŸ³ç¬¦
#                 other_algorithm_notes = []  # [(algorithm_name, play_note), ...]
#                 if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
#                     active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
#                     for alg in active_algorithms:
#                         if alg.metadata.algorithm_name == algorithm_name:
#                             continue  # è·³è¿‡å½“å‰ç®—æ³•ï¼ˆå·²ç»ç»˜åˆ¶ï¼‰
                        
#                         if not alg.analyzer or not hasattr(alg.analyzer, 'matched_pairs'):
#                             continue
                        
#                         matched_pairs = alg.analyzer.matched_pairs
                        # æŸ¥æ‰¾åŒ¹é…åˆ°åŒä¸€ä¸ªrecord_indexçš„æ’­æ”¾éŸ³ç¬¦
#                         for r_idx, p_idx, r_note, p_note in matched_pairs:
#                             if r_idx == record_index:
#                                 other_algorithm_notes.append((alg.metadata.algorithm_name, p_note))
#                                 logger.info(f"[OK] æ‰¾åˆ°ç®—æ³• '{alg.metadata.algorithm_name}' çš„åŒ¹é…æ’­æ”¾éŸ³ç¬¦")
#                                 break
                
                # è®¡ç®—å¹³å‡å»¶æ—¶
#                 mean_delays = {}
#                 if backend.multi_algorithm_mode and backend.multi_algorithm_manager and algorithm_name:
                    # å¤šç®—æ³•æ¨¡å¼
#                     algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name)
#                     if algorithm and algorithm.analyzer:
#                         mean_error_0_1ms = algorithm.analyzer.get_mean_error()
#                         mean_delays[algorithm_name] = mean_error_0_1ms / 10.0  # è½¬æ¢ä¸ºæ¯«ç§’
#                     else:
#                         logger.error(f"[ERROR] æ— æ³•è·å–ç®—æ³• '{algorithm_name}' çš„å¹³å‡å»¶æ—¶")
#                         return current_style, [], no_update
#                 else:
                    # å•ç®—æ³•æ¨¡å¼
#                     if backend.analyzer:
#                         mean_error_0_1ms = backend.analyzer.get_mean_error()
#                         mean_delays[final_algorithm_name or 'default'] = mean_error_0_1ms / 10.0  # è½¬æ¢ä¸ºæ¯«ç§’
#                     else:
#                         logger.error("[ERROR] æ— æ³•è·å–å•ç®—æ³•æ¨¡å¼çš„å¹³å‡å»¶æ—¶")
#                         return current_style, [], no_update, no_update
                
                # ç”Ÿæˆå¯¹æ¯”æ›²çº¿ï¼ˆåŒ…å«å…¶ä»–ç®—æ³•çš„æ’­æ”¾æ›²çº¿ï¼‰
#                 import spmid
#                 detail_figure_combined = spmid.plot_note_comparison_plotly(
#                     record_note, 
#                     replay_note, 
#                     algorithm_name=final_algorithm_name,
#                     other_algorithm_notes=other_algorithm_notes,  # ä¼ é€’å…¶ä»–ç®—æ³•çš„æ’­æ”¾éŸ³ç¬¦
#                     mean_delays=mean_delays
#                 )
                
#                 if not detail_figure_combined:
#                     logger.error("[ERROR] æ›²çº¿ç”Ÿæˆå¤±è´¥")
#                     return current_style, [], no_update, no_update
                
                # å­˜å‚¨å½“å‰ç‚¹å‡»çš„æ•°æ®ç‚¹ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æŒ‰é’®
#                 point_info = {
#                     'algorithm_name': final_algorithm_name,
#                     'record_idx': record_index,
#                     'replay_idx': replay_index,
#                     'key_id': key_id,
#                     'source_plot_id': 'delay-time-series-plot',  # è®°å½•æ¥æºå›¾è¡¨ID
#                     'center_time_ms': center_time_ms  # é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯
#                 }
                
                # æ˜¾ç¤ºæ¨¡æ€æ¡†
#                 modal_style = {
#                     'display': 'block',
#                     'position': 'fixed',
#                     'zIndex': '9999',
#                     'left': '0',
#                     'top': '0',
#                     'width': '100%',
#                     'height': '100%',
#                     'backgroundColor': 'rgba(0,0,0,0.6)',
#                     'backdropFilter': 'blur(5px)'
#                 }
                
#                 rendered_row = dcc.Graph(figure=detail_figure_combined, style={'height': '600px'})
                
#                 logger.info("[OK] å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»å¤„ç†æˆåŠŸ")
#                 return modal_style, [rendered_row], point_info, no_update

#         except Exception as e:
#                 logger.error(f"[ERROR] å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»å¤±è´¥: {e}")

#                 logger.error(traceback.format_exc())
#                 return current_style, [], no_update, no_update, no_update

#         return current_style, [], no_update, no_update, no_update

    # å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»å›è°ƒ - å¤šç®—æ³•æ¨¡å¼ï¼ˆä»…ç›‘å¬ delay-time-series-plotï¼‰
#     @app.callback(
#         [Output('key-curves-modal', 'style', allow_duplicate=True),
#          Output('key-curves-comparison-container', 'children', allow_duplicate=True),
#          Output('current-clicked-point-info', 'data', allow_duplicate=True),
#          Output('delay-time-series-plot', 'clickData', allow_duplicate=True)],
#         [Input('delay-time-series-plot', 'clickData'),
#          Input('close-key-curves-modal', 'n_clicks'),
#          Input('close-key-curves-modal-btn', 'n_clicks')],
#         [State('session-id', 'data'),
#          State('key-curves-modal', 'style')],
#         prevent_initial_call=True
#     )
    def handle_delay_time_series_click_multi(delay_click_data, close_modal_clicks, close_btn_clicks, session_id, current_style):
        """å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»ï¼ˆå¤šç®—æ³•æ¨¡å¼ï¼‰ï¼Œæ˜¾ç¤ºéŸ³ç¬¦åˆ†ææ›²çº¿ï¼ˆæ‚¬æµ®çª—ï¼‰"""
        return delay_time_series_handler.handle_delay_time_series_click_multi(
            delay_click_data, close_modal_clicks, close_btn_clicks, session_id, current_style
        )

    def handle_delay_value_click(max_clicks_list, min_clicks_list, close_modal_clicks, close_btn_clicks,
                                  max_ids_list, min_ids_list, session_id, current_style):
        """å¤„ç†æœ€å¤§/æœ€å°å»¶è¿Ÿå­—æ®µç‚¹å‡»ï¼Œæ˜¾ç¤ºå¯¹åº”æŒ‰é”®çš„æ›²çº¿å¯¹æ¯”å›¾"""
        
        import dash
        
        logger.info("[START] handle_delay_value_click å›è°ƒè¢«è§¦å‘")

        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            return current_style, [], None
        
        trigger_id = ctx.triggered[0]['prop_id']
        trigger_value = ctx.triggered[0].get('value')
        logger.info(f"ğŸ” è§¦å‘ID: {trigger_id}, è§¦å‘å€¼: {trigger_value}")
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯å…³é—­æŒ‰é’®çš„ç‚¹å‡»
        if trigger_id in ['close-key-curves-modal.n_clicks', 'close-key-curves-modal-btn.n_clicks']:
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, [], None
        
        # å¯¹äºæœ€å¤§/æœ€å°å»¶è¿Ÿå­—æ®µçš„ç‚¹å‡»ï¼Œéœ€è¦ç¡®ä¿æ˜¯çœŸæ­£çš„ç”¨æˆ·ç‚¹å‡»
        # æ£€æŸ¥clicksåˆ—è¡¨ä¸­æ˜¯å¦æœ‰ä»»ä½•å€¼>0ï¼ˆçœŸæ­£çš„ç‚¹å‡»ï¼‰
        has_real_click = False
        if max_clicks_list:
            for clicks in max_clicks_list:
                if clicks is not None and clicks > 0:
                    has_real_click = True
                    break
        if not has_real_click and min_clicks_list:
            for clicks in min_clicks_list:
                if clicks is not None and clicks > 0:
                    has_real_click = True
                    break
        
        # å¦‚æœæ²¡æœ‰çœŸæ­£çš„ç‚¹å‡»ï¼Œå¯èƒ½æ˜¯å¸ƒå±€æ›´æ–°å¯¼è‡´çš„ï¼Œè·³è¿‡å¤„ç†
        if not has_real_click:
            logger.info(f"[WARNING] æ²¡æœ‰æ£€æµ‹åˆ°çœŸæ­£çš„ç”¨æˆ·ç‚¹å‡»ï¼ˆå¯èƒ½æ˜¯å¸ƒå±€æ›´æ–°ï¼‰ï¼Œè·³è¿‡å¤„ç†: trigger_id={trigger_id}")
            return current_style, [], None
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal.n_clicks', 'close-key-curves-modal-btn.n_clicks']:
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, []
        
        # è§£æè§¦å‘IDï¼Œæå–å»¶è¿Ÿç±»å‹å’Œç®—æ³•åç§°
        # ä½¿ç”¨callback_contextæ¥å‡†ç¡®è¯†åˆ«å“ªä¸ªInputè¢«è§¦å‘
        delay_type = None
        algorithm_name = None

        try:
            # ä»triggeredä¿¡æ¯ä¸­æå–è¢«è§¦å‘çš„ç»„ä»¶ID
            triggered_prop = ctx.triggered[0]
            prop_id_str = triggered_prop['prop_id']

            # prop_idæ ¼å¼å¯èƒ½æ˜¯: {'type': 'max-delay-value', 'algorithm': 'xxx'}.n_clicks
            # æˆ–è€…: {'type': 'min-delay-value', 'algorithm': 'xxx'}.n_clicks

            # ä½¿ç”¨å­—ç¬¦ä¸²è§£ææ¥æå–ç®—æ³•åç§°
            import ast
            if 'max-delay-value' in prop_id_str:
                delay_type = 'max'
                try:
                    # prop_idæ ¼å¼: {"type": "max-delay-value", "algorithm": "xxx"}.n_clicks
                    # æå–å­—å…¸éƒ¨åˆ†
                    dict_str = prop_id_str.split('.')[0]  # å»æ‰.n_clickséƒ¨åˆ†
                    id_dict = ast.literal_eval(dict_str)
                    algorithm_name = id_dict.get('algorithm')
                    if algorithm_name:
                        logger.info(f"[OK] ä»prop_idè§£æå¾—åˆ°æœ€å¤§å»¶è¿Ÿç‚¹å‡»: ç®—æ³•={algorithm_name}")
                    else:
                        logger.warning(f"[WARNING] prop_idä¸­æ²¡æœ‰algorithmå­—æ®µ: {prop_id_str}")
                except Exception as e:
                    logger.warning(f"[WARNING] è§£æprop_idå¤±è´¥: {prop_id_str}, é”™è¯¯: {e}")
            elif 'min-delay-value' in prop_id_str:
                delay_type = 'min'
                try:
                    # prop_idæ ¼å¼: {"type": "min-delay-value", "algorithm": "xxx"}.n_clicks
                    # æå–å­—å…¸éƒ¨åˆ†
                    dict_str = prop_id_str.split('.')[0]  # å»æ‰.n_clickséƒ¨åˆ†
                    id_dict = ast.literal_eval(dict_str)
                    algorithm_name = id_dict.get('algorithm')
                    if algorithm_name:
                        logger.info(f"[OK] ä»prop_idè§£æå¾—åˆ°æœ€å°å»¶è¿Ÿç‚¹å‡»: ç®—æ³•={algorithm_name}")
                    else:
                        logger.warning(f"[WARNING] prop_idä¸­æ²¡æœ‰algorithmå­—æ®µ: {prop_id_str}")
                except Exception as e:
                    logger.warning(f"[WARNING] è§£æprop_idå¤±è´¥: {prop_id_str}, é”™è¯¯: {e}")

            # å¦‚æœä¸Šé¢çš„æ–¹æ³•æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•ï¼šæ£€æŸ¥å“ªä¸ªclicksåˆ—è¡¨æœ‰å˜åŒ–
            if not delay_type or not algorithm_name:
                logger.warning(f"[WARNING] ä¸»è¦è§£ææ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                # æ£€æŸ¥max_clicks_listä¸­æ˜¯å¦æœ‰ç‚¹å‡»
                if max_clicks_list:
                    for i, clicks in enumerate(max_clicks_list):
                        if clicks is not None and clicks > 0:
                            if max_ids_list and i < len(max_ids_list):
                                max_id = max_ids_list[i]
                                if max_id and isinstance(max_id, dict):
                                    algorithm_name = max_id.get('algorithm')
                                    delay_type = 'max'
                                    logger.info(f"[OK] å¤‡ç”¨æ–¹æ³•ï¼šæ£€æµ‹åˆ°æœ€å¤§å»¶è¿Ÿç‚¹å‡»: ç®—æ³•={algorithm_name}, clicks={clicks}")
                                    break

                # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œæ£€æŸ¥min_clicks_list
                if not delay_type and min_clicks_list:
                    for i, clicks in enumerate(min_clicks_list):
                        if clicks is not None and clicks > 0:
                            if min_ids_list and i < len(min_ids_list):
                                min_id = min_ids_list[i]
                                if min_id and isinstance(min_id, dict):
                                    algorithm_name = min_id.get('algorithm')
                                    delay_type = 'min'
                                    logger.info(f"[OK] å¤‡ç”¨æ–¹æ³•ï¼šæ£€æµ‹åˆ°æœ€å°å»¶è¿Ÿç‚¹å‡»: ç®—æ³•={algorithm_name}, clicks={clicks}")
                                    break
        except Exception as e:
            logger.warning(f"[WARNING] è§£æè§¦å‘IDå¤±è´¥: {e}, trigger_id={trigger_id}")
            
            logger.error(traceback.format_exc())
        
        if not delay_type or not algorithm_name:
            logger.warning(f"[WARNING] æ— æ³•è§£æå»¶è¿Ÿç±»å‹æˆ–ç®—æ³•åç§°: delay_id={trigger_id}, delay_type={delay_type}, algorithm_name={algorithm_name}")
            logger.warning(f"[WARNING] max_clicks_list: {max_clicks_list}, min_clicks_list: {min_clicks_list}")
            logger.warning(f"[WARNING] max_ids_list: {max_ids_list}, min_ids_list: {min_ids_list}")
            return current_style, [], None
        
        logger.info(f"[STATS] å»¶è¿Ÿç±»å‹: {delay_type}, ç®—æ³•åç§°: {algorithm_name}")
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("[WARNING] backendä¸ºç©º")
            return current_style, [], None
        
        try:
            # è·å–å¯¹åº”å»¶è¿Ÿç±»å‹çš„éŸ³ç¬¦
            notes = backend.get_notes_by_delay_type(algorithm_name, delay_type)
            if notes is None:
                logger.warning(f"[WARNING] æ— æ³•è·å–{delay_type}å»¶è¿Ÿå¯¹åº”çš„éŸ³ç¬¦")
                return current_style, [], None

            record_note, replay_note, record_index, replay_index = notes
            
            # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ç®—æ³•ä¸­åŒ¹é…åˆ°åŒä¸€ä¸ªå½•åˆ¶éŸ³ç¬¦çš„æ’­æ”¾éŸ³ç¬¦
            other_algorithm_notes = []  # [(algorithm_name, play_note), ...]
            if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                for alg in active_algorithms:
                    if alg.metadata.algorithm_name == algorithm_name:
                        continue  # è·³è¿‡å½“å‰ç®—æ³•ï¼ˆå·²ç»ç»˜åˆ¶ï¼‰
                    
                    if not alg.analyzer or not hasattr(alg.analyzer, 'matched_pairs'):
                        continue
                    
                    matched_pairs = alg.analyzer.matched_pairs
                    # æŸ¥æ‰¾åŒ¹é…åˆ°åŒä¸€ä¸ªrecord_noteçš„æ’­æ”¾éŸ³ç¬¦
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_note is record_note:  # ä½¿ç”¨isæ¯”è¾ƒå¯¹è±¡å¼•ç”¨
                            other_algorithm_notes.append((alg.metadata.algorithm_name, p_note))
                            logger.info(f"[OK] æ‰¾åˆ°ç®—æ³• '{alg.metadata.algorithm_name}' çš„åŒ¹é…æ’­æ”¾éŸ³ç¬¦")
                            break
            
            # è®¡ç®—å¹³å‡å»¶æ—¶ï¼Œç”¨äºæ›²çº¿åç§»æ˜¾ç¤º
            mean_delays = {}
            # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹æ‰¾åˆ°å¯¹åº”çš„ç®—æ³•å¯¹è±¡
            if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                target_algorithm = None
                for alg in active_algorithms:
                    if alg.metadata.algorithm_name == algorithm_name:
                        target_algorithm = alg
                        break

                if target_algorithm and target_algorithm.analyzer:
                    mean_error_0_1ms = target_algorithm.analyzer.get_mean_error()
                    if mean_error_0_1ms is not None:
                        mean_delays[algorithm_name] = mean_error_0_1ms / 10.0  # è½¬æ¢ä¸ºmså•ä½
                        logger.info(f"[OK] è®¡ç®—å¹³å‡å»¶æ—¶: {mean_delays[algorithm_name]:.2f}ms")
                    else:
                        logger.warning("[WARNING] æ— æ³•è·å–å¹³å‡å»¶æ—¶ï¼Œä½¿ç”¨é»˜è®¤å€¼0")
                        mean_delays[algorithm_name] = 0.0
                else:
                    logger.warning("[WARNING] æœªæ‰¾åˆ°ç›®æ ‡ç®—æ³•æˆ–åˆ†æå™¨ï¼Œä½¿ç”¨é»˜è®¤å¹³å‡å»¶æ—¶0")
                    mean_delays[algorithm_name] = 0.0
            else:
                logger.warning("[WARNING] éå¤šç®—æ³•æ¨¡å¼ï¼Œæ— æ³•è®¡ç®—å¹³å‡å»¶æ—¶ï¼Œä½¿ç”¨é»˜è®¤å€¼0")
                mean_delays[algorithm_name] = 0.0

            # ç”Ÿæˆå¯¹æ¯”æ›²çº¿ï¼ˆåŒ…å«å…¶ä»–ç®—æ³•çš„æ’­æ”¾æ›²çº¿å’Œå¹³å‡å»¶æ—¶åç§»ï¼‰
            import spmid
            detail_figure_combined = spmid.plot_note_comparison_plotly(
                record_note, 
                replay_note, 
                algorithm_name=algorithm_name,
                other_algorithm_notes=other_algorithm_notes,  # ä¼ é€’å…¶ä»–ç®—æ³•çš„æ’­æ”¾éŸ³ç¬¦
                mean_delays=mean_delays
            )
            
            if not detail_figure_combined:
                logger.error("[ERROR] æ›²çº¿ç”Ÿæˆå¤±è´¥")
                return current_style, []
            
            # æ˜¾ç¤ºæ¨¡æ€æ¡†
            modal_style = {
                'display': 'block',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            
            rendered_row = dcc.Graph(figure=detail_figure_combined, style={'height': '600px'})

            # è®¾ç½®ç‚¹å‡»ç‚¹ä¿¡æ¯ï¼Œç”¨äºè·³è½¬åˆ°ç€‘å¸ƒå›¾
            key_id = getattr(record_note, 'id', 'N/A') if record_note else 'N/A'
            clicked_point_info = {
                'algorithm_name': algorithm_name,
                'record_idx': record_index,
                'replay_idx': replay_index,
                'key_id': key_id,
                'source_plot_id': 'delay-value-click',  # æ ‡è¯†æ¥æºæ˜¯å»¶è¿Ÿå€¼ç‚¹å‡»
                'delay_type': delay_type
            }

            delay_type_name = "æœ€å¤§" if delay_type == 'max' else "æœ€å°"
            logger.info(f"[OK] {delay_type_name}å»¶è¿Ÿå­—æ®µç‚¹å‡»å¤„ç†æˆåŠŸï¼Œç®—æ³•: {algorithm_name}, æŒ‰é”®ID: {key_id}")
            return modal_style, [rendered_row], clicked_point_info
            
        except Exception as e:
            logger.error(f"[ERROR] å¤„ç†{delay_type}å»¶è¿Ÿå­—æ®µç‚¹å‡»å¤±è´¥: {e}")

            logger.error(traceback.format_exc())
        return current_style, [], None
    
    # å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾å›è°ƒ - æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('delay-histogram-plot', 'figure'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_delay_histogram(report_content, session_id):
        """å¤„ç†å»¶æ—¶ç›´æ–¹å›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
            active_algorithms = backend.get_active_algorithms()
            if not active_algorithms:
                logger.warning("[WARNING] æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆå»¶æ—¶ç›´æ–¹å›¾")
                return backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
            fig = backend.generate_delay_histogram_plot()
            logger.info("[OK] å»¶æ—¶ç›´æ–¹å›¾ç”ŸæˆæˆåŠŸ")
            return fig
        except Exception as e:
            logger.error(f"[ERROR] ç”Ÿæˆå»¶æ—¶ç›´æ–¹å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return backend.plot_generator._create_empty_plot(f"ç”Ÿæˆç›´æ–¹å›¾å¤±è´¥: {str(e)}")

    # å¯¼å‡ºå»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾æ•°æ®ä¸ºCSV
    @app.callback(
        Output('export-delay-histogram-status', 'children'),
        Input('export-delay-histogram-csv', 'n_clicks'),
        State('session-id', 'data'),
        prevent_initial_call=True
    )
    def export_delay_histogram_csv(n_clicks, session_id):
        """å¯¼å‡ºå»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾æ•°æ®ä¸ºCSVæ–‡ä»¶"""
        import os

        backend = session_manager.get_backend(session_id)
        if not backend:
            return html.Div("âŒ åç«¯æœªåˆå§‹åŒ–", style={'color': '#dc3545'})

        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
            if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                # å¤šç®—æ³•æ¨¡å¼ï¼šå¯¼å‡ºå¤šç®—æ³•æ•°æ®
                active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                if not active_algorithms:
                    return html.Div("âŒ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•", style={'color': '#dc3545'})

                csv_paths = backend.multi_algorithm_plot_generator.export_multi_algorithm_delay_histogram_data_to_csv(active_algorithms)
            else:
                # å•ç®—æ³•æ¨¡å¼ï¼šå¯¼å‡ºå•ç®—æ³•æ•°æ®
                csv_path = backend.export_delay_histogram_data_to_csv()
                csv_paths = [csv_path] if csv_path else None

            if csv_paths and len(csv_paths) > 0:
                if len(csv_paths) == 1:
                    filename = os.path.basename(csv_paths[0])
                    return html.Div([
                        html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '8px'}),
                        f"âœ… æ•°æ®å·²å¯¼å‡º: {filename}"
                    ], style={'color': '#28a745'})
                else:
                    filenames = [os.path.basename(path) for path in csv_paths]
                    return html.Div([
                        html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '8px'}),
                        f"âœ… æ•°æ®å·²å¯¼å‡º {len(csv_paths)} ä¸ªæ–‡ä»¶: {', '.join(filenames)}"
                    ], style={'color': '#28a745'})
            else:
                return html.Div("âŒ å¯¼å‡ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®", style={'color': '#dc3545'})

        except Exception as e:
            logger.error(f"å¯¼å‡ºå»¶æ—¶åˆ†å¸ƒæ•°æ®å¤±è´¥: {e}")
            return html.Div(f"âŒ å¯¼å‡ºå¼‚å¸¸: {str(e)}", style={'color': '#dc3545'})

    # å¯¼å‡ºåŒ¹é…å‰æ•°æ®ä¸ºCSVï¼ˆæµ‹è¯•åŠŸèƒ½ï¼‰
    @app.callback(
        Output('export-pre-match-status', 'children'),
        Input('export-pre-match-csv', 'n_clicks'),
        State('session-id', 'data'),
        prevent_initial_call=True
    )
    def export_pre_match_csv(n_clicks, session_id):
        """å¯¼å‡ºåŒ¹é…å‰çš„æ•°æ®ä¸ºCSVæ–‡ä»¶ï¼ˆæµ‹è¯•åŠŸèƒ½ï¼‰"""
        import os

        backend = session_manager.get_backend(session_id)
        if not backend:
            return html.Div("âŒ åç«¯æœªåˆå§‹åŒ–", style={'color': '#dc3545'})

        try:
            # æ£€æŸ¥å½“å‰æ¨¡å¼
            if hasattr(backend, 'multi_algorithm_mode') and backend.multi_algorithm_mode:
                # å¤šç®—æ³•æ¨¡å¼
                active_algorithms = backend.get_active_algorithms()
                if not active_algorithms:
                    return html.Div("âŒ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•", style={'color': '#dc3545'})

                csv_paths = backend.multi_algorithm_plot_generator.export_multi_algorithm_pre_match_data_to_csv(active_algorithms)
            else:
                # å•ç®—æ³•æ¨¡å¼
                csv_paths = backend.export_pre_match_data_to_csv()
                if csv_paths and not isinstance(csv_paths, list):
                    csv_paths = [csv_paths]  # ç»Ÿä¸€è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼

            if csv_paths:
                if len(csv_paths) > 1:
                    # å¤šæ–‡ä»¶æƒ…å†µ
                    filenames = [os.path.basename(path) for path in csv_paths]
                    return html.Div([
                        html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '8px'}),
                        f"âœ… åŒ¹é…å‰æ•°æ®å·²å¯¼å‡º {len(csv_paths)} ä¸ªæ–‡ä»¶: {', '.join(filenames)}"
                    ], style={'color': '#28a745'})
                else:
                    # å•æ–‡ä»¶æƒ…å†µ
                    filename = os.path.basename(csv_paths[0])
                    return html.Div([
                        html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '8px'}),
                        f"âœ… åŒ¹é…å‰æ•°æ®å·²å¯¼å‡º: {filename}"
                    ], style={'color': '#28a745'})
            else:
                return html.Div("âŒ å¯¼å‡ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®", style={'color': '#dc3545'})

        except Exception as e:
            logger.error(f"å¯¼å‡ºåŒ¹é…å‰æ•°æ®å¤±è´¥: {e}")
            return html.Div(f"âŒ å¯¼å‡ºå¼‚å¸¸: {str(e)}", style={'color': '#dc3545'})

    # é‡å¤éªŒè¯ä¸€è‡´æ€§æŒ‰é’®
    @app.callback(
        Output('repeat-verification-status', 'children'),
        Input('repeat-verification-btn', 'n_clicks'),
        State('session-id', 'data'),
        prevent_initial_call=True
    )
    def repeat_verification(n_clicks, session_id):
        """é‡å¤éªŒè¯ç³»ç»Ÿè®¡ç®—ä¸€è‡´æ€§"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return html.Div("âŒ ä¼šè¯æ— æ•ˆ", style={'color': '#dc3545'})

        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„æ•°æ®å¯ä»¥éªŒè¯
            if not hasattr(backend, '_last_upload_content') or not backend._last_upload_content:
                return html.Div("âŒ æ²¡æœ‰å¯éªŒè¯çš„å†å²æ•°æ®ï¼Œè¯·å…ˆä¸Šä¼ æ–‡ä»¶", style={'color': '#dc3545'})

            logger.info(f"ğŸ”„ ç”¨æˆ·ä¸»åŠ¨è§¦å‘é‡å¤éªŒè¯ - ç¬¬ {getattr(backend, '_analysis_count', 0) + 1} æ¬¡åˆ†æ")

            # å¼ºåˆ¶é‡æ–°å¤„ç†ç›¸åŒæ–‡ä»¶
            filename = getattr(backend, '_last_upload_filename', 'unknown')
            contents = backend._last_upload_content

            # è®¾ç½®é‡å¤éªŒè¯æ ‡å¿—
            backend._is_repeat_verification = True

            # é‡æ–°å¤„ç†æ–‡ä»¶
            success, result_data, error_msg = backend.process_spmid_upload(contents, filename)

            if success:
                analysis_count = getattr(backend, '_analysis_count', 1)
                return html.Div([
                    html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '8px'}),
                    f"âœ… é‡å¤éªŒè¯å®Œæˆï¼ˆç¬¬ {analysis_count} æ¬¡åˆ†æï¼‰"
                ], style={'color': '#28a745'})
            else:
                return html.Div(f"âŒ é‡å¤éªŒè¯å¤±è´¥: {error_msg}", style={'color': '#dc3545'})

        except Exception as e:
            logger.error(f"é‡å¤éªŒè¯å¼‚å¸¸: {e}")
            return html.Div(f"âŒ éªŒè¯å¼‚å¸¸: {str(e)}", style={'color': '#dc3545'})

        except Exception as e:
            logger.error(f"[ERROR] å¯¼å‡ºå»¶æ—¶åˆ†å¸ƒæ•°æ®å¤±è´¥: {e}")
            return html.Div(f"âŒ å¯¼å‡ºå¼‚å¸¸: {str(e)}", style={'color': '#dc3545'})

    # å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæŒ‡å®šå»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹è¯¦æƒ…
    @app.callback(
        [Output('delay-histogram-detail-table', 'data'),
         Output('delay-histogram-detail-table', 'style_table'),
         Output('delay-histogram-selection-info', 'children')],
        [Input('delay-histogram-plot', 'clickData')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_delay_histogram_click(click_data, session_id):
        """å¤„ç†å»¶æ—¶ç›´æ–¹å›¾ç‚¹å‡»äº‹ä»¶ï¼Œæ˜¾ç¤ºè¯¥å»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹è¯¦æƒ…"""
        
        logger.info(f"ğŸ” å»¶æ—¶ç›´æ–¹å›¾ç‚¹å‡»å›è°ƒè¢«è§¦å‘ï¼Œclick_data: {click_data}")
        print(f"ğŸ” å»¶æ—¶ç›´æ–¹å›¾ç‚¹å‡»å›è°ƒè¢«è§¦å‘ï¼Œclick_data: {click_data}")
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("[WARNING] backend ä¸ºç©º")
            return [], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px', 'display': 'none'}, ""
        
        # å¦‚æœæ²¡æœ‰ç‚¹å‡»æ•°æ®ï¼Œéšè—è¡¨æ ¼
        if not click_data:
            logger.info("[WARNING] click_data ä¸ºç©º")
            return [], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px', 'display': 'none'}, ""
        
        if 'points' not in click_data or not click_data['points']:
            logger.info(f"[WARNING] click_data ä¸­æ²¡æœ‰ points æˆ– points ä¸ºç©ºï¼Œclick_data keys: {click_data.keys() if isinstance(click_data, dict) else 'not dict'}")
            return [], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px', 'display': 'none'}, ""
        
        try:
            # è·å–ç‚¹å‡»çš„æŸ±çŠ¶å›¾ä¿¡æ¯
            # Plotly Histogram ç‚¹å‡»æ—¶ï¼Œpoints[0] åŒ…å« 'x' å­—æ®µï¼Œè¡¨ç¤ºè¯¥æŸ±çŠ¶å›¾çš„ä¸­å¿ƒ x åæ ‡
            # æˆ‘ä»¬éœ€è¦è·å–è¯¥æŸ±çŠ¶å›¾çš„ x èŒƒå›´
            point = click_data['points'][0]
            logger.info(f"[STATS] ç‚¹å‡»çš„ point æ•°æ®: {point}")
            print(f"[STATS] ç‚¹å‡»çš„ point æ•°æ®: {point}")
            
            # å¯¹äº Histogramï¼Œç‚¹å‡»çš„ point å¯èƒ½åŒ…å« 'x'ï¼ˆä¸­å¿ƒå€¼ï¼‰æˆ– 'bin' ä¿¡æ¯
            # æˆ‘ä»¬éœ€è¦æ ¹æ®å®é™…çš„ bin èŒƒå›´æ¥ç­›é€‰æ•°æ®
            # å¦‚æœ point ä¸­æœ‰ 'x'ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒä½œä¸ºå‚è€ƒï¼Œä½†æ›´å‡†ç¡®çš„æ˜¯ä½¿ç”¨ 'bin' ä¿¡æ¯
            
            # å°è¯•è·å– bin èŒƒå›´
            if 'x' in point:
                x_value = point['x']
                
                # è·å–æ‰€æœ‰å»¶æ—¶æ•°æ®æ¥ä¼°ç®— bin å®½åº¦
                # æ”¯æŒå•ç®—æ³•å’Œå¤šç®—æ³•æ¨¡å¼
                if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                    # å¤šç®—æ³•æ¨¡å¼ï¼šä»æ‰€æœ‰æ¿€æ´»ç®—æ³•æ”¶é›†æ•°æ®
                    active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                    delays_ms = []
                    for algorithm in active_algorithms:
                        if algorithm.analyzer and algorithm.analyzer.note_matcher:
                            offset_data = algorithm.analyzer.get_offset_alignment_data()
                            if offset_data:
                                delays_ms.extend([item.get('keyon_offset', 0.0) / 10.0 for item in offset_data])
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    offset_data = backend.analyzer.get_offset_alignment_data() if backend.analyzer else []
                    if not offset_data:
                        return [], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px', 'display': 'none'}, ""
                    delays_ms = [item.get('keyon_offset', 0.0) / 10.0 for item in offset_data]
                
                if not delays_ms:
                    return [], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px', 'display': 'none'}, ""
                
                # æ–¹æ³•1ï¼šå°è¯•ä» point ä¸­è·å– bin è¾¹ç•Œä¿¡æ¯ï¼ˆå¦‚æœ Plotly æä¾›äº†ï¼‰
                # Plotly Histogram çš„ç‚¹å‡»äº‹ä»¶å¯èƒ½åŒ…å« 'bin' æˆ– 'x0', 'x1' ç­‰ä¿¡æ¯
                if 'x0' in point and 'x1' in point:
                    # å¦‚æœ Plotly ç›´æ¥æä¾›äº† bin è¾¹ç•Œï¼Œä½¿ç”¨å®ƒï¼ˆæœ€å‡†ç¡®ï¼‰
                    delay_min = point['x0']
                    delay_max = point['x1']
                else:
                    # æ–¹æ³•2ï¼šä¼°ç®— bin å®½åº¦
                    # ä½¿ç”¨ Sturges' rule ä¼°ç®— bin æ•°é‡
                    n = len(delays_ms)
                    if n > 1:
                        num_bins = min(50, max(10, int(1 + 3.322 * math.log10(n))))
                    else:
                        num_bins = 10
                    
                    data_range = max(delays_ms) - min(delays_ms)
                    estimated_bin_width = data_range / num_bins if num_bins > 0 else max(1.0, data_range / 10)
                    
                    # è®¡ç®— bin çš„èŒƒå›´ï¼ˆä»¥ç‚¹å‡»çš„ x ä¸ºä¸­å¿ƒï¼‰
                    delay_min = x_value - estimated_bin_width / 2
                    delay_max = x_value + estimated_bin_width / 2
                    
                    # ç¡®ä¿èŒƒå›´åˆç†ï¼ˆè‡³å°‘ 1ms å®½åº¦ï¼Œé¿å…èŒƒå›´å¤ªå°ï¼‰
                    if delay_max - delay_min < 1.0:
                        delay_min = x_value - 0.5
                        delay_max = x_value + 0.5
            else:
                # å¦‚æœæ²¡æœ‰ x å€¼ï¼Œæ— æ³•ç¡®å®šèŒƒå›´
                return [], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px', 'display': 'none'}, ""
            
            # è·å–è¯¥å»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹
            data_points = backend.get_delay_range_data_points(delay_min, delay_max)
            
            if not data_points:
                info_text = f"å»¶æ—¶èŒƒå›´ [{delay_min:.2f}ms, {delay_max:.2f}ms] å†…æ²¡æœ‰æ•°æ®ç‚¹"
                return [], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px', 'display': 'none'}, info_text
            
            # å‡†å¤‡è¡¨æ ¼æ•°æ®
            table_data = []
            for item in data_points:
                table_data.append({
                    'algorithm_name': item.get('algorithm_name', 'N/A'),
                    'key_id': item.get('key_id', 'N/A'),
                    'delay_ms': item.get('delay_ms', 0.0),
                    'record_index': item.get('record_index', 'N/A'),
                    'replay_index': item.get('replay_index', 'N/A'),
                    'record_keyon': item.get('record_keyon', 'N/A'),
                    'replay_keyon': item.get('replay_keyon', 'N/A'),
                    'duration_offset': item.get('duration_offset', 'N/A'),
                })
            
            # æ˜¾ç¤ºä¿¡æ¯
            info_text = f"å»¶æ—¶èŒƒå›´ [{delay_min:.2f}ms, {delay_max:.2f}ms] å†…å…±æœ‰ {len(data_points)} ä¸ªæ•°æ®ç‚¹"
            
            # æ˜¾ç¤ºè¡¨æ ¼ï¼Œæ·»åŠ å‚ç›´æ»šåŠ¨æ¡ï¼Œé™åˆ¶æœ€å¤§é«˜åº¦ä¸º600px
            table_style = {
                'overflowX': 'auto',
                'overflowY': 'auto',
                'maxHeight': '600px',
                'display': 'block'
            }
            return table_data, table_style, info_text
            
        except Exception as e:
            logger.error(f"[ERROR] å¤„ç†å»¶æ—¶ç›´æ–¹å›¾ç‚¹å‡»äº‹ä»¶å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return [], {'overflowX': 'auto', 'overflowY': 'auto', 'maxHeight': '600px', 'display': 'none'}, f"å¤„ç†å¤±è´¥: {str(e)}"
    
    # å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾è¯¦æƒ…è¡¨æ ¼ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºå½•åˆ¶ä¸æ’­æ”¾å¯¹æ¯”æ›²çº¿
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True)],
        [Input('delay-histogram-detail-table', 'active_cell'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('delay-histogram-detail-table', 'data'),
         State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_delay_histogram_table_click(active_cell, close_modal_clicks, close_btn_clicks, table_data, session_id, current_style):
        """å¤„ç†å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾è¯¦æƒ…è¡¨æ ¼ç‚¹å‡»ï¼Œæ˜¾ç¤ºå½•åˆ¶ä¸æ’­æ”¾å¯¹æ¯”æ›²çº¿ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾"""
        
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            return current_style, [], no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"[PROCESS] å»¶æ—¶ç›´æ–¹å›¾è¡¨æ ¼ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")
        print(f"[PROCESS] å»¶æ—¶ç›´æ–¹å›¾è¡¨æ ¼ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            logger.info("[OK] å…³é—­æŒ‰é”®æ›²çº¿å¯¹æ¯”æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, [], no_update
        
        # å¦‚æœæ˜¯è¡¨æ ¼ç‚¹å‡»
        if trigger_id == 'delay-histogram-detail-table':
            backend = session_manager.get_backend(session_id)
            if not backend:
                logger.warning("[WARNING] æ²¡æœ‰æ‰¾åˆ°backend")
                return current_style, [], no_update
            
            if not active_cell or not table_data:
                logger.warning("[WARNING] active_cellæˆ–table_dataä¸ºç©º")
                return current_style, [], no_update
            
            try:
                # è·å–ç‚¹å‡»çš„è¡Œæ•°æ®
                row_idx = active_cell.get('row')
                if row_idx is None or row_idx >= len(table_data):
                    logger.warning(f"[WARNING] è¡Œç´¢å¼•è¶…å‡ºèŒƒå›´: row_idx={row_idx}, table_dataé•¿åº¦={len(table_data)}")
                    return current_style, [], no_update
                
                row_data = table_data[row_idx]
                record_index = row_data.get('record_index')
                replay_index = row_data.get('replay_index')
                key_id = row_data.get('key_id')  # è·å–æŒ‰é”®IDç”¨äºéªŒè¯
                algorithm_name = row_data.get('algorithm_name')  # å¯èƒ½ä¸º Noneï¼ˆå•ç®—æ³•æ¨¡å¼ï¼‰
                
                logger.info(f"[STATS] ç‚¹å‡»çš„è¡Œæ•°æ®: record_index={record_index}, replay_index={replay_index}, key_id={key_id}, algorithm_name={algorithm_name}")
                print(f"[STATS] ç‚¹å‡»çš„è¡Œæ•°æ®: record_index={record_index}, replay_index={replay_index}, key_id={key_id}, algorithm_name={algorithm_name}")
                
                # æ£€æŸ¥ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
                if record_index == 'N/A' or replay_index == 'N/A' or record_index is None or replay_index is None:
                    logger.warning("[WARNING] ç´¢å¼•æ— æ•ˆ")
                    return current_style, [], no_update
                
                try:
                    record_index = int(record_index)
                    replay_index = int(replay_index)
                    if key_id and key_id != 'N/A':
                        key_id = int(key_id)
                    else:
                        key_id = None
                except (ValueError, TypeError) as e:
                    logger.warning(f"[WARNING] æ— æ³•è½¬æ¢ç´¢å¼•æˆ–key_id: record_index={record_index}, replay_index={replay_index}, key_id={key_id}, error={e}")
                    return current_style, [], no_update
                
                # è·å–å¯¹åº”çš„éŸ³ç¬¦æ•°æ® - å¿…é¡»ä»matched_pairsä¸­è·å–ï¼Œç¡®ä¿æ˜¯é…å¯¹çš„
                record_note = None
                replay_note = None
                center_time_ms = None  # ç”¨äºè·³è½¬çš„æ—¶é—´ä¿¡æ¯
                
                # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼ä¸”æä¾›äº†ç®—æ³•åç§°
                if backend.multi_algorithm_mode and backend.multi_algorithm_manager and algorithm_name and algorithm_name != 'N/A':
                    # å¤šç®—æ³•æ¨¡å¼ï¼šä»æŒ‡å®šç®—æ³•è·å–æ•°æ®
                    active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                    target_algorithm = None
                    for alg in active_algorithms:
                        if alg.metadata.algorithm_name == algorithm_name:
                            target_algorithm = alg
                            break
                    
                    if not target_algorithm or not target_algorithm.analyzer:
                        logger.warning(f"[WARNING] æœªæ‰¾åˆ°ç®—æ³•: {algorithm_name}")
                        return current_style, [], no_update
                    
                    # ä»matched_pairsä¸­æŸ¥æ‰¾åŒ¹é…å¯¹ï¼Œç¡®ä¿record_indexå’Œreplay_indexå¯¹åº”åŒä¸€ä¸ªåŒ¹é…å¯¹
                    matched_pairs = target_algorithm.analyzer.matched_pairs if hasattr(target_algorithm.analyzer, 'matched_pairs') else []
                    if not matched_pairs:
                        logger.warning("[WARNING] ç®—æ³•æ²¡æœ‰åŒ¹é…å¯¹æ•°æ®")
                        return current_style, [], no_update
                    
                    # æŸ¥æ‰¾åŒ¹é…å¯¹ï¼šrecord_indexå’Œreplay_indexå¿…é¡»åŒæ—¶åŒ¹é…
                    found_pair = False
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_idx == record_index and p_idx == replay_index:
                            # éªŒè¯key_idï¼ˆå¦‚æœæä¾›äº†ï¼‰
                            if key_id is not None and r_note.id != key_id:
                                logger.warning(f"[WARNING] key_idä¸åŒ¹é…: è¡¨æ ¼ä¸­çš„key_id={key_id}, åŒ¹é…å¯¹ä¸­çš„key_id={r_note.id}")
                                continue
                            record_note = r_note
                            replay_note = p_note
                            found_pair = True
                            logger.info(f"[OK] ä»matched_pairsä¸­æ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}, key_id={r_note.id}")
                            print(f"[OK] ä»matched_pairsä¸­æ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}, key_id={r_note.id}")
                            
                            # è®¡ç®—keyonæ—¶é—´ï¼Œç”¨äºè·³è½¬
                            try:
                                record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
                                replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
                                center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
                            except Exception as e:
                                logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                                # å¤‡ç”¨æ–¹æ¡ˆï¼šä» offset_data è·å–
                                if target_algorithm.analyzer.note_matcher:
                                    try:
                                        offset_data = target_algorithm.analyzer.note_matcher.get_offset_alignment_data()
                                        if offset_data:
                                            for item in offset_data:
                                                if item.get('record_index') == record_index and item.get('replay_index') == replay_index:
                                                    record_keyon = item.get('record_keyon', 0)
                                                    replay_keyon = item.get('replay_keyon', 0)
                                                    if record_keyon and replay_keyon:
                                                        center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                                                        break
                                    except Exception as e2:
                                        logger.warning(f"[WARNING] ä»offset_dataè·å–æ—¶é—´ä¿¡æ¯å¤±è´¥: {e2}")
                            
                            break
                    
                    if not found_pair:
                        logger.warning(f"[WARNING] æœªæ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}")
                        return current_style, [], no_update
                    
                    # ä½¿ç”¨ç®—æ³•åç§°
                    final_algorithm_name = algorithm_name
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    if not backend.analyzer:
                        logger.warning("[WARNING] æ²¡æœ‰åˆ†æå™¨")
                        return current_style, [], no_update
                    
                    # ä»matched_pairsä¸­æŸ¥æ‰¾åŒ¹é…å¯¹
                    matched_pairs = backend.analyzer.matched_pairs if hasattr(backend.analyzer, 'matched_pairs') else []
                    if not matched_pairs:
                        logger.warning("[WARNING] æ²¡æœ‰åŒ¹é…å¯¹æ•°æ®")
                        return current_style, [], no_update
                    
                    # æŸ¥æ‰¾åŒ¹é…å¯¹ï¼šrecord_indexå’Œreplay_indexå¿…é¡»åŒæ—¶åŒ¹é…
                    found_pair = False
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_idx == record_index and p_idx == replay_index:
                            # éªŒè¯key_idï¼ˆå¦‚æœæä¾›äº†ï¼‰
                            if key_id is not None and r_note.id != key_id:
                                logger.warning(f"[WARNING] key_idä¸åŒ¹é…: è¡¨æ ¼ä¸­çš„key_id={key_id}, åŒ¹é…å¯¹ä¸­çš„key_id={r_note.id}")
                                continue
                            record_note = r_note
                            replay_note = p_note
                            found_pair = True
                            logger.info(f"[OK] ä»matched_pairsä¸­æ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}, key_id={r_note.id}")
                            print(f"[OK] ä»matched_pairsä¸­æ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}, key_id={r_note.id}")
                            
                            # è®¡ç®—keyonæ—¶é—´ï¼Œç”¨äºè·³è½¬
                            try:
                                record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
                                replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
                                center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
                            except Exception as e:
                                logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                                # å¤‡ç”¨æ–¹æ¡ˆï¼šä» offset_data è·å–
                                if backend.analyzer.note_matcher:
                                    try:
                                        offset_data = backend.analyzer.note_matcher.get_offset_alignment_data()
                                        if offset_data:
                                            for item in offset_data:
                                                if item.get('record_index') == record_index and item.get('replay_index') == replay_index:
                                                    record_keyon = item.get('record_keyon', 0)
                                                    replay_keyon = item.get('replay_keyon', 0)
                                                    if record_keyon and replay_keyon:
                                                        center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                                                        break
                                    except Exception as e2:
                                        logger.warning(f"[WARNING] ä»offset_dataè·å–æ—¶é—´ä¿¡æ¯å¤±è´¥: {e2}")
                            
                            break
                    
                    if not found_pair:
                        logger.warning(f"[WARNING] æœªæ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}")
                        return current_style, [], no_update
                    
                    # å•ç®—æ³•æ¨¡å¼ï¼Œalgorithm_name å¯èƒ½ä¸º None
                    final_algorithm_name = algorithm_name if algorithm_name and algorithm_name != 'N/A' else None
                
                # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ç®—æ³•ä¸­åŒ¹é…åˆ°åŒä¸€ä¸ªå½•åˆ¶éŸ³ç¬¦çš„æ’­æ”¾éŸ³ç¬¦
                other_algorithm_notes = []  # [(algorithm_name, play_note), ...]
                if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                    active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                    for alg in active_algorithms:
                        if alg.metadata.algorithm_name == final_algorithm_name:
                            continue  # è·³è¿‡å½“å‰ç®—æ³•ï¼ˆå·²ç»ç»˜åˆ¶ï¼‰
                        
                        if not alg.analyzer or not hasattr(alg.analyzer, 'matched_pairs'):
                            continue
                        
                        matched_pairs = alg.analyzer.matched_pairs
                        # æŸ¥æ‰¾åŒ¹é…åˆ°åŒä¸€ä¸ªrecord_indexçš„æ’­æ”¾éŸ³ç¬¦
                        for r_idx, p_idx, r_note, p_note in matched_pairs:
                            if r_idx == record_index:
                                other_algorithm_notes.append((alg.metadata.algorithm_name, p_note))
                                logger.info(f"[OK] æ‰¾åˆ°ç®—æ³• '{alg.metadata.algorithm_name}' çš„åŒ¹é…æ’­æ”¾éŸ³ç¬¦")
                                break
                
                # è®¡ç®—å¹³å‡å»¶æ—¶
                mean_delays = {}
                if backend.multi_algorithm_mode and backend.multi_algorithm_manager and final_algorithm_name:
                    # å¤šç®—æ³•æ¨¡å¼
                    algorithm = backend.multi_algorithm_manager.get_algorithm(final_algorithm_name)
                    if algorithm and algorithm.analyzer:
                        mean_error_0_1ms = algorithm.analyzer.get_mean_error()
                        mean_delays[final_algorithm_name] = mean_error_0_1ms / 10.0  # è½¬æ¢ä¸ºæ¯«ç§’
                    else:
                        logger.error(f"[ERROR] æ— æ³•è·å–ç®—æ³• '{final_algorithm_name}' çš„å¹³å‡å»¶æ—¶")
                        return current_style, [], no_update
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    if backend.analyzer:
                        mean_error_0_1ms = backend.analyzer.get_mean_error()
                        mean_delays[final_algorithm_name or 'default'] = mean_error_0_1ms / 10.0  # è½¬æ¢ä¸ºæ¯«ç§’
                    else:
                        logger.error("[ERROR] æ— æ³•è·å–å•ç®—æ³•æ¨¡å¼çš„å¹³å‡å»¶æ—¶")
                        return current_style, [], no_update, no_update
                
                # ç”Ÿæˆå¯¹æ¯”æ›²çº¿å›¾ï¼ˆåŒ…å«å…¶ä»–ç®—æ³•çš„æ’­æ”¾æ›²çº¿ï¼‰
                import spmid
                detail_figure_combined = spmid.plot_note_comparison_plotly(
                    record_note, 
                    replay_note, 
                    algorithm_name=final_algorithm_name,
                    other_algorithm_notes=other_algorithm_notes,  # ä¼ é€’å…¶ä»–ç®—æ³•çš„æ’­æ”¾éŸ³ç¬¦
                    mean_delays=mean_delays
                )
                
                if not detail_figure_combined:
                    logger.error("[ERROR] æ›²çº¿ç”Ÿæˆå¤±è´¥")
                    return current_style, [], no_update, no_update
                
                logger.info(f"[OK] æˆåŠŸç”Ÿæˆå¯¹æ¯”æ›²çº¿: record_index={record_index}, replay_index={replay_index}")
                print(f"[OK] æˆåŠŸç”Ÿæˆå¯¹æ¯”æ›²çº¿: record_index={record_index}, replay_index={replay_index}")
                
                # å­˜å‚¨å½“å‰ç‚¹å‡»çš„æ•°æ®ç‚¹ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æŒ‰é’®
                point_info = {
                    'algorithm_name': final_algorithm_name,
                    'record_idx': record_index,
                    'replay_idx': replay_index,
                    'key_id': key_id,
                    'source_plot_id': 'delay-histogram-detail-table',  # è®°å½•æ¥æºå›¾è¡¨ID
                    'center_time_ms': center_time_ms  # é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯
                }
                
                # æ˜¾ç¤ºæ¨¡æ€æ¡†
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                
                # åˆ›å»ºæ¨¡æ€æ¡†å†…å®¹ï¼ˆåªåŒ…å«å›¾è¡¨ï¼ŒæŒ‰é’®å·²åœ¨å¸ƒå±€ä¸­å®šä¹‰ï¼‰
                # ä½¿ç”¨ä¸ handle_waterfall_click ç›¸åŒçš„æ ¼å¼
                rendered_row = dcc.Graph(figure=detail_figure_combined, style={'height': '600px'})
                
                return modal_style, [rendered_row], point_info
                
            except Exception as e:
                logger.error(f"[ERROR] å¤„ç†å»¶æ—¶ç›´æ–¹å›¾è¡¨æ ¼ç‚¹å‡»å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                return current_style, [], no_update
        
        return current_style, [], no_update

    # ==================== å¤šç®—æ³•å¯¹æ¯”æ¨¡å¼å›è°ƒ ====================
    
    # å¤šç®—æ³•æ¨¡å¼åˆå§‹åŒ–å›è°ƒ - åœ¨ä¼šè¯åˆå§‹åŒ–æ—¶è‡ªåŠ¨è§¦å‘
    @app.callback(
        [Output('multi-algorithm-upload-area', 'style', allow_duplicate=True),
         Output('multi-algorithm-upload-area', 'children'),
         Output('multi-algorithm-management-area', 'style', allow_duplicate=True),
         Output('multi-algorithm-management-area', 'children'),
         Output('main-plot', 'figure', allow_duplicate=True),
         Output('report-content', 'children', allow_duplicate=True)],
        [Input('session-id', 'data')],
        prevent_initial_call='initial_duplicate',
        prevent_duplicate=True
    )
    def initialize_multi_algorithm_mode(session_id):
        """åˆå§‹åŒ–å¤šç®—æ³•æ¨¡å¼ - ç¡®ä¿ä¸Šä¼ åŒºåŸŸå’Œç®¡ç†åŒºåŸŸæ˜¾ç¤º"""
        logger.info(f"[PROCESS] åˆå§‹åŒ–å¤šç®—æ³•æ¨¡å¼: session_id={session_id}")
        
        if not session_id:
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        session_id, backend = session_manager.get_or_create_backend(session_id)
        if not backend:
            logger.warning("[WARNING] æ— æ³•è·å–backendå®ä¾‹")
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        try:
            # å¤šç®—æ³•æ¨¡å¼å§‹ç»ˆå¯ç”¨
            # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
            if not backend.multi_algorithm_manager:
                backend._ensure_multi_algorithm_manager()
            has_existing_data = False
            existing_filename = None
            logger.info("[OK] å¤šç®—æ³•æ¨¡å¼å·²å°±ç»ª")
            
            success = True
            if success:
                upload_style = {'display': 'block'}
                try:
                    upload_area = create_multi_algorithm_upload_area()
                    logger.info("[OK] åˆ›å»ºå¤šç®—æ³•ä¸Šä¼ åŒºåŸŸæˆåŠŸ")
                except Exception as e:
                    logger.error(f"[ERROR] åˆ›å»ºå¤šç®—æ³•ä¸Šä¼ åŒºåŸŸå¤±è´¥: {e}")
                    upload_area = html.Div("ä¸Šä¼ åŒºåŸŸåˆ›å»ºå¤±è´¥", style={'color': '#dc3545'})
                
                management_style = {'display': 'block'}
                try:
                    management_area = create_multi_algorithm_management_area()
                    logger.info("[OK] åˆ›å»ºå¤šç®—æ³•ç®¡ç†åŒºåŸŸæˆåŠŸ")
                except Exception as e:
                    logger.error(f"[ERROR] åˆ›å»ºå¤šç®—æ³•ç®¡ç†åŒºåŸŸå¤±è´¥: {e}")
                    management_area = html.Div("ç®¡ç†åŒºåŸŸåˆ›å»ºå¤±è´¥", style={'color': '#dc3545'})
            else:
                upload_style = {'display': 'block'}  # å³ä½¿å¤±è´¥ä¹Ÿæ˜¾ç¤ºï¼Œè®©ç”¨æˆ·çŸ¥é“æœ‰é—®é¢˜
                upload_area = html.Div("å¤šç®—æ³•æ¨¡å¼å¯ç”¨å¤±è´¥", style={'color': '#dc3545'})
                management_style = {'display': 'block'}
                management_area = html.Div("å¤šç®—æ³•æ¨¡å¼å¯ç”¨å¤±è´¥", style={'color': '#dc3545'})
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ›´æ–°ç€‘å¸ƒå›¾
            plot_fig = no_update
            report_content = no_update
            
            active_algorithms = backend.get_active_algorithms()
            # è¿›ä¸€æ­¥æ£€æŸ¥ï¼šåªæœ‰ç®—æ³•çœŸæ­£æœ‰æ•°æ®ï¼ˆanalyzerå­˜åœ¨ä¸”æœ‰matched_pairsï¼‰æ‰ç”Ÿæˆå›¾å½¢
            algorithms_with_data = []
            for alg in active_algorithms:
                if alg.analyzer and hasattr(alg.analyzer, 'matched_pairs') and alg.analyzer.matched_pairs:
                    algorithms_with_data.append(alg)
            
            if algorithms_with_data:
                try:
                    logger.info(f"[PROCESS] æ›´æ–°ç€‘å¸ƒå›¾ï¼Œå…± {len(algorithms_with_data)} ä¸ªæœ‰æ•°æ®çš„æ¿€æ´»ç®—æ³•")
                    plot_fig = backend.generate_waterfall_plot()
                    report_content = create_report_layout(backend)
                except Exception as e:
                    logger.error(f"[ERROR] æ›´æ–°ç€‘å¸ƒå›¾å¤±è´¥: {e}")
                    plot_fig = _create_empty_figure_for_callback(f"æ›´æ–°å¤±è´¥: {str(e)}")
                    # ä½¿ç”¨ create_report_layout ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€çš„ç»„ä»¶
                    try:
                        report_content = create_report_layout(backend)
                    except:
                        # å¦‚æœ create_report_layout ä¹Ÿå¤±è´¥ï¼Œè¿”å›åŒ…å«å¿…éœ€ç»„ä»¶çš„é”™è¯¯å¸ƒå±€
                        empty_fig = {}
                        report_content = html.Div([
                            html.H4("æ›´æ–°å¤±è´¥", className="text-center text-danger"),
                            html.P(f"é”™è¯¯ä¿¡æ¯: {str(e)}", className="text-center"),
                            # åŒ…å«æ‰€æœ‰å¿…éœ€çš„å›¾è¡¨ç»„ä»¶ï¼ˆéšè—ï¼‰ï¼Œç¡®ä¿å›è°ƒå‡½æ•°ä¸ä¼šæŠ¥é”™
                            dcc.Graph(id='key-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                            dcc.Graph(id='key-delay-zscore-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                            dcc.Graph(id='hammer-velocity-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                            # key-hammer-velocity-scatter-plot å·²åˆ é™¤ï¼ˆåŠŸèƒ½ä¸æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾é‡å¤ï¼‰
                            html.Div(id='offset-alignment-plot', style={'display': 'none'}),
                            html.Div([
                                dash_table.DataTable(
                                    id='offset-alignment-table',
                                    data=[],
                                    columns=[]
                                )
                            ], style={'display': 'none'})
                        ])
            else:
                # æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•æ—¶ï¼Œä¸è°ƒç”¨ create_report_layoutï¼Œç›´æ¥è¿”å›ç©ºå¸ƒå±€
                # é¿å…åœ¨æ²¡æœ‰æ•°æ®æ—¶æ‰§è¡Œä¸å¿…è¦çš„æ“ä½œ
                logger.info("[INFO] æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å›¾å½¢ç”Ÿæˆï¼Œè¿”å›ç©ºå¸ƒå±€")
                empty_fig = {}
                report_content = html.Div([
                        html.H4("æš‚æ— æ•°æ®", className="text-center text-muted"),
                        html.P("è¯·è‡³å°‘æ¿€æ´»ä¸€ä¸ªç®—æ³•ä»¥æŸ¥çœ‹åˆ†ææŠ¥å‘Š", className="text-center text-muted"),
                        # åŒ…å«æ‰€æœ‰å¿…éœ€çš„å›¾è¡¨ç»„ä»¶ï¼ˆéšè—ï¼‰ï¼Œç¡®ä¿å›è°ƒå‡½æ•°ä¸ä¼šæŠ¥é”™
                        dcc.Graph(id='key-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                        dcc.Graph(id='key-delay-zscore-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                        dcc.Graph(id='hammer-velocity-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                        # key-hammer-velocity-scatter-plot å·²åˆ é™¤ï¼ˆåŠŸèƒ½ä¸æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾é‡å¤ï¼‰
                        dcc.Graph(id='key-force-interaction-plot', figure=empty_fig, style={'display': 'none'}),
                        dcc.Store(id='key-force-interaction-selected-algorithms', data=[]),
                        dcc.Graph(id='relative-delay-distribution-plot', figure=empty_fig, style={'display': 'none'}),
                        html.Div(id='offset-alignment-plot', style={'display': 'none'}),
                        dcc.Graph(id='delay-time-series-plot', figure=empty_fig, style={'display': 'none'}),
                        dcc.Graph(id='delay-histogram-plot', figure=empty_fig, style={'display': 'none'}),
                        html.Div([
                            dash_table.DataTable(
                                id='offset-alignment-table',
                                data=[],
                                columns=[]
                            )
                        ], style={'display': 'none'}),
                        html.Div([
                            dash_table.DataTable(
                                id='delay-histogram-detail-table',
                                data=[],
                                columns=[
                                    {"name": "ç®—æ³•åç§°", "id": "algorithm_name"},
                                    {"name": "æŒ‰é”®ID", "id": "key_id"},
                                    {"name": "å»¶æ—¶(ms)", "id": "delay_ms"},
                                    {"name": "å½•åˆ¶ç´¢å¼•", "id": "record_index"},
                                    {"name": "æ’­æ”¾ç´¢å¼•", "id": "replay_index"},
                                    {"name": "å½•åˆ¶å¼€å§‹(0.1ms)", "id": "record_keyon"},
                                    {"name": "æ’­æ”¾å¼€å§‹(0.1ms)", "id": "replay_keyon"},
                                    {"name": "æŒç»­æ—¶é—´å·®(0.1ms)", "id": "duration_offset"},
                                ]
                            )
                        ], style={'display': 'none'}),
                        html.Div(id='delay-histogram-selection-info', style={'display': 'none'})
                        ])
            
            logger.info(f"[OK] å¤šç®—æ³•æ¨¡å¼åˆå§‹åŒ–å®Œæˆ")
            return upload_style, upload_area, management_style, management_area, plot_fig, report_content
            
        except Exception as e:
            logger.error(f"[ERROR] åˆå§‹åŒ–å¤šç®—æ³•æ¨¡å¼å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return (
                {'display': 'block'}, 
                html.Div("åˆå§‹åŒ–å¤±è´¥", style={'color': '#dc3545'}), 
                {'display': 'block'}, 
                html.Div("åˆå§‹åŒ–å¤±è´¥", style={'color': '#dc3545'}), 
                no_update, 
                no_update
            )
    
    @app.callback(
        [Output('upload-multi-algorithm-data', 'contents', allow_duplicate=True),
         Output('upload-multi-algorithm-data', 'filename', allow_duplicate=True),
         Output('multi-algorithm-file-list', 'children', allow_duplicate=True),
         Output('multi-algorithm-upload-status', 'children', allow_duplicate=True)],
        [Input('reset-multi-algorithm-upload', 'n_clicks')],
        prevent_initial_call=True
    )
    def reset_multi_algorithm_upload(n_clicks):
        """é‡ç½®å¤šç®—æ³•ä¸Šä¼ åŒºåŸŸï¼Œæ¸…é™¤ä¸Šä¼ çŠ¶æ€"""
        if not n_clicks:
            return no_update, no_update, no_update, no_update

        # é‡ç½®ä¸Šä¼ ç»„ä»¶å’ŒçŠ¶æ€
        return None, None, html.Div(), html.Span("ä¸Šä¼ åŒºåŸŸå·²é‡ç½®ï¼Œå¯ä»¥é‡æ–°é€‰æ‹©æ–‡ä»¶", style={'color': '#17a2b8'})

    @app.callback(
        [Output('multi-algorithm-upload-area', 'style', allow_duplicate=True),
         Output('multi-algorithm-management-area', 'style', allow_duplicate=True),
         Output('multi-algorithm-file-list', 'children', allow_duplicate=True),
         Output('multi-algorithm-upload-status', 'children', allow_duplicate=True),
         Output('multi-algorithm-files-store', 'data', allow_duplicate=True)],
        [Input('upload-multi-algorithm-data', 'contents')],
        [State('upload-multi-algorithm-data', 'filename'),
         State('session-id', 'data'),
         State('multi-algorithm-files-store', 'data')],
        prevent_initial_call=True
    )
    def handle_multi_file_upload(contents_list, filename_list, session_id, store_data):
        """å¤„ç†å¤šæ–‡ä»¶ä¸Šä¼ ï¼Œæ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨ä¾›ç”¨æˆ·è¾“å…¥ç®—æ³•åç§°"""
        # è·å–åç«¯å®ä¾‹
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update, no_update, no_update, no_update
        
        # ç¡®ä¿å¤šç®—æ³•æ¨¡å¼å·²å¯ç”¨
        # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
        if not backend.multi_algorithm_manager:
            backend._ensure_multi_algorithm_manager()
        
        # ç¡®ä¿ä¸Šä¼ åŒºåŸŸå’Œç®¡ç†åŒºåŸŸå§‹ç»ˆæ˜¾ç¤º
        upload_style = {'display': 'block'}
        management_style = {'display': 'block'}
        
        # ä½¿ç”¨MultiFileUploadHandlerå¤„ç†æ–‡ä»¶ä¸Šä¼ 
        upload_handler = MultiFileUploadHandler()
        file_list, status_text, new_store_data = upload_handler.process_uploaded_files(contents_list, filename_list, store_data, backend)
        
        return upload_style, management_style, file_list, status_text, new_store_data
    
    @app.callback(
        Output({'type': 'algorithm-status', 'index': dash.dependencies.MATCH}, 'children'),
        [Input({'type': 'confirm-algorithm-btn', 'index': dash.dependencies.MATCH}, 'n_clicks')],
        [State({'type': 'algorithm-name-input', 'index': dash.dependencies.MATCH}, 'value'),
         State({'type': 'confirm-algorithm-btn', 'index': dash.dependencies.MATCH}, 'id'),
         State('multi-algorithm-files-store', 'data'),
         State('session-id', 'data')],
        prevent_initial_call=True
    )
    def confirm_add_algorithm(n_clicks, algorithm_name, button_id, store_data, session_id):
        """ç¡®è®¤æ·»åŠ ç®—æ³•"""
        if not n_clicks or not algorithm_name or not algorithm_name.strip():
            return html.Span("è¯·è¾“å…¥ç®—æ³•åç§°", style={'color': '#ffc107'})
        
        # è·å–åç«¯å®ä¾‹
        backend = session_manager.get_backend(session_id)
        if not backend:
            return html.Span("ä¼šè¯æ— æ•ˆ", style={'color': '#dc3545'})
        
        # ç¡®ä¿å¤šç®—æ³•æ¨¡å¼å·²å¯ç”¨
        # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
        if not backend.multi_algorithm_manager:
            backend._ensure_multi_algorithm_manager()
        
        if not store_data or 'contents' not in store_data or 'filenames' not in store_data:
            return html.Span("æ–‡ä»¶æ•°æ®ä¸¢å¤±ï¼Œè¯·é‡æ–°ä¸Šä¼ ", style={'color': '#dc3545'})
        
        try:
            # ä½¿ç”¨MultiFileUploadHandlerè·å–æ–‡ä»¶æ•°æ®
            upload_handler = MultiFileUploadHandler()
            file_id = button_id['index']
            file_data = upload_handler.get_file_data_by_id(file_id, store_data)
            
            if not file_data:
                return html.Span("æ–‡ä»¶æ•°æ®æ— æ•ˆ", style={'color': '#dc3545'})
            
            content, filename = file_data
            algorithm_name = algorithm_name.strip()
            
            # å¼‚æ­¥æ·»åŠ ç®—æ³•
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            success, error_msg = loop.run_until_complete(
                backend.add_algorithm(algorithm_name, filename, content)
            )
            loop.close()
            
            if success:
                # ç¡®ä¿æ–°æ·»åŠ çš„ç®—æ³•é»˜è®¤æ˜¾ç¤ºï¼ˆis_active åº”è¯¥å·²ç»æ˜¯ Trueï¼Œä½†ç¡®ä¿ä¸€ä¸‹ï¼‰
                algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name) if hasattr(backend, 'multi_algorithm_manager') else None
                if algorithm:
                    algorithm.is_active = True
                    logger.info(f"[OK] ç¡®ä¿ç®—æ³• '{algorithm_name}' é»˜è®¤æ˜¾ç¤º: is_active={algorithm.is_active}")
                logger.info(f"[OK] ç®—æ³• '{algorithm_name}' æ·»åŠ æˆåŠŸ")
                return html.Span("[OK] æ·»åŠ æˆåŠŸ", style={'color': '#28a745', 'fontWeight': 'bold'})
            else:
                return html.Span(f"[ERROR] {error_msg}", style={'color': '#dc3545'})
            
        except Exception as e:
            logger.error(f"[ERROR] æ·»åŠ ç®—æ³•å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return html.Span(f"æ·»åŠ å¤±è´¥: {str(e)}", style={'color': '#dc3545'})
    
    @app.callback(
        Output('algorithm-list-trigger', 'data', allow_duplicate=True),
        [Input({'type': 'algorithm-status', 'index': dash.dependencies.ALL}, 'children'),
         Input('confirm-migrate-existing-data-btn', 'n_clicks')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def trigger_algorithm_list_update(status_children, migrate_clicks, session_id):
        """å½“ç®—æ³•çŠ¶æ€æ”¹å˜æ—¶è§¦å‘ç®—æ³•åˆ—è¡¨æ›´æ–°"""
        import time
        # å½“ç®—æ³•çŠ¶æ€æ”¹å˜æˆ–è¿ç§»æŒ‰é’®è¢«ç‚¹å‡»æ—¶ï¼Œè§¦å‘åˆ—è¡¨æ›´æ–°
        # è¿™ä¼šåœ¨ç®—æ³•æ·»åŠ æˆåŠŸåè‡ªåŠ¨è§¦å‘ï¼Œå› ä¸º algorithm-status ä¼šæ›´æ–°
        # status_children å¯èƒ½æ˜¯ None æˆ–ç©ºåˆ—è¡¨ï¼ˆå½“æ²¡æœ‰ç®—æ³•æ—¶ï¼‰ï¼Œéœ€è¦å¤„ç†
        if status_children is None:
            status_children = []
        trigger_value = time.time()
        logger.info(f"[PROCESS] è§¦å‘ç®—æ³•åˆ—è¡¨æ›´æ–°: trigger_value={trigger_value}, status_childrenæ•°é‡={len(status_children) if status_children else 0}")
        return trigger_value
    
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('report-content', 'children', allow_duplicate=True)],
        [Input('algorithm-list-trigger', 'data'),
         Input({'type': 'algorithm-toggle', 'index': dash.dependencies.ALL}, 'value')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def update_plot_on_algorithm_change(trigger_data, toggle_values, session_id):
        """å½“ç®—æ³•æ·»åŠ /åˆ é™¤/åˆ‡æ¢æ—¶ï¼Œè‡ªåŠ¨æ›´æ–°ç€‘å¸ƒå›¾å’ŒæŠ¥å‘Š"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update
        
        # ç¡®ä¿å¤šç®—æ³•æ¨¡å¼å·²å¯ç”¨
        # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
        if not backend.multi_algorithm_manager:
            backend._ensure_multi_algorithm_manager()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
        active_algorithms = backend.get_active_algorithms()
        if not active_algorithms:
            # æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ˜¾ç¤ºç©ºå›¾è¡¨
            empty_fig = _create_empty_figure_for_callback("è¯·è‡³å°‘æ¿€æ´»ä¸€ä¸ªç®—æ³•ä»¥æŸ¥çœ‹ç€‘å¸ƒå›¾")
            # ä½¿ç”¨ create_report_layout ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€çš„ç»„ä»¶
            empty_report = create_report_layout(backend)
            return empty_fig, empty_report
        
        try:
            # ç”Ÿæˆå¤šç®—æ³•ç€‘å¸ƒå›¾
            logger.info(f"[PROCESS] æ›´æ–°å¤šç®—æ³•ç€‘å¸ƒå›¾ï¼Œå…± {len(active_algorithms)} ä¸ªæ¿€æ´»ç®—æ³•")
            fig = backend.generate_waterfall_plot()
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹ï¼ˆå¤šç®—æ³•æ¨¡å¼ä¸‹çš„æŠ¥å‘Šï¼‰
            report_content = create_report_layout(backend)
            
            logger.info("[OK] å¤šç®—æ³•ç€‘å¸ƒå›¾å’ŒæŠ¥å‘Šæ›´æ–°å®Œæˆ")
            return fig, report_content
            
        except Exception as e:
            logger.error(f"[ERROR] æ›´æ–°å¤šç®—æ³•ç€‘å¸ƒå›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            error_fig = _create_empty_figure_for_callback(f"æ›´æ–°å¤±è´¥: {str(e)}")
            # ä½¿ç”¨ create_report_layout ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€çš„ç»„ä»¶
            try:
                error_report = create_report_layout(backend)
            except:
                # å¦‚æœ create_report_layout ä¹Ÿå¤±è´¥ï¼Œè¿”å›åŒ…å«å¿…éœ€ç»„ä»¶çš„é”™è¯¯å¸ƒå±€
                empty_fig = {}
                error_report = html.Div([
                    html.H4("æ›´æ–°å¤±è´¥", className="text-center text-danger"),
                    html.P(f"é”™è¯¯ä¿¡æ¯: {str(e)}", className="text-center"),
                    # åŒ…å«æ‰€æœ‰å¿…éœ€çš„å›¾è¡¨ç»„ä»¶ï¼ˆéšè—ï¼‰ï¼Œç¡®ä¿å›è°ƒå‡½æ•°ä¸ä¼šæŠ¥é”™
                    dcc.Graph(id='key-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                    dcc.Graph(id='key-delay-zscore-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                    dcc.Graph(id='hammer-velocity-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                    # key-hammer-velocity-scatter-plot å·²åˆ é™¤ï¼ˆåŠŸèƒ½ä¸æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾é‡å¤ï¼‰
                    html.Div(id='offset-alignment-plot', style={'display': 'none'}),
                    html.Div([
                        dash_table.DataTable(
                            id='offset-alignment-table',
                            data=[],
                            columns=[]
                        )
                    ], style={'display': 'none'})
                ])
            return error_fig, error_report
    
    @app.callback(
        [Output('existing-data-migration-area', 'style'),
         Output('existing-data-migration-area', 'children')],
        [Input('session-id', 'data'),
         Input('confirm-migrate-existing-data-btn', 'n_clicks')],
        [State('existing-data-algorithm-name-input', 'value')],
        prevent_initial_call=True
    )
    def handle_existing_data_migration(session_id_trigger, migrate_clicks, algorithm_name):
        """å¤„ç†ç°æœ‰æ•°æ®è¿ç§»åŒºåŸŸçš„æ˜¾ç¤ºå’Œè¿ç§»æ“ä½œ"""
        logger.info(f"[PROCESS] handle_existing_data_migration: migrate_clicks={migrate_clicks}")
        
        # ä» session_id_trigger è·å– session_idï¼ˆå®ƒå¯èƒ½æ˜¯ None æˆ–å®é™…å€¼ï¼‰
        session_id = session_id_trigger if session_id_trigger else None
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("[WARNING] æ— æ³•è·å–backendå®ä¾‹ï¼ˆhandle_existing_data_migrationï¼‰")
            return {'display': 'none'}, None
        
        ctx = callback_context
        if not ctx.triggered:
            return {'display': 'none'}, None
        
        trigger_id = ctx.triggered[0]['prop_id']
        logger.info(f"ğŸ” è§¦å‘æº: {trigger_id}")
        
        try:
            # å¦‚æœæ˜¯ä¼šè¯åˆå§‹åŒ–è§¦å‘
            if 'session-id' in trigger_id:
                # å¤šç®—æ³•æ¨¡å¼å§‹ç»ˆå¯ç”¨
                logger.info("[INFO] å¤šç®—æ³•æ¨¡å¼å§‹ç»ˆå¯ç”¨")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰åˆ†ææ•°æ®
                has_existing_data = False
                existing_filename = None
                
                try:
                    if backend.analyzer and backend.analyzer.note_matcher and hasattr(backend.analyzer, 'matched_pairs') and len(backend.analyzer.matched_pairs) > 0:
                        has_existing_data = True
                        data_source_info = backend.get_data_source_info()
                        existing_filename = data_source_info.get('filename', 'æœªçŸ¥æ–‡ä»¶')
                        logger.info(f"[OK] æ£€æµ‹åˆ°ç°æœ‰åˆ†ææ•°æ®: {existing_filename}")
                except Exception as e:
                    logger.warning(f"[WARNING] æ£€æŸ¥ç°æœ‰æ•°æ®æ—¶å‡ºé”™: {e}")
                    has_existing_data = False
                
                if has_existing_data:
                    # æ˜¾ç¤ºè¿ç§»æç¤ºï¼ˆæŒ‰é’®å’Œè¾“å…¥æ¡†åœ¨å¸ƒå±€ä¸­å·²å®šä¹‰ï¼Œé€šè¿‡æ˜¾ç¤ºå®ƒä»¬ï¼‰
                    migration_area = dbc.Alert([
                        html.H6("æ£€æµ‹åˆ°ç°æœ‰åˆ†ææ•°æ®", className="mb-2", style={'fontWeight': 'bold'}),
                        html.P(f"æ–‡ä»¶: {existing_filename}", style={'fontSize': '14px', 'marginBottom': '10px'}),
                        html.P("è¯·ä¸ºè¿™ä¸ªç®—æ³•è¾“å…¥åç§°ï¼Œä»¥ä¾¿åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹è¿›è¡Œå¯¹æ¯”ï¼š", style={'fontSize': '14px', 'marginBottom': '10px'}),
                        html.Div(id='migration-components-placeholder', children=[
                            html.P("è¯·åœ¨ä¸‹æ–¹è¾“å…¥ç®—æ³•åç§°å¹¶ç‚¹å‡»ç¡®è®¤è¿ç§»æŒ‰é’®", style={'fontSize': '12px', 'color': '#6c757d'})
                        ])
                    ], color='info', className='mb-3')
                    logger.info("[OK] æ˜¾ç¤ºè¿ç§»æç¤ºåŒºåŸŸ")
                    return {'display': 'block'}, migration_area
                else:
                    logger.info("[INFO] æ²¡æœ‰ç°æœ‰æ•°æ®éœ€è¦è¿ç§»")
                    return {'display': 'none'}, None
            
            # å¦‚æœæ˜¯è¿ç§»æŒ‰é’®è§¦å‘
            elif 'confirm-migrate-existing-data-btn' in trigger_id:
                if not migrate_clicks or not algorithm_name or not algorithm_name.strip():
                    return no_update, no_update
                
                try:
                    # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
                    if not backend.multi_algorithm_manager:
                        backend._ensure_multi_algorithm_manager()
                    
                    algorithm_name = algorithm_name.strip()
                    logger.info(f"ğŸ“¤ å¼€å§‹è¿ç§»ç°æœ‰æ•°æ®åˆ°ç®—æ³•: {algorithm_name}")
                    success, error_msg = backend.migrate_existing_data_to_algorithm(algorithm_name)
                    
                    if success:
                        # éšè—è¿ç§»åŒºåŸŸ
                        logger.info("[OK] æ•°æ®è¿ç§»æˆåŠŸ")
                        return {'display': 'none'}, None
                    else:
                        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                        logger.error(f"[ERROR] æ•°æ®è¿ç§»å¤±è´¥: {error_msg}")
                        error_alert = dbc.Alert([
                            html.H6("è¿ç§»å¤±è´¥", className="mb-2", style={'fontWeight': 'bold', 'color': '#dc3545'}),
                            html.P(f"é”™è¯¯: {error_msg}", style={'fontSize': '14px'})
                        ], color='danger', className='mb-3')
                        return no_update, error_alert
                except Exception as e:
                    logger.error(f"[ERROR] è¿ç§»æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                    logger.error(traceback.format_exc())
                    error_alert = dbc.Alert([
                        html.H6("è¿ç§»å¤±è´¥", className="mb-2", style={'fontWeight': 'bold', 'color': '#dc3545'}),
                        html.P(f"å¼‚å¸¸: {str(e)}", style={'fontSize': '14px'})
                    ], color='danger', className='mb-3')
                    return no_update, error_alert
            else:
                # æœªçŸ¥è§¦å‘æº
                logger.warning(f"[WARNING] æœªçŸ¥è§¦å‘æº: {trigger_id}")
                return {'display': 'none'}, None
                
        except Exception as e:
            logger.error(f"[ERROR] handle_existing_data_migration å‘ç”Ÿå¼‚å¸¸: {e}")
            logger.error(traceback.format_exc())
            return {'display': 'none'}, None
        
        return {'display': 'none'}, None
    
    @app.callback(
        [Output('algorithm-list', 'children', allow_duplicate=True),
         Output('algorithm-management-status', 'children', allow_duplicate=True)],
        [Input('algorithm-list-trigger', 'data')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def update_algorithm_list(trigger_data, session_id):
        """æ›´æ–°ç®—æ³•åˆ—è¡¨æ˜¾ç¤º"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return [], ""
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            return [], ""
        
        # ç¡®ä¿å¤šç®—æ³•æ¨¡å¼å·²å¯ç”¨
        # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
        if not backend.multi_algorithm_manager:
            backend._ensure_multi_algorithm_manager()
        
        try:
            algorithms = backend.get_all_algorithms()
            
            if not algorithms:
                return [], html.Span("æš‚æ— ç®—æ³•ï¼Œè¯·ä¸Šä¼ æ–‡ä»¶", style={'color': '#6c757d'})
            
            algorithm_items = []
            for alg_info in algorithms:
                alg_name = alg_info['algorithm_name']  # å†…éƒ¨å”¯ä¸€æ ‡è¯†ï¼ˆç”¨äºæŸ¥æ‰¾ï¼‰
                display_name = alg_info.get('display_name', alg_name)  # æ˜¾ç¤ºåç§°ï¼ˆç”¨äºUIæ˜¾ç¤ºï¼‰
                filename = alg_info['filename']
                status = alg_info['status']
                # è·å–is_activeï¼Œå¦‚æœæœªè®¾ç½®æˆ–ä¸ºNoneï¼Œåˆ™é»˜è®¤ä¸ºTrueï¼ˆæ–°ä¸Šä¼ çš„æ–‡ä»¶åº”è¯¥é»˜è®¤æ˜¾ç¤ºï¼‰
                is_active = alg_info.get('is_active')
                if is_active is None:
                    is_active = True
                    # å¦‚æœis_activeä¸ºNoneï¼Œç¡®ä¿ç®—æ³•å¯¹è±¡ä¸­çš„is_activeä¹Ÿè¢«è®¾ç½®ä¸ºTrue
                    algorithm = backend.multi_algorithm_manager.get_algorithm(alg_name) if hasattr(backend, 'multi_algorithm_manager') else None
                    if algorithm:
                        algorithm.is_active = True
                        logger.info(f"[OK] ç¡®ä¿ç®—æ³• '{display_name}' é»˜è®¤æ˜¾ç¤º: is_active={is_active}")
                color = alg_info['color']
                is_ready = alg_info['is_ready']
                
                # çŠ¶æ€å›¾æ ‡
                if status == 'ready' and is_ready:
                    status_icon = html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '5px'})
                    status_text = "å°±ç»ª"
                elif status == 'loading':
                    status_icon = html.I(className="fas fa-spinner fa-spin", style={'color': '#17a2b8', 'marginRight': '5px'})
                    status_text = "åŠ è½½ä¸­"
                elif status == 'error':
                    status_icon = html.I(className="fas fa-exclamation-circle", style={'color': '#dc3545', 'marginRight': '5px'})
                    status_text = "é”™è¯¯"
                else:
                    status_icon = html.I(className="fas fa-clock", style={'color': '#ffc107', 'marginRight': '5px'})
                    status_text = "ç­‰å¾…ä¸­"
                
                # æ˜¾ç¤º/éšè—å¼€å…³
                toggle_switch = dbc.Switch(
                    id={'type': 'algorithm-toggle', 'index': alg_name},
                    label='æ˜¾ç¤º',
                    value=is_active,
                    style={'fontSize': '12px'}
                )
                
                algorithm_items.append(
                    dbc.Card([
                        dbc.CardBody([
                            html.Div([
                                html.Div([
                                    html.Span(display_name, style={'fontWeight': 'bold', 'fontSize': '14px', 'color': color}),
                                    html.Br(),
                                    html.Small(filename, style={'color': '#6c757d', 'fontSize': '11px'}),
                                    html.Br(),
                                    html.Small([status_icon, status_text], style={'fontSize': '11px'})
                                ], style={'flex': '1'}),
                                html.Div([
                                    toggle_switch,
                                    dbc.Button("åˆ é™¤", 
                                             id={'type': 'algorithm-delete-btn', 'index': alg_name},
                                             color='danger',
                                             size='sm',
                                             n_clicks=0,
                                             style={'marginTop': '5px', 'width': '100%'})
                                ], style={'marginLeft': '10px'})
                            ], style={'display': 'flex', 'justifyContent': 'space-between', 'alignItems': 'center'})
                        ])
                    ], className='mb-2', style={'border': f'2px solid {color}', 'borderRadius': '5px'})
                )
            
            # åˆ›å»ºç®—æ³•åˆ—è¡¨ï¼ˆä½¿ç”¨åˆ—è¡¨è€Œä¸æ˜¯Divï¼Œä¿æŒä¸€è‡´æ€§ï¼‰
            algorithm_list = algorithm_items  # ç›´æ¥è¿”å›åˆ—è¡¨ï¼ŒDashä¼šè‡ªåŠ¨å¤„ç†
            status_text = html.Span(f"å…± {len(algorithms)} ä¸ªç®—æ³•", style={'color': '#6c757d'})
            
            return algorithm_list, status_text
            
        except Exception as e:
            logger.error(f"[ERROR] æ›´æ–°ç®—æ³•åˆ—è¡¨å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return [], html.Span(f"æ›´æ–°å¤±è´¥: {str(e)}", style={'color': '#dc3545'})
    
    @app.callback(
        [Output('algorithm-list', 'children', allow_duplicate=True),
         Output('algorithm-management-status', 'children', allow_duplicate=True),
         Output('algorithm-list-trigger', 'data', allow_duplicate=True),
         Output('multi-algorithm-file-list', 'children', allow_duplicate=True),
         Output('multi-algorithm-upload-status', 'children', allow_duplicate=True),
         Output('multi-algorithm-files-store', 'data', allow_duplicate=True)],
        [Input({'type': 'algorithm-toggle', 'index': dash.dependencies.ALL}, 'value'),
         Input({'type': 'algorithm-delete-btn', 'index': dash.dependencies.ALL}, 'n_clicks')],
        [State({'type': 'algorithm-toggle', 'index': dash.dependencies.ALL}, 'id'),
         State({'type': 'algorithm-delete-btn', 'index': dash.dependencies.ALL}, 'id'),
         State('session-id', 'data'),
         State('multi-algorithm-files-store', 'data')],
        prevent_initial_call=True
    )
    def handle_algorithm_management(toggle_values, delete_clicks_list, toggle_ids, delete_ids, session_id, store_data):
        """å¤„ç†ç®—æ³•ç®¡ç†æ“ä½œï¼ˆæ˜¾ç¤º/éšè—ã€åˆ é™¤ï¼‰"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        # ç¡®ä¿å¤šç®—æ³•æ¨¡å¼å·²å¯ç”¨
        # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
        if not backend.multi_algorithm_manager:
            backend._ensure_multi_algorithm_manager()
        
        ctx = callback_context
        if not ctx.triggered:
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        trigger_id = ctx.triggered[0]['prop_id']
        
        # æ ‡è®°æ˜¯å¦åˆ é™¤äº†ç®—æ³•ï¼Œç”¨äºæ›´æ–°æ–‡ä»¶åˆ—è¡¨
        algorithm_deleted = False
        deleted_algorithm_filename = None
        
        try:
            # è§£æ trigger_idï¼Œæ ¼å¼é€šå¸¸æ˜¯ '{"type":"...","index":"..."}.property'
            import json
            trigger_prop_id = trigger_id.split('.')[0]
            try:
                trigger_data = json.loads(trigger_prop_id)
                algorithm_name = trigger_data.get('index', '')
            except (json.JSONDecodeError, KeyError):
                logger.error(f"æ— æ³•è§£æ trigger_id: {trigger_id}")
                return no_update, no_update, no_update, no_update, no_update, no_update
            
            if 'algorithm-toggle' in trigger_id:
                # æ ¹æ®å¼€å…³çš„æ–°å€¼è®¾ç½®æ˜¾ç¤º/éšè—çŠ¶æ€ï¼ˆè€Œä¸æ˜¯åˆ‡æ¢ï¼‰
                # æ‰¾åˆ°å¯¹åº”çš„å¼€å…³ç´¢å¼•å’Œå€¼
                if toggle_values and toggle_ids:
                    for i, toggle_id in enumerate(toggle_ids):
                        if toggle_id and toggle_id.get('index') == algorithm_name:
                            new_value = toggle_values[i] if i < len(toggle_values) else None
                            if new_value is not None:
                                # è·å–ç®—æ³•å¯¹è±¡
                                algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name) if hasattr(backend, 'multi_algorithm_manager') else None
                                if algorithm:
                                    # ç›´æ¥è®¾ç½®ä¸ºæ–°å€¼ï¼Œè€Œä¸æ˜¯åˆ‡æ¢
                                    if algorithm.is_active != new_value:
                                        algorithm.is_active = new_value
                                        logger.info(f"[OK] ç®—æ³• '{algorithm_name}' æ˜¾ç¤ºçŠ¶æ€è®¾ç½®ä¸º: {'æ˜¾ç¤º' if new_value else 'éšè—'}")
                                    else:
                                        logger.debug(f"[INFO] ç®—æ³• '{algorithm_name}' æ˜¾ç¤ºçŠ¶æ€æœªå˜åŒ–: {new_value}")
                            break
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„å¼€å…³ï¼Œä½¿ç”¨åˆ‡æ¢æ–¹å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                    backend.toggle_algorithm(algorithm_name)
            elif 'algorithm-delete-btn' in trigger_id:
                # åˆ é™¤ç®—æ³•
                # æ£€æŸ¥æ˜¯å¦æœ‰ç‚¹å‡»ï¼ˆn_clicks > 0ï¼‰
                if delete_clicks_list:
                    # æ‰¾åˆ°å¯¹åº”çš„æŒ‰é’®ç´¢å¼•
                    for i, delete_id in enumerate(delete_ids):
                        if delete_id and delete_id.get('index') == algorithm_name:
                            if delete_clicks_list[i] and delete_clicks_list[i] > 0:
                                # åœ¨åˆ é™¤å‰è·å–ç®—æ³•ä¿¡æ¯ï¼Œä»¥ä¾¿ä»æ–‡ä»¶åˆ—è¡¨ä¸­ç§»é™¤
                                algorithms_before = backend.get_all_algorithms()
                                for alg_info in algorithms_before:
                                    if alg_info['algorithm_name'] == algorithm_name:
                                        deleted_algorithm_filename = alg_info.get('filename', '')
                                        break
                                
                                backend.remove_algorithm(algorithm_name)
                                algorithm_deleted = True

                                logger.info(f"[OK] ç®—æ³• '{algorithm_name}' å·²åˆ é™¤")
                                break
                    else:
                        return no_update, no_update, no_update, no_update, no_update, no_update
                else:
                    return no_update, no_update, no_update, no_update, no_update, no_update
            else:
                return no_update, no_update, no_update, no_update, no_update, no_update
            
            # é‡æ–°è·å–ç®—æ³•åˆ—è¡¨
            algorithms = backend.get_all_algorithms()
            
            # æ›´æ–°æ–‡ä»¶åˆ—è¡¨ï¼šå¦‚æœåˆ é™¤äº†ç®—æ³•ï¼Œä»æ–‡ä»¶åˆ—è¡¨ä¸­ç§»é™¤å¯¹åº”çš„æ–‡ä»¶
            # æ— è®ºæ˜¯å¦åˆ é™¤äº†ç®—æ³•ï¼Œéƒ½è¦æ›´æ–°æ–‡ä»¶åˆ—è¡¨ï¼Œç¡®ä¿åªæ˜¾ç¤ºæœªæ·»åŠ çš„æ–‡ä»¶
            file_list_children = no_update
            upload_status_text = no_update
            updated_store_data = no_update

            # è·å–æ‰€æœ‰å·²æ·»åŠ ç®—æ³•çš„æ–‡ä»¶å
            added_filenames = set()
            for alg_info in algorithms:
                added_filenames.add(alg_info.get('filename', ''))
                
            # å¦‚æœåˆ é™¤äº†ç®—æ³•ï¼Œæˆ–è€…æœ‰store_dataï¼Œéƒ½éœ€è¦æ›´æ–°æ–‡ä»¶åˆ—è¡¨
            if algorithm_deleted or (store_data and 'filenames' in store_data):
                # ä»store_dataä¸­è·å–æ–‡ä»¶åˆ—è¡¨
                if store_data and 'contents' in store_data and 'filenames' in store_data:
                    contents_list = store_data.get('contents', [])
                    filenames_list = store_data.get('filenames', [])
                    file_ids = store_data.get('file_ids', [])
                    
                    # è¿‡æ»¤å‡ºæœªæ·»åŠ çš„æ–‡ä»¶
                    filtered_contents = []
                    filtered_filenames = []
                    filtered_file_ids = []
                    
                    for i, filename in enumerate(filenames_list):
                        if filename not in added_filenames:
                            if i < len(contents_list):
                                filtered_contents.append(contents_list[i])
                            filtered_filenames.append(filename)
                            if i < len(file_ids):
                                filtered_file_ids.append(file_ids[i])
                    
                    # æ›´æ–°store_data
                    updated_store_data = {
                        'contents': filtered_contents,
                        'filenames': filtered_filenames,
                        'file_ids': filtered_file_ids
                    }

                    # ç›´æ¥ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨UIï¼Œä½¿ç”¨ç°æœ‰çš„æ–‡ä»¶IDï¼Œé¿å…é‡å¤åˆå¹¶
                    from ui.multi_file_upload_handler import MultiFileUploadHandler
                    upload_handler = MultiFileUploadHandler()
                    # ç›´æ¥ä½¿ç”¨è¿‡æ»¤åçš„æ–‡ä»¶åˆ—è¡¨ç”ŸæˆUIï¼Œä¸è°ƒç”¨process_uploaded_filesé¿å…é‡å¤åˆå¹¶
                    file_items = []
                    for i, (content, filename, file_id) in enumerate(zip(
                            filtered_contents, 
                            filtered_filenames, 
                        filtered_file_ids
                    )):
                        # ç¡®ä¿ä¸ä¼šæ˜¾ç¤ºå·²æ·»åŠ çš„æ–‡ä»¶ï¼ˆåŒé‡æ£€æŸ¥ï¼‰
                        if filename not in added_filenames:
                            file_card = upload_handler.create_file_card(file_id, filename)
                            file_items.append(file_card)
                    
                    file_list_children = html.Div(file_items) if file_items else []
                    # ç”Ÿæˆä¸Šä¼ çŠ¶æ€æ–‡æœ¬
                    total_files = len(filtered_filenames)
                    if total_files > 0:
                        upload_status_text = html.Span(
                            f"å…± {total_files} ä¸ªæ–‡ä»¶ï¼Œè¯·ä¸ºæ¯ä¸ªæ–‡ä»¶è¾“å…¥ç®—æ³•åç§°",
                            style={'color': '#17a2b8', 'fontWeight': 'bold'}
                        )
                    else:
                        upload_status_text = html.Span("", style={'color': '#6c757d'})
                elif algorithm_deleted:
                    # å¦‚æœåˆ é™¤äº†ç®—æ³•ä½†æ²¡æœ‰store_dataï¼Œæ¸…ç©ºæ–‡ä»¶åˆ—è¡¨
                    file_list_children = []
                    upload_status_text = html.Span("", style={'color': '#6c757d'})
                    updated_store_data = {'contents': [], 'filenames': [], 'file_ids': []}
            
            if not algorithms:
                # è¿”å›ç©ºåˆ—è¡¨å’ŒçŠ¶æ€æ–‡æœ¬ï¼Œä»¥åŠè§¦å‘æ›´æ–°
                empty_list = []  # ç©ºåˆ—è¡¨ï¼Œè€Œä¸æ˜¯ Div
                status_text = html.Span("æš‚æ— ç®—æ³•ï¼Œè¯·ä¸Šä¼ æ–‡ä»¶", style={'color': '#6c757d'})
                # å¦‚æœæ²¡æœ‰ç®—æ³•äº†ï¼Œä¹Ÿæ¸…ç©ºæ–‡ä»¶åˆ—è¡¨
                if file_list_children == no_update:
                    file_list_children = []
                if updated_store_data == no_update:
                    updated_store_data = {'contents': [], 'filenames': [], 'file_ids': []}
                if upload_status_text == no_update:
                    upload_status_text = html.Span("", style={'color': '#6c757d'})
                return empty_list, status_text, time.time(), file_list_children, upload_status_text, updated_store_data
            
            algorithm_items = []
            for alg_info in algorithms:
                alg_name = alg_info['algorithm_name']
                filename = alg_info['filename']
                status = alg_info['status']
                is_active = alg_info['is_active']
                color = alg_info['color']
                is_ready = alg_info['is_ready']
                
                if status == 'ready' and is_ready:
                    status_icon = html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '5px'})
                    status_text = "å°±ç»ª"
                elif status == 'loading':
                    status_icon = html.I(className="fas fa-spinner fa-spin", style={'color': '#17a2b8', 'marginRight': '5px'})
                    status_text = "åŠ è½½ä¸­"
                elif status == 'error':
                    status_icon = html.I(className="fas fa-exclamation-circle", style={'color': '#dc3545', 'marginRight': '5px'})
                    status_text = "é”™è¯¯"
                else:
                    status_icon = html.I(className="fas fa-clock", style={'color': '#ffc107', 'marginRight': '5px'})
                    status_text = "ç­‰å¾…ä¸­"
                
                toggle_switch = dbc.Switch(
                    id={'type': 'algorithm-toggle', 'index': alg_name},
                    label='æ˜¾ç¤º',
                    value=is_active,
                    style={'fontSize': '12px'}
                )
                
                algorithm_items.append(
                    dbc.Card([
                        dbc.CardBody([
                            html.Div([
                                html.Div([
                                    html.Span(alg_name, style={'fontWeight': 'bold', 'fontSize': '14px', 'color': color}),
                                    html.Br(),
                                    html.Small(filename, style={'color': '#6c757d', 'fontSize': '11px'}),
                                    html.Br(),
                                    html.Small([status_icon, status_text], style={'fontSize': '11px'})
                                ], style={'flex': '1'}),
                                html.Div([
                                    toggle_switch,
                                    dbc.Button("åˆ é™¤", 
                                             id={'type': 'algorithm-delete-btn', 'index': alg_name},
                                             color='danger',
                                             size='sm',
                                             n_clicks=0,
                                             style={'marginTop': '5px', 'width': '100%'})
                                ], style={'marginLeft': '10px'})
                            ], style={'display': 'flex', 'justifyContent': 'space-between', 'alignItems': 'center'})
                        ])
                    ], className='mb-2', style={'border': f'2px solid {color}', 'borderRadius': '5px'})
                )
            
            # åˆ›å»ºç®—æ³•åˆ—è¡¨ï¼ˆä½¿ç”¨åˆ—è¡¨è€Œä¸æ˜¯Divï¼Œä¿æŒä¸€è‡´æ€§ï¼‰
            algorithm_list = algorithm_items  # ç›´æ¥è¿”å›åˆ—è¡¨ï¼ŒDashä¼šè‡ªåŠ¨å¤„ç†
            status_text = html.Span(f"å…± {len(algorithms)} ä¸ªç®—æ³•", style={'color': '#6c757d'})
            
            # å¦‚æœæ²¡æœ‰æ›´æ–°ä¸Šä¼ çŠ¶æ€æ–‡æœ¬ï¼Œæ ¹æ®æ–‡ä»¶åˆ—è¡¨ç”Ÿæˆ
            if upload_status_text == no_update:
                if updated_store_data != no_update and isinstance(updated_store_data, dict):
                    total_files = len(updated_store_data.get('filenames', []))
                    if total_files > 0:
                        upload_status_text = html.Span(
                            f"å…± {total_files} ä¸ªæ–‡ä»¶ï¼Œè¯·ä¸ºæ¯ä¸ªæ–‡ä»¶è¾“å…¥ç®—æ³•åç§°",
                            style={'color': '#17a2b8', 'fontWeight': 'bold'}
                        )
                    else:
                        upload_status_text = html.Span("", style={'color': '#6c757d'})
                elif store_data and isinstance(store_data, dict):
                    total_files = len(store_data.get('filenames', []))
                    # è¿‡æ»¤æ‰å·²æ·»åŠ çš„æ–‡ä»¶
                    added_filenames = set()
                    for alg_info in algorithms:
                        added_filenames.add(alg_info.get('filename', ''))
                    filtered_count = sum(1 for f in store_data.get('filenames', []) if f not in added_filenames)
                    if filtered_count > 0:
                        upload_status_text = html.Span(
                            f"å…± {filtered_count} ä¸ªæ–‡ä»¶ï¼Œè¯·ä¸ºæ¯ä¸ªæ–‡ä»¶è¾“å…¥ç®—æ³•åç§°",
                            style={'color': '#17a2b8', 'fontWeight': 'bold'}
                        )
                    else:
                        upload_status_text = html.Span("", style={'color': '#6c757d'})
                else:
                    upload_status_text = html.Span("", style={'color': '#6c757d'})
            
            return algorithm_list, status_text, time.time(), file_list_children, upload_status_text, updated_store_data
            
        except Exception as e:
            logger.error(f"[ERROR] å¤„ç†ç®—æ³•ç®¡ç†æ“ä½œå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return no_update, no_update, no_update, no_update, no_update, no_update
    
    # æ›´æ–°å•é”®é€‰æ‹©å™¨çš„é€‰é¡¹
    @app.callback(
        Output('single-key-selector', 'options'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def update_single_key_selector_options(report_content, session_id):
        backend = session_manager.get_backend(session_id)
        if not backend or not hasattr(backend, 'multi_algorithm_manager'):
            return []
            
        try:
            active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
            if not active_algorithms:
                return []
                
            all_keys = set()
            for alg in active_algorithms:
                if alg.analyzer and alg.analyzer.note_matcher:
                    offset_data = alg.analyzer.note_matcher.get_offset_alignment_data()
                    if offset_data:
                        for item in offset_data:
                            if item.get('key_id') is not None:
                                all_keys.add(item.get('key_id'))
                                
            sorted_keys = sorted(list(all_keys))
            return [{'label': f'Key {k}', 'value': k} for k in sorted_keys]
            
        except Exception as e:
            logger.error(f"[ERROR] æ›´æ–°å•é”®é€‰æ‹©å™¨å¤±è´¥: {e}")
            return []

    # å•é”®å¤šæ›²å»¶æ—¶å¯¹æ¯”å›¾è‡ªåŠ¨ç”Ÿæˆå›è°ƒ
    @app.callback(
        Output('single-key-delay-comparison-plot', 'figure'),
        [Input('single-key-selector', 'value'),
         Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_single_key_comparison_plot(key_id, report_content, session_id):
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update

        if not key_id:
            # è¿”å›ç©ºå›¾è¡¨æç¤º
            return {
                "layout": {
                    "xaxis": {"visible": False},
                    "yaxis": {"visible": False},
                    "annotations": [
                        {
                            "text": "è¯·é€‰æ‹©ä¸€ä¸ªæŒ‰é”®è¿›è¡Œåˆ†æ",
                            "xref": "paper",
                            "yref": "paper",
                            "showarrow": False,
                            "font": {"size": 20},
                            "x": 0.5,
                            "y": 0.5
                        }
                    ]
                }
            }
            
        try:
            fig = backend.generate_single_key_delay_comparison_plot(key_id)
            return fig
        except Exception as e:
            logger.error(f"[ERROR] ç”Ÿæˆå•é”®å¯¹æ¯”å›¾å¤±è´¥: {e}")
            return backend.plot_generator._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")

    # æŒ‰é”®å»¶æ—¶åˆ†æè¡¨æ ¼ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæŒ‰é”®æ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True)],
        [Input('offset-alignment-table', 'active_cell'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('offset-alignment-table', 'data'),
         State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_key_table_click(active_cell, close_modal_clicks, close_btn_clicks, table_data, session_id, current_style):
        """å¤„ç†æŒ‰é”®å»¶æ—¶åˆ†æè¡¨æ ¼ç‚¹å‡»ï¼Œæ˜¾ç¤ºæŒ‰é”®æ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾"""
        
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            logger.debug("[WARNING] æŒ‰é”®è¡¨æ ¼ç‚¹å‡»å›è°ƒï¼šæ²¡æœ‰è§¦å‘æº")
            return current_style, [], no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"[PROCESS] æŒ‰é”®è¡¨æ ¼ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            logger.info("[OK] å…³é—­æŒ‰é”®æ›²çº¿å¯¹æ¯”æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, [], no_update
        
        # å¦‚æœæ˜¯è¡¨æ ¼ç‚¹å‡»
        if trigger_id == 'offset-alignment-table':
            logger.info(f"[PROCESS] è¡¨æ ¼ç‚¹å‡»ï¼šactive_cell={active_cell}, table_dataé•¿åº¦={len(table_data) if table_data else 0}")
            backend = session_manager.get_backend(session_id)
            if not backend:
                logger.warning("[WARNING] æ²¡æœ‰æ‰¾åˆ°backend")
                return current_style, [], no_update
            if not active_cell or not table_data:
                logger.warning("[WARNING] active_cellæˆ–table_dataä¸ºç©º")
                return current_style, [], no_update
            
            try:
                # è·å–ç‚¹å‡»çš„è¡Œæ•°æ®
                row_idx = active_cell.get('row')
                if row_idx is None or row_idx >= len(table_data):
                    return current_style, [], no_update
                
                row_data = table_data[row_idx]
                algorithm_name = row_data.get('algorithm_name')
                key_id_str = row_data.get('key_id')
                
                # è·³è¿‡æ±‡æ€»è¡Œ
                if key_id_str in ['æ€»ä½“', 'æ±‡æ€»'] or not algorithm_name:
                    return current_style, [], no_update
                
                # è½¬æ¢æŒ‰é”®ID
                try:
                    key_id = int(key_id_str)
                except (ValueError, TypeError):
                    return current_style, [], no_update
                
                # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
                if not backend.multi_algorithm_mode or not backend.multi_algorithm_manager:
                    logger.info("[INFO] ä¸åœ¨å¤šç®—æ³•æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºæ›²çº¿å¯¹æ¯”å›¾")
                    return current_style, [], no_update
                
                # è·å–æ¿€æ´»çš„ç®—æ³•åˆ—è¡¨
                active_algorithms = backend.get_active_algorithms()
                if len(active_algorithms) < 2:
                    modal_style = {
                        'display': 'block',
                        'position': 'fixed',
                        'zIndex': '9999',
                        'left': '0',
                        'top': '0',
                        'width': '100%',
                        'height': '100%',
                        'backgroundColor': 'rgba(0,0,0,0.6)',
                        'backdropFilter': 'blur(5px)'
                    }
                    return modal_style, [html.Div([
                        html.P("éœ€è¦è‡³å°‘2ä¸ªæ¿€æ´»çš„ç®—æ³•æ‰èƒ½è¿›è¡Œå¯¹æ¯”", className="text-muted text-center")
                    ])], no_update
                
                # è·å–æ‰€æœ‰æ¿€æ´»ç®—æ³•çš„åŒ¹é…å¯¹
                algorithm_pairs_dict = {}
                all_timestamps = set()
                
                for alg in active_algorithms:
                    alg_name = alg.metadata.algorithm_name
                    pairs = backend.get_key_matched_pairs_by_algorithm(alg_name, key_id)
                    if pairs:
                        algorithm_pairs_dict[alg_name] = pairs
                        for _, _, _, _, timestamp in pairs:
                            all_timestamps.add(timestamp)
                
                if not algorithm_pairs_dict:
                    modal_style = {
                        'display': 'block',
                        'position': 'fixed',
                        'zIndex': '9999',
                        'left': '0',
                        'top': '0',
                        'width': '100%',
                        'height': '100%',
                        'backgroundColor': 'rgba(0,0,0,0.6)',
                        'backdropFilter': 'blur(5px)'
                    }
                    return modal_style, [html.Div([
                        html.P(f"æŒ‰é”®ID {key_id} åœ¨æ‰€æœ‰æ¿€æ´»ç®—æ³•ä¸­éƒ½æ²¡æœ‰åŒ¹é…æ•°æ®", className="text-muted text-center")
                    ])], no_update
                
                # é€‰æ‹©å‰ä¸¤ä¸ªæœ‰æ•°æ®çš„ç®—æ³•è¿›è¡Œå¯¹æ¯”
                alg_names = list(algorithm_pairs_dict.keys())[:2]
                if len(alg_names) < 2:
                    # å¦‚æœåªæœ‰ä¸€ä¸ªç®—æ³•æœ‰æ•°æ®ï¼Œé€‰æ‹©å‰ä¸¤ä¸ªæ¿€æ´»çš„ç®—æ³•ï¼ˆå³ä½¿ç¬¬äºŒä¸ªæ²¡æœ‰æ•°æ®ï¼‰
                    alg_names = [alg.metadata.algorithm_name for alg in active_algorithms[:2]]
                    if alg_names[0] not in algorithm_pairs_dict:
                        alg_names[0] = list(algorithm_pairs_dict.keys())[0]
                
                alg1_name = alg_names[0]
                alg2_name = alg_names[1]
                
                alg1_pairs = algorithm_pairs_dict.get(alg1_name, [])
                alg2_pairs = algorithm_pairs_dict.get(alg2_name, [])
                
                # ç”Ÿæˆå¯¹æ¯”æ›²çº¿å›¾
                import spmid
                from plotly.subplots import make_subplots
                
                comparison_rows = []
                
                # ä½¿ç”¨åŒæŒ‡é’ˆæŒ‰æ—¶é—´æˆ³å¯¹é½
                # æ³¨æ„ï¼šä¸¤ä¸ªç®—æ³•å¤„ç†çš„æ˜¯å®Œå…¨ä¸åŒçš„SPMIDæ–‡ä»¶ï¼Œå„è‡ªæœ‰ç‹¬ç«‹çš„å½•åˆ¶æ•°æ®å’Œæ’­æ”¾æ•°æ®
                # - ç®—æ³•Aï¼šSPMIDæ–‡ä»¶1çš„å½•åˆ¶æ•°æ®1 vs æ’­æ”¾æ•°æ®1
                # - ç®—æ³•Bï¼šSPMIDæ–‡ä»¶2çš„å½•åˆ¶æ•°æ®2 vs æ’­æ”¾æ•°æ®2
                # å®ƒä»¬ä¹‹é—´æ²¡æœ‰ä»»ä½•å…³è”ï¼Œrecord_indexå’Œrecord_keyonéƒ½æ˜¯å„è‡ªæ–‡ä»¶å†…çš„
                # æ­¥éª¤ï¼š
                # - æå–ä¸¤ä¸ªç®—æ³•çš„æ—¶é—´æˆ³åºåˆ—ï¼ˆå•ä½ï¼š0.1msï¼Œrecord_keyonæ˜¯å„è‡ªæ–‡ä»¶å†…å½•åˆ¶æŒ‰é”®å¼€å§‹æ—¶é—´ï¼‰
                # - ä½¿ç”¨ä¸¤ä¸ªæŒ‡é’ˆåœ¨åˆå¹¶æ—¶é—´çº¿ä¸Šå‰è¿›ï¼Œå°½é‡å°†æ—¶é—´ä¸´è¿‘çš„é…å¯¹ï¼Œå¦åˆ™å•ä¾§æ˜¾ç¤º
                ALIGN_WINDOW_01MS = 200  # å¯¹é½çª—å£ï¼š200(0.1ms) = 20ms
                
                alg1_pairs_sorted = sorted(alg1_pairs, key=lambda p: p[4])
                alg2_pairs_sorted = sorted(alg2_pairs, key=lambda p: p[4])
                i, j = 0, 0
                while i < len(alg1_pairs_sorted) or j < len(alg2_pairs_sorted):
                    if i < len(alg1_pairs_sorted) and j < len(alg2_pairs_sorted):
                        t1 = alg1_pairs_sorted[i][4]
                        t2 = alg2_pairs_sorted[j][4]
                        diff = abs(t1 - t2)
                        if diff <= ALIGN_WINDOW_01MS:
                            # é…å¯¹æ˜¾ç¤º
                            comparison_rows.append((alg1_pairs_sorted[i], alg2_pairs_sorted[j], t1, t2))
                            i += 1
                            j += 1
                        elif t1 < t2:
                            # å·¦ä¾§å•ç‹¬æ˜¾ç¤º
                            comparison_rows.append((alg1_pairs_sorted[i], None, t1, None))
                            i += 1
                        else:
                            # å³ä¾§å•ç‹¬æ˜¾ç¤º
                            comparison_rows.append((None, alg2_pairs_sorted[j], None, t2))
                            j += 1
                    elif i < len(alg1_pairs_sorted):
                        t1 = alg1_pairs_sorted[i][4]
                        comparison_rows.append((alg1_pairs_sorted[i], None, t1, None))
                        i += 1
                    else:
                        t2 = alg2_pairs_sorted[j][4]
                        comparison_rows.append((None, alg2_pairs_sorted[j], None, t2))
                        j += 1
                
                # ä¸ºæ¯ä¸ªå¯¹é½é¡¹åˆ›å»ºå¯¹æ¯”å›¾
                rendered_rows = []
                for alg1_pair, alg2_pair, t1, t2 in comparison_rows:
                    if not alg1_pair and not alg2_pair:
                        continue
                    
                    # åˆ›å»ºå·¦å³å¯¹æ¯”çš„å­å›¾ï¼Œæ ‡é¢˜æ˜¾ç¤ºå„è‡ªæ—¶é—´
                    # record_keyonï¼šå„è‡ªSPMIDæ–‡ä»¶å†…å½•åˆ¶æŒ‰é”®å¼€å§‹æ—¶é—´ï¼ˆä¸¤ä¸ªæ–‡ä»¶ç‹¬ç«‹ï¼Œæ—¶é—´æˆ³æ— å…³è”ï¼‰
                    if alg1_pair and t1 is not None:
                        title1 = f"{alg1_name}<br>å½•åˆ¶æŒ‰é”®å¼€å§‹: {t1/10:.2f}ms"
                    else:
                        title1 = f"{alg1_name} (æ— æ•°æ®)"
                    
                    if alg2_pair and t2 is not None:
                        title2 = f"{alg2_name}<br>å½•åˆ¶æŒ‰é”®å¼€å§‹: {t2/10:.2f}ms"
                    else:
                        title2 = f"{alg2_name} (æ— æ•°æ®)"
                    
                    fig = make_subplots(
                        rows=1, cols=2,
                        subplot_titles=(title1, title2),
                        horizontal_spacing=0.15
                    )
                    
                    # å·¦ä¾§ï¼šç®—æ³•1çš„æ›²çº¿
                    if alg1_pair:
                        _, _, record_note1, replay_note1, _ = alg1_pair
                        if record_note1 and hasattr(record_note1, 'after_touch') and not record_note1.after_touch.empty:
                            x_at = (record_note1.after_touch.index + record_note1.offset) / 10.0
                            y_at = record_note1.after_touch.values
                            fig.add_trace(go.Scatter(x=x_at, y=y_at, mode='lines', name='å½•åˆ¶è§¦å', 
                                                    line=dict(color='blue', width=2), showlegend=False), row=1, col=1)
                        if record_note1 and hasattr(record_note1, 'hammers') and not record_note1.hammers.empty:
                            x_hm = (record_note1.hammers.index + record_note1.offset) / 10.0
                            y_hm = record_note1.hammers.values
                            fig.add_trace(go.Scatter(x=x_hm, y=y_hm, mode='markers', name='å½•åˆ¶é”¤å­',
                                                    marker=dict(color='blue', size=6), showlegend=False), row=1, col=1)
                        if replay_note1 and hasattr(replay_note1, 'after_touch') and not replay_note1.after_touch.empty:
                            x_at = (replay_note1.after_touch.index + replay_note1.offset) / 10.0
                            y_at = replay_note1.after_touch.values
                            fig.add_trace(go.Scatter(x=x_at, y=y_at, mode='lines', name='å›æ”¾è§¦å',
                                                    line=dict(color='red', width=2), showlegend=False), row=1, col=1)
                        if replay_note1 and hasattr(replay_note1, 'hammers') and not replay_note1.hammers.empty:
                            x_hm = (replay_note1.hammers.index + replay_note1.offset) / 10.0
                            y_hm = replay_note1.hammers.values
                            fig.add_trace(go.Scatter(x=x_hm, y=y_hm, mode='markers', name='å›æ”¾é”¤å­',
                                                    marker=dict(color='red', size=6), showlegend=False), row=1, col=1)
                    
                    # å³ä¾§ï¼šç®—æ³•2çš„æ›²çº¿
                    if alg2_pair:
                        _, _, record_note2, replay_note2, _ = alg2_pair
                        if record_note2 and hasattr(record_note2, 'after_touch') and not record_note2.after_touch.empty:
                            x_at = (record_note2.after_touch.index + record_note2.offset) / 10.0
                            y_at = record_note2.after_touch.values
                            fig.add_trace(go.Scatter(x=x_at, y=y_at, mode='lines', name='å½•åˆ¶è§¦å',
                                                    line=dict(color='blue', width=2), showlegend=False), row=1, col=2)
                        if record_note2 and hasattr(record_note2, 'hammers') and not record_note2.hammers.empty:
                            x_hm = (record_note2.hammers.index + record_note2.offset) / 10.0
                            y_hm = record_note2.hammers.values
                            fig.add_trace(go.Scatter(x=x_hm, y=y_hm, mode='markers', name='å½•åˆ¶é”¤å­',
                                                    marker=dict(color='blue', size=6), showlegend=False), row=1, col=2)
                        if replay_note2 and hasattr(replay_note2, 'after_touch') and not replay_note2.after_touch.empty:
                            x_at = (replay_note2.after_touch.index + replay_note2.offset) / 10.0
                            y_at = replay_note2.after_touch.values
                            fig.add_trace(go.Scatter(x=x_at, y=y_at, mode='lines', name='å›æ”¾è§¦å',
                                                    line=dict(color='red', width=2), showlegend=False), row=1, col=2)
                        if replay_note2 and hasattr(replay_note2, 'hammers') and not replay_note2.hammers.empty:
                            x_hm = (replay_note2.hammers.index + replay_note2.offset) / 10.0
                            y_hm = replay_note2.hammers.values
                            fig.add_trace(go.Scatter(x=x_hm, y=y_hm, mode='markers', name='å›æ”¾é”¤å­',
                                                    marker=dict(color='red', size=6), showlegend=False), row=1, col=2)
                    
                    # ä¸»æ ‡é¢˜
                    title_text = f"æŒ‰é”®ID {key_id} æ›²çº¿å¯¹æ¯”"
                    
                    fig.update_layout(
                        title=title_text,
                        height=400,
                        showlegend=False
                    )
                    fig.update_xaxes(title_text="æ—¶é—´ (ms)", row=1, col=1)
                    fig.update_xaxes(title_text="æ—¶é—´ (ms)", row=1, col=2)
                    fig.update_yaxes(title_text="å€¼", row=1, col=1)
                    fig.update_yaxes(title_text="å€¼", row=1, col=2)
                    
                    rendered_rows.append(
                        dbc.Row([
                            dbc.Col([
                                dcc.Graph(figure=fig, style={'height': '400px'})
                            ], width=12)
                        ], className="mb-3")
                    )
                
                if not rendered_rows:
                    modal_style = {
                        'display': 'block',
                        'position': 'fixed',
                        'zIndex': '9999',
                        'left': '0',
                        'top': '0',
                        'width': '100%',
                        'height': '100%',
                        'backgroundColor': 'rgba(0,0,0,0.6)',
                        'backdropFilter': 'blur(5px)'
                    }
                    return modal_style, [html.Div([
                        html.P(f"æŒ‰é”®ID {key_id} æ²¡æœ‰å¯æ˜¾ç¤ºçš„å¯¹æ¯”æ•°æ®", className="text-muted text-center")
                    ])], no_update
                
                # è®¡ç®—æ—¶é—´ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æ—¶ç›´æ¥ä½¿ç”¨
                center_time_ms = None
                record_idx = None
                replay_idx = None
                first_algorithm_name = None
                
                try:
                    # è·å–ç¬¬ä¸€ä¸ªåŒ¹é…å¯¹ç”¨äºè·³è½¬
                    if alg1_pairs:
                        first_pair = alg1_pairs[0]
                        record_idx, replay_idx, record_note, replay_note, _ = first_pair
                        first_algorithm_name = alg1_name
                        
                        if record_note and replay_note:
                            try:
                                # è®¡ç®—keyonæ—¶é—´
                                record_keyon = record_note.after_touch.index[0] + record_note.offset if hasattr(record_note, 'after_touch') and not record_note.after_touch.empty else record_note.offset
                                replay_keyon = replay_note.after_touch.index[0] + replay_note.offset if hasattr(replay_note, 'after_touch') and not replay_note.after_touch.empty else replay_note.offset
                                center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
                                logger.info(f"[OK] è®¡ç®—å¾—åˆ°center_time_ms: {center_time_ms}ms")
                            except Exception as e:
                                logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                                # å¤‡ç”¨æ–¹æ¡ˆï¼šä» offset_data è·å–
                                try:
                                    algorithm = backend.multi_algorithm_manager.get_algorithm(alg1_name)
                                    if algorithm and algorithm.analyzer and algorithm.analyzer.note_matcher:
                                        offset_data = algorithm.analyzer.note_matcher.get_offset_alignment_data()
                                        if offset_data:
                                            for item in offset_data:
                                                if item.get('record_index') == record_idx and item.get('replay_index') == replay_idx:
                                                    record_keyon = item.get('record_keyon', 0)
                                                    replay_keyon = item.get('replay_keyon', 0)
                                                    if record_keyon and replay_keyon:
                                                        center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                                                        logger.info(f"[OK] ä»offset_dataè·å–center_time_ms: {center_time_ms}ms")
                                                        break
                                except Exception as e2:
                                    logger.warning(f"[WARNING] ä»offset_dataè·å–æ—¶é—´ä¿¡æ¯å¤±è´¥: {e2}")
                except Exception as e:
                    logger.warning(f"[WARNING] è·å–è·³è½¬ä¿¡æ¯å¤±è´¥: {e}")
                
                # å­˜å‚¨å½“å‰ç‚¹å‡»çš„æ•°æ®ç‚¹ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æŒ‰é’®
                point_info = {
                    'algorithm_name': first_algorithm_name,
                    'record_idx': record_idx,
                    'replay_idx': replay_idx,
                    'key_id': key_id,
                    'source_plot_id': 'offset-alignment-table',  # è®°å½•æ¥æºè¡¨æ ¼ID
                    'center_time_ms': center_time_ms  # é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯
                }
                
                # æ˜¾ç¤ºæ¨¡æ€æ¡†
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                
                return modal_style, rendered_rows, point_info
                
            except Exception as e:
                logger.error(f"[ERROR] ç”ŸæˆæŒ‰é”®æ›²çº¿å¯¹æ¯”å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                return modal_style, [html.Div([
                    html.P(f"ç”Ÿæˆå¯¹æ¯”å›¾å¤±è´¥: {str(e)}", className="text-danger text-center")
                ])], no_update
        
        # å…¶ä»–æƒ…å†µï¼Œä¿æŒå½“å‰çŠ¶æ€
        return current_style, [], no_update
    
    # ç€‘å¸ƒå›¾ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰
    @app.callback(
        [Output('waterfall-curves-modal', 'style'),
         Output('waterfall-curves-comparison-container', 'children')],
        [Input('main-plot', 'clickData'),
         Input('close-waterfall-curves-modal', 'n_clicks'),
         Input('close-waterfall-curves-modal-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('waterfall-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_waterfall_click(click_data, close_modal_clicks, close_btn_clicks, session_id, current_style):
        """å¤„ç†ç€‘å¸ƒå›¾ç‚¹å‡»ï¼Œæ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰"""
        
        
        print("=" * 80)
        print("[START] handle_waterfall_click å›è°ƒè¢«è§¦å‘ï¼")
        print("=" * 80)
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            print("[ERROR] æ²¡æœ‰è§¦å‘æº")
            return current_style, []
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        print(f"ğŸ” è§¦å‘ID: {trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-waterfall-curves-modal', 'close-waterfall-curves-modal-btn']:
            print("[OK] å…³é—­ç€‘å¸ƒå›¾æ›²çº¿æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, []
        
        # å¦‚æœæ˜¯ç€‘å¸ƒå›¾ç‚¹å‡»
        if trigger_id == 'main-plot' and click_data:
            print("[TARGET] æ£€æµ‹åˆ°ç€‘å¸ƒå›¾ç‚¹å‡»ï¼")
            
            backend = session_manager.get_backend(session_id)
            if not backend:
                print("[ERROR] backendä¸ºç©º")
                return current_style, []
            
            try:
                if 'points' not in click_data or len(click_data['points']) == 0:
                    print("[ERROR] clickDataä¸­æ²¡æœ‰points")
                    return current_style, []
                
                point = click_data['points'][0]
                
                # ä¼˜å…ˆä»customdataè·å–ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»åæ ‡è·å–
                algorithm_name = None
                key_id = None
                data_type = None
                index = None
                
                if point.get('customdata'):
                    # æœ‰customdataï¼šç‚¹å‡»åˆ°äº†èµ·å§‹æ—¶é—´
                    raw_customdata = point['customdata']
                    customdata = raw_customdata[0] if isinstance(raw_customdata, list) and len(raw_customdata) > 0 and isinstance(raw_customdata[0], list) else raw_customdata
                else:
                    # æ²¡æœ‰customdataï¼Œè®¾ç½®ä¸ºç©º
                    customdata = None
                
                print(f"[DATA] customdata: {customdata}")

                if isinstance(customdata, list) and len(customdata) >= 7:
                    # ä»customdataæå–ä¿¡æ¯ï¼š[t_on/10, t_off/10, original_key_id, value, label, index, algorithm_name]
                    algorithm_name = customdata[6]
                    key_id = int(customdata[2])
                    data_type = customdata[4]  # 'record' æˆ– 'play'
                    index = int(customdata[5])
                    print(f"[STATS] ä»customdataæå–: algorithm_name={algorithm_name}, key_id={key_id}, data_type={data_type}, index={index}")
                
                # å¦‚æœæ²¡æœ‰customdataï¼Œä»ç‚¹å‡»åæ ‡æŸ¥æ‰¾å¯¹åº”çš„éŸ³ç¬¦
                if not algorithm_name or key_id is None or index is None:
                    # è·å–ç‚¹å‡»çš„åæ ‡
                    click_x = point.get('x')  # æ—¶é—´ï¼ˆmsï¼‰
                    click_y = point.get('y')  # æŒ‰é”®ID
                    
                    if click_x is None or click_y is None:
                        print("[ERROR] æ— æ³•ä»åæ ‡è·å–ç‚¹å‡»ä½ç½®")
                        return current_style, []
                    
                    print(f"[LOCATION] ä»åæ ‡è·å–: x={click_x}ms, y={click_y}")
                    
                    # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ï¼Œéœ€è¦æ ¹æ®yåæ ‡åˆ¤æ–­æ˜¯å“ªä¸ªç®—æ³•
                    if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                        algorithm_y_range = 100  # æ¯ä¸ªç®—æ³•åç§»100ä¸ªå•ä½
                        
                        # æ ¹æ®yåæ ‡æ‰¾åˆ°å¯¹åº”çš„ç®—æ³•å’Œå®é™…æŒ‰é”®ID
                        for alg_idx, alg in enumerate(active_algorithms):
                            alg_y_offset = alg_idx * algorithm_y_range
                            if alg_y_offset <= click_y < alg_y_offset + algorithm_y_range:
                                algorithm_name = alg.metadata.algorithm_name
                                key_id = int(click_y - alg_y_offset)
                                print(f"[OK] æ‰¾åˆ°ç®—æ³•: {algorithm_name}, å®é™…æŒ‰é”®ID: {key_id}")
                                break
                    else:
                        # å•ç®—æ³•æ¨¡å¼
                        key_id = int(click_y)
                        algorithm_name = None
                    
                    if not algorithm_name and backend.multi_algorithm_mode:
                        print("[ERROR] æ— æ³•ç¡®å®šç®—æ³•")
                        return current_style, []
                    
                    # æ ¹æ®æ—¶é—´å’ŒæŒ‰é”®IDæŸ¥æ‰¾å¯¹åº”çš„éŸ³ç¬¦
                # è·å–ç®—æ³•å¯¹è±¡
                    if not backend.multi_algorithm_manager:
                        backend._ensure_multi_algorithm_manager()
                    
                    if algorithm_name:
                        algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name)
                    else:
                        # å•ç®—æ³•æ¨¡å¼
                        algorithm = None
                        if backend.analyzer:
                            # ä½¿ç”¨offset_dataæŸ¥æ‰¾
                            if backend.analyzer.note_matcher:
                                offset_data = backend.analyzer.note_matcher.get_offset_alignment_data()
                                if offset_data:
                                    # æŸ¥æ‰¾æ—¶é—´èŒƒå›´å†…çš„éŸ³ç¬¦
                                    click_time_01ms = click_x * 10  # è½¬æ¢ä¸º0.1mså•ä½
                                    for item in offset_data:
                                        item_key_id = item.get('key_id')
                                        # ç¡®ä¿key_idç±»å‹ä¸€è‡´
                                        try:
                                            item_key_id = int(item_key_id) if item_key_id is not None else None
                                        except (ValueError, TypeError):
                                            continue
                                        
                                        record_keyon = item.get('record_keyon', 0)
                                        record_keyoff = item.get('record_keyoff', 0)
                                        # å¦‚æœæ²¡æœ‰record_keyoffï¼Œä½¿ç”¨record_keyon + record_duration
                                        if record_keyoff == 0:
                                            record_duration = item.get('record_duration', 0)
                                            record_keyoff = record_keyon + record_duration
                                        
                                        if item_key_id == key_id and record_keyon <= click_time_01ms <= record_keyoff:
                                            index = item.get('record_index')
                                            data_type = 'record'
                                            print(f"[OK] å•ç®—æ³•æ¨¡å¼: æ‰¾åˆ°éŸ³ç¬¦ index={index}, data_type={data_type}, æ—¶é—´èŒƒå›´: {record_keyon/10:.1f}ms - {record_keyoff/10:.1f}ms, ç‚¹å‡»æ—¶é—´: {click_time_01ms/10:.1f}ms")
                                            break
                    
                    if algorithm_name and not algorithm:
                        print("[ERROR] æ— æ³•è·å–ç®—æ³•å¯¹è±¡")
                        return current_style, []
                    
                    # å¤šç®—æ³•æ¨¡å¼ï¼šä»offset_dataæŸ¥æ‰¾
                    if algorithm_name and algorithm and algorithm.analyzer and algorithm.analyzer.note_matcher:
                        offset_data = algorithm.analyzer.note_matcher.get_offset_alignment_data()
                        if offset_data:
                            click_time_01ms = click_x * 10  # è½¬æ¢ä¸º0.1mså•ä½
                            for item in offset_data:
                                item_key_id = item.get('key_id')
                                # ç¡®ä¿key_idç±»å‹ä¸€è‡´
                                try:
                                    item_key_id = int(item_key_id) if item_key_id is not None else None
                                except (ValueError, TypeError):
                                    continue
                                
                                record_keyon = item.get('record_keyon', 0)
                                record_keyoff = item.get('record_keyoff', 0)
                                # å¦‚æœæ²¡æœ‰record_keyoffï¼Œä½¿ç”¨record_keyon + record_duration
                                if record_keyoff == 0:
                                    record_duration = item.get('record_duration', 0)
                                    record_keyoff = record_keyon + record_duration
                                
                                if item_key_id == key_id and record_keyon <= click_time_01ms <= record_keyoff:
                                    index = item.get('record_index')
                                    data_type = 'record'
                                    print(f"[OK] å¤šç®—æ³•æ¨¡å¼: æ‰¾åˆ°éŸ³ç¬¦ index={index}, data_type={data_type}, æ—¶é—´èŒƒå›´: {record_keyon/10:.1f}ms - {record_keyoff/10:.1f}ms, ç‚¹å‡»æ—¶é—´: {click_time_01ms/10:.1f}ms")
                                    break
                
                if key_id is None or index is None:
                    print(f"[ERROR] æ— æ³•ç¡®å®šæŒ‰é”®ä¿¡æ¯: key_id={key_id}, index={index}")
                    print(f"ğŸ” è°ƒè¯•ä¿¡æ¯: click_x={point.get('x')}, click_y={point.get('y')}, algorithm_name={algorithm_name}")
                    if not point.get('customdata'):
                        print(f"[WARNING] æ²¡æœ‰customdataï¼Œå°è¯•ä»åæ ‡æŸ¥æ‰¾å¤±è´¥")
                    return current_style, []
                
                print(f"[STATS] æœ€ç»ˆæå–çš„æ•°æ®: algorithm_name={algorithm_name}, key_id={key_id}, data_type={data_type}, index={index}")
                
                # è·å–ç®—æ³•å¯¹è±¡
                algorithm = None
                if backend.multi_algorithm_mode:
                    if not algorithm_name:
                        print("[ERROR] å¤šç®—æ³•æ¨¡å¼ä¸‹æ— æ³•ç¡®å®šç®—æ³•åç§°")
                        return current_style, []
                if not backend.multi_algorithm_manager:
                    backend._ensure_multi_algorithm_manager()
                algorithm = None
                if backend.multi_algorithm_manager:
                    algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name)
                    print(f"[DEBUG] æŸ¥æ‰¾ç®—æ³•: algorithm_name='{algorithm_name}', algorithm={algorithm is not None}")
                    if algorithm:
                        print(f"[DEBUG] ç®—æ³•çŠ¶æ€: is_active={algorithm.is_active}, is_ready={algorithm.is_ready()}, analyzer={algorithm.analyzer is not None}")
                    if not algorithm or not algorithm.analyzer:
                        print(f"[ERROR] ç®—æ³•å¯¹è±¡æˆ–analyzerä¸ºç©º: algorithm={algorithm is not None}, analyzer={algorithm.analyzer is not None if algorithm else None}")

                        # è°ƒè¯•ï¼šåˆ—å‡ºæ‰€æœ‰å¯ç”¨ç®—æ³•
                        all_algorithms = backend.multi_algorithm_manager.get_all_algorithms()
                        print(f"[DEBUG] æ‰€æœ‰å¯ç”¨ç®—æ³•: {[alg.metadata.algorithm_name for alg in all_algorithms]}")

                        # å¦‚æœæ˜¯å¤šç®—æ³•æ¨¡å¼ä½†æ‰¾ä¸åˆ°ç®—æ³•ï¼Œå°è¯•å•ç®—æ³•æ¨¡å¼
                        if backend.analyzer:
                            print("[INFO] å°è¯•ä½¿ç”¨å•ç®—æ³•æ¨¡å¼")
                            algorithm = None  # æ ‡è®°ä¸ºå•ç®—æ³•æ¨¡å¼
                        else:
                            return current_style, []
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    if not backend.analyzer:
                        print("[ERROR] analyzerä¸ºç©º")
                        return current_style, []
                    algorithm = None  # å•ç®—æ³•æ¨¡å¼ä¸‹ä¸éœ€è¦algorithmå¯¹è±¡
                
                # è·å–matched_pairsï¼ˆå·²ä¿å­˜çš„é…å¯¹æ•°æ®ï¼‰
                if algorithm is not None:
                    # å¤šç®—æ³•æ¨¡å¼
                    matched_pairs = algorithm.analyzer.matched_pairs if hasattr(algorithm.analyzer, 'matched_pairs') else []
                    valid_record_data = algorithm.analyzer.valid_record_data if hasattr(algorithm.analyzer, 'valid_record_data') else []
                    valid_replay_data = algorithm.analyzer.valid_replay_data if hasattr(algorithm.analyzer, 'valid_replay_data') else []
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    matched_pairs = backend.analyzer.matched_pairs if hasattr(backend.analyzer, 'matched_pairs') else []
                    valid_record_data = backend.analyzer.valid_record_data if hasattr(backend.analyzer, 'valid_record_data') else []
                    valid_replay_data = backend.analyzer.valid_replay_data if hasattr(backend.analyzer, 'valid_replay_data') else []
                
                # æ­¥éª¤1ï¼šå…ˆåˆ¤æ–­è¿™ä¸ªæŒ‰é”®IDï¼ˆé€šè¿‡indexï¼‰æ˜¯å¦åœ¨matched_pairsä¸­æœ‰åŒ¹é…å¯¹
                has_matched_pair = False
                record_note = None
                replay_note = None
                
                print(f"ğŸ” å¼€å§‹æŸ¥æ‰¾åŒ¹é…å¯¹: key_id={key_id}, data_type={data_type}, index={index}")
                print(f"[STATS] matched_pairsæ•°é‡: {len(matched_pairs)}")
                
                # æ ¹æ®data_typeå’Œindexåœ¨matched_pairsä¸­æŸ¥æ‰¾
                if data_type == 'record':
                    # ç‚¹å‡»çš„æ˜¯å½•åˆ¶çº¿ï¼ŒæŸ¥æ‰¾r_idx == indexçš„åŒ¹é…å¯¹
                    print(f"ğŸ” åœ¨matched_pairsä¸­æŸ¥æ‰¾: r_idx == {index}")
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_idx == index and r_note.id == key_id:
                            # æ‰¾åˆ°åŒ¹é…å¯¹
                            has_matched_pair = True
                            record_note = r_note
                            replay_note = p_note
                            print(f"[OK] æ‰¾åˆ°å®Œæ•´åŒ¹é…å¯¹ï¼")
                            break
                else:
                    # ç‚¹å‡»çš„æ˜¯æ’­æ”¾çº¿ï¼ŒæŸ¥æ‰¾p_idx == indexçš„åŒ¹é…å¯¹
                    print(f"ğŸ” åœ¨matched_pairsä¸­æŸ¥æ‰¾: p_idx == {index}")
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if p_idx == index and p_note.id == key_id:
                            # æ‰¾åˆ°åŒ¹é…å¯¹
                            has_matched_pair = True
                            record_note = r_note
                            replay_note = p_note
                            print(f"[OK] æ‰¾åˆ°å®Œæ•´åŒ¹é…å¯¹ï¼")
                            break
                
                print(f"[TARGET] åŒ¹é…ç»“æœ: has_matched_pair={has_matched_pair}")
                
                # æ­¥éª¤2ï¼šæ ¹æ®åŒ¹é…ç»“æœç”Ÿæˆæ›²çº¿
                import spmid
                if has_matched_pair:
                    # è·å–å½“å‰ç®—æ³•çš„display_nameï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦æ˜¯åŒç§ç®—æ³•çš„ä¸åŒæ›²å­
                    current_display_name = None
                    if algorithm and algorithm.metadata:
                        current_display_name = algorithm.metadata.display_name

                    # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ç®—æ³•ä¸­åŒ¹é…åˆ°åŒä¸€ä¸ªå½•åˆ¶éŸ³ç¬¦çš„æ’­æ”¾éŸ³ç¬¦
                    # ä½†æ˜¯ï¼Œå¯¹äºåŒç§ç®—æ³•çš„ä¸åŒæ›²å­ï¼ˆç›¸åŒdisplay_nameï¼‰ï¼Œä¸æ·»åŠ å…¶ä»–ç®—æ³•çš„æ›²çº¿
                    other_algorithm_notes = []  # [(algorithm_name, play_note), ...]
                    if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                        for alg in active_algorithms:
                            if alg.metadata.algorithm_name == algorithm_name:
                                continue  # è·³è¿‡å½“å‰ç®—æ³•ï¼ˆå·²ç»ç»˜åˆ¶ï¼‰

                            # å¦‚æœæ˜¯åŒç§ç®—æ³•çš„ä¸åŒæ›²å­ï¼ˆç›¸åŒdisplay_nameï¼‰ï¼Œè·³è¿‡
                            if current_display_name and alg.metadata.display_name == current_display_name:
                                logger.info(f"[SKIP] è·³è¿‡åŒç§ç®—æ³•çš„ä¸åŒæ›²å­: {alg.metadata.algorithm_name} (display_name={alg.metadata.display_name})")
                                continue

                            if not alg.analyzer or not hasattr(alg.analyzer, 'matched_pairs'):
                                continue

                            alg_matched_pairs = alg.analyzer.matched_pairs
                            # æŸ¥æ‰¾åŒ¹é…åˆ°åŒä¸€ä¸ªrecord_indexçš„æ’­æ”¾éŸ³ç¬¦
                            for r_idx, p_idx, r_note, p_note in alg_matched_pairs:
                                if r_idx == index and r_note.id == key_id:
                                    other_algorithm_notes.append((alg.metadata.algorithm_name, p_note))
                                    logger.info(f"[OK] æ‰¾åˆ°ç®—æ³• '{alg.metadata.algorithm_name}' çš„åŒ¹é…æ’­æ”¾éŸ³ç¬¦")
                                    break

                    # æœ‰åŒ¹é…å¯¹ï¼šç»˜åˆ¶å½•åˆ¶+æ’­æ”¾å¯¹æ¯”æ›²çº¿
                    # å¯¹äºåŒç§ç®—æ³•çš„ä¸åŒæ›²å­ï¼Œother_algorithm_notesä¸ºç©ºï¼Œåªæ˜¾ç¤ºå½•åˆ¶å’Œæ’­æ”¾æ›²çº¿

                    # è®¡ç®—å„ç®—æ³•çš„å¹³å‡å»¶æ—¶
                    mean_delays = {}
                    if not algorithm or not algorithm.analyzer:
                        print(f"[ERROR] ç®—æ³•å¯¹è±¡æˆ–åˆ†æå™¨ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—å¹³å‡å»¶æ—¶")
                        return current_style, []

                    mean_error_0_1ms = algorithm.analyzer.get_mean_error()
                    mean_delays[algorithm_name] = mean_error_0_1ms / 10.0  # è½¬æ¢ä¸ºæ¯«ç§’

                    # ä¸ºå…¶ä»–ç®—æ³•ä¹Ÿè®¡ç®—å¹³å‡å»¶æ—¶
                    for other_alg_name, _ in other_algorithm_notes:
                        if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                            other_alg = None
                            for alg in backend.multi_algorithm_manager.get_active_algorithms():
                                if alg.metadata.algorithm_name == other_alg_name:
                                    other_alg = alg
                                    break
                            if other_alg and other_alg.analyzer:
                                other_mean_error_0_1ms = other_alg.analyzer.get_mean_error()
                                mean_delays[other_alg_name] = other_mean_error_0_1ms / 10.0  # è½¬æ¢ä¸ºæ¯«ç§’
                            else:
                                print(f"[ERROR] å…¶ä»–ç®—æ³• '{other_alg_name}' å¯¹è±¡æˆ–åˆ†æå™¨ä¸ºç©º")
                                return current_style, []

                    detail_figure_combined = spmid.plot_note_comparison_plotly(
                        record_note,
                        replay_note,
                        algorithm_name=algorithm_name,
                        other_algorithm_notes=other_algorithm_notes,  # å¯¹äºåŒç§ç®—æ³•çš„ä¸åŒæ›²å­ï¼Œè¿™æ˜¯ç©ºåˆ—è¡¨
                        mean_delays=mean_delays
                    )
                    print(f"[OK] æŒ‰é”®ID {key_id} æœ‰åŒ¹é…å¯¹ï¼Œç»˜åˆ¶å½•åˆ¶+æ’­æ”¾å¯¹æ¯”æ›²çº¿ï¼ˆåŒç§ç®—æ³•ä¸åŒæ›²å­æ—¶ä¸æ˜¾ç¤ºå…¶ä»–ç®—æ³•æ›²çº¿ï¼‰")
                else:
                    # æ²¡æœ‰åŒ¹é…å¯¹ï¼šåªç»˜åˆ¶è¿™ä¸ªæ•°æ®ç‚¹çš„æ•°æ®ï¼ˆå¯èƒ½æ˜¯å½•åˆ¶ï¼Œä¹Ÿå¯èƒ½æ˜¯æ’­æ”¾ï¼‰
                    if data_type == 'record' and index >= 0 and index < len(valid_record_data):
                        record_note = valid_record_data[index]
                        replay_note = None
                    elif data_type == 'play' and index >= 0 and index < len(valid_replay_data):
                        record_note = None
                        replay_note = valid_replay_data[index]

                    # è®¡ç®—å¹³å‡å»¶æ—¶
                    mean_delays = {}
                    if not algorithm or not algorithm.analyzer:
                        print(f"[ERROR] ç®—æ³•å¯¹è±¡æˆ–åˆ†æå™¨ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—å¹³å‡å»¶æ—¶")
                        return current_style, []

                    mean_error_0_1ms = algorithm.analyzer.get_mean_error()
                    mean_delays[algorithm_name] = mean_error_0_1ms / 10.0  # è½¬æ¢ä¸ºæ¯«ç§’

                    detail_figure_combined = spmid.plot_note_comparison_plotly(record_note, replay_note, algorithm_name=algorithm_name, mean_delays=mean_delays)
                    print(f"[WARNING] æŒ‰é”®ID {key_id} æ— åŒ¹é…å¯¹ï¼Œåªç»˜åˆ¶å•ä¾§æ•°æ®")
                
                if not detail_figure_combined:
                    print("[ERROR] æ›²çº¿ç”Ÿæˆå¤±è´¥")
                    return current_style, []
                
                # æ˜¾ç¤ºæ¨¡æ€æ¡†
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                

                
                # ç”Ÿæˆå…¨è¿‡ç¨‹å¤„ç†å›¾
                processing_stages_figure = None
                if backend.force_curve_analyzer and record_note and replay_note:
                    try:
                        comparison_result = backend.force_curve_analyzer.compare_curves(record_note, replay_note)
                        if comparison_result:
                            processing_stages_figure = backend.force_curve_analyzer.visualize_all_processing_stages(comparison_result)
                    except Exception as e:
                        print(f"[ERROR] ç”Ÿæˆå…¨è¿‡ç¨‹å¤„ç†å›¾å¤±è´¥: {e}")

                # æ„å»ºæ¨¡æ€æ¡†å†…å®¹ï¼šä½¿ç”¨Tabså±•ç¤ºå¯¹æ¯”å›¾å’Œå…¨è¿‡ç¨‹å›¾
                modal_content = [
                    dcc.Tabs([
                        dcc.Tab(label='æ›²çº¿å¯¹æ¯”', children=[
                            dcc.Graph(
                                figure=detail_figure_combined, 
                                style={'height': '700px'},
                                config={'scrollZoom': True, 'displayModeBar': True}
                            )
                        ]),
                        dcc.Tab(label='å¤„ç†å…¨è¿‡ç¨‹', children=[
                            html.Div(
                                style={'height': '85vh', 'overflowY': 'auto', 'padding': '10px'},
                                children=[
                            dcc.Graph(
                                figure=processing_stages_figure if processing_stages_figure else go.Figure(),
                                        style={'height': f"{processing_stages_figure.layout.height}px"} if processing_stages_figure and processing_stages_figure.layout.height else {'height': '2000px'},
                                        config={'scrollZoom': True, 'displayModeBar': True, 'responsive': True}
                            ) if processing_stages_figure else html.Div("æ— æ³•ç”Ÿæˆå¤„ç†å…¨è¿‡ç¨‹å›¾ï¼ˆå¯èƒ½åªæœ‰å•ä¾§æ•°æ®ï¼‰", className="text-center p-3 text-muted")
                                ]
                            )
                        ])
                    ])
                ]
                
                rendered_row = html.Div(modal_content)
                
                print("[OK] æ˜¾ç¤ºæ¨¡æ€æ¡†")
                return modal_style, [rendered_row]
                
            except Exception as e:
                logger.error(f"[ERROR] ç€‘å¸ƒå›¾ç‚¹å‡»å¤„ç†å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                print(traceback.format_exc())
                return current_style, []
        
        # å…¶ä»–æƒ…å†µï¼Œä¿æŒå½“å‰çŠ¶æ€
        return current_style, []
    
    # æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('main-plot', 'figure', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True),
         Output('key-force-interaction-plot', 'clickData', allow_duplicate=True)],
        [Input('key-force-interaction-plot', 'clickData'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_key_force_interaction_plot_click(click_data, close_modal_clicks, close_btn_clicks, session_id, current_style):
        """å¤„ç†æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡»ï¼Œæ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶è°ƒæ•´ç€‘å¸ƒå›¾æ˜¾ç¤ºèŒƒå›´"""
        from dash import callback_context
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            logger.debug("[WARNING] æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡»å›è°ƒï¼šæ²¡æœ‰è§¦å‘æº")
            return current_style, [], no_update, no_update, no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"[PROCESS] æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            logger.info("[OK] å…³é—­æŒ‰é”®æ›²çº¿å¯¹æ¯”æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, [], no_update, no_update, no_update
        
        # å¦‚æœæ˜¯æ•£ç‚¹å›¾ç‚¹å‡»
        if trigger_id == 'key-force-interaction-plot':
            logger.info(f"[PROCESS] æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡»ï¼šclick_data={click_data}")
            backend = session_manager.get_backend(session_id)
            if not backend:
                logger.warning("[WARNING] æ²¡æœ‰æ‰¾åˆ°backend")
                return current_style, [], no_update, no_update, no_update

            if not click_data or 'points' not in click_data or not click_data['points']:
                logger.warning("[WARNING] click_dataä¸ºç©ºæˆ–æ²¡æœ‰points")
                return current_style, [], no_update, no_update, no_update
            
            try:
                # è·å–ç‚¹å‡»çš„æ•°æ®ç‚¹
                point = click_data['points'][0]
                logger.info(f"ğŸ” æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡» - ç‚¹å‡»ç‚¹æ•°æ®: {point}")
                
                if not point.get('customdata'):
                    logger.warning("[WARNING] æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡» - ç‚¹æ²¡æœ‰customdata")
                    return current_style, [], no_update, no_update, no_update
                
                # å®‰å…¨åœ°æå–customdata
                raw_customdata = point['customdata']
                logger.info(f"ğŸ” æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡» - raw_customdataç±»å‹: {type(raw_customdata)}, å€¼: {raw_customdata}")
                
                if isinstance(raw_customdata, list) and len(raw_customdata) > 0:
                    customdata = raw_customdata[0] if isinstance(raw_customdata[0], list) else raw_customdata
                else:
                    customdata = raw_customdata
                
                # ç¡®ä¿customdataæ˜¯åˆ—è¡¨ç±»å‹
                if not isinstance(customdata, list):
                    logger.warning(f"[WARNING] æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡» - customdataä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(customdata)}, å€¼: {customdata}")
                    return current_style, [], no_update, no_update, no_update
                
                logger.info(f"ğŸ” æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡» - customdata: {customdata}, é•¿åº¦: {len(customdata)}")
                
                # è§£æcustomdata
                # å¤šç®—æ³•æ¨¡å¼: [key_id, algorithm_display_name, orig_force, abs_delay, rel_delay, record_idx, replay_idx]
                # å•ç®—æ³•æ¨¡å¼: [key_id, orig_force, abs_delay, rel_delay, record_idx, replay_idx]
                if len(customdata) < 5:
                    logger.warning(f"[WARNING] customdataé•¿åº¦ä¸è¶³ï¼š{len(customdata)}ï¼ŒæœŸæœ›è‡³å°‘5ä¸ªå…ƒç´ ")
                    return current_style, [], no_update
                
                # åˆ¤æ–­æ˜¯å•ç®—æ³•è¿˜æ˜¯å¤šç®—æ³•æ¨¡å¼
                if len(customdata) >= 8:
                    # å¤šç®—æ³•æ¨¡å¼ï¼šæœ‰algorithm_display_name
                    key_id = customdata[0]
                    algorithm_display_name = customdata[1]
                    original_velocity = customdata[2]
                    abs_delay = customdata[3]
                    rel_delay = customdata[4]
                    log10_force = customdata[5]  # æ–°å¢log10_forceå­—æ®µ
                    record_idx = customdata[6]
                    replay_idx = customdata[7]
                else:
                    # å•ç®—æ³•æ¨¡å¼ï¼šæ²¡æœ‰algorithm_display_name
                    key_id = customdata[0]
                    algorithm_display_name = None
                    original_velocity = customdata[1]
                    abs_delay = customdata[2]
                    rel_delay = customdata[3]
                    log10_force = customdata[4] if len(customdata) > 4 else None  # å•ç®—æ³•æ¨¡å¼ä¹Ÿå¯èƒ½æœ‰log10_force
                    record_idx = customdata[5] if len(customdata) > 5 else None
                    replay_idx = customdata[6] if len(customdata) > 6 else None
                
                if record_idx is None or replay_idx is None:
                    logger.warning(f"[WARNING] æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡» - ç¼ºå°‘ç´¢å¼•ä¿¡æ¯: record_idx={record_idx}, replay_idx={replay_idx}")
                    return current_style, [], no_update
                
                logger.info(f"ğŸ–±ï¸ æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡»: ç®—æ³•={algorithm_display_name}, æŒ‰é”®={key_id}, é”¤é€Ÿ={original_velocity}, record_idx={record_idx}, replay_idx={replay_idx}")
                
                # éœ€è¦å°†algorithm_display_nameè½¬æ¢ä¸ºalgorithm_name
                algorithm_name_for_waterfall = None
                if algorithm_display_name:
                    active_algorithms = backend.get_active_algorithms()
                    for alg in active_algorithms:
                        if alg.metadata.display_name == algorithm_display_name:
                            algorithm_name_for_waterfall = alg.metadata.algorithm_name
                            break
                        # å¦‚æœdisplay_nameåŒ…å«æ–‡ä»¶ååç¼€ï¼Œå°è¯•åŒ¹é…åŸºç¡€åç§°
                        if '(' in algorithm_display_name:
                            base_name = algorithm_display_name.split('(')[0].strip()
                            if alg.metadata.display_name == base_name:
                                algorithm_name_for_waterfall = alg.metadata.algorithm_name
                                break
                
                # è®¡ç®—æ—¶é—´ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æ—¶ç›´æ¥ä½¿ç”¨
                center_time_ms = None
                try:
                    if algorithm_name_for_waterfall:
                        # å¤šç®—æ³•æ¨¡å¼
                        if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                            algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name_for_waterfall)
                            if algorithm and algorithm.analyzer and algorithm.analyzer.note_matcher:
                                matched_pairs = algorithm.analyzer.matched_pairs
                                for r_idx, p_idx, r_note, p_note in matched_pairs:
                                    if r_idx == record_idx and p_idx == replay_idx:
                                        # è®¡ç®—keyonæ—¶é—´
                                        record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
                                        replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
                                        center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
                                        break
                                # å¤‡ç”¨æ–¹æ¡ˆï¼šä» offset_data è·å–
                                if center_time_ms is None:
                                    offset_data = algorithm.analyzer.note_matcher.get_offset_alignment_data()
                                    if offset_data:
                                        for item in offset_data:
                                            if item.get('record_index') == record_idx and item.get('replay_index') == replay_idx:
                                                record_keyon = item.get('record_keyon', 0)
                                                replay_keyon = item.get('replay_keyon', 0)
                                                if record_keyon and replay_keyon:
                                                    center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                                                    break
                    else:
                        # å•ç®—æ³•æ¨¡å¼
                        if backend.analyzer and backend.analyzer.note_matcher:
                            matched_pairs = backend.analyzer.matched_pairs
                            for r_idx, p_idx, r_note, p_note in matched_pairs:
                                if r_idx == record_idx and p_idx == replay_idx:
                                    # è®¡ç®—keyonæ—¶é—´
                                    record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
                                    replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
                                    center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
                                    break
                            # å¤‡ç”¨æ–¹æ¡ˆï¼šä» offset_data è·å–
                            if center_time_ms is None:
                                offset_data = backend.analyzer.note_matcher.get_offset_alignment_data()
                                if offset_data:
                                    for item in offset_data:
                                        if item.get('record_index') == record_idx and item.get('replay_index') == replay_idx:
                                            record_keyon = item.get('record_keyon', 0)
                                            replay_keyon = item.get('replay_keyon', 0)
                                            if record_keyon and replay_keyon:
                                                center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                                                break
                except Exception as e:
                    logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                
                # å­˜å‚¨å½“å‰ç‚¹å‡»çš„æ•°æ®ç‚¹ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æŒ‰é’®
                point_info = {
                    'algorithm_name': algorithm_name_for_waterfall,
                    'record_idx': record_idx,
                    'replay_idx': replay_idx,
                    'key_id': key_id,
                    'source_plot_id': 'key-force-interaction-plot',  # è®°å½•æ¥æºå›¾è¡¨ID
                    'center_time_ms': center_time_ms  # é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯
                }
                
                # ä¸è‡ªåŠ¨è°ƒæ•´ç€‘å¸ƒå›¾ï¼Œç­‰å¾…ç”¨æˆ·ç‚¹å‡»è·³è½¬æŒ‰é’®
                waterfall_fig = no_update
                
                # å¦‚æœæ˜¯å¤šç®—æ³•æ¨¡å¼ä¸”æœ‰ç®—æ³•åç§°ï¼Œä½¿ç”¨generate_multi_algorithm_scatter_detail_plot_by_indices
                if algorithm_display_name:
                    # å¤šç®—æ³•æ¨¡å¼ï¼šéœ€è¦æ‰¾åˆ°å¯¹åº”çš„ç®—æ³•å†…éƒ¨åç§°
                    # ä»algorithm_display_nameæ‰¾åˆ°å¯¹åº”çš„algorithm_name
                    active_algorithms = backend.get_active_algorithms()
                    algorithm_internal_name = None
                    for alg in active_algorithms:
                        if alg.metadata.display_name == algorithm_display_name:
                            algorithm_internal_name = alg.metadata.algorithm_name
                            break
                        # å¦‚æœdisplay_nameåŒ…å«æ–‡ä»¶ååç¼€ï¼Œå°è¯•åŒ¹é…åŸºç¡€åç§°
                        if '(' in algorithm_display_name:
                            base_name = algorithm_display_name.split('(')[0].strip()
                            if alg.metadata.display_name == base_name:
                                algorithm_internal_name = alg.metadata.algorithm_name
                                break
                    
                    if not algorithm_internal_name:
                        logger.warning(f"[WARNING] æœªæ‰¾åˆ°å¯¹åº”çš„ç®—æ³•å†…éƒ¨åç§°: {algorithm_display_name}")
                        return current_style, [], no_update
                    
                    logger.info(f"ğŸ” è°ƒç”¨generate_multi_algorithm_scatter_detail_plot_by_indices: algorithm_name={algorithm_internal_name}, record_index={record_idx}, replay_index={replay_idx}")

                    detail_figure1, detail_figure2, detail_figure_combined = backend.generate_multi_algorithm_scatter_detail_plot_by_indices(
                        algorithm_name=algorithm_internal_name,
                        record_index=record_idx,
                        replay_index=replay_idx
                    )

                    logger.info(f"ğŸ” æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡»å›è°ƒ - å›¾è¡¨ç”Ÿæˆç»“æœ: figure1={detail_figure1 is not None}, figure2={detail_figure2 is not None}, figure_combined={detail_figure_combined is not None}")
                    if detail_figure_combined is None:
                        logger.error(f"âŒ å›¾è¡¨ç”Ÿæˆå¤±è´¥ - æ£€æŸ¥ç®—æ³•æ˜¯å¦å­˜åœ¨: {algorithm_internal_name}")
                        # æ£€æŸ¥ç®—æ³•æ˜¯å¦å­˜åœ¨
                        if backend.multi_algorithm_manager:
                            algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_internal_name)
                            logger.error(f"âŒ ç®—æ³•å¯¹è±¡: {algorithm is not None}")
                            if algorithm:
                                logger.error(f"âŒ ç®—æ³•is_ready: {algorithm.is_ready()}")
                                logger.error(f"âŒ ç®—æ³•analyzer: {algorithm.analyzer is not None}")
                                if algorithm.analyzer:
                                    logger.error(f"âŒ ç®—æ³•note_matcher: {algorithm.analyzer.note_matcher is not None}")
                                    if algorithm.analyzer.note_matcher:
                                        matched_pairs = algorithm.analyzer.note_matcher.get_matched_pairs()
                                        logger.error(f"âŒ matched_pairsé•¿åº¦: {len(matched_pairs)}")
                                        # æ£€æŸ¥record_indexå’Œreplay_indexæ˜¯å¦å­˜åœ¨
                                        found_pair = False
                                        for r_idx, p_idx, r_note, p_note in matched_pairs:
                                            if r_idx == record_idx and p_idx == replay_idx:
                                                found_pair = True
                                                break
                                        logger.error(f"âŒ æ‰¾åˆ°åŒ¹é…å¯¹: {found_pair}")
                    
                    if detail_figure1 and detail_figure2 and detail_figure_combined:
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        logger.info("[OK] æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡»å›è°ƒ - è¿”å›æ¨¡æ€æ¡†å’Œå›¾è¡¨")
                        return modal_style, dcc.Graph(figure=detail_figure_combined, style={'height': '600px'}), waterfall_fig, point_info, no_update
                    else:
                        logger.warning(f"[WARNING] æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡»å›è°ƒ - å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼Œéƒ¨åˆ†å›¾è¡¨ä¸ºNone")
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        return modal_style, [html.Div([
                            html.P("å›¾è¡¨ç”Ÿæˆå¤±è´¥", className="text-danger text-center")
                        ])], waterfall_fig, point_info, no_update
                else:
                    # å•ç®—æ³•æ¨¡å¼ï¼šä½¿ç”¨generate_scatter_detail_plot_by_indices
                    detail_figure1, detail_figure2, detail_figure_combined = backend.generate_scatter_detail_plot_by_indices(
                        record_index=record_idx,
                        replay_index=replay_idx
                    )
                    
                    logger.info(f"ğŸ” æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡»å›è°ƒï¼ˆå•ç®—æ³•ï¼‰ - å›¾è¡¨ç”Ÿæˆç»“æœ: figure1={detail_figure1 is not None}, figure2={detail_figure2 is not None}, figure_combined={detail_figure_combined is not None}")
                    
                    if detail_figure1 and detail_figure2 and detail_figure_combined:
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        logger.info("[OK] æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡»å›è°ƒï¼ˆå•ç®—æ³•ï¼‰ - è¿”å›æ¨¡æ€æ¡†å’Œå›¾è¡¨")
                        return modal_style, dcc.Graph(figure=detail_figure_combined, style={'height': '600px'}), waterfall_fig, point_info, no_update
                    else:
                        logger.warning(f"[WARNING] æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾ç‚¹å‡»å›è°ƒï¼ˆå•ç®—æ³•ï¼‰ - å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼Œéƒ¨åˆ†å›¾è¡¨ä¸ºNone")
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        return modal_style, [html.Div([
                            html.P("å›¾è¡¨ç”Ÿæˆå¤±è´¥", className="text-danger text-center")
                        ])], waterfall_fig, point_info, no_update
                
            except Exception as e:
                logger.error(f"[ERROR] ç”Ÿæˆæ›²çº¿å¯¹æ¯”å¤±è´¥: {e}")
                
                logger.error(traceback.format_exc())
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                return modal_style, [html.Div([
                    html.P(f"ç”Ÿæˆæ›²çº¿å¯¹æ¯”å¤±è´¥: {str(e)}", className="text-danger text-center")
                ])], no_update, no_update, no_update

        # å…¶ä»–æƒ…å†µï¼Œä¿æŒå½“å‰çŠ¶æ€
        return current_style, [], no_update, no_update, no_update
    
    # è·³è½¬åˆ°ç€‘å¸ƒå›¾æŒ‰é’®å›è°ƒ
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('main-tabs', 'value', allow_duplicate=True),
         Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('jump-source-plot-id', 'data', allow_duplicate=True)],
        [Input('jump-to-waterfall-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('current-clicked-point-info', 'data')],
        prevent_initial_call=True
    )
    def handle_jump_to_waterfall(n_clicks, session_id, point_info):
        """å¤„ç†è·³è½¬åˆ°ç€‘å¸ƒå›¾æŒ‰é’®ç‚¹å‡»"""
        return waterfall_jump_handler.handle_jump_to_waterfall(n_clicks, session_id, point_info)
    
    # è¿”å›æŠ¥å‘Šç•Œé¢æŒ‰é’®å›è°ƒ
    @app.callback(
        [Output('main-tabs', 'value', allow_duplicate=True),
         Output('scroll-to-plot-trigger', 'data', allow_duplicate=True),
         Output('grade-detail-section-scroll-trigger', 'data', allow_duplicate=True)],
        [Input('btn-return-to-report', 'n_clicks')],
        [State('jump-source-plot-id', 'data')],
        prevent_initial_call=True
    )
    def handle_return_to_report(n_clicks, source_plot_id):
        """å¤„ç†è¿”å›æŠ¥å‘Šç•Œé¢æŒ‰é’®ç‚¹å‡»ï¼Œå¹¶è§¦å‘æ»šåŠ¨åˆ°æ¥æºå›¾è¡¨"""
        if n_clicks and n_clicks > 0:
            logger.info(f"[PROCESS] è¿”å›æŠ¥å‘Šç•Œé¢ï¼Œæ¥æºå›¾è¡¨: {source_plot_id}")
            
            # å¦‚æœæ˜¯ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if isinstance(source_plot_id, dict):
                # ä»point_infoä¸­è·å–å­å›¾ç´¢å¼•
                # source_plot_id å¯èƒ½åŒ…å«å­å›¾ç´¢å¼•ä¿¡æ¯
                if source_plot_id.get('type') == 'relative-delay-distribution-plot':
                    subplot_idx = source_plot_id.get('index')
                    if subplot_idx is not None:
                        # è¿”å›åŒ…å«å­å›¾ç´¢å¼•çš„æ»šåŠ¨æ•°æ®
                        scroll_data = {
                            'plot_type': 'relative-delay-distribution',
                            'subplot_index': int(subplot_idx)  # ç¡®ä¿æ˜¯æ•´æ•°
                        }
                        return 'report-tab', scroll_data, no_update
                # å…¶ä»–æƒ…å†µï¼Œè¿”å›åŸå§‹æ•°æ®ï¼ˆä½†éœ€è¦ç¡®ä¿æ˜¯JSONå¯åºåˆ—åŒ–çš„ï¼‰
                return 'report-tab', source_plot_id, no_update
            elif isinstance(source_plot_id, str) and source_plot_id == 'relative-delay-distribution-plot':
                # éœ€è¦ä»point_infoä¸­è·å–å­å›¾ç´¢å¼•
                # ä½†ç”±äºè¿™é‡Œæ²¡æœ‰point_infoï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼è·å–
                # æš‚æ—¶è¿”å›ä¸€ä¸ªé€šç”¨çš„æ»šåŠ¨æ•°æ®ï¼Œè®©å®¢æˆ·ç«¯å›è°ƒå¤„ç†
                scroll_data = {
                    'plot_type': 'relative-delay-distribution',
                    'subplot_index': None  # å®¢æˆ·ç«¯ä¼šå°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯è§çš„å­å›¾
                }
                return 'report-tab', scroll_data, no_update
            elif source_plot_id == 'grade-detail-curves-modal':
                # ä»è¯„çº§ç»Ÿè®¡æ¨¡æ€æ¡†è·³è½¬å›æ¥ï¼Œæ»šåŠ¨åˆ°è¯„çº§ç»Ÿè®¡åŒºåŸŸ
                section_scroll_data = {'scroll_to': 'grade_detail_section'}
                logger.info("[PROCESS] ä»è¯„çº§ç»Ÿè®¡è·³è½¬å›æ¥ï¼Œè§¦å‘åŒºåŸŸæ»šåŠ¨")
                return 'report-tab', no_update, section_scroll_data
            elif source_plot_id in ['error-table-drop', 'error-table-multi']:
                # ä»é”™è¯¯è¡¨æ ¼æ¨¡æ€æ¡†è·³è½¬å›æ¥ï¼Œæ»šåŠ¨åˆ°å¯¹åº”çš„é”™è¯¯è¡¨æ ¼åŒºåŸŸ
                error_table_scroll_data = {'scroll_to': 'error_table_section', 'table_type': source_plot_id.split('-')[-1]}
                logger.info(f"[PROCESS] ä»{source_plot_id}è·³è½¬å›æ¥ï¼Œè§¦å‘é”™è¯¯è¡¨æ ¼åŒºåŸŸæ»šåŠ¨")
                return 'report-tab', no_update, error_table_scroll_data
            elif source_plot_id in ['raw-delay-time-series-plot', 'relative-delay-time-series-plot']:
                # ä»å»¶æ—¶æ—¶é—´åºåˆ—å›¾è·³è½¬å›æ¥ï¼Œæ»šåŠ¨åˆ°å¯¹åº”çš„æ—¶é—´åºåˆ—å›¾åŒºåŸŸ
                time_series_scroll_data = {'scroll_to': 'delay_time_series_section', 'plot_type': source_plot_id}
                logger.info(f"[PROCESS] ä»{source_plot_id}è·³è½¬å›æ¥ï¼Œè§¦å‘æ—¶é—´åºåˆ—å›¾åŒºåŸŸæ»šåŠ¨")
                return 'report-tab', no_update, time_series_scroll_data
            else:
                # æ™®é€šå›¾è¡¨ï¼Œç›´æ¥è¿”å›IDï¼ˆå­—ç¬¦ä¸²ï¼‰
                if source_plot_id:
                    return 'report-tab', str(source_plot_id), no_update
                else:
                    return 'report-tab', None, no_update

            return no_update, no_update, no_update
    
    # å®¢æˆ·ç«¯å›è°ƒï¼šæ»šåŠ¨åˆ°æŒ‡å®šå›¾è¡¨
    app.clientside_callback(
        """
        function(scroll_data) {
            if (scroll_data === null || scroll_data === undefined) {
                return window.dash_clientside.no_update;
            }
            
            try {
                // å¦‚æœæ˜¯ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾çš„æ»šåŠ¨æ•°æ®ï¼ˆå¯¹è±¡æ ¼å¼ï¼‰
                if (typeof scroll_data === 'object' && scroll_data !== null && scroll_data.plot_type === 'relative-delay-distribution') {
                    const subplotIndex = scroll_data.subplot_index;
                    // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ ‡ç­¾é¡µåˆ‡æ¢å®Œæˆ
                    setTimeout(function() {
                        try {
                            // æŸ¥æ‰¾æ‰€æœ‰ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾çš„å­å›¾å®¹å™¨
                            // å­å›¾å®¹å™¨çš„ç»“æ„ï¼šæ¯ä¸ªå­å›¾éƒ½åœ¨ä¸€ä¸ªDivä¸­ï¼ŒåŒ…å«Graphå…ƒç´ 
                            const allContainers = document.querySelectorAll('[id*="relative-delay-distribution"]');
                            let targetElement = null;
                            
                            // å¦‚æœæŒ‡å®šäº†å­å›¾ç´¢å¼•ï¼Œå°è¯•æ‰¾åˆ°å¯¹åº”çš„å­å›¾
                            if (subplotIndex) {
                                // æŸ¥æ‰¾åŒ…å«æŒ‡å®šç´¢å¼•çš„å­å›¾å®¹å™¨
                                // ç”±äºPattern Matching Callbacksï¼ŒIDæ ¼å¼æ˜¯åŠ¨æ€çš„
                                // æˆ‘ä»¬éœ€è¦é€šè¿‡éå†æ‰€æœ‰å®¹å™¨æ¥æ‰¾åˆ°å¯¹åº”çš„å­å›¾
                                let currentIndex = 1;
                                allContainers.forEach(function(container) {
                                    // æ£€æŸ¥æ˜¯å¦æ˜¯å›¾è¡¨å®¹å™¨ï¼ˆåŒ…å«Graphå…ƒç´ ï¼‰
                                    const graphElement = container.querySelector('.js-plotly-plot');
                                    if (graphElement && currentIndex === subplotIndex) {
                                        targetElement = container;
                                    }
                                    if (graphElement) {
                                        currentIndex++;
                                    }
                                });
                            }
                            
                            // å¦‚æœæ‰¾åˆ°äº†ç›®æ ‡å…ƒç´ ï¼Œæ»šåŠ¨åˆ°å®ƒ
                            if (targetElement) {
                                const elementPosition = targetElement.getBoundingClientRect().top + window.pageYOffset;
                                const offsetPosition = elementPosition - 100;
                                window.scrollTo({
                                    top: offsetPosition,
                                    behavior: 'smooth'
                                });
                            } else if (allContainers.length > 0) {
                                // å¦‚æœæ‰¾ä¸åˆ°ï¼Œæ»šåŠ¨åˆ°ç¬¬ä¸€ä¸ªå¯è§çš„ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å­å›¾
                                const firstContainer = allContainers[0];
                                const elementPosition = firstContainer.getBoundingClientRect().top + window.pageYOffset;
                                const offsetPosition = elementPosition - 100;
                                window.scrollTo({
                                    top: offsetPosition,
                                    behavior: 'smooth'
                                });
                            }
                        } catch (e) {
                            console.error('æ»šåŠ¨åˆ°ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å¤±è´¥:', e);
                        }
                    }, 300);
                    return window.dash_clientside.no_update;
                }
                
                // æ™®é€šå›¾è¡¨IDï¼ˆå­—ç¬¦ä¸²ï¼‰
                if (typeof scroll_data === 'string') {
                    const plot_id = scroll_data;
                    // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ ‡ç­¾é¡µåˆ‡æ¢å®Œæˆ
                    setTimeout(function() {
                        try {
                            // æŸ¥æ‰¾å¯¹åº”çš„å›¾è¡¨å…ƒç´ 
                            const plotElement = document.getElementById(plot_id);
                            if (plotElement) {
                                // æ»šåŠ¨åˆ°å›¾è¡¨ä½ç½®ï¼Œå¹¶æ·»åŠ ä¸€äº›åç§»é‡ï¼ˆå‘ä¸Šåç§»100pxï¼Œé¿å…è¢«é¡¶éƒ¨å¯¼èˆªæ é®æŒ¡ï¼‰
                                const elementPosition = plotElement.getBoundingClientRect().top + window.pageYOffset;
                                const offsetPosition = elementPosition - 100;
                                
                                window.scrollTo({
                                    top: offsetPosition,
                                    behavior: 'smooth'  // å¹³æ»‘æ»šåŠ¨
                                });
                            }
                        } catch (e) {
                            console.error('æ»šåŠ¨åˆ°å›¾è¡¨å¤±è´¥:', e);
                        }
                    }, 300);  // å»¶è¿Ÿ300msï¼Œç¡®ä¿DOMæ›´æ–°å®Œæˆ
                }
            } catch (e) {
                console.error('å®¢æˆ·ç«¯å›è°ƒé”™è¯¯:', e);
            }
            
            return window.dash_clientside.no_update;
        }
        """,
        Output('scroll-to-plot-trigger', 'data', allow_duplicate=True),
        Input('scroll-to-plot-trigger', 'data'),
        prevent_initial_call=True
    )
    
    # å®¢æˆ·ç«¯å›è°ƒï¼šæ»šåŠ¨åˆ°ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾çš„å¯¹åº”å­å›¾ä½ç½®
    app.clientside_callback(
        """
        function(scroll_data) {
            if (!scroll_data || !scroll_data.subplot_index) {
                return window.dash_clientside.no_update;
            }
            
            const subplotIndex = scroll_data.subplot_index;
            const graphElement = document.getElementById('relative-delay-distribution-plot');
            if (!graphElement) {
                return window.dash_clientside.no_update;
            }
            
            // è®¡ç®—å­å›¾çš„ä½ç½®ï¼ˆæ¯ä¸ªå­å›¾é«˜åº¦çº¦500pxï¼‰
            const baseHeightPerSubplot = 500;
            const subplotTop = (subplotIndex - 1) * baseHeightPerSubplot;
            
            // è·å–å›¾è¡¨å…ƒç´ çš„ä½ç½®
            setTimeout(function() {
                const graphRect = graphElement.getBoundingClientRect();
                const absoluteGraphTop = graphRect.top + window.pageYOffset;
                const targetScrollTop = absoluteGraphTop + subplotTop;
                
                // æ»šåŠ¨åˆ°å¯¹åº”å­å›¾ä½ç½®
                window.scrollTo({
                    top: targetScrollTop,
                    behavior: 'smooth'
                });
                
                // å»¶è¿Ÿåæ»šåŠ¨åˆ°è¡¨æ ¼ä½ç½®
                setTimeout(function() {
                    const tableContainer = document.getElementById('relative-delay-distribution-table-container');
                    if (tableContainer) {
                        const tableRect = tableContainer.getBoundingClientRect();
                        const absoluteTableTop = tableRect.top + window.pageYOffset;
                        const offset = 100;
                        window.scrollTo({
                            top: absoluteTableTop - offset,
                            behavior: 'smooth'
                        });
                    }
                }, 500);
            }, 300);
            
            return window.dash_clientside.no_update;
        }
        """,
        Output('relative-delay-distribution-scroll-trigger', 'data', allow_duplicate=True),
        Input('relative-delay-distribution-scroll-trigger', 'data'),
        prevent_initial_call=True
    )

    # å®¢æˆ·ç«¯å›è°ƒï¼šè¯„çº§ç»Ÿè®¡è¿”å›æ—¶æ»šåŠ¨åˆ°å¯¹åº”è¡Œ
    app.clientside_callback(
        """
        function(scroll_data) {
            if (!scroll_data || !scroll_data.table_index || scroll_data.row_index === undefined) {
                return window.dash_clientside.no_update;
            }

            const tableIndex = scroll_data.table_index;
            const rowIndex = scroll_data.row_index;

            // æŸ¥æ‰¾å¯¹åº”çš„è¡¨æ ¼
            const tableSelector = `[data-dash-component-id*="grade-detail-datatable"][data-dash-component-id*="${tableIndex}"]`;
            const tableElement = document.querySelector(tableSelector);

            if (!tableElement) {
                console.warn('Grade detail table not found:', tableSelector);
                return window.dash_clientside.no_update;
            }

            // æ¨¡æ‹Ÿç‚¹å‡»å¯¹åº”è¡Œæ¥æ¿€æ´»å®ƒ
            setTimeout(function() {
                try {
                    // æ„é€ è¡¨æ ¼è¡Œçš„é€‰æ‹©å™¨
                    // Dashè¡¨æ ¼çš„è¡Œé€šå¸¸æœ‰ç‰¹å®šçš„ç±»åå’Œç»“æ„
                    const tableBody = tableElement.querySelector('.dash-table-body');
                    if (tableBody) {
                        const rows = tableBody.querySelectorAll('.dash-table-row');
                        if (rows && rows.length > rowIndex) {
                            const targetRow = rows[rowIndex];

                            // æ»šåŠ¨åˆ°ç›®æ ‡è¡Œ
                            targetRow.scrollIntoView({
                                behavior: 'smooth',
                                block: 'center'
                            });

                            // è§¦å‘è¡Œçš„ç‚¹å‡»äº‹ä»¶æ¥æ¿€æ´»å®ƒ
                            // æ³¨æ„ï¼šè¿™å¯èƒ½éœ€è¦æ ¹æ®Dashè¡¨æ ¼çš„å…·ä½“å®ç°è¿›è¡Œè°ƒæ•´
                            setTimeout(function() {
                                // å°è¯•è®¾ç½®active_cellï¼ˆå¦‚æœå¯èƒ½çš„è¯ï¼‰
                                // è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
                                console.log('Scrolled to grade detail table row:', rowIndex);
                            }, 300);
                        } else {
                            console.warn('Target row not found in grade detail table:', rowIndex);
                        }
                    }
                } catch (error) {
                    console.error('Error scrolling to grade detail table row:', error);
                }
            }, 500);  // ç­‰å¾…æ¨¡æ€æ¡†æ˜¾ç¤ºåå†æ»šåŠ¨

            return window.dash_clientside.no_update;
        }
        """,
        Output('grade-detail-return-scroll-trigger', 'data', allow_duplicate=True),
        Input('grade-detail-return-scroll-trigger', 'data'),
        prevent_initial_call=True
    )

    # å®¢æˆ·ç«¯å›è°ƒï¼šæ»šåŠ¨åˆ°è¯„çº§ç»Ÿè®¡åŒºåŸŸ
    app.clientside_callback(
        """
        function(scroll_data) {
            if (!scroll_data) {
                return window.dash_clientside.no_update;
            }

            if (scroll_data.scroll_to === 'grade_detail_section') {
                // æŸ¥æ‰¾è¯„çº§ç»Ÿè®¡åŒºåŸŸ
                // ä¼˜å…ˆæŸ¥æ‰¾æœ‰ç‰¹å®šIDçš„å¡ç‰‡
                let targetElement = document.getElementById('grade-statistics-card');

                if (!targetElement) {
                    // å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šIDï¼ŒæŸ¥æ‰¾æ‰€æœ‰å¡ç‰‡ï¼Œå¯»æ‰¾åŒ…å«"åŒ¹é…è´¨é‡è¯„çº§ç»Ÿè®¡"çš„æ ‡é¢˜
                    const allCards = document.querySelectorAll('.card');
                    for (let card of allCards) {
                        const header = card.querySelector('h4');
                        if (header && header.textContent && header.textContent.includes('åŒ¹é…è´¨é‡è¯„çº§ç»Ÿè®¡')) {
                            targetElement = card;
                            console.log('Found grade detail card by title:', header.textContent);
                            break;
                        }
                    }
                }

                // å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«grade-detailçš„å…ƒç´ 
                if (!targetElement) {
                    const gradeDetailElements = document.querySelectorAll('[id*="grade-detail"]');
                    if (gradeDetailElements.length > 0) {
                        // å‘ä¸ŠæŸ¥æ‰¾æœ€è¿‘çš„å¡ç‰‡å®¹å™¨
                        targetElement = gradeDetailElements[0].closest('.card') || gradeDetailElements[0];
                        console.log('Found grade detail element by fallback');
                    }
                }

                if (targetElement) {
                    setTimeout(function() {
                        try {
                            // æ»šåŠ¨åˆ°è¯„çº§ç»Ÿè®¡åŒºåŸŸ
                            targetElement.scrollIntoView({
                                behavior: 'smooth',
                                block: 'start',
                                inline: 'nearest'
                            });

                            console.log('Scrolled to grade detail section successfully');
                        } catch (error) {
                            console.error('Error scrolling to grade detail section:', error);
                        }
                    }, 500);  // ç­‰å¾…æ›´é•¿æ—¶é—´è®©é¡µé¢å®Œå…¨åŠ è½½
                } else {
                    console.warn('Grade detail section not found. Available cards:');
                    const cards = document.querySelectorAll('.card');
                    for (let card of cards) {
                        const header = card.querySelector('h4');
                        if (header) {
                            console.warn('Card header:', header.textContent);
                        }
                    }
                }
            } else if (scroll_data.scroll_to === 'error_table_section') {
                // æŸ¥æ‰¾é”™è¯¯è¡¨æ ¼åŒºåŸŸ
                const tableType = scroll_data.table_type; // 'drop' æˆ– 'multi'
                let targetElement = null;

                if (tableType === 'drop') {
                    // æŸ¥æ‰¾ä¸¢é”¤è¡¨æ ¼
                    const dropTables = document.querySelectorAll('[id*="drop-hammers-table"]');
                    if (dropTables.length > 0) {
                        targetElement = dropTables[0].closest('.card') || dropTables[0];
                        console.log('Found drop hammers table');
                    }
                } else if (tableType === 'multi') {
                    // æŸ¥æ‰¾å¤šé”¤è¡¨æ ¼
                    const multiTables = document.querySelectorAll('[id*="multi-hammers-table"]');
                    if (multiTables.length > 0) {
                        targetElement = multiTables[0].closest('.card') || multiTables[0];
                        console.log('Found multi hammers table');
                    }
                }

                if (targetElement) {
                    setTimeout(function() {
                        try {
                            // æ»šåŠ¨åˆ°é”™è¯¯è¡¨æ ¼åŒºåŸŸ
                            targetElement.scrollIntoView({
                                behavior: 'smooth',
                                block: 'start',
                                inline: 'nearest'
                            });

                            console.log(`Scrolled to ${tableType} hammers table section successfully`);
                        } catch (error) {
                            console.error(`Error scrolling to ${tableType} hammers table section:`, error);
                        }
                    }, 500);
                } else {
                    console.warn(`${tableType} hammers table section not found`);
                }
            } else if (scroll_data.scroll_to === 'delay_time_series_section') {
                // æŸ¥æ‰¾å»¶æ—¶æ—¶é—´åºåˆ—å›¾åŒºåŸŸ
                const plotType = scroll_data.plot_type; // 'raw-delay-time-series-plot' æˆ– 'relative-delay-time-series-plot'
                let targetElement = null;

                // æ ¹æ®å›¾è¡¨ç±»å‹æŸ¥æ‰¾å¯¹åº”çš„å›¾è¡¨
                if (plotType === 'raw-delay-time-series-plot') {
                    // æŸ¥æ‰¾åŸå§‹å»¶æ—¶æ—¶é—´åºåˆ—å›¾
                    targetElement = document.getElementById('raw-delay-time-series-plot');
                    if (targetElement) {
                        // å‘ä¸ŠæŸ¥æ‰¾æœ€è¿‘çš„å¡ç‰‡å®¹å™¨
                        targetElement = targetElement.closest('.card') || targetElement;
                        console.log('Found raw delay time series plot');
                    }
                } else if (plotType === 'relative-delay-time-series-plot') {
                    // æŸ¥æ‰¾ç›¸å¯¹å»¶æ—¶æ—¶é—´åºåˆ—å›¾
                    targetElement = document.getElementById('relative-delay-time-series-plot');
                    if (targetElement) {
                        // å‘ä¸ŠæŸ¥æ‰¾æœ€è¿‘çš„å¡ç‰‡å®¹å™¨
                        targetElement = targetElement.closest('.card') || targetElement;
                        console.log('Found relative delay time series plot');
                    }
                }

                // å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šå›¾è¡¨ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«æ—¶é—´åºåˆ—å›¾æ ‡é¢˜çš„å¡ç‰‡
                if (!targetElement) {
                    const allCards = document.querySelectorAll('.card');
                    for (let card of allCards) {
                        const header = card.querySelector('h6');
                        if (header && header.textContent) {
                            if (plotType === 'raw-delay-time-series-plot' &&
                                header.textContent.includes('åŸå§‹å»¶æ—¶æ—¶é—´åºåˆ—å›¾')) {
                                targetElement = card;
                                console.log('Found raw delay time series card by title');
                                break;
                            } else if (plotType === 'relative-delay-time-series-plot' &&
                                     header.textContent.includes('ç›¸å¯¹å»¶æ—¶æ—¶é—´åºåˆ—å›¾')) {
                                targetElement = card;
                                console.log('Found relative delay time series card by title');
                                break;
                            }
                        }
                    }
                }

                if (targetElement) {
                    setTimeout(function() {
                        try {
                            // æ»šåŠ¨åˆ°æ—¶é—´åºåˆ—å›¾åŒºåŸŸ
                            targetElement.scrollIntoView({
                                behavior: 'smooth',
                                block: 'start',
                                inline: 'nearest'
                            });

                            console.log(`Scrolled to ${plotType} successfully`);
                        } catch (error) {
                            console.error(`Error scrolling to ${plotType}:`, error);
                        }
                    }, 500);  // ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
                } else {
                    console.warn(`${plotType} not found. Available cards:`);
                    const cards = document.querySelectorAll('.card');
                    for (let card of cards) {
                        const header = card.querySelector('h6');
                        if (header) {
                            console.warn('Card header:', header.textContent);
                        }
                    }
                }
            }

            return window.dash_clientside.no_update;
        }
        """,
        Output('grade-detail-section-scroll-trigger', 'data', allow_duplicate=True),
        Input('grade-detail-section-scroll-trigger', 'data'),
        prevent_initial_call=True
    )

    # é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶è°ƒæ•´ç€‘å¸ƒå›¾
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('main-plot', 'figure', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True),
         Output('hammer-velocity-delay-scatter-plot', 'clickData', allow_duplicate=True)],
        [Input('hammer-velocity-delay-scatter-plot', 'clickData'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_hammer_velocity_scatter_click(click_data, close_modal_clicks, close_btn_clicks, session_id, current_style):
        """å¤„ç†é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ç‚¹å‡»ï¼Œæ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶è°ƒæ•´ç€‘å¸ƒå›¾æ˜¾ç¤ºèŒƒå›´"""
        from dash import callback_context

        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            logger.debug("[WARNING] æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒï¼šæ²¡æœ‰è§¦å‘æº")
            return current_style, [], no_update, no_update, no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"[PROCESS] æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            logger.info("[OK] å…³é—­æŒ‰é”®æ›²çº¿å¯¹æ¯”æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, [], no_update, no_update, no_update
        
        # å¦‚æœæ˜¯æ•£ç‚¹å›¾ç‚¹å‡»
        if trigger_id == 'hammer-velocity-delay-scatter-plot':
            logger.info(f"[PROCESS] æ•£ç‚¹å›¾ç‚¹å‡»ï¼šclick_data={click_data}")
            backend = session_manager.get_backend(session_id)
            if not backend:
                logger.warning("[WARNING] æ²¡æœ‰æ‰¾åˆ°backend")
                return current_style, [], no_update, no_update, no_update

            if not click_data or 'points' not in click_data or not click_data['points']:
                logger.warning("[WARNING] click_dataä¸ºç©ºæˆ–æ²¡æœ‰points")
                return current_style, [], no_update, no_update, no_update
            
            try:
                # è·å–ç‚¹å‡»çš„æ•°æ®ç‚¹
                point = click_data['points'][0]
                logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡» - ç‚¹å‡»ç‚¹æ•°æ®: {point}")
                
                if not point.get('customdata'):
                    logger.warning("[WARNING] æ•£ç‚¹å›¾ç‚¹å‡» - ç‚¹æ²¡æœ‰customdata")
                    return current_style, [], no_update, no_update, no_update
                
                # å®‰å…¨åœ°æå–customdataï¼ˆå‚è€ƒZ-Scoreæ•£ç‚¹å›¾çš„é€»è¾‘ï¼‰
                raw_customdata = point['customdata']
                logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡» - raw_customdataç±»å‹: {type(raw_customdata)}, å€¼: {raw_customdata}")
                
                if isinstance(raw_customdata, list) and len(raw_customdata) > 0:
                    customdata = raw_customdata[0] if isinstance(raw_customdata[0], list) else raw_customdata
                else:
                    customdata = raw_customdata
                
                # ç¡®ä¿customdataæ˜¯åˆ—è¡¨ç±»å‹
                if not isinstance(customdata, list):
                    logger.warning(f"[WARNING] æ•£ç‚¹å›¾ç‚¹å‡» - customdataä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(customdata)}, å€¼: {customdata}")
                    return current_style, [], no_update, no_update, no_update
                
                logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡» - customdata: {customdata}, é•¿åº¦: {len(customdata)}")
                
                # è§£æcustomdata
                # å•ç®—æ³•æ¨¡å¼: [delay_ms, original_velocity, record_idx, replay_idx, key_id]
                # å¤šç®—æ³•æ¨¡å¼: [delay_ms, original_velocity, record_idx, replay_idx, algorithm_name, key_id]
                if len(customdata) < 5:
                    logger.warning(f"[WARNING] customdataé•¿åº¦ä¸è¶³ï¼š{len(customdata)}ï¼ŒæœŸæœ›è‡³å°‘5ä¸ªå…ƒç´ ")
                    return current_style, [], no_update
                
                delay_ms = customdata[0]
                original_velocity = customdata[1]  # åŸå§‹é”¤é€Ÿå€¼ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
                record_idx = customdata[2]
                replay_idx = customdata[3]
                # åˆ¤æ–­æ˜¯å•ç®—æ³•è¿˜æ˜¯å¤šç®—æ³•æ¨¡å¼
                if len(customdata) >= 6:
                    # å¤šç®—æ³•æ¨¡å¼ï¼šæœ‰algorithm_name
                    algorithm_name = customdata[4]
                    key_id = customdata[5]
                else:
                    # å•ç®—æ³•æ¨¡å¼ï¼šæ²¡æœ‰algorithm_name
                    algorithm_name = None
                    key_id = customdata[4]
                
                logger.info(f"ğŸ–±ï¸ æ•£ç‚¹å›¾ç‚¹å‡»: ç®—æ³•={algorithm_name}, æŒ‰é”®={key_id}, é”¤é€Ÿ={original_velocity}, record_idx={record_idx}, replay_idx={replay_idx}")
                
                # è®¡ç®—æ—¶é—´ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æ—¶ç›´æ¥ä½¿ç”¨
                center_time_ms = None
                try:
                    if algorithm_name:
                        # å¤šç®—æ³•æ¨¡å¼
                        if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                            algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name)
                            if algorithm and algorithm.analyzer and algorithm.analyzer.note_matcher:
                                matched_pairs = algorithm.analyzer.matched_pairs
                                for r_idx, p_idx, r_note, p_note in matched_pairs:
                                    if r_idx == record_idx and p_idx == replay_idx:
                                        # è®¡ç®—keyonæ—¶é—´
                                        record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
                                        replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
                                        center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
                                        break
                                # å¤‡ç”¨æ–¹æ¡ˆï¼šä» offset_data è·å–
                                if center_time_ms is None:
                                    offset_data = algorithm.analyzer.note_matcher.get_offset_alignment_data()
                                    if offset_data:
                                        for item in offset_data:
                                            if item.get('record_index') == record_idx and item.get('replay_index') == replay_idx:
                                                record_keyon = item.get('record_keyon', 0)
                                                replay_keyon = item.get('replay_keyon', 0)
                                                if record_keyon and replay_keyon:
                                                    center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                                                    break
                    else:
                        # å•ç®—æ³•æ¨¡å¼
                        if backend.analyzer and backend.analyzer.note_matcher:
                            matched_pairs = backend.analyzer.matched_pairs
                            for r_idx, p_idx, r_note, p_note in matched_pairs:
                                if r_idx == record_idx and p_idx == replay_idx:
                                    # è®¡ç®—keyonæ—¶é—´
                                    record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
                                    replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
                                    center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
                                    break
                            # å¤‡ç”¨æ–¹æ¡ˆï¼šä» offset_data è·å–
                            if center_time_ms is None:
                                offset_data = backend.analyzer.note_matcher.get_offset_alignment_data()
                                if offset_data:
                                    for item in offset_data:
                                        if item.get('record_index') == record_idx and item.get('replay_index') == replay_idx:
                                            record_keyon = item.get('record_keyon', 0)
                                            replay_keyon = item.get('replay_keyon', 0)
                                            if record_keyon and replay_keyon:
                                                center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                                                break
                except Exception as e:
                    logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                
                # å­˜å‚¨å½“å‰ç‚¹å‡»çš„æ•°æ®ç‚¹ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æŒ‰é’®
                point_info = {
                    'algorithm_name': algorithm_name,
                    'record_idx': record_idx,
                    'replay_idx': replay_idx,
                    'key_id': key_id,
                    'source_plot_id': 'hammer-velocity-delay-scatter-plot',  # è®°å½•æ¥æºå›¾è¡¨ID
                    'center_time_ms': center_time_ms  # é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯
                }
                
                # ä¸è‡ªåŠ¨è°ƒæ•´ç€‘å¸ƒå›¾ï¼Œç­‰å¾…ç”¨æˆ·ç‚¹å‡»è·³è½¬æŒ‰é’®
                waterfall_fig = no_update
                
                # å¦‚æœæ˜¯å¤šç®—æ³•æ¨¡å¼ä¸”æœ‰ç®—æ³•åç§°ï¼Œä½¿ç”¨generate_multi_algorithm_scatter_detail_plot_by_indices
                if algorithm_name:
                    # å¤šç®—æ³•æ¨¡å¼ï¼šä½¿ç”¨ä¸Z-Scoreæ•£ç‚¹å›¾ç›¸åŒçš„æ–¹æ³•
                    detail_figure1, detail_figure2, detail_figure_combined = backend.generate_multi_algorithm_scatter_detail_plot_by_indices(
                        algorithm_name=algorithm_name,
                        record_index=record_idx,
                        replay_index=replay_idx
                    )
                    
                    logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - å›¾è¡¨ç”Ÿæˆç»“æœ: figure1={detail_figure1 is not None}, figure2={detail_figure2 is not None}, figure_combined={detail_figure_combined is not None}")
                    
                    if detail_figure1 and detail_figure2 and detail_figure_combined:
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        logger.info("[OK] æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - è¿”å›æ¨¡æ€æ¡†å’Œå›¾è¡¨")
                        # å°†Plotly figureå¯¹è±¡åŒ…è£…åœ¨dcc.Graphç»„ä»¶ä¸­
                        return modal_style, dcc.Graph(figure=detail_figure_combined, style={'height': '600px'}), waterfall_fig, point_info, no_update
                    else:
                        logger.warning(f"[WARNING] æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼Œéƒ¨åˆ†å›¾è¡¨ä¸ºNone")
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        return modal_style, [html.Div([
                            html.P("å›¾è¡¨ç”Ÿæˆå¤±è´¥", className="text-danger text-center")
                        ])], waterfall_fig, point_info, no_update
                else:
                    # å•ç®—æ³•æ¨¡å¼ï¼šä½¿ç”¨generate_scatter_detail_plot_by_indices
                    detail_figure1, detail_figure2, detail_figure_combined = backend.generate_scatter_detail_plot_by_indices(
                        record_index=record_idx,
                        replay_index=replay_idx
                    )
                    
                    logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒï¼ˆå•ç®—æ³•ï¼‰ - å›¾è¡¨ç”Ÿæˆç»“æœ: figure1={detail_figure1 is not None}, figure2={detail_figure2 is not None}, figure_combined={detail_figure_combined is not None}")
                    
                    if detail_figure1 and detail_figure2 and detail_figure_combined:
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        logger.info("[OK] æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒï¼ˆå•ç®—æ³•ï¼‰ - è¿”å›æ¨¡æ€æ¡†å’Œå›¾è¡¨")
                        # å°†Plotly figureå¯¹è±¡åŒ…è£…åœ¨dcc.Graphç»„ä»¶ä¸­
                        return modal_style, dcc.Graph(figure=detail_figure_combined, style={'height': '600px'}), waterfall_fig, point_info, no_update
                    else:
                        logger.warning(f"[WARNING] æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒï¼ˆå•ç®—æ³•ï¼‰ - å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼Œéƒ¨åˆ†å›¾è¡¨ä¸ºNone")
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        return modal_style, [html.Div([
                            html.P("å›¾è¡¨ç”Ÿæˆå¤±è´¥", className="text-danger text-center")
                        ])], waterfall_fig, point_info, no_update
                
            except Exception as e:
                logger.error(f"[ERROR] ç”Ÿæˆæ›²çº¿å¯¹æ¯”å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                return modal_style, [html.Div([
                    html.P(f"ç”Ÿæˆå¯¹æ¯”å›¾å¤±è´¥: {str(e)}", className="text-danger text-center")
                ])], no_update, no_update, no_update

        # å…¶ä»–æƒ…å†µï¼Œä¿æŒå½“å‰çŠ¶æ€
        return current_style, [], no_update, no_update, no_update

    # ==================== é”¤é€Ÿå¯¹æ¯”å›¾ç‚¹å‡»å›è°ƒ ====================
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('main-plot', 'figure', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True),
         Output('hammer-velocity-comparison-plot', 'clickData', allow_duplicate=True)],
        [Input('hammer-velocity-comparison-plot', 'clickData'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_hammer_velocity_comparison_click(
        click_data: Optional[Dict[str, Any]],
        close_modal_clicks: Optional[int],
        close_btn_clicks: Optional[int],
        session_id: str,
        current_style: Dict[str, Any]
    ) -> Tuple[Dict[str, Any], List[Union[html.Div, dcc.Graph]], Union[Figure, NoUpdate], Dict[str, Any], Optional[Dict[str, Any]]]:
        """å¤„ç†é”¤é€Ÿå¯¹æ¯”å›¾ç‚¹å‡»ï¼Œæ˜¾ç¤ºå¯¹åº”æŒ‰é”®çš„æ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰"""
        from dash import callback_context

        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            logger.debug("[WARNING] é”¤é€Ÿå¯¹æ¯”å›¾ç‚¹å‡»å›è°ƒï¼šæ²¡æœ‰è§¦å‘æº")
            return current_style, [], no_update, no_update, no_update

        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"[PROCESS] é”¤é€Ÿå¯¹æ¯”å›¾ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")

        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            logger.info("[OK] å…³é—­æŒ‰é”®æ›²çº¿å¯¹æ¯”æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, [], no_update, no_update, no_update

        # å¦‚æœæ˜¯é”¤é€Ÿå¯¹æ¯”å›¾ç‚¹å‡»
        if trigger_id == 'hammer-velocity-comparison-plot' and click_data:
            logger.info(f"[PROCESS] é”¤é€Ÿå¯¹æ¯”å›¾ç‚¹å‡»ï¼šclick_data={click_data}")

            backend = session_manager.get_backend(session_id)
            if not backend:
                logger.warning("[WARNING] æ²¡æœ‰æ‰¾åˆ°backend")
                return current_style, [], no_update, no_update, no_update

            try:
                # è§£æç‚¹å‡»æ•°æ®
                point = click_data['points'][0]
                customdata = point.get('customdata', [])

                if len(customdata) >= 4:
                    key_id = int(customdata[0])
                    algorithm_name = customdata[1]
                    record_index = int(customdata[2])
                    replay_index = int(customdata[3])

                    logger.info(f"[INFO] ç‚¹å‡»æ•°æ®è§£æï¼škey_id={key_id}, algorithm_name={algorithm_name}, record_index={record_index}, replay_index={replay_index}")

                    # ç”Ÿæˆæ›²çº¿å¯¹æ¯”å›¾
                    if backend.multi_algorithm_mode:
                        # å¤šç®—æ³•æ¨¡å¼ï¼šä½¿ç”¨ä¸Z-Scoreæ•£ç‚¹å›¾ç›¸åŒçš„æ–¹æ³•
                        detail_figure1, detail_figure2, detail_figure_combined = backend.generate_multi_algorithm_scatter_detail_plot_by_indices(
                            algorithm_name=algorithm_name,
                            record_index=record_index,
                            replay_index=replay_index
                        )
                    else:
                        # å•ç®—æ³•æ¨¡å¼ï¼šä½¿ç”¨record_indexå’Œreplay_index
                        detail_figure1, detail_figure2, detail_figure_combined = backend.generate_scatter_detail_plot_by_indices(
                            record_index, replay_index
                        )

                    if detail_figure_combined is None:
                        logger.error("[ERROR] ç”Ÿæˆæ›²çº¿å¯¹æ¯”å›¾å¤±è´¥")
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        return modal_style, [html.Div([
                            html.P("ç”Ÿæˆæ›²çº¿å¯¹æ¯”å›¾å¤±è´¥", className="text-danger text-center")
                        ])], no_update, no_update, no_update

                    # ç”Ÿæˆç€‘å¸ƒå›¾å¹¶è°ƒæ•´æ˜¾ç¤ºèŒƒå›´
                    waterfall_fig = backend.generate_waterfall_plot()
                    if waterfall_fig:
                        # è°ƒæ•´ç€‘å¸ƒå›¾çš„æ˜¾ç¤ºèŒƒå›´ä»¥çªå‡ºæ˜¾ç¤ºç‚¹å‡»çš„æŒ‰é”®
                        # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ç€‘å¸ƒå›¾çš„xè½´èŒƒå›´

                        # å­˜å‚¨ç‚¹å‡»ç‚¹ä¿¡æ¯ç”¨äºå…¶ä»–ç»„ä»¶ä½¿ç”¨
                        point_info = {
                            'key_id': key_id,
                            'algorithm_name': algorithm_name,
                            'source': 'hammer_velocity_comparison'
                        }

                        # æ˜¾ç¤ºæ¨¡æ€æ¡†
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }

                        return modal_style, [dcc.Graph(
                                        figure=detail_figure_combined,
                            style={'height': '800px'}
                        )], waterfall_fig, point_info, no_update

                    else:
                        logger.error("[ERROR] ç”Ÿæˆç€‘å¸ƒå›¾å¤±è´¥")
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        return modal_style, [html.Div([
                            html.P("ç”Ÿæˆç€‘å¸ƒå›¾å¤±è´¥", className="text-danger text-center")
                        ])], no_update, no_update, no_update

                else:
                    logger.error("[ERROR] ç‚¹å‡»æ•°æ®æ ¼å¼é”™è¯¯")
                    return current_style, [], no_update, no_update, no_update

            except Exception as e:
                logger.error(f"[ERROR] å¤„ç†é”¤é€Ÿå¯¹æ¯”å›¾ç‚¹å‡»å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                return modal_style, [html.Div([
                    html.P(f"å¤„ç†ç‚¹å‡»å¤±è´¥: {str(e)}", className="text-danger text-center")
                ])], no_update, no_update, no_update

        # å…¶ä»–æƒ…å†µï¼Œä¿æŒå½“å‰çŠ¶æ€
        return current_style, [], no_update, no_update, no_update

    # ==================== æ›²çº¿å¯¹é½æµ‹è¯•å›è°ƒ ====================
    @app.callback(
        Output('curve-alignment-test-result', 'children'),
        Input('btn-test-curve-alignment', 'n_clicks'),
        State('session-id', 'data'),
        prevent_initial_call=True
    )
    def handle_test_curve_alignment(n_clicks, session_id):
        """å¤„ç†æ›²çº¿å¯¹é½æµ‹è¯•æŒ‰é’®ç‚¹å‡»"""
        if n_clicks is None or n_clicks == 0:
            return html.Div("ç‚¹å‡»æŒ‰é’®å¼€å§‹æµ‹è¯•", 
                           className="text-muted text-center",
                           style={'padding': '20px', 'fontSize': '14px'})
        
        try:
            backend = session_manager.get_backend(session_id)
            if not backend:
                return html.Div([
                    dbc.Alert("[WARNING] æ— æ³•è·å–backendï¼Œè¯·å…ˆä¸Šä¼ æ•°æ®", color="warning")
                ])
            
            # æ‰§è¡Œæµ‹è¯•
            test_result = backend.test_curve_alignment()
            
            if test_result is None or test_result.get('status') != 'success':
                error_msg = test_result.get('message', 'æµ‹è¯•å¤±è´¥') if test_result else 'æµ‹è¯•å¤±è´¥'
                return html.Div([
                    dbc.Alert([
                        html.I(className="fas fa-exclamation-triangle me-2"),
                        html.Strong(f"æµ‹è¯•å¤±è´¥: {error_msg}")
                    ], color="danger")
                ])
            
            result = test_result['result']
            comparison_fig = test_result.get('comparison_figure')  # å¯¹é½å‰åå¯¹æ¯”å›¾ï¼ˆå‘åå…¼å®¹ï¼‰
            all_stages_fig = test_result.get('all_stages_figure')  # æ‰€æœ‰å¤„ç†é˜¶æ®µçš„å¯¹æ¯”å›¾ (å…¼å®¹æ—§ç‰ˆ)
            individual_stage_figures = test_result.get('individual_stage_figures', []) # æ–°ç‰ˆç‹¬ç«‹å›¾è¡¨åˆ—è¡¨
            
            # æ„å»ºç»“æœæ˜¾ç¤º
            children = []
            
            # æ¸²æŸ“æ‰€æœ‰å¤„ç†é˜¶æ®µçš„å›¾è¡¨
            # ä¼˜å…ˆä½¿ç”¨æ–°çš„ç‹¬ç«‹å›¾è¡¨åˆ—è¡¨
            if individual_stage_figures:
                children.append(html.H6("å„å¤„ç†é˜¶æ®µæ›²çº¿å¯¹æ¯”ï¼ˆæ’­æ”¾æ›²çº¿å¯¹é½åˆ°å½•åˆ¶æ›²çº¿ï¼‰", 
                           className="mb-3",
                           style={'color': '#2c3e50', 'fontWeight': 'bold'}))
                
                for stage_info in individual_stage_figures:
                    title = stage_info.get('title', 'æœªçŸ¥é˜¶æ®µ')
                    fig = stage_info.get('figure')
                    
                    if fig:
                        children.append(html.Div([
                            html.H6(title, className="mt-4 mb-2", style={'fontSize': '14px', 'fontWeight': 'bold', 'color': '#555'}),
                            dcc.Graph(
                                figure=fig, 
                                config={'displayModeBar': True}
                            )
                        ], className="mb-2"))
            
            # å¦‚æœæ²¡æœ‰æ–°ç‰ˆå›¾è¡¨ï¼Œå›é€€åˆ°æ—§ç‰ˆå¤§å›¾
            elif all_stages_fig is not None:
                children.append(html.Div([
                    html.H6("å„å¤„ç†é˜¶æ®µæ›²çº¿å¯¹æ¯”ï¼ˆæ’­æ”¾æ›²çº¿å¯¹é½åˆ°å½•åˆ¶æ›²çº¿ï¼‰", 
                           className="mb-3",
                           style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                    dcc.Graph(figure=all_stages_fig, style={'height': '2800px', 'minHeight': '2000px'})
                ], className="mb-4"))
            
            # ç›¸ä¼¼åº¦ä¿¡æ¯
            children.append(
                html.Div([
                    html.H6("ç›¸ä¼¼åº¦ç»“æœ", className="mb-3",
                           style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                    dbc.Row([
                        dbc.Col([
                            dbc.Card([
                                dbc.CardBody([
                                    html.Small("ä¸Šå‡æ²¿ç›¸ä¼¼åº¦", className="text-muted d-block mb-1"),
                                    html.H4(f"{result.get('rising_edge_similarity', 0):.3f}", 
                                           style={'color': '#1f77b4', 'fontWeight': 'bold'})
                                ])
                            ], color="primary", outline=True)
                        ], width=4),
                        dbc.Col([
                            dbc.Card([
                                dbc.CardBody([
                                    html.Small("ä¸‹é™æ²¿ç›¸ä¼¼åº¦", className="text-muted d-block mb-1"),
                                    html.H4(f"{result.get('falling_edge_similarity', 0):.3f}", 
                                           style={'color': '#ff7f0e', 'fontWeight': 'bold'})
                                ])
                            ], color="warning", outline=True)
                        ], width=4),
                        dbc.Col([
                            dbc.Card([
                                dbc.CardBody([
                                    html.Small("æ•´ä½“ç›¸ä¼¼åº¦", className="text-muted d-block mb-1"),
                                    html.H4(f"{result.get('overall_similarity', 0):.3f}", 
                                           style={'color': '#2ca02c', 'fontWeight': 'bold'})
                                ])
                            ], color="success", outline=True)
                        ], width=4)
                    ], className="mb-3"),
                ], className="mb-4")
            )

            # ç‰¹å¾é‡åŒ–åˆ†æè¡¨æ ¼
            record_feat = result.get('record_features', {})
            replay_feat = result.get('replay_features', {})
            feat_diff = result.get('feature_comparison', {})
            
            if record_feat and replay_feat:
                import pandas as pd
                
                # å‡†å¤‡è¡¨æ ¼æ•°æ®
                table_data = [
                    {
                        "æŒ‡æ ‡": "å³°å€¼åŠ›åº¦ (Peak)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('peak_value', 0):.1f}", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('peak_value', 0):.1f}", 
                        "å·®å¼‚": f"{feat_diff.get('peak_diff', 0):.1f}",
                        "è¯´æ˜": "Max Value"
                    },
                    {
                        "æŒ‡æ ‡": "å³°å€¼æ—¶é—´ (Time)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('peak_time', 0):.1f}ms", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('peak_time', 0):.1f}ms", 
                        "å·®å¼‚": f"{feat_diff.get('peak_time_lag', 0):.1f}ms",
                        "è¯´æ˜": "Time Lag"
                    },
                    {
                        "æŒ‡æ ‡": "ä¸Šå‡æ—¶é—´ (Rise Time)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('rise_time_ms', 0):.1f}ms", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('rise_time_ms', 0):.1f}ms", 
                        "å·®å¼‚": f"{feat_diff.get('rise_time_diff', 0):.1f}ms",
                        "è¯´æ˜": "10% -> 90%"
                    },
                    {
                        "æŒ‡æ ‡": "ä¸Šå‡æ–œç‡ (Rise Slope)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('rise_slope', 0):.2f}", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('rise_slope', 0):.2f}", 
                        "å·®å¼‚": f"{replay_feat.get('rise_slope', 0) - record_feat.get('rise_slope', 0):.2f}",
                        "è¯´æ˜": "Value / ms"
                    },
                    {
                        "æŒ‡æ ‡": "ä¸‹é™æ—¶é—´ (Fall Time)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('fall_time_ms', 0):.1f}ms", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('fall_time_ms', 0):.1f}ms", 
                        "å·®å¼‚": f"{feat_diff.get('fall_time_diff', 0):.1f}ms",
                        "è¯´æ˜": "90% -> 10%"
                    },
                    {
                        "æŒ‡æ ‡": "ä¸‹é™æ–œç‡ (Fall Slope)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('fall_slope', 0):.2f}", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('fall_slope', 0):.2f}", 
                        "å·®å¼‚": f"{replay_feat.get('fall_slope', 0) - record_feat.get('fall_slope', 0):.2f}",
                        "è¯´æ˜": "Value / ms"
                    },
                    {
                        "æŒ‡æ ‡": "æŠ–åŠ¨åº¦ (Jitter RMSE)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('jitter', 0):.2f}", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('jitter', 0):.2f}", 
                        "å·®å¼‚": f"x{feat_diff.get('jitter_ratio', 0):.2f}",
                        "è¯´æ˜": "Raw - Smooth"
                    }
                ]
                
                table_header = [
                    html.Thead(html.Tr([html.Th(col) for col in ["æŒ‡æ ‡", "å½•åˆ¶å€¼", "æ’­æ”¾å€¼", "å·®å¼‚", "è¯´æ˜"]]))
                ]
                table_body = [
                    html.Tbody([
                        html.Tr([
                            html.Td(row["æŒ‡æ ‡"], style={'fontWeight': 'bold'}),
                            html.Td(row["å½•åˆ¶å€¼"]),
                            html.Td(row["æ’­æ”¾å€¼"]),
                            html.Td(row["å·®å¼‚"], style={'color': 'red' if 'x' in row['å·®å¼‚'] and float(row['å·®å¼‚'][1:]) > 2 else 'black'}),
                            html.Td(row["è¯´æ˜"], style={'fontSize': '0.85em', 'color': '#666'})
                        ]) for row in table_data
                    ])
                ]
                
                children.append(html.Div([
                    html.H6("ç‰©ç†ç‰¹å¾é‡åŒ–åˆ†æ", className="mb-3", style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                    dbc.Table(table_header + table_body, bordered=True, hover=True, striped=True, className="mb-4")
                ]))

            
            # å…¶ä»–ä¿¡æ¯
            children.append(html.Div([
                    dbc.Row([
                        dbc.Col([
                            html.Small(f"DTWè·ç¦»: {result.get('dtw_distance', 0):.3f}", 
                                      className="text-muted"),
                            html.Br(),
                            html.Small(f"æµ‹è¯•æ•°æ®: record_index={test_result.get('record_index', 'N/A')}, "
                                      f"replay_index={test_result.get('replay_index', 'N/A')}", 
                                      className="text-muted")
                        ], width=12)
                    ])
                ], className="mb-4")
            )
            
            # å¯¹é½å‰åå¯¹æ¯”å›¾
            if comparison_fig:
                children.append(
                    html.Div([
                        html.H6("å¯¹é½å‰åå¯¹æ¯”", className="mb-3",
                               style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                        dcc.Graph(
                            figure=comparison_fig,
                            style={'height': '800px'}
                        )
                    ], className="mb-4")
                )
            else:
                children.append(
                    html.Div([
                        dbc.Alert("[WARNING] æ— æ³•ç”Ÿæˆå¯¹é½å¯¹æ¯”å›¾", color="warning")
                    ])
                )
            
            return html.Div(children)
            
        except Exception as e:
            logger.error(f"[ERROR] æ›²çº¿å¯¹é½æµ‹è¯•å¤±è´¥: {e}")
            
            logger.error(traceback.format_exc())
            return html.Div([
                dbc.Alert([
                    html.I(className="fas fa-exclamation-triangle me-2"),
                    html.Strong(f"æµ‹è¯•å¤±è´¥: {str(e)}")
                ], color="danger")
            ])


            
            if record_idx is None or replay_idx is None:
                logger.warning(f"[WARNING] æ•°æ®ç‚¹ä¿¡æ¯ä¸å®Œæ•´: {point_info}")
                return no_update, no_update
            
            logger.info(f"[PROCESS] è·³è½¬åˆ°ç€‘å¸ƒå›¾: ç®—æ³•={algorithm_name}, record_idx={record_idx}, replay_idx={replay_idx}")
            
            # è·å–éŸ³ç¬¦æ—¶é—´èŒƒå›´
            time_range = backend.get_note_time_range_for_waterfall(algorithm_name, record_idx, replay_idx, margin_ms=500.0)
            if not time_range:
                logger.warning(f"[WARNING] æ— æ³•è·å–éŸ³ç¬¦æ—¶é—´èŒƒå›´")
                return no_update, no_update
            
            # ç”Ÿæˆæ–°çš„ç€‘å¸ƒå›¾
            waterfall_fig = backend.generate_waterfall_plot()
            if not waterfall_fig:
                logger.warning(f"[WARNING] ç€‘å¸ƒå›¾ç”Ÿæˆå¤±è´¥")
                return no_update, no_update
            
            # æ›´æ–°xè½´èŒƒå›´
            if hasattr(waterfall_fig, 'update_xaxes'):
                waterfall_fig.update_xaxes(
                    range=[time_range[0], time_range[1]],
                    title='Time (ms)',
                    showgrid=True,
                    gridcolor='lightgray',
                    gridwidth=1
                )
                logger.info(f"[OK] ç€‘å¸ƒå›¾å·²è°ƒæ•´åˆ°æ—¶é—´èŒƒå›´: [{time_range[0]:.1f}, {time_range[1]:.1f}]ms")
            elif hasattr(waterfall_fig, 'update_layout'):
                waterfall_fig.update_layout(
                    xaxis=dict(
                        range=[time_range[0], time_range[1]],
                        title='Time (ms)',
                        showgrid=True,
                        gridcolor='lightgray',
                        gridwidth=1
                    )
                )
                logger.info(f"[OK] ç€‘å¸ƒå›¾å·²è°ƒæ•´åˆ°æ—¶é—´èŒƒå›´: [{time_range[0]:.1f}, {time_range[1]:.1f}]ms (ä½¿ç”¨update_layout)")
            else:
                logger.warning(f"[WARNING] ç€‘å¸ƒå›¾å¯¹è±¡ä¸æ”¯æŒæ›´æ–°xè½´èŒƒå›´")
            
            # è¿”å›æ›´æ–°åçš„ç€‘å¸ƒå›¾å’Œåˆ‡æ¢åˆ°ç€‘å¸ƒå›¾æ ‡ç­¾é¡µ
            return waterfall_fig, 'waterfall-tab'
            
        except Exception as e:
            logger.error(f"[ERROR] è·³è½¬åˆ°ç€‘å¸ƒå›¾å¤±è´¥: {e}")

            logger.error(traceback.format_exc())
            return no_update, no_update

    # ä¸¢é”¤å’Œå¤šé”¤è¡¨æ ¼ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True)],
        [Input({'type': 'drop-hammers-table', 'index': dash.ALL}, 'active_cell'),
         Input({'type': 'multi-hammers-table', 'index': dash.ALL}, 'active_cell'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State({'type': 'drop-hammers-table', 'index': dash.ALL}, 'data'),
         State({'type': 'multi-hammers-table', 'index': dash.ALL}, 'data'),
         State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_error_tables_click(active_cells_multi_drop, active_cells_multi_multi, close_modal_clicks, close_btn_clicks,
                                 data_multi_drop, data_multi_multi, session_id, current_style):
        """å¤„ç†ä¸¢é”¤å’Œå¤šé”¤è¡¨æ ¼ç‚¹å‡»ï¼Œæ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾"""
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            return current_style, [], no_update

        trigger_id = ctx.triggered[0]['prop_id']
        trigger_value = ctx.triggered[0].get('value')

        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal.n_clicks', 'close-key-curves-modal-btn.n_clicks']:
            return {'display': 'none'}, [], no_update

        # å¤„ç†è¡¨æ ¼ç‚¹å‡»
        table_type = None
        active_cell = None
        table_data = None
        algorithm_name = None

        # è§£æè§¦å‘æº
        if 'drop-hammers-table' in trigger_id:
            table_type = 'drop'
        elif 'multi-hammers-table' in trigger_id:
            table_type = 'multi'

        if not table_type:
            return current_style, [], no_update

        # è·å–å¯¹åº”çš„æ•°æ®å’Œactive_cell
        try:
            # è§£æID
            id_parts = json.loads(trigger_id.split('.')[0])
            algorithm_name = id_parts.get('index', 'single')  # é»˜è®¤å•ç®—æ³•æ¨¡å¼

            # æ ¹æ®è¡¨æ ¼ç±»å‹è·å–å¯¹åº”çš„æ•°æ®
            if table_type == 'drop':
                # æ‰¾åˆ°å¯¹åº”çš„active_cellå’Œdata
                table_index = None
                for i, cell in enumerate(active_cells_multi_drop):
                    if cell is not None:
                        table_index = i
                        active_cell = cell
                        table_data = data_multi_drop[i] if i < len(data_multi_drop) else None
                        break
            else:  # multi
                # æ‰¾åˆ°å¯¹åº”çš„active_cellå’Œdata
                table_index = None
                for i, cell in enumerate(active_cells_multi_multi):
                    if cell is not None:
                        table_index = i
                        active_cell = cell
                        table_data = data_multi_multi[i] if i < len(data_multi_multi) else None
                        break

        except (json.JSONDecodeError, KeyError, IndexError):
            return current_style, [], no_update

        if not active_cell or not table_data:
            return current_style, [], no_update

        # è·å–åç«¯å®ä¾‹
        backend = session_manager.get_backend(session_id)
        if not backend:
            return current_style, [], no_update

        try:
            # è·å–ç‚¹å‡»çš„è¡Œæ•°æ®
            row_idx = active_cell.get('row')
            if row_idx is None or row_idx >= len(table_data):
                return current_style, [], no_update

            row_data = table_data[row_idx]

            # è·å–éŸ³ç¬¦ä¿¡æ¯
            data_type = row_data.get('data_type')
            key_id_str = row_data.get('keyId')
            global_index = row_data.get('index')

            if key_id_str == 'æ— åŒ¹é…':
                # è¿™æ˜¯æ²¡æœ‰æ•°æ®çš„è¡Œï¼Œè·³è¿‡
                return current_style, [], no_update
            
            # è½¬æ¢key_idä¸ºæ•´æ•°
            try:
                key_id = int(key_id_str) if isinstance(key_id_str, (int, float, str)) and str(key_id_str).isdigit() else None
                if key_id is None:
                    logger.warning(f"[WARNING] æ— æ³•è½¬æ¢keyIdä¸ºæ•´æ•°: {key_id_str}")
                    return current_style, [], no_update
            except (ValueError, TypeError):
                logger.warning(f"[WARNING] keyIdè½¬æ¢å¤±è´¥: {key_id_str}")
                return current_style, [], no_update

            # æ ¹æ®è¡¨æ ¼ç±»å‹ç¡®å®šæ•°æ®ç±»å‹
            if table_type == 'drop':
                # ä¸¢é”¤ï¼šåªæœ‰å½•åˆ¶æ•°æ®
                available_data = 'record'
                data_label = 'å½•åˆ¶'
            else:  # multi
                # å¤šé”¤ï¼šåªæœ‰æ’­æ”¾æ•°æ®
                available_data = 'replay'
                data_label = 'æ’­æ”¾'

            # æŸ¥æ‰¾å¯¹åº”çš„éŸ³ç¬¦æ•°æ®
            # å¯¹äºä¸¢é”¤/å¤šé”¤ï¼Œåº”è¯¥ä½¿ç”¨initial_valid_record_data/initial_valid_replay_data
            # å¹¶ä¸”ä½¿ç”¨global_indexï¼ˆå³è¡¨æ ¼ä¸­çš„indexå­—æ®µï¼‰ä½œä¸ºæ•°ç»„ç´¢å¼•
            note_data = None
            
            # ç¡®ä¿global_indexæ˜¯æ•´æ•°ç±»å‹
            try:
                if isinstance(global_index, str):
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢
                    if global_index == 'æ— åŒ¹é…':
                        return current_style, [], no_update
                    global_index = int(global_index)
            except (ValueError, TypeError):
                logger.warning(f"[WARNING] æ— æ³•è½¬æ¢global_index: {global_index}")
                return current_style, [], no_update
            
            if algorithm_name == 'single':
                # å•ç®—æ³•æ¨¡å¼
                if available_data == 'record':
                    # ä¸¢é”¤ï¼šä½¿ç”¨initial_valid_record_data
                    initial_data = getattr(backend.analyzer, 'initial_valid_record_data', None)
                    if initial_data and global_index < len(initial_data):
                        note_data = initial_data[global_index]
                else:
                    # å¤šé”¤ï¼šä½¿ç”¨initial_valid_replay_data
                    initial_data = getattr(backend.analyzer, 'initial_valid_replay_data', None)
                    if initial_data and global_index < len(initial_data):
                        note_data = initial_data[global_index]
            else:
                # å¤šç®—æ³•æ¨¡å¼
                active_algorithms = backend.get_active_algorithms() if hasattr(backend, 'get_active_algorithms') else []
                target_algorithm = next((alg for alg in active_algorithms if alg.metadata.algorithm_name == algorithm_name), None)
                if target_algorithm and target_algorithm.analyzer:
                    if available_data == 'record':
                        # ä¸¢é”¤ï¼šä½¿ç”¨initial_valid_record_data
                        initial_data = getattr(target_algorithm.analyzer, 'initial_valid_record_data', None)
                        if initial_data and global_index < len(initial_data):
                            note_data = initial_data[global_index]
                    else:
                        # å¤šé”¤ï¼šä½¿ç”¨initial_valid_replay_data
                        initial_data = getattr(target_algorithm.analyzer, 'initial_valid_replay_data', None)
                        if initial_data and global_index < len(initial_data):
                            note_data = initial_data[global_index]

            if not note_data:
                return current_style, [], no_update

            # ç¡®ä¿key_idä¸note_dataä¸­çš„idä¸€è‡´
            actual_key_id = getattr(note_data, 'id', key_id)
            if actual_key_id != key_id:
                logger.info(f"ğŸ” key_idä¸ä¸€è‡´: è¡¨æ ¼ä¸­={key_id}, note_dataä¸­={actual_key_id}, ä½¿ç”¨note_dataä¸­çš„å€¼")
                key_id = actual_key_id

            # ç”Ÿæˆæ›²çº¿å›¾ï¼ˆåªæ˜¾ç¤ºæœ‰æ•°æ®çš„éƒ¨åˆ†ï¼‰
            fig = _create_single_data_curve_figure(note_data, key_id, data_label, algorithm_name)

            # è®¡ç®—æ—¶é—´ä¿¡æ¯ï¼Œç”¨äºè·³è½¬åˆ°ç€‘å¸ƒå›¾
            center_time_ms = None
            record_idx = None
            replay_idx = None
            
            try:
                # å¯¹äºä¸¢é”¤ï¼šåªæœ‰å½•åˆ¶æ•°æ®ï¼Œrecord_idxå°±æ˜¯global_indexï¼ˆåœ¨initial_valid_record_dataä¸­çš„ç´¢å¼•ï¼‰
                # å¯¹äºå¤šé”¤ï¼šåªæœ‰æ’­æ”¾æ•°æ®ï¼Œreplay_idxå°±æ˜¯global_indexï¼ˆåœ¨initial_valid_replay_dataä¸­çš„ç´¢å¼•ï¼‰
                if table_type == 'drop':
                    # ä¸¢é”¤ï¼šåªæœ‰å½•åˆ¶æ•°æ®
                    record_idx = global_index  # åœ¨initial_valid_record_dataä¸­çš„ç´¢å¼•
                    replay_idx = None  # ä¸¢é”¤æ²¡æœ‰æ’­æ”¾æ•°æ®
                    
                    # ä»è¡¨æ ¼æ•°æ®ä¸­è·å–keyOnæ—¶é—´ï¼ˆå·²ç»æ˜¯mså•ä½ï¼‰
                    try:
                        key_on_str = row_data.get('keyOn', '')
                        if key_on_str and key_on_str != 'æ— åŒ¹é…':
                            center_time_ms = float(key_on_str)
                        else:
                            # å¤‡ç”¨æ–¹æ¡ˆï¼šä»note_dataè®¡ç®—
                            if note_data and hasattr(note_data, 'after_touch') and not note_data.after_touch.empty:
                                center_time_ms = (note_data.after_touch.index[0] + note_data.offset) / 10.0
                            elif note_data and hasattr(note_data, 'hammers') and not note_data.hammers.empty:
                                center_time_ms = (note_data.hammers.index[0] + note_data.offset) / 10.0
                            elif note_data and hasattr(note_data, 'offset'):
                                center_time_ms = note_data.offset / 10.0
                    except (ValueError, TypeError):
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                        if note_data and hasattr(note_data, 'after_touch') and not note_data.after_touch.empty:
                            center_time_ms = (note_data.after_touch.index[0] + note_data.offset) / 10.0
                        elif note_data and hasattr(note_data, 'hammers') and not note_data.hammers.empty:
                            center_time_ms = (note_data.hammers.index[0] + note_data.offset) / 10.0
                        elif note_data and hasattr(note_data, 'offset'):
                            center_time_ms = note_data.offset / 10.0
                else:  # multi
                    # å¤šé”¤ï¼šåªæœ‰æ’­æ”¾æ•°æ®
                    record_idx = None  # å¤šé”¤æ²¡æœ‰å½•åˆ¶æ•°æ®
                    replay_idx = global_index  # åœ¨initial_valid_replay_dataä¸­çš„ç´¢å¼•
                    
                    # ä»è¡¨æ ¼æ•°æ®ä¸­è·å–keyOnæ—¶é—´ï¼ˆå·²ç»æ˜¯mså•ä½ï¼‰
                    try:
                        key_on_str = row_data.get('keyOn', '')
                        if key_on_str and key_on_str != 'æ— åŒ¹é…':
                            center_time_ms = float(key_on_str)
                        else:
                            # å¤‡ç”¨æ–¹æ¡ˆï¼šä»note_dataè®¡ç®—
                            if note_data and hasattr(note_data, 'after_touch') and not note_data.after_touch.empty:
                                center_time_ms = (note_data.after_touch.index[0] + note_data.offset) / 10.0
                            elif note_data and hasattr(note_data, 'hammers') and not note_data.hammers.empty:
                                center_time_ms = (note_data.hammers.index[0] + note_data.offset) / 10.0
                            elif note_data and hasattr(note_data, 'offset'):
                                center_time_ms = note_data.offset / 10.0
                    except (ValueError, TypeError):
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                        if note_data and hasattr(note_data, 'after_touch') and not note_data.after_touch.empty:
                            center_time_ms = (note_data.after_touch.index[0] + note_data.offset) / 10.0
                        elif note_data and hasattr(note_data, 'hammers') and not note_data.hammers.empty:
                            center_time_ms = (note_data.hammers.index[0] + note_data.offset) / 10.0
                        elif note_data and hasattr(note_data, 'offset'):
                            center_time_ms = note_data.offset / 10.0
            except Exception as e:
                logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                logger.error(traceback.format_exc())

            # å‡†å¤‡è·³è½¬ä¿¡æ¯
            clicked_info = {
                'key_id': key_id,
                'algorithm_name': algorithm_name,
                'data_type': data_type,
                'global_index': global_index,
                'available_data': available_data,  # æ ‡è®°æœ‰å“ªäº›æ•°æ®å¯ç”¨
                'source_plot_id': f'error-table-{table_type}',  # æ ‡è¯†æ¥æºæ˜¯é”™è¯¯è¡¨æ ¼
                'record_idx': record_idx,  # å½•åˆ¶æ•°æ®ç´¢å¼•
                'replay_idx': replay_idx,  # æ’­æ”¾æ•°æ®ç´¢å¼•
                'center_time_ms': center_time_ms  # é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯
            }

            # æ˜¾ç¤ºæ¨¡æ€æ¡† - ä½¿ç”¨ä¸å…¶ä»–å›è°ƒå‡½æ•°ä¸€è‡´çš„æ ·å¼ï¼Œé¿å…åµŒå¥—
            modal_style = {
                'display': 'block',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }

            # ç›´æ¥è¿”å›å›¾å½¢ï¼Œä¸æ·»åŠ é¢å¤–çš„å®¹å™¨åŒ…è£¹ï¼Œé¿å…å¤šä½™çš„æ¡†
            return modal_style, [dcc.Graph(figure=fig, style={'height': '500px'})], clicked_info

        except Exception as e:
            logger.error(f"[ERROR] å¤„ç†é”™è¯¯è¡¨æ ¼ç‚¹å‡»å¤±è´¥: {e}")
            return current_style, [], no_update

    def _create_single_data_curve_figure(note_data, key_id, data_label, algorithm_name):
        """åˆ›å»ºåªæ˜¾ç¤ºå•ä¾§æ•°æ®çš„æ›²çº¿å›¾"""
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots

        try:
            # åˆ›å»ºå­å›¾
            fig = make_subplots(
                rows=1, cols=1,
                subplot_titles=[f'æŒ‰é”® {key_id} - {data_label}æ•°æ®æ›²çº¿ ({algorithm_name})']
            )

            # æå–æ•°æ®
            if hasattr(note_data, 'after_touch') and note_data.after_touch is not None and len(note_data.after_touch.index) > 0:
                # ä½¿ç”¨after_touchæ•°æ®
                time_data = note_data.after_touch.index
                value_data = note_data.after_touch.values if hasattr(note_data.after_touch, 'values') else [0] * len(time_data)
            elif hasattr(note_data, 'hammers') and note_data.hammers is not None and len(note_data.hammers.index) > 0:
                # ä½¿ç”¨hammersæ•°æ®
                time_data = note_data.hammers.index
                value_data = note_data.hammers.values if hasattr(note_data.hammers, 'values') else [0] * len(time_data)
            else:
                # æ²¡æœ‰å¯ç”¨æ•°æ®
                fig.add_annotation(
                    text="æ— å¯ç”¨æ•°æ®",
                    xref="paper", yref="paper",
                    x=0.5, y=0.5,
                    showarrow=False
                )
                return fig

            # è½¬æ¢ä¸ºæ¯«ç§’
            time_ms = [t / 10.0 for t in time_data]

            # æ·»åŠ æ›²çº¿
            fig.add_trace(
                go.Scatter(
                    x=time_ms,
                    y=value_data,
                    mode='lines+markers',
                    name=f'{data_label}æ•°æ®',
                    line=dict(color='blue', width=2),
                    marker=dict(size=6, color='blue')
                ),
                row=1, col=1
            )

            # æ›´æ–°å¸ƒå±€
            fig.update_layout(
                height=400,
                showlegend=True,
                legend=dict(
                    orientation="h",
                    yanchor="bottom",
                    y=1.02,
                    xanchor="right",
                    x=1
                ),
                hovermode='x unified'
            )

            # æ›´æ–°åæ ‡è½´æ ‡ç­¾
            fig.update_xaxes(title_text="æ—¶é—´ (ms)", row=1, col=1)
            fig.update_yaxes(title_text="è§¦åå€¼", row=1, col=1)

            return fig

        except Exception as e:
            logger.error(f"[ERROR] åˆ›å»ºå•ä¾§æ•°æ®æ›²çº¿å›¾å¤±è´¥: {e}")
            # è¿”å›é”™è¯¯å›¾è¡¨
            error_fig = go.Figure()
            error_fig.add_annotation(
                text=f"ç”Ÿæˆæ›²çº¿å›¾å¤±è´¥: {str(e)}",
                xref="paper", yref="paper",
                x=0.5, y=0.5,
                showarrow=False
            )
            return error_fig

    # å•ç®—æ³•æ¨¡å¼é”™è¯¯è¡¨æ ¼æ•°æ®å¡«å……å›è°ƒ
    # æ³¨å†Œè¯„çº§ç»Ÿè®¡è¯¦æƒ…å›è°ƒ
    register_all_callbacks(app, session_manager)


