"""
å›è°ƒå‡½æ•°æ¨¡å— - å¤„ç†Dashåº”ç”¨çš„æ‰€æœ‰å›è°ƒé€»è¾‘
åŒ…å«æ–‡ä»¶ä¸Šä¼ ã€å†å²è®°å½•è¡¨æ ¼äº¤äº’ç­‰å›è°ƒå‡½æ•°
"""
import uuid
import base64
import os
import time
from datetime import datetime
from dash import Input, Output, State, callback_context, no_update, html, dcc, dash_table
import dash
import dash.dependencies
import dash_bootstrap_components as dbc
from ui.layout_components import create_report_layout, empty_figure, create_multi_algorithm_upload_area, create_multi_algorithm_management_area
from backend.piano_analysis_backend import PianoAnalysisBackend
from backend.data_manager import DataManager
from backend.session_manager import SessionManager
from ui.ui_processor import UIProcessor
from ui.multi_file_upload_handler import MultiFileUploadHandler
from utils.pdf_generator import PDFReportGenerator
from utils.logger import Logger
import plotly.graph_objects as go
import traceback

logger = Logger.get_logger()


def _create_delay_by_key_stats_html(analysis_result):
    """åˆ›å»ºå»¶æ—¶ä¸æŒ‰é”®åˆ†æçš„ç»Ÿè®¡ç»“æœHTML"""
    from typing import Dict, Any
    
    if analysis_result.get('status') != 'success':
        return [html.P("åˆ†æå¤±è´¥æˆ–æ•°æ®ä¸è¶³", className="text-danger")]
    
    children = []
    
    # ANOVAç»“æœ
    anova_result = analysis_result.get('anova_result', {})
    if anova_result:
        f_stat = anova_result.get('f_statistic')
        p_value = anova_result.get('p_value')
        significant = anova_result.get('significant', False)
        
        if f_stat is not None and p_value is not None:
            status_text = "å­˜åœ¨æ˜¾è‘—å·®å¼‚" if significant else "ä¸å­˜åœ¨æ˜¾è‘—å·®å¼‚"
            status_color = "success" if not significant else "warning"
            
            children.append(
                dbc.Alert([
                    html.H6("ANOVAæ£€éªŒç»“æœ", className="mb-2"),
                    html.P(f"Fç»Ÿè®¡é‡: {f_stat:.4f}", className="mb-1"),
                    html.P(f"på€¼: {p_value:.4f}", className="mb-1"),
                    html.P(f"ç»“è®º: {status_text}", className="mb-0", style={'fontWeight': 'bold'})
                ], color=status_color, className="mb-3")
            )
    
    # å¼‚å¸¸æŒ‰é”®
    anomaly_keys = analysis_result.get('anomaly_keys', [])
    if anomaly_keys:
        children.append(
            html.Div([
                html.H6("å¼‚å¸¸æŒ‰é”®åˆ—è¡¨", className="mb-2"),
                html.Ul([
                    html.Li(f"æŒ‰é”®ID {ak['key_id']}: å¹³å‡å»¶æ—¶ {ak['mean_delay']:.2f}ms ({ak['anomaly_type']}), "
                           f"åå·® {ak['deviation']:.2f}ms ({ak['deviation_std']:.2f}å€æ ‡å‡†å·®)")
                    for ak in anomaly_keys[:10]  # åªæ˜¾ç¤ºå‰10ä¸ª
                ])
            ], className="mb-3")
        )
    
    return children if children else [html.P("æš‚æ— ç»Ÿè®¡ç»“æœ", className="text-muted")]


def _create_delay_by_velocity_stats_html(analysis_result):
    """åˆ›å»ºå»¶æ—¶ä¸é”¤é€Ÿåˆ†æçš„ç»Ÿè®¡ç»“æœHTML"""
    from typing import Dict, Any
    
    if analysis_result.get('status') != 'success':
        return [html.P("åˆ†æå¤±è´¥æˆ–æ•°æ®ä¸è¶³", className="text-danger")]
    
    children = []
    
    # ç›¸å…³æ€§åˆ†æ
    correlation_result = analysis_result.get('correlation_result', {})
    if correlation_result:
        pearson_r = correlation_result.get('pearson_r')
        pearson_p = correlation_result.get('pearson_p')
        pearson_significant = correlation_result.get('pearson_significant', False)
        pearson_strength = correlation_result.get('pearson_strength', '')
        
        spearman_r = correlation_result.get('spearman_r')
        spearman_p = correlation_result.get('spearman_p')
        
        if pearson_r is not None:
            status_color = "success" if pearson_significant else "secondary"
            children.append(
                dbc.Alert([
                    html.H6("ç›¸å…³æ€§åˆ†æç»“æœ", className="mb-2"),
                    html.P(f"çš®å°”é€Šç›¸å…³ç³»æ•°: r = {pearson_r:.4f}, p = {pearson_p:.4f} ({pearson_strength})", className="mb-1"),
                    html.P(f"æ–¯çš®å°”æ›¼ç›¸å…³ç³»æ•°: r = {spearman_r:.4f}, p = {spearman_p:.4f}" if spearman_r is not None else "", className="mb-0")
                ], color=status_color, className="mb-3")
            )
    
    # å›å½’åˆ†æ
    regression_result = analysis_result.get('regression_result', {})
    linear_reg = regression_result.get('linear', {})
    if linear_reg:
        r_squared = linear_reg.get('r_squared', 0)
        p_value = linear_reg.get('p_value', 1)
        slope = linear_reg.get('slope', 0)
        intercept = linear_reg.get('intercept', 0)
        
        children.append(
            dbc.Card([
                dbc.CardBody([
                    html.H6("å›å½’åˆ†æç»“æœ", className="mb-2"),
                    html.P(f"çº¿æ€§å›å½’æ–¹ç¨‹: y = {slope:.4f}x + {intercept:.4f}", className="mb-1"),
                    html.P(f"RÂ² = {r_squared:.4f}, p = {p_value:.4f}", className="mb-0")
                ])
            ], className="mb-3")
        )
    
    # åˆ†ç»„åˆ†æ
    grouped_analysis = analysis_result.get('grouped_analysis', {})
    groups = grouped_analysis.get('groups', [])
    if groups:
        children.append(
            html.Div([
                html.H6("æŒ‰é”¤é€ŸåŒºé—´åˆ†ç»„ç»Ÿè®¡", className="mb-2"),
                dbc.Table([
                    html.Thead([
                        html.Tr([
                            html.Th("é”¤é€ŸåŒºé—´"),
                            html.Th("æ ·æœ¬æ•°"),
                            html.Th("å¹³å‡å»¶æ—¶(ms)"),
                            html.Th("æ ‡å‡†å·®(ms)")
                        ])
                    ]),
                    html.Tbody([
                        html.Tr([
                            html.Td(group.get('range_label', '')),
                            html.Td(group.get('count', 0)),
                            html.Td(f"{group.get('mean_delay', 0):.2f}"),
                            html.Td(f"{group.get('std_delay', 0):.2f}")
                        ])
                        for group in groups
                    ])
                ], bordered=True, hover=True, className="mb-3")
            ])
        )
    
    return children if children else [html.P("æš‚æ— ç»Ÿè®¡ç»“æœ", className="text-muted")]


def _create_empty_figure_for_callback(title):
    """åˆ›å»ºç”¨äºå›è°ƒçš„ç©ºPlotly figureå¯¹è±¡"""
    import plotly.graph_objects as go

    fig = go.Figure()
    fig.add_annotation(
        x=0.5,
        y=0.5,
        xref="paper",
        yref="paper",
        text=title,
        showarrow=False,
        font=dict(size=16, color="gray"),
        align="center"
    )

    fig.update_layout(
        title=title,
        xaxis=dict(visible=False),
        yaxis=dict(visible=False),
        height=600,
        template='plotly_white',
        showlegend=False
    )

    return fig


def _detect_trigger_source(ctx, backend, contents, filename, history_id):
    """
    æ£€æµ‹ç”¨æˆ·æ“ä½œçš„è§¦å‘æºï¼Œç¡®å®šéœ€è¦æ‰§è¡Œçš„å¤„ç†é€»è¾‘
    
    è§¦å‘æºä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š
    1. æ–°æ–‡ä»¶ä¸Šä¼  - æœ€é«˜ä¼˜å…ˆçº§ï¼Œä¼šé‡æ–°åŠ è½½æ•°æ®
    2. å†å²è®°å½•é€‰æ‹© - ä¸­ç­‰ä¼˜å…ˆçº§ï¼Œä¼šåˆ‡æ¢æ•°æ®æº
    3. æŒ‰é’®ç‚¹å‡» - æœ€ä½ä¼˜å…ˆçº§ï¼ŒåŸºäºå½“å‰æ•°æ®ç”Ÿæˆè§†å›¾
    
    Args:
        ctx: Dashå›è°ƒä¸Šä¸‹æ–‡ï¼ŒåŒ…å«è§¦å‘ä¿¡æ¯
        backend: åç«¯å®ä¾‹ï¼Œç”¨äºçŠ¶æ€ç®¡ç†
        contents: ä¸Šä¼ æ–‡ä»¶çš„å†…å®¹ï¼ˆbase64ç¼–ç ï¼‰
        filename: ä¸Šä¼ æ–‡ä»¶çš„æ–‡ä»¶å
        history_id: é€‰æ‹©çš„å†å²è®°å½•ID
        
    Returns:
        str: è§¦å‘æºç±»å‹ ('upload', 'history', 'waterfall', 'report', 'skip')
             - 'upload': æ–°æ–‡ä»¶ä¸Šä¼ 
             - 'history': å†å²è®°å½•é€‰æ‹©
             - 'waterfall': ç€‘å¸ƒå›¾æŒ‰é’®ç‚¹å‡»
             - 'report': æŠ¥å‘ŠæŒ‰é’®ç‚¹å‡»
             - 'skip': è·³è¿‡å¤„ç†ï¼ˆé‡å¤æ“ä½œï¼‰
    """
    # è·å–å½“å‰çŠ¶æ€ä¿¡æ¯
    current_time = time.time()
    current_state = _get_current_state(contents, filename, history_id)
    previous_state = _get_previous_state(backend)
    
    # ä»å›è°ƒä¸Šä¸‹æ–‡æ£€æµ‹è§¦å‘æº
    trigger_source = _detect_trigger_from_context(ctx, current_state, previous_state, backend, current_time)
    
    # å¦‚æœæ— æ³•ä»ä¸Šä¸‹æ–‡ç¡®å®šï¼Œåˆ™åŸºäºçŠ¶æ€å˜åŒ–æ™ºèƒ½åˆ¤æ–­
    if not trigger_source:
        trigger_source = _detect_trigger_from_state_change(current_state, previous_state, backend, current_time)
    
    # è®°å½•æœ€ç»ˆç»“æœ
    data_source = getattr(backend, '_data_source', 'none') if backend else 'none'
    logger.info(f"ğŸ” æœ€ç»ˆç¡®å®šè§¦å‘æº: {trigger_source}, å½“å‰æ•°æ®æº: {data_source}")
    return trigger_source

def _get_current_state(contents, filename, history_id):
    """è·å–å½“å‰çŠ¶æ€ä¿¡æ¯"""
    return {
        'has_upload': contents and filename,
        'has_history': history_id is not None,
        'upload_content': contents,
        'filename': filename,
        'history_id': history_id
    }

def _get_previous_state(backend):
    """è·å–ä¸Šæ¬¡çš„çŠ¶æ€ä¿¡æ¯"""
    if not backend:
        return {
            'last_upload_content': None,
            'last_history_id': None
        }
    
    return {
        'last_upload_content': getattr(backend, '_last_upload_content', None),
        'last_history_id': getattr(backend, '_last_selected_history_id', None)
    }

def _detect_trigger_from_context(ctx, current_state, previous_state, backend, current_time):
    """ä»å›è°ƒä¸Šä¸‹æ–‡æ£€æµ‹è§¦å‘æº"""
    if not ctx.triggered:
        return None
    
    recent_trigger = ctx.triggered[0]['prop_id']
    
    # æ£€æŸ¥æ–‡ä»¶ä¸Šä¼ è§¦å‘
    if 'upload-spmid-data' in recent_trigger:
        return _handle_upload_trigger(current_state, previous_state, backend, current_time)
    
    # æ£€æŸ¥å†å²è®°å½•é€‰æ‹©è§¦å‘
    elif 'history-dropdown' in recent_trigger:
        return _handle_history_trigger(current_state, previous_state, backend, current_time)
    
    # ç§»é™¤ç€‘å¸ƒå›¾å’ŒæŠ¥å‘ŠæŒ‰é’®ï¼Œæ”¹ä¸ºè‡ªåŠ¨ç”Ÿæˆ
    
    return None

def _handle_upload_trigger(current_state, previous_state, backend, current_time):
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ è§¦å‘"""
    if not current_state['has_upload']:
        return None
    
    # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦å‘ç”Ÿå˜åŒ–
    if current_state['upload_content'] != previous_state['last_upload_content']:
        _update_upload_state(backend, current_state['upload_content'], current_time)
        logger.info(f"ğŸ”„ æ£€æµ‹åˆ°æ–°æ–‡ä»¶ä¸Šä¼ : {current_state['filename']}")
        return 'upload'
    else:
        logger.warning("âš ï¸ æ–‡ä»¶å†…å®¹æœªå˜åŒ–ï¼Œè·³è¿‡é‡å¤å¤„ç†")
        return 'skip'

def _handle_history_trigger(current_state, previous_state, backend, current_time):
    """å¤„ç†å†å²è®°å½•é€‰æ‹©è§¦å‘"""
    if not current_state['has_history']:
        return None
    
    # æ£€æŸ¥å†å²è®°å½•é€‰æ‹©æ˜¯å¦å‘ç”Ÿå˜åŒ–
    if current_state['history_id'] != previous_state['last_history_id']:
        _update_history_state(backend, current_state['history_id'], current_time)
        logger.info(f"ğŸ”„ æ£€æµ‹åˆ°å†å²è®°å½•é€‰æ‹©å˜åŒ–: {current_state['history_id']}")
        return 'history'
    else:
        logger.warning("âš ï¸ å†å²è®°å½•é€‰æ‹©æœªå˜åŒ–ï¼Œè·³è¿‡é‡å¤å¤„ç†")
        return 'skip'

def _detect_trigger_from_state_change(current_state, previous_state, backend, current_time):
    """åŸºäºçŠ¶æ€å˜åŒ–æ™ºèƒ½æ£€æµ‹è§¦å‘æº"""
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„æ–‡ä»¶ä¸Šä¼ 
    if (current_state['has_upload'] and 
        current_state['upload_content'] != previous_state['last_upload_content']):
        _update_upload_state(backend, current_state['upload_content'], current_time)
        logger.info(f"ğŸ”„ æ™ºèƒ½æ£€æµ‹åˆ°æ–°æ–‡ä»¶ä¸Šä¼ : {current_state['filename']}")
        return 'upload'
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„å†å²è®°å½•é€‰æ‹©
    elif (current_state['has_history'] and 
          current_state['history_id'] != previous_state['last_history_id']):
        _update_history_state(backend, current_state['history_id'], current_time)
        logger.info(f"ğŸ”„ æ™ºèƒ½æ£€æµ‹åˆ°å†å²è®°å½•é€‰æ‹©: {current_state['history_id']}")
        return 'history'
    
    return None

def _update_upload_state(backend, upload_content, current_time):
    """æ›´æ–°æ–‡ä»¶ä¸Šä¼ çŠ¶æ€"""
    backend._last_upload_content = upload_content
    backend._last_upload_time = current_time
    backend._data_source = 'upload'

def _update_history_state(backend, history_id, current_time):
    """æ›´æ–°å†å²è®°å½•é€‰æ‹©çŠ¶æ€"""
    backend._last_selected_history_id = history_id
    backend._last_history_time = current_time
    backend._data_source = 'history'


def _handle_file_upload(contents, filename, backend, key_filter):
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ æ“ä½œ"""
    logger.info(f"ğŸ”„ å¤„ç†æ–‡ä»¶ä¸Šä¼ : {filename}")
    
    # ä½¿ç”¨backendä¸­çš„DataManagerå¤„ç†æ–‡ä»¶ä¸Šä¼ 
    success, result_data, error_msg = backend.process_file_upload(contents, filename)
    
    if success:
        # ä½¿ç”¨UIProcessorç”ŸæˆæˆåŠŸå†…å®¹
        ui_processor = UIProcessor()
        info_content = ui_processor.create_upload_success_content(result_data)
        error_content = None
    else:
        # ä½¿ç”¨UIProcessorç”Ÿæˆé”™è¯¯å†…å®¹
        ui_processor = UIProcessor()
        info_content = None
        error_content = ui_processor.create_upload_error_content(filename, error_msg)
    
    if info_content and not error_content:
        # æ‰§è¡Œæ•°æ®åˆ†æ
        backend._perform_error_analysis()
        
        # è®¾ç½®é”®IDç­›é€‰
        if key_filter:
            backend.set_key_filter(key_filter)
        else:
            backend.set_key_filter(None)
        
        # è‡ªåŠ¨ç”Ÿæˆç€‘å¸ƒå›¾å’ŒæŠ¥å‘Š
        fig = backend.generate_waterfall_plot()
        report_content = create_report_layout(backend)
        
        # ä¸åœ¨è¿™é‡Œæ›´æ–°å†å²è®°å½•é€‰é¡¹ï¼Œé¿å…ä¸åˆå§‹åŒ–å›è°ƒå†²çª
        # å†å²è®°å½•é€‰é¡¹ç”±ä¸“é—¨çš„åˆå§‹åŒ–å’Œæœç´¢å›è°ƒç®¡ç†
        
        # è·å–é”®IDå’Œæ—¶é—´ç­›é€‰ç›¸å…³æ•°æ®
        available_keys = backend.get_available_keys()
        key_options = [{'label': f'é”®ä½ {key_id}', 'value': key_id} for key_id in available_keys]
        key_status = backend.get_key_filter_status()
        
        # å°†key_statusè½¬æ¢ä¸ºå¯æ¸²æŸ“çš„å­—ç¬¦ä¸²
        if key_status['enabled']:
            key_status_text = f"å·²ç­›é€‰ {len(key_status['filtered_keys'])} ä¸ªé”®ä½ (å…± {key_status['total_available_keys']} ä¸ª)"
        else:
            key_status_text = f"æ˜¾ç¤ºå…¨éƒ¨ {key_status['total_available_keys']} ä¸ªé”®ä½"
        
        # å®Œå…¨é¿å…æ›´æ–°æ»‘å—å±æ€§ï¼Œé˜²æ­¢æ— é™é€’å½’
        time_status = backend.get_time_filter_status()
        
        # å°†time_statusè½¬æ¢ä¸ºå¯æ¸²æŸ“çš„å­—ç¬¦ä¸²
        if time_status['enabled']:
            time_status_text = f"æ—¶é—´èŒƒå›´: {time_status['start_time']:.2f}s - {time_status['end_time']:.2f}s (æ—¶é•¿: {time_status['duration']:.2f}s)"
        else:
            time_status_text = "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
        
        logger.info("âœ… æ–‡ä»¶ä¸Šä¼ å¤„ç†å®Œæˆï¼Œæ¸…ç©ºå†å²è®°å½•é€‰æ‹©ï¼Œæ˜¾ç¤ºæ–°æ–‡ä»¶æ•°æ®")
        current_value = key_filter if key_filter else []
        return fig, report_content, no_update, key_options, key_status_text, current_value, no_update, no_update, no_update, time_status_text
    else:
        # å¤„ç†ä¸Šä¼ é”™è¯¯
        if error_content:
            if error_msg and ("è½¨é“" in error_msg or "track" in error_msg.lower() or "SPMIDæ–‡ä»¶åªåŒ…å«" in error_msg):
                fig = _create_empty_figure_for_callback("âŒ SPMIDæ–‡ä»¶åªåŒ…å« 1 ä¸ªè½¨é“ï¼Œéœ€è¦è‡³å°‘2ä¸ªè½¨é“ï¼ˆå½•åˆ¶+æ’­æ”¾ï¼‰æ‰èƒ½è¿›è¡Œåˆ†æ")
            else:
                fig = _create_empty_figure_for_callback("æ–‡ä»¶ç±»å‹ä¸ç¬¦")
            # é¡ºåº: fig, report, history_options, key_options, key_status, key_value, time_min, time_max, time_value, time_status
            return fig, error_content, no_update, [], "æ˜¾ç¤ºå…¨éƒ¨é”®ä½", [], 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
        else:
            fig = _create_empty_figure_for_callback("æ–‡ä»¶ä¸Šä¼ å¤±è´¥")
            error_div = html.Div([
                html.H4("æ–‡ä»¶ä¸Šä¼ å¤±è´¥", className="text-center text-danger"),
                html.P("è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æˆ–è”ç³»ç®¡ç†å‘˜ã€‚", className="text-center")
            ])
            return fig, error_div, no_update, [], "æ˜¾ç¤ºå…¨éƒ¨é”®ä½", [], 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"


def _handle_history_selection(history_id, backend):
    """å¤„ç†å†å²è®°å½•é€‰æ‹©æ“ä½œ"""
    logger.info(f"ğŸ”„ åŠ è½½å†å²è®°å½•: {history_id}")
    
    # ä½¿ç”¨HistoryManagerå¤„ç†å†å²è®°å½•é€‰æ‹©ï¼ˆåŒ…å«çŠ¶æ€åˆå§‹åŒ–ï¼‰
    success, result_data, error_msg = backend.history_manager.process_history_selection(history_id, backend)
    
    # ä½¿ç”¨UIProcessorç”ŸæˆUIå†…å®¹
    ui_processor = UIProcessor()

    if success:
        if result_data['has_file_content']:
            # æ‰§è¡Œæ•°æ®åˆ†æ
            backend._perform_error_analysis()
            
            # è‡ªåŠ¨ç”Ÿæˆç€‘å¸ƒå›¾å’ŒæŠ¥å‘Š
            waterfall_fig = backend.generate_waterfall_plot()
            report_content = ui_processor.generate_history_report(backend, result_data['filename'], result_data['history_id'])
        else:
            # æ²¡æœ‰æ–‡ä»¶å†…å®¹ï¼Œåªæ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
            waterfall_fig = ui_processor.create_empty_figure("å†å²è®°å½•æ— æ–‡ä»¶å†…å®¹")
            report_content = ui_processor.create_history_basic_info_content(result_data)
    else:
        waterfall_fig = ui_processor.create_empty_figure("å†å²è®°å½•åŠ è½½å¤±è´¥")
        report_content = ui_processor.create_error_content("å†å²è®°å½•åŠ è½½å¤±è´¥", error_msg)
    
    if waterfall_fig and report_content:
        logger.info("âœ… å†å²è®°å½•åŠ è½½å®Œæˆï¼Œè¿”å›ç€‘å¸ƒå›¾å’ŒæŠ¥å‘Š")
        
        # è·å–é”®IDç­›é€‰ç›¸å…³æ•°æ®
        available_keys = backend.get_available_keys()
        key_options = [{'label': f'é”®ä½ {key_id}', 'value': key_id} for key_id in available_keys]
        key_status = backend.get_key_filter_status()
        
        # å°†key_statusè½¬æ¢ä¸ºå¯æ¸²æŸ“çš„å­—ç¬¦ä¸²
        if key_status['enabled']:
            key_status_text = f"å·²ç­›é€‰ {len(key_status['filtered_keys'])} ä¸ªé”®ä½ (å…± {key_status['total_available_keys']} ä¸ª)"
        else:
            key_status_text = f"æ˜¾ç¤ºå…¨éƒ¨ {key_status['total_available_keys']} ä¸ªé”®ä½"
        
        # å®Œå…¨é¿å…æ›´æ–°æ»‘å—å±æ€§ï¼Œé˜²æ­¢æ— é™é€’å½’
        time_status = backend.get_time_filter_status()
        
        # å°†time_statusè½¬æ¢ä¸ºå¯æ¸²æŸ“çš„å­—ç¬¦ä¸²
        if time_status['enabled']:
            time_status_text = f"æ—¶é—´èŒƒå›´: {time_status['start_time']:.2f}s - {time_status['end_time']:.2f}s (æ—¶é•¿: {time_status['duration']:.2f}s)"
        else:
            time_status_text = "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
        
        # å†å²è®°å½•æƒ…å†µä¸‹ï¼Œå½“å‰ç­›é€‰å€¼å–åç«¯å·²è®¾ç½®çš„filtered_keys
        kstatus = backend.get_key_filter_status()
        current_value = kstatus.get('filtered_keys', []) if kstatus else []
        return waterfall_fig, report_content, no_update, key_options, key_status_text, current_value, no_update, no_update, no_update, time_status_text
    else:
        logger.error("âŒ å†å²è®°å½•åŠ è½½å¤±è´¥")
        empty_fig = _create_empty_figure_for_callback("å†å²è®°å½•åŠ è½½å¤±è´¥")
        error_content = html.Div([
            html.H4("å†å²è®°å½•åŠ è½½å¤±è´¥", className="text-center text-danger"),
            html.P("è¯·å°è¯•é€‰æ‹©å…¶ä»–å†å²è®°å½•", className="text-center")
        ])
        return empty_fig, error_content, no_update, [], "æ˜¾ç¤ºå…¨éƒ¨é”®ä½", 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´", no_update


def _handle_waterfall_button(backend):
    """å¤„ç†ç€‘å¸ƒå›¾æŒ‰é’®ç‚¹å‡»"""
    current_data_source = getattr(backend, '_data_source', 'none') if backend else 'none'
    logger.info(f"ğŸ”„ ç”Ÿæˆç€‘å¸ƒå›¾ï¼ˆæ•°æ®æº: {current_data_source}ï¼‰")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²åŠ è½½çš„æ•°æ® - æ”¹ä¸ºæ£€æŸ¥æ›´åŸºæœ¬çš„æ•°æ®çŠ¶æ€
    has_data = (backend.analyzer and 
                (backend.plot_generator.valid_record_data or backend.plot_generator.valid_replay_data or
                 (hasattr(backend.analyzer, 'valid_record_data') and backend.analyzer.valid_record_data) or
                 (hasattr(backend.analyzer, 'valid_replay_data') and backend.analyzer.valid_replay_data)))
    
    if has_data:
        fig = backend.generate_waterfall_plot()
        
        # è·å–å®é™…çš„æ—¶é—´èŒƒå›´å¹¶æ›´æ–°æ»‘åŠ¨æ¡
        try:
            time_range = backend.get_time_range()
            time_min, time_max = time_range
            
            # ç¡®ä¿æ—¶é—´èŒƒå›´æ˜¯æœ‰æ•ˆçš„
            if isinstance(time_min, (int, float)) and isinstance(time_max, (int, float)) and time_min < time_max:
                # åˆ›å»ºåˆç†çš„æ ‡è®°ç‚¹
                range_size = time_max - time_min
                if range_size <= 1000:
                    step = max(1, range_size // 5)
                elif range_size <= 10000:
                    step = max(10, range_size // 10)
                else:
                    step = max(100, range_size // 20)
                
                marks = {}
                for i in range(int(time_min), int(time_max) + 1, step):
                    if i == time_min or i == time_max or (i - time_min) % (step * 2) == 0:
                        marks[i] = str(i)
                
                logger.info(f"â° ç€‘å¸ƒå›¾æŒ‰é’®æ›´æ–°æ»‘åŠ¨æ¡: min={time_min}, max={time_max}, èŒƒå›´={range_size}")
                # key_value ä¸åœ¨æ­¤å›è°ƒä¸­æ›´æ–°
                return fig, no_update, no_update, [], "æ˜¾ç¤ºå…¨éƒ¨é”®ä½", no_update, time_min, time_max, [time_min, time_max], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
            else:
                logger.warning(f"âš ï¸ æ—¶é—´èŒƒå›´æ— æ•ˆ: {time_range}")
                return fig, no_update, no_update, [], "æ˜¾ç¤ºå…¨éƒ¨é”®ä½", no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
        except Exception as e:
            logger.error(f"âŒ è·å–æ—¶é—´èŒƒå›´å¤±è´¥: {e}")
            return fig, no_update, no_update, [], "æ˜¾ç¤ºå…¨éƒ¨é”®ä½", 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´", no_update
    else:
        if current_data_source == 'history':
            empty_fig = _create_empty_figure_for_callback("è¯·é€‰æ‹©å†å²è®°å½•æˆ–ä¸Šä¼ æ–°æ–‡ä»¶")
        else:
            empty_fig = _create_empty_figure_for_callback("è¯·å…ˆä¸Šä¼ SPMIDæ–‡ä»¶")
            return empty_fig, no_update, no_update, [], "æ˜¾ç¤ºå…¨éƒ¨é”®ä½", no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"


def _handle_report_button(backend):
    """å¤„ç†æŠ¥å‘ŠæŒ‰é’®ç‚¹å‡»"""
    current_data_source = getattr(backend, '_data_source', 'none') if backend else 'none'
    logger.info(f"ğŸ”„ ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆæ•°æ®æº: {current_data_source}ï¼‰")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²åŠ è½½çš„æ•°æ®
    if hasattr(backend, 'all_error_notes') and backend.all_error_notes:
        report_content = create_report_layout(backend)
        return no_update, report_content, no_update, no_update, no_update, no_update, no_update, no_update, no_update, no_update
    else:
        if current_data_source == 'history':
            error_content = html.Div([
                html.H4("è¯·é€‰æ‹©å†å²è®°å½•æˆ–ä¸Šä¼ æ–°æ–‡ä»¶", className="text-center text-warning"),
                html.P("éœ€è¦å…ˆé€‰æ‹©å†å²è®°å½•æˆ–ä¸Šä¼ SPMIDæ–‡ä»¶æ‰èƒ½ç”ŸæˆæŠ¥å‘Š", className="text-center")
            ])
        else:
            error_content = html.Div([
                html.H4("è¯·å…ˆä¸Šä¼ SPMIDæ–‡ä»¶", className="text-center text-warning"),
                html.P("éœ€è¦å…ˆä¸Šä¼ å¹¶åˆ†æSPMIDæ–‡ä»¶æ‰èƒ½ç”ŸæˆæŠ¥å‘Š", className="text-center")
            ])
        return no_update, error_content, no_update, no_update, no_update, no_update, no_update, no_update, no_update, no_update


def _handle_fallback_logic(contents, filename, history_id, backend):
    """å…œåº•é€»è¾‘ï¼šåŸºäºç°æœ‰çŠ¶æ€åˆ¤æ–­"""
    if contents and filename and not history_id:
        logger.info(f"ğŸ”„ å…œåº•å¤„ç†æ–‡ä»¶ä¸Šä¼ : {filename}")
        
        # ä½¿ç”¨backendä¸­çš„DataManagerå¤„ç†æ–‡ä»¶ä¸Šä¼ 
        success, result_data, error_msg = backend.process_file_upload(contents, filename)
        fig = backend.generate_waterfall_plot()
        report_content = create_report_layout(backend)
        
        # ä¸åœ¨è¿™é‡Œæ›´æ–°å†å²è®°å½•é€‰é¡¹ï¼Œé¿å…å¾ªç¯è°ƒç”¨
        return fig, report_content, no_update, [], "æ˜¾ç¤ºå…¨éƒ¨é”®ä½", [], 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
        
    elif history_id:
        logger.info(f"ğŸ”„ å…œåº•å¤„ç†å†å²è®°å½•: {history_id}")
        
        # ä½¿ç”¨UIProcessorç”ŸæˆUIå†…å®¹
        ui_processor = UIProcessor()
        # ä½¿ç”¨HistoryManagerå¤„ç†å†å²è®°å½•é€‰æ‹©ï¼ˆåŒ…å«çŠ¶æ€åˆå§‹åŒ–ï¼‰
        success, result_data, error_msg = backend.history_manager.process_history_selection(history_id, backend)
        
        if success:
            if result_data['has_file_content']:
                # æœ‰æ–‡ä»¶å†…å®¹ï¼Œç”Ÿæˆç€‘å¸ƒå›¾å’ŒæŠ¥å‘Š
                waterfall_fig = ui_processor.generate_history_waterfall(backend, result_data['filename'], result_data['main_record'])
                report_content = ui_processor.generate_history_report(backend, result_data['filename'], result_data['history_id'])
            else:
                # æ²¡æœ‰æ–‡ä»¶å†…å®¹ï¼Œåªæ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                waterfall_fig = ui_processor.create_empty_figure("å†å²è®°å½•æ— æ–‡ä»¶å†…å®¹")
                report_content = ui_processor.create_history_basic_info_content(result_data)
        else:
            waterfall_fig = ui_processor.create_empty_figure("å†å²è®°å½•åŠ è½½å¤±è´¥")
            report_content = ui_processor.create_error_content("å†å²è®°å½•åŠ è½½å¤±è´¥", error_msg)
        if waterfall_fig and report_content:
            return waterfall_fig, report_content, no_update, [], "æ˜¾ç¤ºå…¨éƒ¨é”®ä½", [], 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
        else:
            empty_fig = _create_empty_figure_for_callback("å†å²è®°å½•åŠ è½½å¤±è´¥")
            error_content = html.Div([
                html.H4("å†å²è®°å½•åŠ è½½å¤±è´¥", className="text-center text-danger"),
                html.P("è¯·å°è¯•é€‰æ‹©å…¶ä»–å†å²è®°å½•", className="text-center")
            ])
            return empty_fig, error_content, no_update, [], "æ˜¾ç¤ºå…¨éƒ¨é”®ä½", 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´", no_update

    # æœ€ç»ˆå…œåº•ï¼šæ— ä¸Šä¼ ã€æ— å†å²é€‰æ‹©ã€æ— è§¦å‘
    placeholder_fig = _create_empty_figure_for_callback("ç­‰å¾…æ“ä½œï¼šè¯·ä¸Šä¼ æ–‡ä»¶æˆ–é€‰æ‹©å†å²è®°å½•")
    return placeholder_fig, no_update, no_update, [], "æ˜¾ç¤ºå…¨éƒ¨é”®ä½", [], 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"


def register_callbacks(app, session_manager: SessionManager, history_manager):
    """æ³¨å†Œæ‰€æœ‰å›è°ƒå‡½æ•°"""

    # åˆå§‹åŒ–å›è°ƒï¼šè‡ªåŠ¨å¯ç”¨å¤šç®—æ³•æ¨¡å¼
    @app.callback(
        Output('session-id', 'data'),
        Input('session-id', 'data'),
        prevent_initial_call=False
    )
    def init_session_and_enable_multi_algorithm(session_data):
        """åˆå§‹åŒ–ä¼šè¯IDå¹¶è‡ªåŠ¨å¯ç”¨å¤šç®—æ³•æ¨¡å¼"""
        if session_data is None:
            session_id = str(uuid.uuid4())
        else:
            session_id = session_data
        
        # å¤šç®—æ³•æ¨¡å¼å§‹ç»ˆå¯ç”¨
        session_id, backend = session_manager.get_or_create_backend(session_id)
        if backend:
            # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
            if not backend.multi_algorithm_manager:
                backend._ensure_multi_algorithm_manager()
            logger.info("âœ… å¤šç®—æ³•æ¨¡å¼å·²å°±ç»ª")
        
        return session_id

    # å•ç®—æ³•æ¨¡å¼çš„æ•°æ®å¤„ç†å›è°ƒå·²ç§»é™¤ - ç°åœ¨åªä½¿ç”¨å¤šç®—æ³•æ¨¡å¼


    # è¡¨æ ¼é€‰æ‹©å›è°ƒå’Œç›¸å…³è¾…åŠ©å‡½æ•°å·²åˆ é™¤ - å› ä¸ºå·²åˆ é™¤å¯¹æ¯”åˆ†æå›¾å’Œè¯¦ç»†æ•°æ®ä¿¡æ¯çš„UIç»„ä»¶ï¼Œä¸”è¡¨æ ¼å·²ç¦ç”¨è¡Œé€‰æ‹©
    # åŸå›è°ƒç”¨äºå¤„ç†è¡¨æ ¼é€‰æ‹©å¹¶æ›´æ–°å¯¹æ¯”åˆ†æå›¾å’Œè¯¦ç»†æ•°æ®ä¿¡æ¯ï¼Œç°å·²ä¸å†éœ€è¦


    # æ·»åŠ æ—¶é—´æ»‘å—åˆå§‹åŒ–å›è°ƒ - å½“æ•°æ®åŠ è½½å®Œæˆåè‡ªåŠ¨è®¾ç½®åˆç†çš„æ—¶é—´èŒƒå›´
    @app.callback(
        [Output('time-filter-slider', 'min', allow_duplicate=True),
         Output('time-filter-slider', 'max', allow_duplicate=True),
         Output('time-filter-slider', 'value', allow_duplicate=True),
         Output('time-filter-slider', 'marks', allow_duplicate=True)],
        Input('report-content', 'children'),
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def initialize_time_slider_on_data_load(report_content, session_id):
        """å½“æ•°æ®åŠ è½½å®Œæˆååˆå§‹åŒ–æ—¶é—´æ»‘å—"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update, no_update, no_update
        
        # åªæœ‰å½“æœ‰åˆ†ææ•°æ®æ—¶æ‰æ›´æ–°æ»‘å—
        if not hasattr(backend, 'all_error_notes') or not backend.all_error_notes:
            return no_update, no_update, no_update, no_update
        
        try:
            # è·å–å®é™…çš„æ—¶é—´èŒƒå›´
            time_range = backend.get_time_range()
            time_min, time_max = time_range
            
            # ç¡®ä¿æ—¶é—´èŒƒå›´æ˜¯æœ‰æ•ˆçš„
            if not isinstance(time_min, (int, float)) or not isinstance(time_max, (int, float)):
                return no_update, no_update, no_update, no_update
            
            if time_min >= time_max:
                return no_update, no_update, no_update, no_update
            
            # è½¬æ¢ä¸ºæ•´æ•°ï¼Œé¿å…æ»‘å—ç²¾åº¦é—®é¢˜
            time_min, time_max = int(time_min), int(time_max)
            
            # åˆ›å»ºåˆç†çš„æ ‡è®°ç‚¹
            range_size = time_max - time_min
            if range_size <= 1000:
                step = max(1, range_size // 5)
            elif range_size <= 10000:
                step = max(10, range_size // 10)
            else:
                step = max(100, range_size // 20)
            
            marks = {}
            for i in range(time_min, time_max + 1, step):
                if i == time_min or i == time_max or (i - time_min) % (step * 2) == 0:
                    marks[i] = str(i)
            
            logger.info(f"â° åˆå§‹åŒ–æ—¶é—´æ»‘å—: min={time_min}, max={time_max}, èŒƒå›´={range_size}")
            
            return time_min, time_max, [time_min, time_max], marks
            
        except Exception as e:
            logger.warning(f"âš ï¸ åˆå§‹åŒ–æ—¶é—´æ»‘å—å¤±è´¥: {e}")
            return no_update, no_update, no_update, no_update

    # æ·»åŠ åˆå§‹åŒ–å†å²è®°å½•ä¸‹æ‹‰èœå•çš„å›è°ƒ - åªåœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–ä¸€æ¬¡
    @app.callback(
        [Output('history-dropdown', 'options', allow_duplicate=True),
         Output('history-dropdown', 'value', allow_duplicate=True)],
        Input('session-id', 'data'),
        prevent_initial_call='initial_duplicate'  # ä¿®å¤ï¼šä½¿ç”¨ initial_duplicate å…è®¸åˆå§‹è°ƒç”¨å’Œé‡å¤è¾“å‡º
    )
    def initialize_history_dropdown(session_id):
        """åˆå§‹åŒ–å†å²è®°å½•ä¸‹æ‹‰æ¡†é€‰é¡¹ - åªåœ¨ä¼šè¯åˆå§‹åŒ–æ—¶è°ƒç”¨ä¸€æ¬¡"""
        # æ£€æŸ¥æ˜¯å¦å·²ç»åˆå§‹åŒ–è¿‡
        if hasattr(initialize_history_dropdown, '_initialized'):
            return no_update, no_update
        
        try:
            # è·å–å†å²è®°å½•åˆ—è¡¨
            history_list = history_manager.get_history_list(limit=100)

            if not history_list:
                initialize_history_dropdown._initialized = True
                return [], None

            # è½¬æ¢ä¸ºä¸‹æ‹‰æ¡†é€‰é¡¹æ ¼å¼
            options = []
            for record in history_list:
                label = f"{record['filename']} ({record['timestamp'][:19] if record['timestamp'] else 'æœªçŸ¥æ—¶é—´'}) - å¤šé”¤:{record['multi_hammers']} ä¸¢é”¤:{record['drop_hammers']}"
                options.append({
                    'label': label,
                    'value': record['id']
                })

            logger.info(f"âœ… åˆå§‹åŒ–å†å²è®°å½•ä¸‹æ‹‰èœå•ï¼Œæ‰¾åˆ° {len(options)} æ¡è®°å½•")
            initialize_history_dropdown._initialized = True
            return options, None  # è¿”å›é€‰é¡¹åˆ—è¡¨ï¼Œä½†ä¸é¢„é€‰ä»»ä½•é¡¹

        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å†å²è®°å½•ä¸‹æ‹‰æ¡†å¤±è´¥: {e}")
            initialize_history_dropdown._initialized = True
            return [], None

    @app.callback(
        Output('history-dropdown', 'options', allow_duplicate=True),
        [Input('history-search', 'value'),
         Input('session-id', 'data')],
        prevent_initial_call=True  # ä¿®æ”¹ä¸ºTrueï¼Œé˜²æ­¢åˆå§‹åŒ–æ—¶é‡å¤è°ƒç”¨
    )
    def update_history_dropdown_search(search_value, session_id):
        """æ›´æ–°å†å²è®°å½•ä¸‹æ‹‰æ¡†é€‰é¡¹ - ä»…æœç´¢è§¦å‘"""
        try:
            # è·å–å†å²è®°å½•åˆ—è¡¨
            history_list = history_manager.get_history_list(limit=100)

            if not history_list:
                return []

            # è½¬æ¢ä¸ºä¸‹æ‹‰æ¡†é€‰é¡¹æ ¼å¼
            options = []
            for record in history_list:
                label = f"{record['filename']} ({record['timestamp'][:19] if record['timestamp'] else 'æœªçŸ¥æ—¶é—´'}) - å¤šé”¤:{record['multi_hammers']} ä¸¢é”¤:{record['drop_hammers']}"

                # å¦‚æœæœ‰æœç´¢å€¼ï¼Œåˆ™è¿‡æ»¤é€‰é¡¹
                if search_value and search_value.lower() not in label.lower():
                    continue

                options.append({
                    'label': label,
                    'value': record['id']
                })

            return options

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å†å²è®°å½•ä¸‹æ‹‰æ¡†å¤±è´¥: {e}")
            return []

    @app.callback(
        Output('spmid-filename', 'children'),
        Input('upload-spmid-data', 'contents'),
        State('upload-spmid-data', 'filename'),
        prevent_initial_call=True
    )
    def update_spmid_filename(contents, filename):
        """æ›´æ–°SPMIDæ–‡ä»¶åæ˜¾ç¤º"""
        if filename:
            return html.Div([
                html.I(className="fas fa-file-audio", style={'marginRight': '8px', 'color': '#28a745'}),
                html.Span(f"å·²é€‰æ‹©: {filename}", style={'color': '#28a745', 'fontWeight': 'bold'})
            ])
        return ""

    # ç‚¹å‡»plotçš„ç‚¹æ˜¾ç¤ºè¯¦ç»†å›¾åƒ
    print("=" * 100)
    print("ğŸ”§ æ­£åœ¨æ³¨å†Œ update_plot å›è°ƒ...")
    print("=" * 100)
    
    @app.callback(
        [Output('detail-modal', 'style'),
        Output('detail-plot-combined', 'figure')],
        [Input('key-delay-zscore-scatter-plot', 'clickData'),  # Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»è¾“å…¥
        Input('close-modal', 'n_clicks'),
        Input('close-modal-btn', 'n_clicks'),
        Input({'type': 'drop-hammers-table', 'index': dash.dependencies.ALL}, 'active_cell'),  # ä¸¢é”¤è¡¨æ ¼ç‚¹å‡»
        Input({'type': 'multi-hammers-table', 'index': dash.dependencies.ALL}, 'active_cell')],  # å¤šé”¤è¡¨æ ¼ç‚¹å‡»
        [State('detail-modal', 'style'),
        State('session-id', 'data'),
        State({'type': 'drop-hammers-table', 'index': dash.dependencies.ALL}, 'data'),  # ä¸¢é”¤è¡¨æ ¼æ•°æ®
        State({'type': 'multi-hammers-table', 'index': dash.dependencies.ALL}, 'data')],  # å¤šé”¤è¡¨æ ¼æ•°æ®
        prevent_initial_call=False
        )
    def update_plot(zscore_scatter_clickData, close_clicks, close_btn_clicks, 
                   drop_hammers_active_cells, multi_hammers_active_cells,
                   current_style, session_id, drop_hammers_table_data, multi_hammers_table_data):
        """æ›´æ–°è¯¦ç»†å›¾è¡¨ - æ”¯æŒå¤šç”¨æˆ·ä¼šè¯"""
        from dash import no_update
        

        # if session_id is None:
        # è·å–ç”¨æˆ·ä¼šè¯æ•°æ®
        backend = session_manager.get_backend(session_id)
        if not backend:
            print(f"âŒ backendä¸ºç©º")
            logger.info(f"âŒ backendä¸ºç©º")
            return current_style, no_update

        ctx = callback_context
        if not ctx.triggered:
            print(f"âŒ ctx.triggeredä¸ºç©º")
            logger.info(f"âŒ ctx.triggeredä¸ºç©º")
            return current_style, no_update

        # è·å–è§¦å‘ä¿¡æ¯
        triggered_prop_id = ctx.triggered[0]['prop_id']
        trigger_value = ctx.triggered[0].get('value')
        print(f"ğŸ” è§¦å‘ID: {triggered_prop_id}")
        print(f"ğŸ” è§¦å‘å€¼: {trigger_value}")
        
        # è§£ætrigger_id
        if triggered_prop_id.startswith('{'):
            # Pattern matching ID
            import json
            try:
                trigger_id_dict = json.loads(triggered_prop_id.split('.')[0])
                trigger_id = f"{trigger_id_dict.get('type', 'unknown')}-{trigger_id_dict.get('index', 'unknown')}"
            except:
                trigger_id = triggered_prop_id.split('.')[0]
        else:
            trigger_id = triggered_prop_id.split('.')[0]
        
        logger.info(f"ğŸ” å›è°ƒè§¦å‘: trigger_id={trigger_id}, trigger_value={trigger_value}, triggered_prop_id={triggered_prop_id}")

        # å¤„ç†Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»ï¼ˆç‚¹å‡»ä»»æ„ç‚¹æ—¶æ˜¾ç¤ºæ›²çº¿å›¾ï¼‰
        if trigger_id == 'key-delay-zscore-scatter-plot' and zscore_scatter_clickData:
            logger.info(f"ğŸ” Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒè¢«è§¦å‘ - zscore_scatter_clickData: {zscore_scatter_clickData is not None}")
            
            if 'points' not in zscore_scatter_clickData or len(zscore_scatter_clickData['points']) == 0:
                logger.warning("âš ï¸ Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - zscore_scatter_clickDataæ— æ•ˆæˆ–æ²¡æœ‰points")
                return current_style, no_update
            
            point = zscore_scatter_clickData['points'][0]
            logger.info(f"ğŸ” Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - ç‚¹å‡»ç‚¹æ•°æ®: {point}")
            
            if not point.get('customdata'):
                logger.warning("âš ï¸ Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - ç‚¹æ²¡æœ‰customdata")
                return current_style, no_update
            
            # å®‰å…¨åœ°æå–customdata
            raw_customdata = point['customdata']
            logger.info(f"ğŸ” Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - raw_customdataç±»å‹: {type(raw_customdata)}, å€¼: {raw_customdata}")
            
            if isinstance(raw_customdata, list) and len(raw_customdata) > 0:
                customdata = raw_customdata[0] if isinstance(raw_customdata[0], list) else raw_customdata
            else:
                customdata = raw_customdata
            
            # ç¡®ä¿customdataæ˜¯åˆ—è¡¨ç±»å‹
            if not isinstance(customdata, list):
                logger.warning(f"âš ï¸ customdataä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(customdata)}, å€¼: {customdata}")
                return current_style, no_update
            
            logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡» - customdata: {customdata}, é•¿åº¦: {len(customdata)}")
            
            # æå–å»¶æ—¶å€¼
            delay_ms = point.get('y')
            if delay_ms is None:
                return current_style, no_update
            
            # å¤šç®—æ³•æ¨¡å¼
            if len(customdata) >= 5:
                record_index = customdata[0]
                replay_index = customdata[1]
                algorithm_name = customdata[4]
                
                # è·å–è¯¥ç®—æ³•çš„é˜ˆå€¼
                algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name)
                if algorithm and algorithm.analyzer:
                    me_0_1ms = algorithm.analyzer.get_mean_error()
                    std_0_1ms = algorithm.analyzer.get_standard_deviation()
                    mu = me_0_1ms / 10.0
                    sigma = std_0_1ms / 10.0
                    upper_threshold = mu + 3 * sigma
                    lower_threshold = mu - 3 * sigma
                    
                    # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
                    if delay_ms > upper_threshold or delay_ms < lower_threshold:
                        logger.info(f"ğŸ–±ï¸ æ•£ç‚¹å›¾ç‚¹å‡»ï¼ˆè¶…è¿‡é˜ˆå€¼ï¼‰: ç®—æ³•={algorithm_name}, record_index={record_index}, replay_index={replay_index}, delay={delay_ms:.2f}ms")
                        detail_figure1, detail_figure2, detail_figure_combined = backend.generate_multi_algorithm_scatter_detail_plot_by_indices(
                            algorithm_name=algorithm_name,
                            record_index=record_index,
                            replay_index=replay_index
                        )
                        
                        logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - å›¾è¡¨ç”Ÿæˆç»“æœ: figure1={detail_figure1 is not None}, figure2={detail_figure2 is not None}, figure_combined={detail_figure_combined is not None}")
                        
                        if detail_figure1 and detail_figure2 and detail_figure_combined:
                            modal_style = {
                                'display': 'block',
                                'position': 'fixed',
                                'zIndex': '1000',
                                'left': '0',
                                'top': '0',
                                'width': '100%',
                                'height': '100%',
                                'backgroundColor': 'rgba(0,0,0,0.6)',
                                'backdropFilter': 'blur(5px)'
                            }
                            logger.info("âœ… æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - è¿”å›æ¨¡æ€æ¡†å’Œå›¾è¡¨")
                            return modal_style, detail_figure_combined
                        else:
                            logger.warning(f"âš ï¸ æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼Œéƒ¨åˆ†å›¾è¡¨ä¸ºNone")
                    else:
                        logger.info(f"â„¹ï¸ æ•£ç‚¹å›¾ç‚¹å‡» - ç‚¹æœªè¶…è¿‡é˜ˆå€¼: delay={delay_ms:.2f}ms, é˜ˆå€¼èŒƒå›´=[{lower_threshold:.2f}, {upper_threshold:.2f}]")
            
            return current_style, no_update
        
        # å¤„ç†Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»ï¼ˆç‚¹å‡»ä»»æ„ç‚¹æ—¶æ˜¾ç¤ºæ›²çº¿å›¾ï¼‰
        if trigger_id == 'key-delay-zscore-scatter-plot' and zscore_scatter_clickData:
            logger.info(f"ğŸ” Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒè¢«è§¦å‘ - zscore_scatter_clickData: {zscore_scatter_clickData is not None}")
            
            if 'points' not in zscore_scatter_clickData or len(zscore_scatter_clickData['points']) == 0:
                logger.warning("âš ï¸ Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - zscore_scatter_clickDataæ— æ•ˆæˆ–æ²¡æœ‰points")
                return current_style, no_update
            
            point = zscore_scatter_clickData['points'][0]
            logger.info(f"ğŸ” Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - ç‚¹å‡»ç‚¹æ•°æ®: {point}")
            
            if not point.get('customdata'):
                logger.warning("âš ï¸ Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - ç‚¹æ²¡æœ‰customdata")
                return current_style, no_update
            
            # å®‰å…¨åœ°æå–customdata
            raw_customdata = point['customdata']
            logger.info(f"ğŸ” Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - raw_customdataç±»å‹: {type(raw_customdata)}, å€¼: {raw_customdata}")
            
            if isinstance(raw_customdata, list) and len(raw_customdata) > 0:
                customdata = raw_customdata[0] if isinstance(raw_customdata[0], list) else raw_customdata
            else:
                customdata = raw_customdata
            
            # ç¡®ä¿customdataæ˜¯åˆ—è¡¨ç±»å‹
            if not isinstance(customdata, list):
                logger.warning(f"âš ï¸ Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - customdataä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(customdata)}, å€¼: {customdata}")
                return current_style, no_update
            
            logger.info(f"ğŸ” Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - customdata: {customdata}, é•¿åº¦: {len(customdata)}")
            
            # å¤šç®—æ³•æ¨¡å¼ï¼šä»customdataä¸­æå–ç®—æ³•åç§°å’Œç´¢å¼•
            if len(customdata) >= 5:
                record_index = customdata[0]
                replay_index = customdata[1]
                algorithm_name = customdata[4]  # Z-Scoreæ•£ç‚¹å›¾çš„customdataæ ¼å¼: [record_index, replay_index, key_id_int, delay_ms, algorithm_name]
                
                logger.info(f"ğŸ–±ï¸ Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»: ç®—æ³•={algorithm_name}, record_index={record_index}, replay_index={replay_index}")
                
                # ç”Ÿæˆè¯¦ç»†æ›²çº¿å›¾
                detail_figure1, detail_figure2, detail_figure_combined = backend.generate_multi_algorithm_scatter_detail_plot_by_indices(
                    algorithm_name=algorithm_name,
                    record_index=record_index,
                    replay_index=replay_index
                )
                
                logger.info(f"ğŸ” Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - å›¾è¡¨ç”Ÿæˆç»“æœ: figure1={detail_figure1 is not None}, figure2={detail_figure2 is not None}, figure_combined={detail_figure_combined is not None}")
                
                if detail_figure1 and detail_figure2 and detail_figure_combined:
                    modal_style = {
                        'display': 'block',
                        'position': 'fixed',
                        'zIndex': '1000',
                        'left': '0',
                        'top': '0',
                        'width': '100%',
                        'height': '100%',
                        'backgroundColor': 'rgba(0,0,0,0.6)',
                        'backdropFilter': 'blur(5px)'
                    }
                    logger.info("âœ… Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - è¿”å›æ¨¡æ€æ¡†å’Œå›¾è¡¨")
                    return modal_style, detail_figure_combined
                else:
                    logger.warning(f"âš ï¸ Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼Œéƒ¨åˆ†å›¾è¡¨ä¸ºNone")
            else:
                logger.warning(f"âš ï¸ Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç‚¹å‡» - customdataé•¿åº¦ä¸è¶³: {len(customdata)}")
            
            return current_style, no_update

        # å¤„ç†ä¸¢é”¤è¡¨æ ¼ç‚¹å‡»
        elif 'drop-hammers-table' in str(trigger_id):
            import json
            try:
                logger.info(f"ğŸ” ä¸¢é”¤è¡¨æ ¼ç‚¹å‡» - å¼€å§‹å¤„ç†")
                logger.info(f"ğŸ” trigger_value={trigger_value}, active_cells={drop_hammers_active_cells}")
                
                # è§£æè¡¨æ ¼IDè·å–ç®—æ³•åç§°å’Œè¡¨æ ¼ç´¢å¼•
                triggered_prop = ctx.triggered[0]['prop_id']
                table_id_str = triggered_prop.split('.')[0]
                table_id = json.loads(table_id_str)
                algorithm_name = table_id.get('index')
                
                if not algorithm_name:
                    logger.warning(f"âš ï¸ æ— æ³•è·å–ç®—æ³•åç§°")
                    return current_style, no_update
                
                logger.info(f"ğŸ” ç®—æ³•åç§°: {algorithm_name}, triggered_prop={triggered_prop}")
                
                # æ‰¾åˆ°è¢«ç‚¹å‡»çš„è¡¨æ ¼åœ¨åˆ—è¡¨ä¸­çš„ç´¢å¼•
                # éœ€è¦ä»åç«¯è·å–ç®—æ³•åˆ—è¡¨ï¼Œç¡®ä¿è¡¨æ ¼æ•°æ®ä¸ç®—æ³•å¯¹åº”
                active_algorithms = backend.multi_algorithm_manager.get_active_algorithms() if backend.multi_algorithm_manager else []
                algorithm_names = [alg.metadata.algorithm_name for alg in active_algorithms]
                
                # æ‰¾åˆ°å½“å‰ç®—æ³•åœ¨åˆ—è¡¨ä¸­çš„ç´¢å¼•
                if algorithm_name not in algorithm_names:
                    logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' ä¸åœ¨æ¿€æ´»ç®—æ³•åˆ—è¡¨ä¸­")
                    return current_style, no_update
                
                algorithm_idx = algorithm_names.index(algorithm_name)
                logger.info(f"ğŸ” ç®—æ³•ç´¢å¼•: {algorithm_idx}, ç®—æ³•åç§°: {algorithm_name}")
                
                # ä»å¯¹åº”è¡¨æ ¼çš„active_cellsä¸­è·å–active_cell
                active_cell = None
                if algorithm_idx < len(drop_hammers_active_cells):
                    active_cell = drop_hammers_active_cells[algorithm_idx]
                    logger.info(f"ğŸ” ä»active_cells[{algorithm_idx}]è·å–: {active_cell}")
                
                # å¦‚æœactive_cellsä¸­æ²¡æœ‰ï¼Œå°è¯•ä½¿ç”¨trigger_valueï¼ˆä½†éœ€è¦éªŒè¯æ˜¯å¦æ¥è‡ªæ­£ç¡®çš„è¡¨æ ¼ï¼‰
                if not active_cell and trigger_value and isinstance(trigger_value, dict) and 'row' in trigger_value:
                    # éªŒè¯trigger_valueæ˜¯å¦æ¥è‡ªå½“å‰è¡¨æ ¼
                    # ç”±äºæ— æ³•ç›´æ¥éªŒè¯ï¼Œæˆ‘ä»¬å‡è®¾å®ƒæ¥è‡ªå½“å‰è¡¨æ ¼
                    active_cell = trigger_value
                    logger.info(f"ğŸ” ä½¿ç”¨trigger_value: {active_cell}")
                
                if not active_cell:
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ°active_cell, algorithm_idx={algorithm_idx}, active_cells={drop_hammers_active_cells}")
                    return current_style, no_update
                
                row_idx = active_cell.get('row')
                if row_idx is None:
                    logger.warning(f"âš ï¸ active_cellä¸­æ²¡æœ‰rowç´¢å¼•")
                    return current_style, no_update
                
                logger.info(f"ğŸ” row_idx={row_idx}, algorithm_idx={algorithm_idx}")
                
                # æ‰¾åˆ°å¯¹åº”çš„è¡¨æ ¼æ•°æ® - ä½¿ç”¨å·²ç»è®¡ç®—å¥½çš„algorithm_idx
                
                # é€šè¿‡ç®—æ³•ç´¢å¼•è·å–å¯¹åº”çš„è¡¨æ ¼æ•°æ®
                if algorithm_idx >= len(drop_hammers_table_data):
                    logger.warning(f"âš ï¸ ç®—æ³•ç´¢å¼• {algorithm_idx} è¶…å‡ºè¡¨æ ¼æ•°æ®èŒƒå›´")
                    return current_style, no_update
                
                data_list = drop_hammers_table_data[algorithm_idx]
                if not data_list or row_idx >= len(data_list):
                    logger.warning(f"âš ï¸ è¡¨æ ¼æ•°æ®ä¸ºç©ºæˆ–è¡Œç´¢å¼•è¶…å‡ºèŒƒå›´: algorithm_idx={algorithm_idx}, row_idx={row_idx}, data_listé•¿åº¦={len(data_list) if data_list else 0}")
                    return current_style, no_update
                
                table_data = data_list[row_idx]
                logger.info(f"ğŸ” æ‰¾åˆ°è¡¨æ ¼æ•°æ®: algorithm={algorithm_name}, algorithm_idx={algorithm_idx}, row_idx={row_idx}, data={table_data}")
                
                row_index = table_data.get('index')
                data_type = table_data.get('data_type')
                
                logger.info(f"ğŸ” è¡¨æ ¼æ•°æ®: row_index={row_index}, data_type={data_type}")
                
                # åªå¤„ç†recordç±»å‹çš„è¡Œ
                if data_type != 'record' or row_index == 'æ— åŒ¹é…' or row_index is None:
                    logger.info(f"â„¹ï¸ è·³è¿‡è¯¥è¡Œ: data_type={data_type}, row_index={row_index}")
                    return current_style, no_update
                
                # è·å–è¡¨æ ¼æ•°æ®ä¸­çš„keyIdï¼Œç”¨äºéªŒè¯
                table_key_id = table_data.get('keyId')
                
                # ç”Ÿæˆå›¾è¡¨
                index = int(row_index)
                logger.info(f"ğŸ” ç”Ÿæˆå›¾è¡¨: algorithm={algorithm_name}, index={index}, table_keyId={table_key_id}")
                
                detail_figure1, detail_figure2, detail_figure_combined = backend.generate_multi_algorithm_error_detail_plot_by_index(
                    algorithm_name=algorithm_name,
                    index=index,
                    error_type='drop',
                    expected_key_id=table_key_id  # ä¼ é€’æœŸæœ›çš„keyIdç”¨äºéªŒè¯
                )
                
                if not detail_figure1 or not detail_figure2 or not detail_figure_combined:
                    logger.warning(f"âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥")
                    return current_style, no_update
                
                # è¿”å›ç»“æœ - ç¡®ä¿æ ·å¼æ­£ç¡®
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '1000',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                
                logger.info(f"âœ… ä¸¢é”¤è¡¨æ ¼ - è¿”å›æ¨¡æ€æ¡†å’Œå›¾è¡¨, modal_style={modal_style}")
                logger.info(f"ğŸ” å›¾è¡¨ç±»å‹: figure_combined={type(detail_figure_combined)}")
                return modal_style, detail_figure_combined
                
            except Exception as e:
                logger.error(f"âŒ ä¸¢é”¤è¡¨æ ¼ç‚¹å‡»å¤„ç†å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                return current_style, no_update
        
        # å¤„ç†å¤šé”¤è¡¨æ ¼ç‚¹å‡»
        elif 'multi-hammers-table' in str(trigger_id):
            import json
            try:
                logger.info(f"ğŸ” å¤šé”¤è¡¨æ ¼ç‚¹å‡» - å¼€å§‹å¤„ç†")
                
                # è§£æè¡¨æ ¼IDè·å–ç®—æ³•åç§°å’Œè¡¨æ ¼ç´¢å¼•
                triggered_prop = ctx.triggered[0]['prop_id']
                table_id_str = triggered_prop.split('.')[0]
                table_id = json.loads(table_id_str)
                algorithm_name = table_id.get('index')
                
                if not algorithm_name:
                    logger.warning(f"âš ï¸ æ— æ³•è·å–ç®—æ³•åç§°")
                    return current_style, no_update
                
                logger.info(f"ğŸ” ç®—æ³•åç§°: {algorithm_name}, triggered_prop={triggered_prop}")
                
                # æ‰¾åˆ°è¢«ç‚¹å‡»çš„è¡¨æ ¼åœ¨åˆ—è¡¨ä¸­çš„ç´¢å¼•
                # éœ€è¦ä»åç«¯è·å–ç®—æ³•åˆ—è¡¨ï¼Œç¡®ä¿è¡¨æ ¼æ•°æ®ä¸ç®—æ³•å¯¹åº”
                active_algorithms = backend.multi_algorithm_manager.get_active_algorithms() if backend.multi_algorithm_manager else []
                algorithm_names = [alg.metadata.algorithm_name for alg in active_algorithms]
                
                # æ‰¾åˆ°å½“å‰ç®—æ³•åœ¨åˆ—è¡¨ä¸­çš„ç´¢å¼•
                if algorithm_name not in algorithm_names:
                    logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' ä¸åœ¨æ¿€æ´»ç®—æ³•åˆ—è¡¨ä¸­")
                    return current_style, no_update
                
                algorithm_idx = algorithm_names.index(algorithm_name)
                logger.info(f"ğŸ” ç®—æ³•ç´¢å¼•: {algorithm_idx}, ç®—æ³•åç§°: {algorithm_name}")
                
                # ä»å¯¹åº”è¡¨æ ¼çš„active_cellsä¸­è·å–active_cell
                active_cell = None
                if algorithm_idx < len(multi_hammers_active_cells):
                    active_cell = multi_hammers_active_cells[algorithm_idx]
                    logger.info(f"ğŸ” ä»active_cells[{algorithm_idx}]è·å–: {active_cell}")
                
                # å¦‚æœactive_cellsä¸­æ²¡æœ‰ï¼Œå°è¯•ä½¿ç”¨trigger_valueï¼ˆä½†éœ€è¦éªŒè¯æ˜¯å¦æ¥è‡ªæ­£ç¡®çš„è¡¨æ ¼ï¼‰
                if not active_cell and trigger_value and isinstance(trigger_value, dict) and 'row' in trigger_value:
                    # éªŒè¯trigger_valueæ˜¯å¦æ¥è‡ªå½“å‰è¡¨æ ¼
                    # ç”±äºæ— æ³•ç›´æ¥éªŒè¯ï¼Œæˆ‘ä»¬å‡è®¾å®ƒæ¥è‡ªå½“å‰è¡¨æ ¼
                    active_cell = trigger_value
                    logger.info(f"ğŸ” ä½¿ç”¨trigger_value: {active_cell}")
                
                if not active_cell:
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ°active_cell, algorithm_idx={algorithm_idx}, active_cells={multi_hammers_active_cells}")
                    return current_style, no_update
                
                row_idx = active_cell.get('row')
                if row_idx is None:
                    logger.warning(f"âš ï¸ active_cellä¸­æ²¡æœ‰rowç´¢å¼•")
                    return current_style, no_update
                
                logger.info(f"ğŸ” row_idx={row_idx}, algorithm_idx={algorithm_idx}")
                
                # æ‰¾åˆ°å¯¹åº”çš„è¡¨æ ¼æ•°æ® - ä½¿ç”¨å·²ç»è®¡ç®—å¥½çš„algorithm_idx
                
                # é€šè¿‡ç®—æ³•ç´¢å¼•è·å–å¯¹åº”çš„è¡¨æ ¼æ•°æ®
                if algorithm_idx >= len(multi_hammers_table_data):
                    logger.warning(f"âš ï¸ ç®—æ³•ç´¢å¼• {algorithm_idx} è¶…å‡ºè¡¨æ ¼æ•°æ®èŒƒå›´")
                    return current_style, no_update
                
                data_list = multi_hammers_table_data[algorithm_idx]
                if not data_list or row_idx >= len(data_list):
                    logger.warning(f"âš ï¸ è¡¨æ ¼æ•°æ®ä¸ºç©ºæˆ–è¡Œç´¢å¼•è¶…å‡ºèŒƒå›´: algorithm_idx={algorithm_idx}, row_idx={row_idx}, data_listé•¿åº¦={len(data_list) if data_list else 0}")
                    return current_style, no_update
                
                table_data = data_list[row_idx]
                logger.info(f"ğŸ” æ‰¾åˆ°è¡¨æ ¼æ•°æ®: algorithm={algorithm_name}, algorithm_idx={algorithm_idx}, row_idx={row_idx}, data={table_data}")
                
                row_index = table_data.get('index')
                data_type = table_data.get('data_type')
                
                # åªå¤„ç†playç±»å‹çš„è¡Œ
                if data_type != 'play' or row_index == 'æ— åŒ¹é…' or row_index is None:
                    logger.info(f"â„¹ï¸ è·³è¿‡è¯¥è¡Œ: data_type={data_type}, row_index={row_index}")
                    return current_style, no_update
                
                # è·å–è¡¨æ ¼æ•°æ®ä¸­çš„keyIdï¼Œç”¨äºéªŒè¯
                table_key_id = table_data.get('keyId')
                
                # ç”Ÿæˆå›¾è¡¨
                index = int(row_index)
                logger.info(f"ğŸ” ç”Ÿæˆå›¾è¡¨: algorithm={algorithm_name}, index={index}, table_keyId={table_key_id}")
                
                detail_figure1, detail_figure2, detail_figure_combined = backend.generate_multi_algorithm_error_detail_plot_by_index(
                    algorithm_name=algorithm_name,
                    index=index,
                    error_type='multi',
                    expected_key_id=table_key_id  # ä¼ é€’æœŸæœ›çš„keyIdç”¨äºéªŒè¯
                )
                
                if not detail_figure1 or not detail_figure2 or not detail_figure_combined:
                    logger.warning(f"âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥")
                    return current_style, no_update
                
                # è¿”å›ç»“æœ
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '1000',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                
                logger.info(f"âœ… å¤šé”¤è¡¨æ ¼ - è¿”å›æ¨¡æ€æ¡†å’Œå›¾è¡¨")
                return modal_style, detail_figure_combined
                
            except Exception as e:
                logger.error(f"âŒ å¤šé”¤è¡¨æ ¼ç‚¹å‡»å¤„ç†å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                return current_style, no_update

        if trigger_id in ['close-modal', 'close-modal-btn']:
            # å…³é—­æ¨¡æ€æ¡†
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '1000',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, no_update

        else:
            return current_style, no_update


    # ä¿®å¤PDFå¯¼å‡ºå›è°ƒï¼Œæ·»åŠ åŠ è½½åŠ¨ç”»å’Œå¼‚å¸¸å¤„ç†
    # PDFå¯¼å‡º - ç¬¬ä¸€æ­¥ï¼šæ˜¾ç¤ºåŠ è½½åŠ¨ç”»
    @app.callback(
        Output('pdf-status', 'children'),
        [Input('btn-export-pdf', 'n_clicks')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def show_pdf_loading(n_clicks, session_id):
        """ç¬¬ä¸€æ­¥ï¼šç«‹å³æ˜¾ç¤ºPDFç”ŸæˆåŠ è½½åŠ¨ç”»
        è¯´æ˜ï¼šæ—§ç‰ˆè¦æ±‚å­˜åœ¨ all_error_notes æ‰å…è®¸å¯¼å‡ºï¼Œå¯¼è‡´"æ— å¼‚å¸¸æ—¶æ— æ³•å¯¼å‡ºæ¦‚è§ˆ"ã€‚
        ç°åœ¨æ”¾å®½æ¡ä»¶ï¼šåªè¦å­˜åœ¨æœ‰æ•ˆæ•°æ®ï¼ˆä»»ä¸€è½¨æˆ–æœ‰åŒ¹é…å¯¹ï¼‰å³å¯ç”ŸæˆPDFï¼ˆæ¦‚è§ˆé¡µ+å¯é€‰å¼‚å¸¸é¡µï¼‰ã€‚
        """
        if not n_clicks:
            return no_update

        # æ£€æŸ¥ä¼šè¯å’Œåç«¯å®ä¾‹
        backend = session_manager.get_backend(session_id)
        if not backend:
            return dbc.Alert("âŒ ä¼šè¯å·²è¿‡æœŸï¼Œè¯·åˆ·æ–°é¡µé¢", color="warning", duration=3000)
        # æ”¾å®½æ ¡éªŒï¼šå­˜åœ¨ä»»ä¸€æ•°æ®æˆ–åŒ¹é…ç»“æœå³å¯å¯¼å‡º
        has_data = False
        try:
            dm = getattr(backend, 'data_manager', None)
            record = dm.get_record_data() if dm else None
            replay = dm.get_replay_data() if dm else None
            has_pairs = bool(getattr(backend.analyzer, 'matched_pairs', [])) if hasattr(backend, 'analyzer') else False
            has_data = bool(record) or bool(replay) or has_pairs
        except Exception:
            has_data = False
        if not has_data:
            return dbc.Alert("âŒ æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®ï¼Œè¯·å…ˆä¸Šä¼ SPMIDæ–‡ä»¶å¹¶å®Œæˆåˆ†æ", color="warning", duration=4000)

        # æ˜¾ç¤ºåŠ è½½åŠ¨ç”»
        return dcc.Loading(
            children=[
                dbc.Alert([
                    html.I(className="fas fa-file-pdf", style={'marginRight': '8px'}),
                    f"æ­£åœ¨ç”ŸæˆPDFæŠ¥å‘Šï¼ŒåŒ…å« {len(backend.all_error_notes)} ä¸ªå¼‚å¸¸çš„å®Œæ•´åˆ†æï¼Œè¯·ç¨å€™..."
                ], color="info", style={'margin': '0'})
            ],
            type="dot",
            color="#dc3545",
            style={'textAlign': 'center'}
        )

    # PDFå¯¼å‡º - ç¬¬äºŒæ­¥ï¼šå®é™…ç”ŸæˆPDF
    @app.callback(
        Output('download-pdf', 'data'),
        [Input('pdf-status', 'children')],
        [State('session-id', 'data'),
         State('btn-export-pdf', 'n_clicks')],
        prevent_initial_call=True
    )
    def generate_pdf_after_loading(pdf_status, session_id, n_clicks):
        """ç¬¬äºŒæ­¥ï¼šåœ¨æ˜¾ç¤ºåŠ è½½åŠ¨ç”»åå®é™…ç”ŸæˆPDF
        è¯´æ˜ï¼šä¸å†ä¾èµ– all_error_notes å­˜åœ¨ä¸å¦ï¼›è‹¥æ— å¼‚å¸¸ï¼Œä»…è¾“å‡ºæ¦‚è§ˆé¡µã€‚
        """
        # åªæœ‰å½“çŠ¶æ€æ˜¾ç¤ºä¸ºåŠ è½½ä¸­æ—¶æ‰æ‰§è¡Œ
        if not pdf_status or not n_clicks:
            return no_update

        # æ£€æŸ¥æ˜¯å¦æ˜¯åŠ è½½çŠ¶æ€
        try:
            if isinstance(pdf_status, dict) and 'props' in pdf_status:
                # è¿™æ˜¯ä¸€ä¸ªLoadingç»„ä»¶ï¼Œè¡¨ç¤ºæ­£åœ¨åŠ è½½
                pass
            else:
                # ä¸æ˜¯åŠ è½½çŠ¶æ€ï¼Œä¸æ‰§è¡Œ
                return no_update
        except:
            return no_update

        # æ£€æŸ¥ä¼šè¯å’Œåç«¯å®ä¾‹
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update

        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        # åªè¦æœ‰æœ‰æ•ˆæ•°æ®å³å¯ç”Ÿæˆï¼ˆæ¦‚è§ˆä¸ºä¸»ï¼Œå¼‚å¸¸é¡µå¯ä¸ºç©ºï¼‰
        try:
            dm = getattr(backend, 'data_manager', None)
            record = dm.get_record_data() if dm else None
            replay = dm.get_replay_data() if dm else None
            has_pairs = bool(getattr(backend.analyzer, 'matched_pairs', [])) if hasattr(backend, 'analyzer') else False
            has_data = bool(record) or bool(replay) or has_pairs
        except Exception:
            has_data = False
        if not has_data:
            return no_update

        try:
            # æ·»åŠ å»¶è¿Ÿç¡®ä¿åŠ è½½åŠ¨ç”»æ˜¾ç¤º
            time.sleep(0.3)

            # ç”ŸæˆPDFæŠ¥å‘Š
            source_info = backend.get_data_source_info() 
            current_filename = source_info.get('filename') or "æœªçŸ¥æ–‡ä»¶"
            pdf_generator = PDFReportGenerator(backend)
            pdf_data = pdf_generator.generate_pdf_report(current_filename)

            if not pdf_data:
                return no_update

            # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
            import re
            safe_filename = re.sub(r'[<>:"/\\|?*]', '_', current_filename or "æœªçŸ¥æ–‡ä»¶")
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"SPMID_å®Œæ•´åˆ†ææŠ¥å‘Š_{safe_filename}_{timestamp}.pdf"

            # ç¡®ä¿PDFæ•°æ®æ˜¯base64ç¼–ç çš„å­—ç¬¦ä¸²
            if isinstance(pdf_data, bytes):
                pdf_data_b64 = base64.b64encode(pdf_data).decode('utf-8')
            else:
                pdf_data_b64 = pdf_data

            # æ„å»ºä¸‹è½½æ•°æ®
            download_data = {
                'content': pdf_data_b64,
                'filename': filename,
                'type': 'application/pdf',
                'base64': True
            }

            return download_data

        except Exception as e:
            logger.error(f"PDFç”Ÿæˆå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return no_update

    # PDFå¯¼å‡º - ç¬¬ä¸‰æ­¥ï¼šæ˜¾ç¤ºå®ŒæˆçŠ¶æ€
    @app.callback(
        [Output('pdf-status', 'children', allow_duplicate=True)],
        [Input('download-pdf', 'data')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def show_pdf_completion(download_data, session_id):
        """ç¬¬ä¸‰æ­¥ï¼šæ˜¾ç¤ºPDFç”Ÿæˆå®ŒæˆçŠ¶æ€"""
        if not download_data:
            return [no_update]

        # æ£€æŸ¥ä¼šè¯
        backend = session_manager.get_backend(session_id)
        if not backend:
            return [no_update]

        # æ˜¾ç¤ºæˆåŠŸçŠ¶æ€
        success_alert = dbc.Alert([
            html.I(className="fas fa-check-circle", style={'marginRight': '8px'}),
            # æˆåŠŸæç¤ºè¯´æ˜ï¼šæ ¹æ®å®é™…å¼‚å¸¸æ•°é‡æç¤ºï¼›è‹¥ä¸º0åˆ™æç¤ºç”Ÿæˆæ¦‚è§ˆ
            f"âœ… PDFæŠ¥å‘Šç”ŸæˆæˆåŠŸï¼å¼‚å¸¸æ¡ç›®: {len(getattr(backend, 'all_error_notes', []) or [])}ï¼Œå·²å¼€å§‹ä¸‹è½½ï¼ˆå¦‚æ— å¼‚å¸¸åˆ™ä»…åŒ…å«æ¦‚è§ˆï¼‰"
        ], color="success", duration=5000)

        return [success_alert]

    # é”®IDç­›é€‰å›è°ƒå‡½æ•°
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('key-filter-status', 'children', allow_duplicate=True),
         Output('key-filter-dropdown', 'options', allow_duplicate=True),
         Output('key-filter-dropdown', 'value', allow_duplicate=True)],
        [Input('key-filter-dropdown', 'value'),
         Input('btn-show-all-keys', 'n_clicks')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_key_filter(key_filter, show_all_clicks, session_id):
        """å¤„ç†é”®IDç­›é€‰"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update, no_update, no_update
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®ï¼ˆé€šè¿‡DataManagerçš„getterï¼‰
        if not backend.data_manager.get_record_data() and not backend.data_manager.get_replay_data():
            return no_update, no_update, no_update, no_update
        
        # è·å–è§¦å‘ä¸Šä¸‹æ–‡
        ctx = callback_context
        if not ctx.triggered:
            return no_update, no_update, no_update, no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        
        # å¤„ç†"æ˜¾ç¤ºå…¨éƒ¨é”®ä½"æŒ‰é’®
        if trigger_id == 'btn-show-all-keys' and show_all_clicks and show_all_clicks > 0:
            backend.set_key_filter(None)
            key_filter = None
            logger.info("ğŸ” é‡ç½®é”®IDç­›é€‰")
        # å¤„ç†é”®IDä¸‹æ‹‰æ¡†é€‰æ‹©
        elif trigger_id == 'key-filter-dropdown':
            if key_filter:
                backend.set_key_filter(key_filter)
                logger.info(f"ğŸ” åº”ç”¨é”®IDç­›é€‰: {key_filter}")
            else:
                backend.set_key_filter(None)
                logger.info("ğŸ” æ¸…é™¤é”®IDç­›é€‰")
        else:
            return no_update, no_update, no_update, no_update
        
        # é‡æ–°ç”Ÿæˆç€‘å¸ƒå›¾
        fig = backend.generate_waterfall_plot()
        key_status = backend.get_key_filter_status()
        
        # å°†key_statusè½¬æ¢ä¸ºå¯æ¸²æŸ“çš„å­—ç¬¦ä¸²
        if key_status['enabled']:
            key_status_text = f"å·²ç­›é€‰ {len(key_status['filtered_keys'])} ä¸ªé”®ä½ (å…± {key_status['total_available_keys']} ä¸ª)"
        else:
            key_status_text = f"æ˜¾ç¤ºå…¨éƒ¨ {key_status['total_available_keys']} ä¸ªé”®ä½"
        
        logger.info(f"ğŸ” é”®IDç­›é€‰çŠ¶æ€: {key_status}")
        
        # è·å–é”®IDé€‰é¡¹å¹¶è½¬æ¢ä¸ºDash Dropdownæ ¼å¼
        available_keys = backend.get_available_keys()
        key_options = [{'label': f'é”®ä½ {key_id}', 'value': key_id} for key_id in available_keys]
        
        # è¿”å›å½“å‰é€‰ä¸­çš„valueï¼Œç¡®ä¿UIå›æ˜¾
        return fig, key_status_text, key_options, (key_filter or [])

    # æ—¶é—´è½´ç­›é€‰å›è°ƒå‡½æ•°
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('time-filter-status', 'children', allow_duplicate=True),
         Output('time-filter-slider', 'value', allow_duplicate=True)],
        [Input('btn-apply-time-filter', 'n_clicks'),
         Input('btn-reset-time-filter', 'n_clicks')],
        [State('session-id', 'data'),
         State('time-filter-slider', 'value')],
        prevent_initial_call=True
    )
    def handle_time_filter(apply_clicks, reset_clicks, session_id, time_range):
        """å¤„ç†æ—¶é—´è½´ç­›é€‰"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update, no_update
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        if not hasattr(backend, 'all_error_notes') or not backend.all_error_notes:
            logger.warning("âš ï¸ æ²¡æœ‰åˆ†ææ•°æ®ï¼Œæ— æ³•åº”ç”¨æ—¶é—´ç­›é€‰")
            return no_update, no_update, no_update
        
        # è·å–è§¦å‘ä¸Šä¸‹æ–‡
        ctx = callback_context
        if not ctx.triggered:
            return no_update, no_update, no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"â° æ—¶é—´ç­›é€‰è§¦å‘å™¨: {trigger_id}")
        
        # è·å–åŸå§‹æ—¶é—´èŒƒå›´ï¼ˆç”¨äºé‡ç½®ï¼‰
        original_time_range = backend.get_time_range()
        original_min, original_max = original_time_range
        slider_value = no_update
        
        # å¤„ç†"é‡ç½®æ—¶é—´èŒƒå›´"æŒ‰é’®
        if trigger_id == 'btn-reset-time-filter' and reset_clicks and reset_clicks > 0:
            backend.set_time_filter(None)
            logger.info("â° é‡ç½®æ—¶é—´èŒƒå›´ç­›é€‰")
            # é‡ç½®æ»‘å—åˆ°åŸå§‹èŒƒå›´
            slider_value = [int(original_min), int(original_max)]
            logger.info(f"â° é‡ç½®æ»‘å—åˆ°åŸå§‹èŒƒå›´: {slider_value}")
            
        # å¤„ç†"åº”ç”¨æ—¶é—´ç­›é€‰"æŒ‰é’®
        elif trigger_id == 'btn-apply-time-filter' and apply_clicks and apply_clicks > 0:
            if time_range and len(time_range) == 2 and time_range[0] != time_range[1]:
                # éªŒè¯æ—¶é—´èŒƒå›´çš„åˆç†æ€§
                start_time, end_time = time_range
                if start_time < end_time:
                    backend.set_time_filter(time_range)
                    logger.info(f"â° åº”ç”¨æ—¶é—´è½´ç­›é€‰: {time_range}")
                    # ä¿æŒå½“å‰æ»‘å—å€¼
                    slider_value = no_update
                else:
                    logger.warning(f"âš ï¸ æ—¶é—´èŒƒå›´æ— æ•ˆ: {time_range}")
                    backend.set_time_filter(None)
                    # é‡ç½®æ»‘å—åˆ°åŸå§‹èŒƒå›´
                    slider_value = [int(original_min), int(original_max)]
            else:
                backend.set_time_filter(None)
                logger.info("â° æ¸…é™¤æ—¶é—´è½´ç­›é€‰ï¼ˆæ— æ•ˆèŒƒå›´ï¼‰")
                # é‡ç½®æ»‘å—åˆ°åŸå§‹èŒƒå›´
                slider_value = [int(original_min), int(original_max)]
        else:
            logger.warning(f"âš ï¸ æœªè¯†åˆ«çš„æ—¶é—´ç­›é€‰è§¦å‘å™¨: {trigger_id}")
            return no_update, no_update, no_update
        
        try:
            # é‡æ–°ç”Ÿæˆç€‘å¸ƒå›¾
            fig = backend.generate_waterfall_plot()
            time_status = backend.get_time_filter_status()
            
            # å°†time_statusè½¬æ¢ä¸ºå¯æ¸²æŸ“çš„å­—ç¬¦ä¸²
            if time_status['enabled']:
                time_status_text = f"æ—¶é—´èŒƒå›´: {time_status['start_time']:.2f}s - {time_status['end_time']:.2f}s (æ—¶é•¿: {time_status['duration']:.2f}s)"
            else:
                time_status_text = "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
            
            logger.info(f"â° æ—¶é—´è½´ç­›é€‰çŠ¶æ€: {time_status}")
            
            return fig, time_status_text, slider_value
        except Exception as e:
            logger.error(f"âŒ æ—¶é—´ç­›é€‰åç”Ÿæˆç€‘å¸ƒå›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            
            # è¿”å›é”™è¯¯æç¤ºå›¾
            error_fig = _create_empty_figure_for_callback(f"æ—¶é—´ç­›é€‰å¤±è´¥: {str(e)}")
            return error_fig, "æ—¶é—´ç­›é€‰å‡ºé”™ï¼Œè¯·é‡è¯•", no_update


    # æ—¶é—´èŒƒå›´è¾“å…¥ç¡®è®¤å›è°ƒå‡½æ•°
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('time-range-input-status', 'children', allow_duplicate=True),
         Output('time-filter-slider', 'min', allow_duplicate=True),
         Output('time-filter-slider', 'max', allow_duplicate=True),
         Output('time-filter-slider', 'value', allow_duplicate=True),
         Output('time-filter-slider', 'marks', allow_duplicate=True)],
        [Input('btn-confirm-time-range', 'n_clicks')],
        [State('session-id', 'data'),
         State('time-range-start-input', 'value'),
         State('time-range-end-input', 'value')],
        prevent_initial_call=True
    )
    def handle_time_range_input_confirmation(n_clicks, session_id, start_time, end_time):
        """å¤„ç†æ—¶é—´èŒƒå›´è¾“å…¥ç¡®è®¤"""
        logger.info(f"ğŸ”„ æ—¶é—´èŒƒå›´è¾“å…¥ç¡®è®¤å›è°ƒè¢«è§¦å‘: n_clicks={n_clicks}, start_time={start_time}, end_time={end_time}")
        
        if not n_clicks or n_clicks <= 0:
            logger.info("âš ï¸ æŒ‰é’®æœªç‚¹å‡»ï¼Œè·³è¿‡å¤„ç†")
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("âš ï¸ æ— æ•ˆçš„ä¼šè¯ID")
            return no_update, "æ— æ•ˆçš„ä¼šè¯ID", no_update, no_update, no_update, no_update
        
        if start_time is None or end_time is None:
            logger.warning("âš ï¸ æ—¶é—´èŒƒå›´è¾“å…¥ä¸ºç©º")
            return no_update, "è¯·è¾“å…¥æœ‰æ•ˆçš„æ—¶é—´èŒƒå›´", no_update, no_update, no_update, no_update
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            logger.info(f"ğŸ”„ è°ƒç”¨åç«¯æ›´æ–°æ—¶é—´èŒƒå›´: start_time={start_time}, end_time={end_time}")
            # è°ƒç”¨åç«¯æ–¹æ³•æ›´æ–°æ—¶é—´èŒƒå›´
            success, message = backend.update_time_range_from_input(start_time, end_time)
            
            if success:
                logger.info(f"âœ… åç«¯æ—¶é—´èŒƒå›´æ›´æ–°æˆåŠŸ: {message}")
                # é‡æ–°ç”Ÿæˆç€‘å¸ƒå›¾ï¼ˆä½¿ç”¨æ–°çš„æ—¶é—´èŒƒå›´ï¼‰
                fig = backend.generate_waterfall_plot()
                
                # æ›´æ–°æ»‘åŠ¨æ¡çš„èŒƒå›´å’Œå½“å‰å€¼
                new_min = int(start_time)
                new_max = int(end_time)
                new_value = [new_min, new_max]
                
                # åˆ›å»ºæ–°çš„æ ‡è®°ç‚¹
                range_size = new_max - new_min
                if range_size <= 1000:
                    step = max(1, range_size // 5)
                elif range_size <= 10000:
                    step = max(10, range_size // 10)
                else:
                    step = max(100, range_size // 20)
                
                new_marks = {}
                for i in range(new_min, new_max + 1, step):
                    if i == new_min or i == new_max or (i - new_min) % (step * 2) == 0:
                        new_marks[i] = str(i)
                
                logger.info(f"âœ… æ—¶é—´èŒƒå›´æ›´æ–°æˆåŠŸ: {message}")
                logger.info(f"â° æ›´æ–°æ»‘åŠ¨æ¡èŒƒå›´: min={new_min}, max={new_max}, value={new_value}")
                logger.info(f"â° æ–°æ ‡è®°ç‚¹: {new_marks}")
                status_message = f"âœ… {message}"
                status_style = {'color': '#28a745', 'fontWeight': 'bold'}
                
                return fig, html.Span(status_message, style=status_style), new_min, new_max, new_value, new_marks
            else:
                logger.warning(f"âš ï¸ æ—¶é—´èŒƒå›´æ›´æ–°å¤±è´¥: {message}")
                status_message = f"âŒ {message}"
                status_style = {'color': '#dc3545', 'fontWeight': 'bold'}
                
                return no_update, html.Span(status_message, style=status_style), no_update, no_update, no_update, no_update
                
        except Exception as e:
            logger.error(f"âŒ æ—¶é—´èŒƒå›´è¾“å…¥ç¡®è®¤å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            
            error_message = f"âŒ æ—¶é—´èŒƒå›´æ›´æ–°å¤±è´¥: {str(e)}"
            error_style = {'color': '#dc3545', 'fontWeight': 'bold'}
            
            return no_update, html.Span(error_message, style=error_style), no_update, no_update, no_update, no_update


    # é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´å›è°ƒå‡½æ•°
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('time-range-input-status', 'children', allow_duplicate=True),
         Output('time-filter-slider', 'min', allow_duplicate=True),
         Output('time-filter-slider', 'max', allow_duplicate=True),
         Output('time-filter-slider', 'value', allow_duplicate=True),
         Output('time-filter-slider', 'marks', allow_duplicate=True)],
        [Input('btn-reset-display-time-range', 'n_clicks')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_reset_display_time_range(n_clicks, session_id):
        """å¤„ç†é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´"""
        if not n_clicks or n_clicks <= 0:
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("âš ï¸ æ— æ•ˆçš„ä¼šè¯ID")
            return no_update, "æ— æ•ˆçš„ä¼šè¯ID", no_update, no_update, no_update, no_update
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´
            backend.reset_display_time_range()
            
            # é‡æ–°ç”Ÿæˆç€‘å¸ƒå›¾
            fig = backend.generate_waterfall_plot()
            
            # è·å–åŸå§‹æ•°æ®æ—¶é—´èŒƒå›´å¹¶é‡ç½®æ»‘åŠ¨æ¡åˆ°åŸå§‹èŒƒå›´
            original_min, original_max = backend.get_time_range()
            new_value = [int(original_min), int(original_max)]
            
            logger.info("âœ… æ˜¾ç¤ºæ—¶é—´èŒƒå›´é‡ç½®æˆåŠŸ")
            status_message = "âœ… æ˜¾ç¤ºæ—¶é—´èŒƒå›´å·²é‡ç½®åˆ°åŸå§‹æ•°æ®èŒƒå›´"
            status_style = {'color': '#28a745', 'fontWeight': 'bold'}
            
            return fig, html.Span(status_message, style=status_style), no_update, no_update, new_value, no_update
                
        except Exception as e:
            logger.error(f"âŒ é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            
            error_message = f"âŒ é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´å¤±è´¥: {str(e)}"
            error_style = {'color': '#dc3545', 'fontWeight': 'bold'}
            
            return no_update, html.Span(error_message, style=error_style), no_update, no_update, no_update, no_update


    # å·²ç§»é™¤å…¨å±€å»¶è¿Ÿç»Ÿè®¡å›¾è¡¨ç›¸å…³å›è°ƒï¼ˆä½¿ç”¨æ•°æ®ç»Ÿè®¡æ¦‚è§ˆä¸­çš„å¹³å‡æ—¶å»¶æ›¿ä»£ï¼‰

    # åç§»å¯¹é½åˆ†æ - é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆï¼ˆæ— éœ€ç‚¹å‡»æŒ‰é’®ï¼‰
    @app.callback(
        Output('offset-alignment-plot', 'figure', allow_duplicate=True),
        Output('offset-alignment-table', 'data', allow_duplicate=True),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def auto_generate_alignment_on_load(report_content, session_id):
        """æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶ï¼Œè‡ªåŠ¨ç”Ÿæˆåç§»å¯¹é½æŸ±çŠ¶å›¾ä¸è¡¨æ ¼"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
            active_algorithms = backend.get_active_algorithms()
            if not active_algorithms:
                logger.warning("âš ï¸ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆåç§»å¯¹é½åˆ†æ")
                empty = backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
                return empty, []
            
            fig = backend.generate_offset_alignment_plot()
            table_data = backend.get_offset_alignment_data()
            logger.info("âœ… åç§»å¯¹é½åˆ†æï¼ˆè‡ªåŠ¨ï¼‰ç”ŸæˆæˆåŠŸ")
            return fig, table_data
            
        except Exception as e:
            logger.error(f"âŒ è‡ªåŠ¨ç”Ÿæˆåç§»å¯¹é½åˆ†æå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            empty = backend.plot_generator._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
            return empty, no_update

    # æŒ‰é”®ä¸å»¶æ—¶Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾è‡ªåŠ¨ç”Ÿæˆå›è°ƒå‡½æ•° - å½“æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('key-delay-zscore-scatter-plot', 'figure'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_scatter_plot(report_content, session_id):
        """å¤„ç†æŒ‰é”®ä¸å»¶æ—¶Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†ææ•°æ®
            if not backend.analyzer and not (hasattr(backend, 'multi_algorithm_mode') and backend.multi_algorithm_mode):
                logger.warning("âš ï¸ æ²¡æœ‰åˆ†æå™¨ï¼Œæ— æ³•ç”ŸæˆZ-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾")
                empty = backend.plot_generator._create_empty_plot("æ²¡æœ‰åˆ†æå™¨")
                return empty
            
            # ç”ŸæˆZ-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾
            zscore_fig = backend.generate_key_delay_zscore_scatter_plot()
            
            # éªŒè¯Z-Scoreå›¾è¡¨æ˜¯å¦æ­£ç¡®ç”Ÿæˆ
            if zscore_fig and hasattr(zscore_fig, 'data') and len(zscore_fig.data) > 0:
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹çš„yå€¼æ˜¯å¦æ˜¯Z-Scoreï¼ˆåº”è¯¥åœ¨-3åˆ°3ä¹‹é—´ï¼Œè€Œä¸æ˜¯åŸå§‹çš„å»¶æ—¶å€¼ï¼‰
                first_trace = zscore_fig.data[0]
                if hasattr(first_trace, 'y') and len(first_trace.y) > 0:
                    first_y = first_trace.y[0] if hasattr(first_trace.y, '__getitem__') else first_trace.y
                    logger.info(f"ğŸ” Z-Scoreå›¾è¡¨éªŒè¯: ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹çš„yå€¼={first_y} (åº”è¯¥æ˜¯Z-Scoreå€¼ï¼Œé€šå¸¸åœ¨-3åˆ°3ä¹‹é—´)")
            
            logger.info("âœ… æŒ‰é”®ä¸å»¶æ—¶Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸ")
            return zscore_fig
            
        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆZ-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            empty = backend.plot_generator._create_empty_plot(f"ç”ŸæˆZ-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾å¤±è´¥: {str(e)}")
            return empty

    # é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾è‡ªåŠ¨ç”Ÿæˆå›è°ƒå‡½æ•° - å½“æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('hammer-velocity-delay-scatter-plot', 'figure'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_hammer_velocity_scatter_plot(report_content, session_id):
        """å¤„ç†é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
            active_algorithms = backend.get_active_algorithms()
            if not active_algorithms:
                logger.warning("âš ï¸ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆæ•£ç‚¹å›¾")
                return backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
            # ç”Ÿæˆé”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾
            fig = backend.generate_hammer_velocity_delay_scatter_plot()
            
            logger.info("âœ… é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸ")
            return fig
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ•£ç‚¹å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            
            return backend.plot_generator._create_empty_plot(f"ç”Ÿæˆæ•£ç‚¹å›¾å¤±è´¥: {str(e)}")

    # ==========================================================================
    # æ¯ä¸ªæŒ‰é”®çš„åŠ›åº¦-å»¶æ—¶å…³ç³»æ•£ç‚¹å›¾ - å·²åˆ é™¤ï¼ˆåŠŸèƒ½ä¸æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾é‡å¤ï¼‰
    # ==========================================================================

    # å¤„ç†ç®—æ³•é€‰æ‹©ï¼šç‚¹å‡»ç®—æ³•æ§åˆ¶å›¾æ³¨
    @app.callback(
        Output('key-force-interaction-selected-algorithms', 'data'),
        [Input('key-force-interaction-plot', 'restyleData')],
        [State('key-force-interaction-selected-algorithms', 'data'),
         State('key-force-interaction-plot', 'figure')],
        prevent_initial_call=True
    )
    def handle_key_force_interaction_algorithm_selection(restyle_data, current_selected_algorithms, figure):
        """å¤„ç†ç®—æ³•é€‰æ‹©ï¼šç‚¹å‡»ç®—æ³•æ§åˆ¶å›¾æ³¨ï¼Œåˆ‡æ¢ç®—æ³•é€‰æ‹©çŠ¶æ€"""
        ctx = dash.callback_context
        if not ctx.triggered:
            return current_selected_algorithms or []
        
        if not restyle_data or not figure or 'data' not in figure:
            return current_selected_algorithms or []
        
        try:
            # restyleDataæ ¼å¼: [{'visible': [...]}, [trace_indices]]
            # å½“ç‚¹å‡»legendæ—¶ï¼Œå¯èƒ½ä¼šè§¦å‘å¤šä¸ªtraceçš„visibleå˜åŒ–
            # æˆ‘ä»¬éœ€è¦æ‰¾åˆ°ç®—æ³•æ§åˆ¶å›¾æ³¨çš„trace
            
            selected_algorithms = current_selected_algorithms or []
            
            # æ£€æŸ¥restyleDataæ ¼å¼
            if not isinstance(restyle_data, list) or len(restyle_data) < 2:
                return current_selected_algorithms or []
            
            restyle_dict = restyle_data[0] if isinstance(restyle_data[0], dict) else {}
            trace_indices = restyle_data[1] if len(restyle_data) > 1 and isinstance(restyle_data[1], list) else []
            
            # éå†æ‰€æœ‰è¢«å½±å“çš„traceï¼Œæ‰¾åˆ°ç®—æ³•æ§åˆ¶å›¾æ³¨
            for idx in trace_indices:
                if idx < len(figure['data']):
                    trace = figure['data'][idx]
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç®—æ³•æ§åˆ¶å›¾æ³¨é¡¹
                    legendgroup = trace.get('legendgroup') if isinstance(trace, dict) else (trace.legendgroup if hasattr(trace, 'legendgroup') else None)
                    
                    if legendgroup == 'algorithm_control':
                        # è·å–ç®—æ³•åç§°
                        algorithm_name = None
                        if isinstance(trace, dict):
                            algorithm_name = trace.get('name')
                        else:
                            algorithm_name = trace.name if hasattr(trace, 'name') else None
                        
                        if algorithm_name:
                            # åˆ‡æ¢ç®—æ³•é€‰æ‹©çŠ¶æ€
                            if algorithm_name in selected_algorithms:
                                # å–æ¶ˆé€‰æ‹©
                                selected_algorithms = [a for a in selected_algorithms if a != algorithm_name]
                                logger.info(f"ğŸ”„ å–æ¶ˆé€‰æ‹©ç®—æ³•: {algorithm_name}, å½“å‰é€‰ä¸­: {selected_algorithms}")
                            else:
                                # é€‰æ‹©ç®—æ³•
                                selected_algorithms = selected_algorithms + [algorithm_name]
                                logger.info(f"ğŸ¯ é€‰æ‹©ç®—æ³•: {algorithm_name}, å½“å‰é€‰ä¸­: {selected_algorithms}")
                            
                            # æ‰¾åˆ°ç®—æ³•æ§åˆ¶å›¾æ³¨åç«‹å³è¿”å›ï¼Œé¿å…å¤„ç†å…¶ä»–trace
                            return selected_algorithms
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç®—æ³•æ§åˆ¶å›¾æ³¨ï¼Œå¯èƒ½æ˜¯ç‚¹å‡»äº†å…¶ä»–å›¾æ³¨ï¼Œè¿”å›åŸçŠ¶æ€
            logger.debug(f"ğŸ” æœªæ‰¾åˆ°ç®—æ³•æ§åˆ¶å›¾æ³¨ï¼Œrestyle_data: {restyle_data}")
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†ç®—æ³•é€‰æ‹©äº‹ä»¶å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
        
        return current_selected_algorithms or []
    
    # å¤„ç†æŒ‰é”®é€‰æ‹©ï¼šç‚¹å‡»æŒ‰é”®æ§åˆ¶å›¾æ³¨
    @app.callback(
        Output('key-force-interaction-selected-keys', 'data'),
        [Input('key-force-interaction-plot', 'restyleData')],
        [State('key-force-interaction-selected-keys', 'data'),
         State('key-force-interaction-plot', 'figure')],
        prevent_initial_call=True
    )
    def handle_key_force_interaction_key_selection(restyle_data, current_selected_keys, figure):
        """å¤„ç†æŒ‰é”®é€‰æ‹©ï¼šç‚¹å‡»æŒ‰é”®æ§åˆ¶å›¾æ³¨ï¼Œåˆ‡æ¢æŒ‰é”®é€‰æ‹©çŠ¶æ€"""
        ctx = dash.callback_context
        if not ctx.triggered:
            return current_selected_keys or []
        
        if not restyle_data or not figure or 'data' not in figure:
            return current_selected_keys or []
        
        try:
            # restyleDataæ ¼å¼: [{'visible': [...]}, [trace_indices]]
            selected_keys = current_selected_keys or []
            
            # æ£€æŸ¥restyleDataæ ¼å¼
            if not isinstance(restyle_data, list) or len(restyle_data) < 2:
                return current_selected_keys or []
            
            restyle_dict = restyle_data[0] if isinstance(restyle_data[0], dict) else {}
            trace_indices = restyle_data[1] if len(restyle_data) > 1 and isinstance(restyle_data[1], list) else []
            
            # éå†æ‰€æœ‰è¢«å½±å“çš„traceï¼Œæ‰¾åˆ°æŒ‰é”®æ§åˆ¶å›¾æ³¨
            for idx in trace_indices:
                if idx < len(figure['data']):
                    trace = figure['data'][idx]
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æŒ‰é”®æ§åˆ¶å›¾æ³¨é¡¹
                    legendgroup = trace.get('legendgroup') if isinstance(trace, dict) else (trace.legendgroup if hasattr(trace, 'legendgroup') else None)
                    
                    if legendgroup == 'key_control':
                        # è·å–æŒ‰é”®åç§°
                        name = None
                        if isinstance(trace, dict):
                            name = trace.get('name')
                        else:
                            name = trace.name if hasattr(trace, 'name') else None
                        
                        if name and name.startswith('æŒ‰é”® '):
                            try:
                                clicked_key_id = int(name.split('æŒ‰é”® ')[1])
                                
                                # åˆ‡æ¢æŒ‰é”®é€‰æ‹©çŠ¶æ€
                                if clicked_key_id in selected_keys:
                                    # å–æ¶ˆé€‰æ‹©
                                    selected_keys = [k for k in selected_keys if k != clicked_key_id]
                                    logger.info(f"ğŸ”„ å–æ¶ˆé€‰æ‹©æŒ‰é”®: {clicked_key_id}, å½“å‰é€‰ä¸­: {selected_keys}")
                                else:
                                    # é€‰æ‹©æŒ‰é”®
                                    selected_keys = selected_keys + [clicked_key_id]
                                    logger.info(f"ğŸ¯ é€‰æ‹©æŒ‰é”®: {clicked_key_id}, å½“å‰é€‰ä¸­: {selected_keys}")
                                
                                # æ‰¾åˆ°æŒ‰é”®æ§åˆ¶å›¾æ³¨åç«‹å³è¿”å›ï¼Œé¿å…å¤„ç†å…¶ä»–trace
                                return selected_keys
                            except (ValueError, IndexError) as e:
                                logger.debug(f"âš ï¸ è§£ææŒ‰é”®IDå¤±è´¥: {name}, é”™è¯¯: {e}")
                                continue
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æŒ‰é”®æ§åˆ¶å›¾æ³¨ï¼Œå¯èƒ½æ˜¯ç‚¹å‡»äº†å…¶ä»–å›¾æ³¨ï¼Œè¿”å›åŸçŠ¶æ€
            logger.debug(f"ğŸ” æœªæ‰¾åˆ°æŒ‰é”®æ§åˆ¶å›¾æ³¨ï¼Œrestyle_data: {restyle_data}")
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æŒ‰é”®é€‰æ‹©äº‹ä»¶å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
        
        return current_selected_keys or []
    
    # æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾è‡ªåŠ¨ç”Ÿæˆå’Œæ›´æ–°å›è°ƒå‡½æ•°
    @app.callback(
        Output('key-force-interaction-plot', 'figure'),
        [Input('report-content', 'children'),
         Input('key-force-interaction-selected-algorithms', 'data'),
         Input('key-force-interaction-selected-keys', 'data')],
        [State('session-id', 'data'),
         State('key-force-interaction-plot', 'figure')],
        prevent_initial_call=True
    )
    def handle_generate_key_force_interaction_plot(report_content, selected_algorithms, selected_keys, session_id, current_figure):
        """å¤„ç†æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾è‡ªåŠ¨ç”Ÿæˆå’Œæ›´æ–° - æ ¹æ®é€‰ä¸­çš„ç®—æ³•å’ŒæŒ‰é”®æ›´æ–°å¯è§æ€§"""
        ctx = dash.callback_context
        if not ctx.triggered:
            return no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # æ ¹æ®é€‰ä¸­çš„ç®—æ³•å’ŒæŒ‰é”®æ›´æ–°å¯è§æ€§
            selected_algorithms = selected_algorithms or []
            selected_keys = selected_keys or []
            
            # å¦‚æœæ˜¯report-contentå˜åŒ–ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆå›¾è¡¨
            if trigger_id == 'report-content':
                # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
                active_algorithms = backend.get_active_algorithms()
                if not active_algorithms:
                    logger.warning("âš ï¸ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆäº¤äº’æ•ˆåº”å›¾")
                    return backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
                
                # é‡æ–°ç”Ÿæˆå›¾è¡¨
                fig = backend.generate_key_force_interaction_plot()
                
                # é‡æ–°ç”Ÿæˆå›¾è¡¨åï¼Œéœ€è¦æ ¹æ®é€‰ä¸­çš„ç®—æ³•å’ŒæŒ‰é”®æ¢å¤çŠ¶æ€
                # ç»§ç»­æ‰§è¡Œä¸‹é¢çš„æ›´æ–°é€»è¾‘
            else:
                # å¦‚æœæ˜¯é€‰æ‹©å˜åŒ–ï¼Œä½¿ç”¨å½“å‰å›¾è¡¨å¹¶æ›´æ–°å¯è§æ€§
                if current_figure and isinstance(current_figure, dict) and 'data' in current_figure:
                    import plotly.graph_objects as go
                    # ä»dictåˆ›å»ºFigureï¼Œç¡®ä¿æ‰€æœ‰å±æ€§éƒ½è¢«æ­£ç¡®åŠ è½½
                    fig = go.Figure(current_figure)
                    # ç¡®ä¿dataæ˜¯traceå¯¹è±¡åˆ—è¡¨ï¼Œè€Œä¸æ˜¯dictåˆ—è¡¨
                    if fig.data and isinstance(fig.data[0], dict):
                        # å¦‚æœdataæ˜¯dictåˆ—è¡¨ï¼Œéœ€è¦è½¬æ¢ä¸ºtraceå¯¹è±¡
                        fig_data = []
                        for trace_dict in fig.data:
                            trace_type = trace_dict.get('type', 'scatter')
                            if trace_type == 'scatter':
                                fig_data.append(go.Scatter(trace_dict))
                            else:
                                fig_data.append(trace_dict)
                        fig.data = fig_data
                else:
                    active_algorithms = backend.get_active_algorithms()
                    if not active_algorithms:
                        return no_update
                    fig = backend.generate_key_force_interaction_plot()
            
            # å¦‚æœæ²¡æœ‰é€‰æ‹©ä»»ä½•ç®—æ³•æˆ–æŒ‰é”®ï¼Œä¸æ˜¾ç¤ºä»»ä½•æ•°æ®ï¼›åªæœ‰é€‰æ‹©åæ‰æ˜¾ç¤º
            show_all = False  # é»˜è®¤ä¸æ˜¾ç¤ºï¼Œéœ€è¦é€‰æ‹©åæ‰æ˜¾ç¤º
            
            # è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥traceæ˜¯å¦å±äºæŒ‡å®šçš„ç®—æ³•
            def trace_belongs_to_algorithm(trace, algorithm_name):
                if not algorithm_name:
                    return False
                
                # å¤„ç†dictç±»å‹çš„trace
                if isinstance(trace, dict):
                    customdata = trace.get('customdata')
                    if customdata:
                        try:
                            if isinstance(customdata, list) and len(customdata) > 0:
                                first_point_data = customdata[0]
                                if isinstance(first_point_data, list) and len(first_point_data) >= 2:
                                    trace_algorithm_name = first_point_data[1]
                                    # ç²¾ç¡®åŒ¹é…
                                    if trace_algorithm_name == algorithm_name:
                                        return True
                                    # å¦‚æœç®—æ³•åç§°åŒ…å«æ‹¬å·ï¼ˆå¸¦æ–‡ä»¶ååç¼€ï¼‰ï¼Œå°è¯•åŒ¹é…åŸºç¡€åç§°
                                    # ä¾‹å¦‚ï¼šç®—æ³•A (æ–‡ä»¶å) åº”è¯¥åŒ¹é… ç®—æ³•A
                                    if '(' in algorithm_name:
                                        base_name = algorithm_name.split('(')[0].strip()
                                        if trace_algorithm_name == base_name:
                                            return True
                                    if '(' in trace_algorithm_name:
                                        base_name = trace_algorithm_name.split('(')[0].strip()
                                        if base_name == algorithm_name:
                                            return True
                        except (IndexError, TypeError) as e:
                            logger.debug(f"âš ï¸ æ£€æŸ¥ç®—æ³•åŒ¹é…æ—¶å‡ºé”™: {e}")
                            pass
                    legendgroup = trace.get('legendgroup')
                    if legendgroup:
                        # ç²¾ç¡®åŒ¹é…
                        if legendgroup.startswith(f'data_{algorithm_name}_'):
                            return True
                        # å¦‚æœç®—æ³•åç§°åŒ…å«æ‹¬å·ï¼Œå°è¯•åŒ¹é…åŸºç¡€åç§°
                        if '(' in algorithm_name:
                            base_name = algorithm_name.split('(')[0].strip()
                            if legendgroup.startswith(f'data_{base_name}_'):
                                return True
                else:
                    # å¤„ç†Plotly traceå¯¹è±¡
                    if hasattr(trace, 'customdata') and trace.customdata:
                        try:
                            if isinstance(trace.customdata, list) and len(trace.customdata) > 0:
                                first_point_data = trace.customdata[0]
                                if isinstance(first_point_data, list) and len(first_point_data) >= 2:
                                    trace_algorithm_name = first_point_data[1]
                                    # ç²¾ç¡®åŒ¹é…
                                    if trace_algorithm_name == algorithm_name:
                                        return True
                                    # å¦‚æœç®—æ³•åç§°åŒ…å«æ‹¬å·ï¼ˆå¸¦æ–‡ä»¶ååç¼€ï¼‰ï¼Œå°è¯•åŒ¹é…åŸºç¡€åç§°
                                    if '(' in algorithm_name:
                                        base_name = algorithm_name.split('(')[0].strip()
                                        if trace_algorithm_name == base_name:
                                            return True
                                    if '(' in trace_algorithm_name:
                                        base_name = trace_algorithm_name.split('(')[0].strip()
                                        if base_name == algorithm_name:
                                            return True
                        except (IndexError, TypeError) as e:
                            logger.debug(f"âš ï¸ æ£€æŸ¥ç®—æ³•åŒ¹é…æ—¶å‡ºé”™: {e}")
                            pass
                    if hasattr(trace, 'legendgroup') and trace.legendgroup:
                        # ç²¾ç¡®åŒ¹é…
                        if trace.legendgroup.startswith(f'data_{algorithm_name}_'):
                            return True
                        # å¦‚æœç®—æ³•åç§°åŒ…å«æ‹¬å·ï¼Œå°è¯•åŒ¹é…åŸºç¡€åç§°
                        if '(' in algorithm_name:
                            base_name = algorithm_name.split('(')[0].strip()
                            if trace.legendgroup.startswith(f'data_{base_name}_'):
                                return True
                return False
            
            # è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥traceæ˜¯å¦å±äºæŒ‡å®šçš„æŒ‰é”®
            def trace_belongs_to_key(trace, key_id):
                if key_id is None:
                    return False
                
                # å¤„ç†dictç±»å‹çš„trace
                if isinstance(trace, dict):
                    customdata = trace.get('customdata')
                    if customdata:
                        try:
                            if isinstance(customdata, list) and len(customdata) > 0:
                                first_point_data = customdata[0]
                                if isinstance(first_point_data, list):
                                    if first_point_data[0] == key_id:
                                        return True
                                else:
                                    if first_point_data == key_id:
                                        return True
                        except (IndexError, TypeError):
                            pass
                    legendgroup = trace.get('legendgroup')
                    if legendgroup:
                        return f'_key_{key_id}' in legendgroup
                else:
                    # å¤„ç†Plotly traceå¯¹è±¡
                    if hasattr(trace, 'customdata') and trace.customdata:
                        try:
                            if isinstance(trace.customdata, list) and len(trace.customdata) > 0:
                                first_point_data = trace.customdata[0]
                                if isinstance(first_point_data, list):
                                    if first_point_data[0] == key_id:
                                        return True
                                else:
                                    if first_point_data == key_id:
                                        return True
                        except (IndexError, TypeError):
                            pass
                    if hasattr(trace, 'legendgroup') and trace.legendgroup:
                        return f'_key_{key_id}' in trace.legendgroup
                return False
            
            # å°†fig.dataè½¬æ¢ä¸ºå¯ä¿®æ”¹çš„list
            data_list = list(fig.data)
            
            logger.info(f"ğŸ¨ å¼€å§‹æ›´æ–°å›¾æ³¨é€æ˜åº¦: é€‰ä¸­ç®—æ³•={selected_algorithms}, é€‰ä¸­æŒ‰é”®={selected_keys}")
            
            # æ›´æ–°ç®—æ³•æ§åˆ¶å›¾æ³¨çš„é€æ˜åº¦
            # é€»è¾‘ï¼šé€‰ä¸­çš„ç®—æ³• -> ä¸é€æ˜ï¼ˆ1.0ï¼‰ï¼Œæœªé€‰ä¸­çš„ç®—æ³• -> é€æ˜ï¼ˆ0.2ï¼‰
            # åŒæ—¶é€šè¿‡ä¿®æ”¹markeré¢œè‰²æ·±æµ…æ¥å¢å¼ºè§†è§‰æ•ˆæœï¼ˆå› ä¸ºlegendæ–‡å­—é¢œè‰²æ˜¯å…¨å±€çš„ï¼‰
            for trace_idx, trace in enumerate(data_list):
                # å¤„ç†dictç±»å‹çš„trace
                if isinstance(trace, dict):
                    if trace.get('legendgroup') == 'algorithm_control':
                        if 'name' in trace and trace['name']:
                            algorithm_name = trace['name']
                            # é€‰ä¸­çš„ç®—æ³•ï¼šä¸é€æ˜ï¼ˆ1.0ï¼‰ï¼Œæœªé€‰ä¸­çš„ç®—æ³•ï¼šé€æ˜ï¼ˆ0.2ï¼‰
                            target_opacity = 1.0 if algorithm_name in selected_algorithms else 0.2
                            if 'marker' not in trace:
                                trace['marker'] = {}
                            trace['marker']['opacity'] = target_opacity
                            
                            # é€šè¿‡ä¿®æ”¹markerçš„sizeæ¥å¢å¼ºé€‰ä¸­æ•ˆæœï¼ˆé€‰ä¸­æ—¶æ›´å¤§ï¼‰
                            if algorithm_name in selected_algorithms:
                                trace['marker']['size'] = 14  # é€‰ä¸­æ—¶ç¨å¤§
                            else:
                                trace['marker']['size'] = 12  # æœªé€‰ä¸­æ—¶æ­£å¸¸å¤§å°
                            
                            data_list[trace_idx] = trace
                            logger.info(f"âœï¸ æ›´æ–°ç®—æ³•æ§åˆ¶å›¾æ³¨ '{algorithm_name}' é€æ˜åº¦: {target_opacity} (é€‰ä¸­: {algorithm_name in selected_algorithms})")
                else:
                    # å¤„ç†Plotly traceå¯¹è±¡
                    if hasattr(trace, 'legendgroup') and trace.legendgroup == 'algorithm_control':
                        if hasattr(trace, 'name') and trace.name:
                            algorithm_name = trace.name
                            # é€‰ä¸­çš„ç®—æ³•ï¼šä¸é€æ˜ï¼ˆ1.0ï¼‰ï¼Œæœªé€‰ä¸­çš„ç®—æ³•ï¼šé€æ˜ï¼ˆ0.2ï¼‰
                            target_opacity = 1.0 if algorithm_name in selected_algorithms else 0.2
                            # ç›´æ¥ä¿®æ”¹marker.opacityå±æ€§ï¼ˆå¯¹è±¡å¼•ç”¨å·²ä¿®æ”¹ï¼Œä¸éœ€è¦é‡æ–°èµ‹å€¼ï¼‰
                            if hasattr(trace, 'marker') and trace.marker is not None:
                                trace.marker.opacity = target_opacity
                                # é€šè¿‡ä¿®æ”¹markerçš„sizeæ¥å¢å¼ºé€‰ä¸­æ•ˆæœ
                                if algorithm_name in selected_algorithms:
                                    trace.marker.size = 14  # é€‰ä¸­æ—¶ç¨å¤§
                                else:
                                    trace.marker.size = 12  # æœªé€‰ä¸­æ—¶æ­£å¸¸å¤§å°
                            # logger.info(f"âœï¸ æ›´æ–°ç®—æ³•æ§åˆ¶å›¾æ³¨ '{algorithm_name}' é€æ˜åº¦: {target_opacity} (é€‰ä¸­: {algorithm_name in selected_algorithms})")
                
            # æ›´æ–°æŒ‰é”®æ§åˆ¶å›¾æ³¨çš„é€æ˜åº¦
            # é€»è¾‘ï¼šé€‰ä¸­çš„æŒ‰é”® -> ä¸é€æ˜ï¼ˆ1.0ï¼‰ï¼Œæœªé€‰ä¸­çš„æŒ‰é”® -> é€æ˜ï¼ˆ0.2ï¼‰
            # åŒæ—¶é€šè¿‡ä¿®æ”¹markerå¤§å°æ¥å¢å¼ºè§†è§‰æ•ˆæœ
            for trace_idx, trace in enumerate(data_list):
                # å¤„ç†dictç±»å‹çš„trace
                if isinstance(trace, dict):
                    if trace.get('legendgroup') == 'key_control':
                        if 'name' in trace and trace['name']:
                            name = trace['name']
                            if name.startswith('æŒ‰é”® '):
                                try:
                                    key_id = int(name.split('æŒ‰é”® ')[1])
                                    # é€‰ä¸­çš„æŒ‰é”®ï¼šä¸é€æ˜ï¼ˆ1.0ï¼‰ï¼Œæœªé€‰ä¸­çš„æŒ‰é”®ï¼šé€æ˜ï¼ˆ0.2ï¼‰
                                    target_opacity = 1.0 if key_id in selected_keys else 0.2
                                    if 'marker' not in trace:
                                        trace['marker'] = {}
                                    trace['marker']['opacity'] = target_opacity
                                    
                                    # é€šè¿‡ä¿®æ”¹markerçš„sizeæ¥å¢å¼ºé€‰ä¸­æ•ˆæœï¼ˆé€‰ä¸­æ—¶æ›´å¤§ï¼‰
                                    if key_id in selected_keys:
                                        trace['marker']['size'] = 17  # é€‰ä¸­æ—¶ç¨å¤§
                                    else:
                                        trace['marker']['size'] = 15  # æœªé€‰ä¸­æ—¶æ­£å¸¸å¤§å°
                                    
                                    data_list[trace_idx] = trace
                                    logger.info(f"âœï¸ æ›´æ–°æŒ‰é”®æ§åˆ¶å›¾æ³¨ 'æŒ‰é”® {key_id}' é€æ˜åº¦: {target_opacity} (é€‰ä¸­: {key_id in selected_keys})")
                                except (ValueError, IndexError):
                                    continue
                else:
                    # å¤„ç†Plotly traceå¯¹è±¡
                    if hasattr(trace, 'legendgroup') and trace.legendgroup == 'key_control':
                        if hasattr(trace, 'name') and trace.name:
                            name = trace.name
                            if name.startswith('æŒ‰é”® '):
                                try:
                                    key_id = int(name.split('æŒ‰é”® ')[1])
                                    # é€‰ä¸­çš„æŒ‰é”®ï¼šä¸é€æ˜ï¼ˆ1.0ï¼‰ï¼Œæœªé€‰ä¸­çš„æŒ‰é”®ï¼šé€æ˜ï¼ˆ0.2ï¼‰
                                    target_opacity = 1.0 if key_id in selected_keys else 0.2
                                    # ç›´æ¥ä¿®æ”¹marker.opacityå±æ€§ï¼ˆå¯¹è±¡å¼•ç”¨å·²ä¿®æ”¹ï¼Œä¸éœ€è¦é‡æ–°èµ‹å€¼ï¼‰
                                    if hasattr(trace, 'marker') and trace.marker is not None:
                                        trace.marker.opacity = target_opacity
                                        # é€šè¿‡ä¿®æ”¹markerçš„sizeæ¥å¢å¼ºé€‰ä¸­æ•ˆæœ
                                        if key_id in selected_keys:
                                            trace.marker.size = 17  # é€‰ä¸­æ—¶ç¨å¤§
                                        else:
                                            trace.marker.size = 15  # æœªé€‰ä¸­æ—¶æ­£å¸¸å¤§å°
                                
                                except (ValueError, IndexError):
                                    continue
            
            # æ›´æ–°æ•°æ®traceçš„å¯è§æ€§
            for trace_idx, trace in enumerate(data_list):
                # è·³è¿‡æ§åˆ¶å›¾æ³¨é¡¹
                legendgroup = trace.get('legendgroup') if isinstance(trace, dict) else (trace.legendgroup if hasattr(trace, 'legendgroup') else None)
                if legendgroup in ['algorithm_control', 'key_control']:
                    continue
                
                # æ•°æ®traceï¼šåªæœ‰åŒæ—¶æ»¡è¶³ç®—æ³•å’ŒæŒ‰é”®æ¡ä»¶æ—¶æ‰æ˜¾ç¤º
                # å¦‚æœæ²¡æœ‰é€‰æ‹©ä»»ä½•ç®—æ³•æˆ–æŒ‰é”®ï¼Œä¸æ˜¾ç¤ºä»»ä½•æ•°æ®
                if len(selected_algorithms) == 0 and len(selected_keys) == 0:
                    target_visible = False
                else:
                    # æ£€æŸ¥æ˜¯å¦å±äºé€‰ä¸­çš„ç®—æ³•
                    belongs_to_selected_algorithm = False
                    if len(selected_algorithms) == 0:
                        belongs_to_selected_algorithm = True  # å¦‚æœæ²¡æœ‰é€‰æ‹©ç®—æ³•ï¼Œæ˜¾ç¤ºæ‰€æœ‰ç®—æ³•
                    else:
                        # å°è¯•åŒ¹é…æ¯ä¸ªé€‰ä¸­çš„ç®—æ³•
                        for alg in selected_algorithms:
                            if trace_belongs_to_algorithm(trace, alg):
                                belongs_to_selected_algorithm = True
                                break
                    
                    # æ£€æŸ¥æ˜¯å¦å±äºé€‰ä¸­çš„æŒ‰é”®
                    belongs_to_selected_key = False
                    if len(selected_keys) == 0:
                        belongs_to_selected_key = True  # å¦‚æœæ²¡æœ‰é€‰æ‹©æŒ‰é”®ï¼Œæ˜¾ç¤ºæ‰€æœ‰æŒ‰é”®
                    else:
                        for key_id in selected_keys:
                            if trace_belongs_to_key(trace, key_id):
                                belongs_to_selected_key = True
                                break
                    
                    # åªæœ‰åŒæ—¶æ»¡è¶³ç®—æ³•å’ŒæŒ‰é”®æ¡ä»¶æ—¶æ‰æ˜¾ç¤º
                    target_visible = belongs_to_selected_algorithm and belongs_to_selected_key
                
                # æ›´æ–°å¯è§æ€§
                if isinstance(trace, dict):
                    trace['visible'] = target_visible
                    data_list[trace_idx] = trace
                else:
                    trace.visible = target_visible
            
            # å°†ä¿®æ”¹åçš„traceåˆ—è¡¨èµ‹å€¼å›fig.data
            fig.data = data_list
            
            logger.info("âœ… æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾æ›´æ–°æˆåŠŸ")
            return fig
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆ/æ›´æ–°æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return backend.plot_generator._create_empty_plot(f"ç”Ÿæˆäº¤äº’æ•ˆåº”å›¾å¤±è´¥: {str(e)}")

    # æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾å·²åˆ é™¤ï¼ˆåŠŸèƒ½ä¸æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾é‡å¤ï¼‰

    # åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å›è°ƒ - æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('relative-delay-distribution-plot', 'figure'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_relative_delay_distribution_plot(report_content, session_id):
        """å¤„ç†åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
            if not backend.multi_algorithm_mode or not backend.multi_algorithm_manager:
                logger.warning("âš ï¸ æœªå¯ç”¨å¤šç®—æ³•æ¨¡å¼ï¼Œæ— æ³•ç”Ÿæˆç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾")
                return backend.plot_generator._create_empty_plot("æœªå¯ç”¨å¤šç®—æ³•æ¨¡å¼")
            
            # ç”Ÿæˆç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾
            fig = backend.generate_relative_delay_distribution_plot()
            
            logger.info("âœ… åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ç”ŸæˆæˆåŠŸ")
            return fig
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return backend.plot_generator._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")

    # å»¶æ—¶æ—¶é—´åºåˆ—å›¾å›è°ƒ - æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('delay-time-series-plot', 'figure'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_delay_time_series(report_content, session_id):
        """å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
            active_algorithms = backend.get_active_algorithms()
            if not active_algorithms:
                logger.warning("âš ï¸ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆå»¶æ—¶æ—¶é—´åºåˆ—å›¾")
                return backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
            fig = backend.generate_delay_time_series_plot()
            logger.info("âœ… å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç”ŸæˆæˆåŠŸ")
            return fig
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå»¶æ—¶æ—¶é—´åºåˆ—å›¾å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return backend.plot_generator._create_empty_plot(f"ç”Ÿæˆæ—¶é—´åºåˆ—å›¾å¤±è´¥: {str(e)}")
    
    # å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºéŸ³ç¬¦åˆ†ææ›²çº¿
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True)],
        [Input('delay-time-series-plot', 'clickData'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True,
        prevent_duplicate=True
    )
    def handle_delay_time_series_click(click_data, close_modal_clicks, close_btn_clicks, session_id, current_style):
        """å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»ï¼Œæ˜¾ç¤ºéŸ³ç¬¦åˆ†ææ›²çº¿ï¼ˆæ‚¬æµ®çª—ï¼‰"""
        from dash import callback_context, no_update
        
        logger.info("ğŸš€ handle_delay_time_series_click å›è°ƒè¢«è§¦å‘")
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            return current_style, []
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"ğŸ” è§¦å‘ID: {trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, []
        
        # å¦‚æœæ˜¯æ—¶é—´åºåˆ—å›¾ç‚¹å‡»
        if trigger_id == 'delay-time-series-plot' and click_data:
            logger.info("ğŸ¯ æ£€æµ‹åˆ°å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»")
            
            backend = session_manager.get_backend(session_id)
            if not backend:
                logger.warning("âš ï¸ backendä¸ºç©º")
                return current_style, []
            
            try:
                if 'points' not in click_data or len(click_data['points']) == 0:
                    logger.warning("âš ï¸ clickDataä¸­æ²¡æœ‰points")
                    return current_style, []
                
                point = click_data['points'][0]
                if not point.get('customdata'):
                    logger.warning("âš ï¸ pointä¸­æ²¡æœ‰customdata")
                    return current_style, []
                
                # æå–customdata: [key_id, record_index, replay_index] æˆ– [key_id, record_index, replay_index, algorithm_name]
                customdata = point['customdata']
                logger.info(f"ğŸ“¦ customdata: {customdata}")
                
                if not isinstance(customdata, list) or len(customdata) < 3:
                    logger.warning(f"âš ï¸ customdataæ ¼å¼é”™è¯¯: {customdata}")
                    return current_style, []
                
                key_id = customdata[0]
                record_index = customdata[1]
                replay_index = customdata[2]
                algorithm_name = customdata[3] if len(customdata) > 3 else None
                
                logger.info(f"ğŸ“Š æå–çš„æ•°æ®: key_id={key_id}, record_index={record_index}, replay_index={replay_index}, algorithm_name={algorithm_name}")
                
                # è·å–ç®—æ³•å¯¹è±¡å’ŒåŒ¹é…å¯¹
                record_note = None
                replay_note = None
                final_algorithm_name = None
                
                if backend.multi_algorithm_mode and backend.multi_algorithm_manager and algorithm_name:
                    # å¤šç®—æ³•æ¨¡å¼
                    algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name)
                    if not algorithm or not algorithm.analyzer:
                        logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' ä¸å­˜åœ¨æˆ–analyzerä¸ºç©º")
                        return current_style, []
                    
                    # è·å–matched_pairs
                    matched_pairs = algorithm.analyzer.matched_pairs if hasattr(algorithm.analyzer, 'matched_pairs') else []
                    
                    # åœ¨matched_pairsä¸­æŸ¥æ‰¾åŒ¹é…å¯¹
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_idx == record_index and p_idx == replay_index:
                            record_note = r_note
                            replay_note = p_note
                            final_algorithm_name = algorithm_name
                            logger.info(f"âœ… åœ¨å¤šç®—æ³•æ¨¡å¼ä¸­æ‰¾åˆ°åŒ¹é…å¯¹")
                            break
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    if not backend.analyzer or not backend.analyzer.note_matcher:
                        logger.warning("âš ï¸ analyzeræˆ–note_matcherä¸ºç©º")
                        return current_style, []
                    
                    matched_pairs = backend.analyzer.matched_pairs if hasattr(backend.analyzer, 'matched_pairs') else []
                    
                    # åœ¨matched_pairsä¸­æŸ¥æ‰¾åŒ¹é…å¯¹
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_idx == record_index and p_idx == replay_index:
                            record_note = r_note
                            replay_note = p_note
                            final_algorithm_name = None
                            logger.info(f"âœ… åœ¨å•ç®—æ³•æ¨¡å¼ä¸­æ‰¾åˆ°åŒ¹é…å¯¹")
                            break
                
                if not record_note or not replay_note:
                    logger.warning("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…å¯¹")
                    return current_style, []
                
                # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ç®—æ³•ä¸­åŒ¹é…åˆ°åŒä¸€ä¸ªå½•åˆ¶éŸ³ç¬¦çš„æ’­æ”¾éŸ³ç¬¦
                other_algorithm_notes = []  # [(algorithm_name, play_note), ...]
                if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                    active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                    for alg in active_algorithms:
                        if alg.metadata.algorithm_name == algorithm_name:
                            continue  # è·³è¿‡å½“å‰ç®—æ³•ï¼ˆå·²ç»ç»˜åˆ¶ï¼‰
                        
                        if not alg.analyzer or not hasattr(alg.analyzer, 'matched_pairs'):
                            continue
                        
                        matched_pairs = alg.analyzer.matched_pairs
                        # æŸ¥æ‰¾åŒ¹é…åˆ°åŒä¸€ä¸ªrecord_indexçš„æ’­æ”¾éŸ³ç¬¦
                        for r_idx, p_idx, r_note, p_note in matched_pairs:
                            if r_idx == record_index:
                                other_algorithm_notes.append((alg.metadata.algorithm_name, p_note))
                                logger.info(f"âœ… æ‰¾åˆ°ç®—æ³• '{alg.metadata.algorithm_name}' çš„åŒ¹é…æ’­æ”¾éŸ³ç¬¦")
                                break
                
                # ç”Ÿæˆå¯¹æ¯”æ›²çº¿ï¼ˆåŒ…å«å…¶ä»–ç®—æ³•çš„æ’­æ”¾æ›²çº¿ï¼‰
                import spmid
                detail_figure_combined = spmid.plot_note_comparison_plotly(
                    record_note, 
                    replay_note, 
                    algorithm_name=final_algorithm_name,
                    other_algorithm_notes=other_algorithm_notes  # ä¼ é€’å…¶ä»–ç®—æ³•çš„æ’­æ”¾éŸ³ç¬¦
                )
                
                if not detail_figure_combined:
                    logger.error("âŒ æ›²çº¿ç”Ÿæˆå¤±è´¥")
                    return current_style, []
                
                # æ˜¾ç¤ºæ¨¡æ€æ¡†
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                
                rendered_row = dcc.Graph(figure=detail_figure_combined, style={'height': '600px'})
                
                logger.info("âœ… å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»å¤„ç†æˆåŠŸ")
                return modal_style, [rendered_row]
                
            except Exception as e:
                logger.error(f"âŒ å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»å¤±è´¥: {e}")
                import traceback
                logger.error(traceback.format_exc())
                return current_style, []
        
        return current_style, []
    
    # å¤„ç†æœ€å¤§/æœ€å°å»¶è¿Ÿå­—æ®µç‚¹å‡»ï¼Œæ˜¾ç¤ºå¯¹åº”æŒ‰é”®çš„æ›²çº¿å¯¹æ¯”å›¾
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True)],
        [Input({'type': 'max-delay-value', 'algorithm': dash.dependencies.ALL}, 'n_clicks'),
         Input({'type': 'min-delay-value', 'algorithm': dash.dependencies.ALL}, 'n_clicks'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State({'type': 'max-delay-value', 'algorithm': dash.dependencies.ALL}, 'id'),
         State({'type': 'min-delay-value', 'algorithm': dash.dependencies.ALL}, 'id'),
         State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True,
        prevent_duplicate=True
    )
    def handle_delay_value_click(max_clicks_list, min_clicks_list, close_modal_clicks, close_btn_clicks, 
                                  max_ids_list, min_ids_list, session_id, current_style):
        """å¤„ç†æœ€å¤§/æœ€å°å»¶è¿Ÿå­—æ®µç‚¹å‡»ï¼Œæ˜¾ç¤ºå¯¹åº”æŒ‰é”®çš„æ›²çº¿å¯¹æ¯”å›¾"""
        from dash import callback_context, no_update
        import dash
        
        logger.info("ğŸš€ handle_delay_value_click å›è°ƒè¢«è§¦å‘")
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            return current_style, []
        
        trigger_id = ctx.triggered[0]['prop_id']
        trigger_value = ctx.triggered[0].get('value')
        logger.info(f"ğŸ” è§¦å‘ID: {trigger_id}, è§¦å‘å€¼: {trigger_value}")
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯å…³é—­æŒ‰é’®çš„ç‚¹å‡»
        if trigger_id in ['close-key-curves-modal.n_clicks', 'close-key-curves-modal-btn.n_clicks']:
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, []
        
        # å¯¹äºæœ€å¤§/æœ€å°å»¶è¿Ÿå­—æ®µçš„ç‚¹å‡»ï¼Œéœ€è¦ç¡®ä¿æ˜¯çœŸæ­£çš„ç”¨æˆ·ç‚¹å‡»
        # æ£€æŸ¥clicksåˆ—è¡¨ä¸­æ˜¯å¦æœ‰ä»»ä½•å€¼>0ï¼ˆçœŸæ­£çš„ç‚¹å‡»ï¼‰
        has_real_click = False
        if max_clicks_list:
            for clicks in max_clicks_list:
                if clicks is not None and clicks > 0:
                    has_real_click = True
                    break
        if not has_real_click and min_clicks_list:
            for clicks in min_clicks_list:
                if clicks is not None and clicks > 0:
                    has_real_click = True
                    break
        
        # å¦‚æœæ²¡æœ‰çœŸæ­£çš„ç‚¹å‡»ï¼Œå¯èƒ½æ˜¯å¸ƒå±€æ›´æ–°å¯¼è‡´çš„ï¼Œè·³è¿‡å¤„ç†
        if not has_real_click:
            logger.info(f"âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ°çœŸæ­£çš„ç”¨æˆ·ç‚¹å‡»ï¼ˆå¯èƒ½æ˜¯å¸ƒå±€æ›´æ–°ï¼‰ï¼Œè·³è¿‡å¤„ç†: trigger_id={trigger_id}")
            return current_style, []
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal.n_clicks', 'close-key-curves-modal-btn.n_clicks']:
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, []
        
        # è§£æè§¦å‘IDï¼Œæå–å»¶è¿Ÿç±»å‹å’Œç®—æ³•åç§°
        # ä½¿ç”¨callback_contextæ¥å‡†ç¡®è¯†åˆ«å“ªä¸ªInputè¢«è§¦å‘
        delay_type = None
        algorithm_name = None
        
        try:
            # ä»triggeredä¿¡æ¯ä¸­æå–è¢«è§¦å‘çš„ç»„ä»¶ID
            triggered_prop = ctx.triggered[0]
            prop_id_str = triggered_prop['prop_id']
            
            # prop_idæ ¼å¼å¯èƒ½æ˜¯: {'type': 'max-delay-value', 'algorithm': 'xxx'}.n_clicks
            # æˆ–è€…: {'type': 'min-delay-value', 'algorithm': 'xxx'}.n_clicks
            if 'max-delay-value' in prop_id_str:
                delay_type = 'max'
                # ä»max_ids_listä¸­æ‰¾åˆ°å¯¹åº”çš„ID
                if max_ids_list:
                    for max_id in max_ids_list:
                        if max_id and isinstance(max_id, dict):
                            # æ£€æŸ¥è¿™ä¸ªIDæ˜¯å¦åŒ¹é…triggeredçš„ID
                            # ç”±äºDashçš„Pattern Matchingï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡ç®—æ³•åç§°æ¥åŒ¹é…
                            # ä»prop_id_strä¸­æå–ç®—æ³•åç§°ï¼ˆå¦‚æœå¯èƒ½ï¼‰
                            # æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ£€æŸ¥clickså€¼çš„å˜åŒ–æ¥ç¡®å®š
                            algorithm_name = max_id.get('algorithm')
                            # éªŒè¯ï¼šæ£€æŸ¥å¯¹åº”çš„clicksæ˜¯å¦çœŸçš„è¢«è§¦å‘äº†ï¼ˆå¿…é¡»>0æ‰æ˜¯çœŸæ­£çš„ç‚¹å‡»ï¼‰
                            idx = max_ids_list.index(max_id)
                            if idx < len(max_clicks_list) and max_clicks_list[idx] is not None and max_clicks_list[idx] > 0:
                                logger.info(f"âœ… æ£€æµ‹åˆ°æœ€å¤§å»¶è¿Ÿç‚¹å‡»: ç®—æ³•={algorithm_name}, clicks={max_clicks_list[idx]}")
                                break
            elif 'min-delay-value' in prop_id_str:
                delay_type = 'min'
                # ä»min_ids_listä¸­æ‰¾åˆ°å¯¹åº”çš„ID
                if min_ids_list:
                    for min_id in min_ids_list:
                        if min_id and isinstance(min_id, dict):
                            algorithm_name = min_id.get('algorithm')
                            # éªŒè¯ï¼šæ£€æŸ¥å¯¹åº”çš„clicksæ˜¯å¦çœŸçš„è¢«è§¦å‘äº†ï¼ˆå¿…é¡»>0æ‰æ˜¯çœŸæ­£çš„ç‚¹å‡»ï¼‰
                            idx = min_ids_list.index(min_id)
                            if idx < len(min_clicks_list) and min_clicks_list[idx] is not None and min_clicks_list[idx] > 0:
                                logger.info(f"âœ… æ£€æµ‹åˆ°æœ€å°å»¶è¿Ÿç‚¹å‡»: ç®—æ³•={algorithm_name}, clicks={min_clicks_list[idx]}")
                                break
            
            # å¦‚æœä¸Šé¢çš„æ–¹æ³•æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•ï¼šæ£€æŸ¥å“ªä¸ªclicksåˆ—è¡¨æœ‰å˜åŒ–
            if not delay_type or not algorithm_name:
                # æ£€æŸ¥max_clicks_listä¸­æ˜¯å¦æœ‰ç‚¹å‡»
                if max_clicks_list:
                    for i, clicks in enumerate(max_clicks_list):
                        if clicks is not None and clicks > 0:
                            if max_ids_list and i < len(max_ids_list):
                                max_id = max_ids_list[i]
                                if max_id and isinstance(max_id, dict):
                                    algorithm_name = max_id.get('algorithm')
                                    delay_type = 'max'
                                    logger.info(f"âœ… å¤‡ç”¨æ–¹æ³•ï¼šæ£€æµ‹åˆ°æœ€å¤§å»¶è¿Ÿç‚¹å‡»: ç®—æ³•={algorithm_name}, clicks={clicks}")
                                    break
                
                # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œæ£€æŸ¥min_clicks_list
                if not delay_type and min_clicks_list:
                    for i, clicks in enumerate(min_clicks_list):
                        if clicks is not None and clicks > 0:
                            if min_ids_list and i < len(min_ids_list):
                                min_id = min_ids_list[i]
                                if min_id and isinstance(min_id, dict):
                                    algorithm_name = min_id.get('algorithm')
                                    delay_type = 'min'
                                    logger.info(f"âœ… å¤‡ç”¨æ–¹æ³•ï¼šæ£€æµ‹åˆ°æœ€å°å»¶è¿Ÿç‚¹å‡»: ç®—æ³•={algorithm_name}, clicks={clicks}")
                                    break
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æè§¦å‘IDå¤±è´¥: {e}, trigger_id={trigger_id}")
            import traceback
            logger.error(traceback.format_exc())
        
        if not delay_type or not algorithm_name:
            logger.warning(f"âš ï¸ æ— æ³•è§£æå»¶è¿Ÿç±»å‹æˆ–ç®—æ³•åç§°: delay_id={trigger_id}, delay_type={delay_type}, algorithm_name={algorithm_name}")
            logger.warning(f"âš ï¸ max_clicks_list: {max_clicks_list}, min_clicks_list: {min_clicks_list}")
            logger.warning(f"âš ï¸ max_ids_list: {max_ids_list}, min_ids_list: {min_ids_list}")
            return current_style, []
        
        logger.info(f"ğŸ“Š å»¶è¿Ÿç±»å‹: {delay_type}, ç®—æ³•åç§°: {algorithm_name}")
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("âš ï¸ backendä¸ºç©º")
            return current_style, []
        
        try:
            # è·å–å¯¹åº”å»¶è¿Ÿç±»å‹çš„éŸ³ç¬¦
            notes = backend.get_notes_by_delay_type(algorithm_name, delay_type)
            if notes is None:
                logger.warning(f"âš ï¸ æ— æ³•è·å–{delay_type}å»¶è¿Ÿå¯¹åº”çš„éŸ³ç¬¦")
                return current_style, []
            
            record_note, replay_note = notes
            
            # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ç®—æ³•ä¸­åŒ¹é…åˆ°åŒä¸€ä¸ªå½•åˆ¶éŸ³ç¬¦çš„æ’­æ”¾éŸ³ç¬¦
            other_algorithm_notes = []  # [(algorithm_name, play_note), ...]
            if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                for alg in active_algorithms:
                    if alg.metadata.algorithm_name == algorithm_name:
                        continue  # è·³è¿‡å½“å‰ç®—æ³•ï¼ˆå·²ç»ç»˜åˆ¶ï¼‰
                    
                    if not alg.analyzer or not hasattr(alg.analyzer, 'matched_pairs'):
                        continue
                    
                    matched_pairs = alg.analyzer.matched_pairs
                    # æŸ¥æ‰¾åŒ¹é…åˆ°åŒä¸€ä¸ªrecord_noteçš„æ’­æ”¾éŸ³ç¬¦
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_note is record_note:  # ä½¿ç”¨isæ¯”è¾ƒå¯¹è±¡å¼•ç”¨
                            other_algorithm_notes.append((alg.metadata.algorithm_name, p_note))
                            logger.info(f"âœ… æ‰¾åˆ°ç®—æ³• '{alg.metadata.algorithm_name}' çš„åŒ¹é…æ’­æ”¾éŸ³ç¬¦")
                            break
            
            # ç”Ÿæˆå¯¹æ¯”æ›²çº¿ï¼ˆåŒ…å«å…¶ä»–ç®—æ³•çš„æ’­æ”¾æ›²çº¿ï¼‰
            import spmid
            detail_figure_combined = spmid.plot_note_comparison_plotly(
                record_note, 
                replay_note, 
                algorithm_name=algorithm_name,
                other_algorithm_notes=other_algorithm_notes  # ä¼ é€’å…¶ä»–ç®—æ³•çš„æ’­æ”¾éŸ³ç¬¦
            )
            
            if not detail_figure_combined:
                logger.error("âŒ æ›²çº¿ç”Ÿæˆå¤±è´¥")
                return current_style, []
            
            # æ˜¾ç¤ºæ¨¡æ€æ¡†
            modal_style = {
                'display': 'block',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            
            rendered_row = dcc.Graph(figure=detail_figure_combined, style={'height': '600px'})
            
            delay_type_name = "æœ€å¤§" if delay_type == 'max' else "æœ€å°"
            logger.info(f"âœ… {delay_type_name}å»¶è¿Ÿå­—æ®µç‚¹å‡»å¤„ç†æˆåŠŸï¼Œç®—æ³•: {algorithm_name}")
            return modal_style, [rendered_row]
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†{delay_type}å»¶è¿Ÿå­—æ®µç‚¹å‡»å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return current_style, []
    
    # å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾å›è°ƒ - æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('delay-histogram-plot', 'figure'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_delay_histogram(report_content, session_id):
        """å¤„ç†å»¶æ—¶ç›´æ–¹å›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
            active_algorithms = backend.get_active_algorithms()
            if not active_algorithms:
                logger.warning("âš ï¸ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆå»¶æ—¶ç›´æ–¹å›¾")
                return backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
            fig = backend.generate_delay_histogram_plot()
            logger.info("âœ… å»¶æ—¶ç›´æ–¹å›¾ç”ŸæˆæˆåŠŸ")
            return fig
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå»¶æ—¶ç›´æ–¹å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return backend.plot_generator._create_empty_plot(f"ç”Ÿæˆç›´æ–¹å›¾å¤±è´¥: {str(e)}")
    
    # å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæŒ‡å®šå»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹è¯¦æƒ…
    @app.callback(
        [Output('delay-histogram-detail-table', 'data'),
         Output('delay-histogram-detail-table', 'style_table'),
         Output('delay-histogram-selection-info', 'children')],
        [Input('delay-histogram-plot', 'clickData')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_delay_histogram_click(click_data, session_id):
        """å¤„ç†å»¶æ—¶ç›´æ–¹å›¾ç‚¹å‡»äº‹ä»¶ï¼Œæ˜¾ç¤ºè¯¥å»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹è¯¦æƒ…"""
        import math
        
        logger.info(f"ğŸ” å»¶æ—¶ç›´æ–¹å›¾ç‚¹å‡»å›è°ƒè¢«è§¦å‘ï¼Œclick_data: {click_data}")
        print(f"ğŸ” å»¶æ—¶ç›´æ–¹å›¾ç‚¹å‡»å›è°ƒè¢«è§¦å‘ï¼Œclick_data: {click_data}")
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("âš ï¸ backend ä¸ºç©º")
            return [], {'overflowX': 'auto', 'display': 'none'}, ""
        
        # å¦‚æœæ²¡æœ‰ç‚¹å‡»æ•°æ®ï¼Œéšè—è¡¨æ ¼
        if not click_data:
            logger.info("âš ï¸ click_data ä¸ºç©º")
            return [], {'overflowX': 'auto', 'display': 'none'}, ""
        
        if 'points' not in click_data or not click_data['points']:
            logger.info(f"âš ï¸ click_data ä¸­æ²¡æœ‰ points æˆ– points ä¸ºç©ºï¼Œclick_data keys: {click_data.keys() if isinstance(click_data, dict) else 'not dict'}")
            return [], {'overflowX': 'auto', 'display': 'none'}, ""
        
        try:
            # è·å–ç‚¹å‡»çš„æŸ±çŠ¶å›¾ä¿¡æ¯
            # Plotly Histogram ç‚¹å‡»æ—¶ï¼Œpoints[0] åŒ…å« 'x' å­—æ®µï¼Œè¡¨ç¤ºè¯¥æŸ±çŠ¶å›¾çš„ä¸­å¿ƒ x åæ ‡
            # æˆ‘ä»¬éœ€è¦è·å–è¯¥æŸ±çŠ¶å›¾çš„ x èŒƒå›´
            point = click_data['points'][0]
            logger.info(f"ğŸ“Š ç‚¹å‡»çš„ point æ•°æ®: {point}")
            print(f"ğŸ“Š ç‚¹å‡»çš„ point æ•°æ®: {point}")
            
            # å¯¹äº Histogramï¼Œç‚¹å‡»çš„ point å¯èƒ½åŒ…å« 'x'ï¼ˆä¸­å¿ƒå€¼ï¼‰æˆ– 'bin' ä¿¡æ¯
            # æˆ‘ä»¬éœ€è¦æ ¹æ®å®é™…çš„ bin èŒƒå›´æ¥ç­›é€‰æ•°æ®
            # å¦‚æœ point ä¸­æœ‰ 'x'ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒä½œä¸ºå‚è€ƒï¼Œä½†æ›´å‡†ç¡®çš„æ˜¯ä½¿ç”¨ 'bin' ä¿¡æ¯
            
            # å°è¯•è·å– bin èŒƒå›´
            if 'x' in point:
                x_value = point['x']
                
                # è·å–æ‰€æœ‰å»¶æ—¶æ•°æ®æ¥ä¼°ç®— bin å®½åº¦
                # æ”¯æŒå•ç®—æ³•å’Œå¤šç®—æ³•æ¨¡å¼
                if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                    # å¤šç®—æ³•æ¨¡å¼ï¼šä»æ‰€æœ‰æ¿€æ´»ç®—æ³•æ”¶é›†æ•°æ®
                    active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                    delays_ms = []
                    for algorithm in active_algorithms:
                        if algorithm.analyzer and algorithm.analyzer.note_matcher:
                            offset_data = algorithm.analyzer.get_offset_alignment_data()
                            if offset_data:
                                delays_ms.extend([item.get('keyon_offset', 0.0) / 10.0 for item in offset_data])
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    offset_data = backend.analyzer.get_offset_alignment_data() if backend.analyzer else []
                    if not offset_data:
                        return [], {'overflowX': 'auto', 'display': 'none'}, ""
                    delays_ms = [item.get('keyon_offset', 0.0) / 10.0 for item in offset_data]
                
                if not delays_ms:
                    return [], {'overflowX': 'auto', 'display': 'none'}, ""
                
                # æ–¹æ³•1ï¼šå°è¯•ä» point ä¸­è·å– bin è¾¹ç•Œä¿¡æ¯ï¼ˆå¦‚æœ Plotly æä¾›äº†ï¼‰
                # Plotly Histogram çš„ç‚¹å‡»äº‹ä»¶å¯èƒ½åŒ…å« 'bin' æˆ– 'x0', 'x1' ç­‰ä¿¡æ¯
                if 'x0' in point and 'x1' in point:
                    # å¦‚æœ Plotly ç›´æ¥æä¾›äº† bin è¾¹ç•Œï¼Œä½¿ç”¨å®ƒï¼ˆæœ€å‡†ç¡®ï¼‰
                    delay_min = point['x0']
                    delay_max = point['x1']
                else:
                    # æ–¹æ³•2ï¼šä¼°ç®— bin å®½åº¦
                    # ä½¿ç”¨ Sturges' rule ä¼°ç®— bin æ•°é‡
                    n = len(delays_ms)
                    if n > 1:
                        num_bins = min(50, max(10, int(1 + 3.322 * math.log10(n))))
                    else:
                        num_bins = 10
                    
                    data_range = max(delays_ms) - min(delays_ms)
                    estimated_bin_width = data_range / num_bins if num_bins > 0 else max(1.0, data_range / 10)
                    
                    # è®¡ç®— bin çš„èŒƒå›´ï¼ˆä»¥ç‚¹å‡»çš„ x ä¸ºä¸­å¿ƒï¼‰
                    delay_min = x_value - estimated_bin_width / 2
                    delay_max = x_value + estimated_bin_width / 2
                    
                    # ç¡®ä¿èŒƒå›´åˆç†ï¼ˆè‡³å°‘ 1ms å®½åº¦ï¼Œé¿å…èŒƒå›´å¤ªå°ï¼‰
                    if delay_max - delay_min < 1.0:
                        delay_min = x_value - 0.5
                        delay_max = x_value + 0.5
            else:
                # å¦‚æœæ²¡æœ‰ x å€¼ï¼Œæ— æ³•ç¡®å®šèŒƒå›´
                return [], {'overflowX': 'auto', 'display': 'none'}, ""
            
            # è·å–è¯¥å»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹
            data_points = backend.get_delay_range_data_points(delay_min, delay_max)
            
            if not data_points:
                info_text = f"å»¶æ—¶èŒƒå›´ [{delay_min:.2f}ms, {delay_max:.2f}ms] å†…æ²¡æœ‰æ•°æ®ç‚¹"
                return [], {'overflowX': 'auto', 'display': 'none'}, info_text
            
            # å‡†å¤‡è¡¨æ ¼æ•°æ®
            table_data = []
            for item in data_points:
                table_data.append({
                    'algorithm_name': item.get('algorithm_name', 'N/A'),
                    'key_id': item.get('key_id', 'N/A'),
                    'delay_ms': item.get('delay_ms', 0.0),
                    'record_index': item.get('record_index', 'N/A'),
                    'replay_index': item.get('replay_index', 'N/A'),
                    'record_keyon': item.get('record_keyon', 'N/A'),
                    'replay_keyon': item.get('replay_keyon', 'N/A'),
                    'duration_offset': item.get('duration_offset', 'N/A'),
                })
            
            # æ˜¾ç¤ºä¿¡æ¯
            info_text = f"å»¶æ—¶èŒƒå›´ [{delay_min:.2f}ms, {delay_max:.2f}ms] å†…å…±æœ‰ {len(data_points)} ä¸ªæ•°æ®ç‚¹"
            
            # æ˜¾ç¤ºè¡¨æ ¼
            return table_data, {'overflowX': 'auto', 'display': 'block'}, info_text
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†å»¶æ—¶ç›´æ–¹å›¾ç‚¹å‡»äº‹ä»¶å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return [], {'overflowX': 'auto', 'display': 'none'}, f"å¤„ç†å¤±è´¥: {str(e)}"
    
    # å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾è¯¦æƒ…è¡¨æ ¼ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºå½•åˆ¶ä¸æ’­æ”¾å¯¹æ¯”æ›²çº¿
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True)],
        [Input('delay-histogram-detail-table', 'active_cell'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('delay-histogram-detail-table', 'data'),
         State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True,
        prevent_duplicate=True
    )
    def handle_delay_histogram_table_click(active_cell, close_modal_clicks, close_btn_clicks, table_data, session_id, current_style):
        """å¤„ç†å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾è¯¦æƒ…è¡¨æ ¼ç‚¹å‡»ï¼Œæ˜¾ç¤ºå½•åˆ¶ä¸æ’­æ”¾å¯¹æ¯”æ›²çº¿ï¼ˆæ‚¬æµ®çª—ï¼‰"""
        from dash import callback_context, no_update
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            return current_style, []
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"ğŸ”„ å»¶æ—¶ç›´æ–¹å›¾è¡¨æ ¼ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")
        print(f"ğŸ”„ å»¶æ—¶ç›´æ–¹å›¾è¡¨æ ¼ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            logger.info("âœ… å…³é—­æŒ‰é”®æ›²çº¿å¯¹æ¯”æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, []
        
        # å¦‚æœæ˜¯è¡¨æ ¼ç‚¹å‡»
        if trigger_id == 'delay-histogram-detail-table':
            backend = session_manager.get_backend(session_id)
            if not backend:
                logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°backend")
                return current_style, []
            
            if not active_cell or not table_data:
                logger.warning("âš ï¸ active_cellæˆ–table_dataä¸ºç©º")
                return current_style, []
            
            try:
                # è·å–ç‚¹å‡»çš„è¡Œæ•°æ®
                row_idx = active_cell.get('row')
                if row_idx is None or row_idx >= len(table_data):
                    logger.warning(f"âš ï¸ è¡Œç´¢å¼•è¶…å‡ºèŒƒå›´: row_idx={row_idx}, table_dataé•¿åº¦={len(table_data)}")
                    return current_style, []
                
                row_data = table_data[row_idx]
                record_index = row_data.get('record_index')
                replay_index = row_data.get('replay_index')
                key_id = row_data.get('key_id')  # è·å–æŒ‰é”®IDç”¨äºéªŒè¯
                algorithm_name = row_data.get('algorithm_name')  # å¯èƒ½ä¸º Noneï¼ˆå•ç®—æ³•æ¨¡å¼ï¼‰
                
                logger.info(f"ğŸ“Š ç‚¹å‡»çš„è¡Œæ•°æ®: record_index={record_index}, replay_index={replay_index}, key_id={key_id}, algorithm_name={algorithm_name}")
                print(f"ğŸ“Š ç‚¹å‡»çš„è¡Œæ•°æ®: record_index={record_index}, replay_index={replay_index}, key_id={key_id}, algorithm_name={algorithm_name}")
                
                # æ£€æŸ¥ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
                if record_index == 'N/A' or replay_index == 'N/A' or record_index is None or replay_index is None:
                    logger.warning("âš ï¸ ç´¢å¼•æ— æ•ˆ")
                    return current_style, []
                
                try:
                    record_index = int(record_index)
                    replay_index = int(replay_index)
                    if key_id and key_id != 'N/A':
                        key_id = int(key_id)
                    else:
                        key_id = None
                except (ValueError, TypeError) as e:
                    logger.warning(f"âš ï¸ æ— æ³•è½¬æ¢ç´¢å¼•æˆ–key_id: record_index={record_index}, replay_index={replay_index}, key_id={key_id}, error={e}")
                    return current_style, []
                
                # è·å–å¯¹åº”çš„éŸ³ç¬¦æ•°æ® - å¿…é¡»ä»matched_pairsä¸­è·å–ï¼Œç¡®ä¿æ˜¯é…å¯¹çš„
                record_note = None
                replay_note = None
                
                # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼ä¸”æä¾›äº†ç®—æ³•åç§°
                if backend.multi_algorithm_mode and backend.multi_algorithm_manager and algorithm_name and algorithm_name != 'N/A':
                    # å¤šç®—æ³•æ¨¡å¼ï¼šä»æŒ‡å®šç®—æ³•è·å–æ•°æ®
                    active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                    target_algorithm = None
                    for alg in active_algorithms:
                        if alg.metadata.algorithm_name == algorithm_name:
                            target_algorithm = alg
                            break
                    
                    if not target_algorithm or not target_algorithm.analyzer:
                        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ç®—æ³•: {algorithm_name}")
                        return current_style, []
                    
                    # ä»matched_pairsä¸­æŸ¥æ‰¾åŒ¹é…å¯¹ï¼Œç¡®ä¿record_indexå’Œreplay_indexå¯¹åº”åŒä¸€ä¸ªåŒ¹é…å¯¹
                    matched_pairs = target_algorithm.analyzer.matched_pairs if hasattr(target_algorithm.analyzer, 'matched_pairs') else []
                    if not matched_pairs:
                        logger.warning("âš ï¸ ç®—æ³•æ²¡æœ‰åŒ¹é…å¯¹æ•°æ®")
                        return current_style, []
                    
                    # æŸ¥æ‰¾åŒ¹é…å¯¹ï¼šrecord_indexå’Œreplay_indexå¿…é¡»åŒæ—¶åŒ¹é…
                    found_pair = False
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_idx == record_index and p_idx == replay_index:
                            # éªŒè¯key_idï¼ˆå¦‚æœæä¾›äº†ï¼‰
                            if key_id is not None and r_note.id != key_id:
                                logger.warning(f"âš ï¸ key_idä¸åŒ¹é…: è¡¨æ ¼ä¸­çš„key_id={key_id}, åŒ¹é…å¯¹ä¸­çš„key_id={r_note.id}")
                                continue
                            record_note = r_note
                            replay_note = p_note
                            found_pair = True
                            logger.info(f"âœ… ä»matched_pairsä¸­æ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}, key_id={r_note.id}")
                            print(f"âœ… ä»matched_pairsä¸­æ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}, key_id={r_note.id}")
                            break
                    
                    if not found_pair:
                        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}")
                        return current_style, []
                    
                    # ä½¿ç”¨ç®—æ³•åç§°
                    final_algorithm_name = algorithm_name
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    if not backend.analyzer:
                        logger.warning("âš ï¸ æ²¡æœ‰åˆ†æå™¨")
                        return current_style, []
                    
                    # ä»matched_pairsä¸­æŸ¥æ‰¾åŒ¹é…å¯¹
                    matched_pairs = backend.analyzer.matched_pairs if hasattr(backend.analyzer, 'matched_pairs') else []
                    if not matched_pairs:
                        logger.warning("âš ï¸ æ²¡æœ‰åŒ¹é…å¯¹æ•°æ®")
                        return current_style, []
                    
                    # æŸ¥æ‰¾åŒ¹é…å¯¹ï¼šrecord_indexå’Œreplay_indexå¿…é¡»åŒæ—¶åŒ¹é…
                    found_pair = False
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_idx == record_index and p_idx == replay_index:
                            # éªŒè¯key_idï¼ˆå¦‚æœæä¾›äº†ï¼‰
                            if key_id is not None and r_note.id != key_id:
                                logger.warning(f"âš ï¸ key_idä¸åŒ¹é…: è¡¨æ ¼ä¸­çš„key_id={key_id}, åŒ¹é…å¯¹ä¸­çš„key_id={r_note.id}")
                                continue
                            record_note = r_note
                            replay_note = p_note
                            found_pair = True
                            logger.info(f"âœ… ä»matched_pairsä¸­æ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}, key_id={r_note.id}")
                            print(f"âœ… ä»matched_pairsä¸­æ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}, key_id={r_note.id}")
                            break
                    
                    if not found_pair:
                        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}")
                        return current_style, []
                    
                    # å•ç®—æ³•æ¨¡å¼ï¼Œalgorithm_name å¯èƒ½ä¸º None
                    final_algorithm_name = algorithm_name if algorithm_name and algorithm_name != 'N/A' else None
                
                # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ç®—æ³•ä¸­åŒ¹é…åˆ°åŒä¸€ä¸ªå½•åˆ¶éŸ³ç¬¦çš„æ’­æ”¾éŸ³ç¬¦
                other_algorithm_notes = []  # [(algorithm_name, play_note), ...]
                if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                    active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                    for alg in active_algorithms:
                        if alg.metadata.algorithm_name == final_algorithm_name:
                            continue  # è·³è¿‡å½“å‰ç®—æ³•ï¼ˆå·²ç»ç»˜åˆ¶ï¼‰
                        
                        if not alg.analyzer or not hasattr(alg.analyzer, 'matched_pairs'):
                            continue
                        
                        matched_pairs = alg.analyzer.matched_pairs
                        # æŸ¥æ‰¾åŒ¹é…åˆ°åŒä¸€ä¸ªrecord_indexçš„æ’­æ”¾éŸ³ç¬¦
                        for r_idx, p_idx, r_note, p_note in matched_pairs:
                            if r_idx == record_index:
                                other_algorithm_notes.append((alg.metadata.algorithm_name, p_note))
                                logger.info(f"âœ… æ‰¾åˆ°ç®—æ³• '{alg.metadata.algorithm_name}' çš„åŒ¹é…æ’­æ”¾éŸ³ç¬¦")
                                break
                
                # ç”Ÿæˆå¯¹æ¯”æ›²çº¿å›¾ï¼ˆåŒ…å«å…¶ä»–ç®—æ³•çš„æ’­æ”¾æ›²çº¿ï¼‰
                import spmid
                detail_figure_combined = spmid.plot_note_comparison_plotly(
                    record_note, 
                    replay_note, 
                    algorithm_name=final_algorithm_name,
                    other_algorithm_notes=other_algorithm_notes  # ä¼ é€’å…¶ä»–ç®—æ³•çš„æ’­æ”¾éŸ³ç¬¦
                )
                
                if not detail_figure_combined:
                    logger.error("âŒ æ›²çº¿ç”Ÿæˆå¤±è´¥")
                    return current_style, []
                
                logger.info(f"âœ… æˆåŠŸç”Ÿæˆå¯¹æ¯”æ›²çº¿: record_index={record_index}, replay_index={replay_index}")
                print(f"âœ… æˆåŠŸç”Ÿæˆå¯¹æ¯”æ›²çº¿: record_index={record_index}, replay_index={replay_index}")
                
                # æ˜¾ç¤ºæ¨¡æ€æ¡†
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                
                # åˆ›å»ºæ¨¡æ€æ¡†å†…å®¹ï¼ˆåªåŒ…å«å›¾è¡¨ï¼ŒæŒ‰é’®å·²åœ¨å¸ƒå±€ä¸­å®šä¹‰ï¼‰
                # ä½¿ç”¨ä¸ handle_waterfall_click ç›¸åŒçš„æ ¼å¼
                rendered_row = dcc.Graph(figure=detail_figure_combined, style={'height': '600px'})
                
                return modal_style, [rendered_row]
                
            except Exception as e:
                logger.error(f"âŒ å¤„ç†å»¶æ—¶ç›´æ–¹å›¾è¡¨æ ¼ç‚¹å‡»å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                return current_style, []
        
        return current_style, []

    # ==================== å¤šç®—æ³•å¯¹æ¯”æ¨¡å¼å›è°ƒ ====================
    
    # å¤šç®—æ³•æ¨¡å¼åˆå§‹åŒ–å›è°ƒ - åœ¨ä¼šè¯åˆå§‹åŒ–æ—¶è‡ªåŠ¨è§¦å‘
    @app.callback(
        [Output('multi-algorithm-upload-area', 'style'),
         Output('multi-algorithm-upload-area', 'children'),
         Output('multi-algorithm-management-area', 'style'),
         Output('multi-algorithm-management-area', 'children'),
         Output('main-plot', 'figure', allow_duplicate=True),
         Output('report-content', 'children', allow_duplicate=True)],
        [Input('session-id', 'data')],
        prevent_initial_call='initial_duplicate',
        prevent_duplicate=True
    )
    def initialize_multi_algorithm_mode(session_id):
        """åˆå§‹åŒ–å¤šç®—æ³•æ¨¡å¼ - ç¡®ä¿ä¸Šä¼ åŒºåŸŸå’Œç®¡ç†åŒºåŸŸæ˜¾ç¤º"""
        logger.info(f"ğŸ”„ åˆå§‹åŒ–å¤šç®—æ³•æ¨¡å¼: session_id={session_id}")
        
        if not session_id:
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        session_id, backend = session_manager.get_or_create_backend(session_id)
        if not backend:
            logger.warning("âš ï¸ æ— æ³•è·å–backendå®ä¾‹")
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        try:
            # å¤šç®—æ³•æ¨¡å¼å§‹ç»ˆå¯ç”¨
            # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
            if not backend.multi_algorithm_manager:
                backend._ensure_multi_algorithm_manager()
            has_existing_data = False
            existing_filename = None
            logger.info("âœ… å¤šç®—æ³•æ¨¡å¼å·²å°±ç»ª")
            
            success = True
            if success:
                upload_style = {'display': 'block'}
                try:
                    upload_area = create_multi_algorithm_upload_area()
                    logger.info("âœ… åˆ›å»ºå¤šç®—æ³•ä¸Šä¼ åŒºåŸŸæˆåŠŸ")
                except Exception as e:
                    logger.error(f"âŒ åˆ›å»ºå¤šç®—æ³•ä¸Šä¼ åŒºåŸŸå¤±è´¥: {e}")
                    upload_area = html.Div("ä¸Šä¼ åŒºåŸŸåˆ›å»ºå¤±è´¥", style={'color': '#dc3545'})
                
                management_style = {'display': 'block'}
                try:
                    management_area = create_multi_algorithm_management_area()
                    logger.info("âœ… åˆ›å»ºå¤šç®—æ³•ç®¡ç†åŒºåŸŸæˆåŠŸ")
                except Exception as e:
                    logger.error(f"âŒ åˆ›å»ºå¤šç®—æ³•ç®¡ç†åŒºåŸŸå¤±è´¥: {e}")
                    management_area = html.Div("ç®¡ç†åŒºåŸŸåˆ›å»ºå¤±è´¥", style={'color': '#dc3545'})
            else:
                upload_style = {'display': 'block'}  # å³ä½¿å¤±è´¥ä¹Ÿæ˜¾ç¤ºï¼Œè®©ç”¨æˆ·çŸ¥é“æœ‰é—®é¢˜
                upload_area = html.Div("å¤šç®—æ³•æ¨¡å¼å¯ç”¨å¤±è´¥", style={'color': '#dc3545'})
                management_style = {'display': 'block'}
                management_area = html.Div("å¤šç®—æ³•æ¨¡å¼å¯ç”¨å¤±è´¥", style={'color': '#dc3545'})
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ›´æ–°ç€‘å¸ƒå›¾
            plot_fig = no_update
            report_content = no_update
            
            active_algorithms = backend.get_active_algorithms()
            # è¿›ä¸€æ­¥æ£€æŸ¥ï¼šåªæœ‰ç®—æ³•çœŸæ­£æœ‰æ•°æ®ï¼ˆanalyzerå­˜åœ¨ä¸”æœ‰matched_pairsï¼‰æ‰ç”Ÿæˆå›¾å½¢
            algorithms_with_data = []
            for alg in active_algorithms:
                if alg.analyzer and hasattr(alg.analyzer, 'matched_pairs') and alg.analyzer.matched_pairs:
                    algorithms_with_data.append(alg)
            
            if algorithms_with_data:
                try:
                    logger.info(f"ğŸ”„ æ›´æ–°ç€‘å¸ƒå›¾ï¼Œå…± {len(algorithms_with_data)} ä¸ªæœ‰æ•°æ®çš„æ¿€æ´»ç®—æ³•")
                    plot_fig = backend.generate_waterfall_plot()
                    report_content = create_report_layout(backend)
                except Exception as e:
                    logger.error(f"âŒ æ›´æ–°ç€‘å¸ƒå›¾å¤±è´¥: {e}")
                    plot_fig = _create_empty_figure_for_callback(f"æ›´æ–°å¤±è´¥: {str(e)}")
                    # ä½¿ç”¨ create_report_layout ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€çš„ç»„ä»¶
                    try:
                        report_content = create_report_layout(backend)
                    except:
                        # å¦‚æœ create_report_layout ä¹Ÿå¤±è´¥ï¼Œè¿”å›åŒ…å«å¿…éœ€ç»„ä»¶çš„é”™è¯¯å¸ƒå±€
                        empty_fig = {}
                        report_content = html.Div([
                            html.H4("æ›´æ–°å¤±è´¥", className="text-center text-danger"),
                            html.P(f"é”™è¯¯ä¿¡æ¯: {str(e)}", className="text-center"),
                            # åŒ…å«æ‰€æœ‰å¿…éœ€çš„å›¾è¡¨ç»„ä»¶ï¼ˆéšè—ï¼‰ï¼Œç¡®ä¿å›è°ƒå‡½æ•°ä¸ä¼šæŠ¥é”™
                            dcc.Graph(id='key-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                            dcc.Graph(id='key-delay-zscore-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                            dcc.Graph(id='hammer-velocity-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                            # key-hammer-velocity-scatter-plot å·²åˆ é™¤ï¼ˆåŠŸèƒ½ä¸æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾é‡å¤ï¼‰
                            dcc.Graph(id='offset-alignment-plot', figure=empty_fig, style={'display': 'none'}),
                            html.Div([
                                dash_table.DataTable(
                                    id='offset-alignment-table',
                                    data=[],
                                    columns=[]
                                )
                            ], style={'display': 'none'})
                        ])
            else:
                # æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•æ—¶ï¼Œä¸è°ƒç”¨ create_report_layoutï¼Œç›´æ¥è¿”å›ç©ºå¸ƒå±€
                # é¿å…åœ¨æ²¡æœ‰æ•°æ®æ—¶æ‰§è¡Œä¸å¿…è¦çš„æ“ä½œ
                logger.info("â„¹ï¸ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å›¾å½¢ç”Ÿæˆï¼Œè¿”å›ç©ºå¸ƒå±€")
                empty_fig = {}
                report_content = html.Div([
                    html.H4("æš‚æ— æ•°æ®", className="text-center text-muted"),
                    html.P("è¯·è‡³å°‘æ¿€æ´»ä¸€ä¸ªç®—æ³•ä»¥æŸ¥çœ‹åˆ†ææŠ¥å‘Š", className="text-center text-muted"),
                    # åŒ…å«æ‰€æœ‰å¿…éœ€çš„å›¾è¡¨ç»„ä»¶ï¼ˆéšè—ï¼‰ï¼Œç¡®ä¿å›è°ƒå‡½æ•°ä¸ä¼šæŠ¥é”™
                    dcc.Graph(id='key-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                    dcc.Graph(id='key-delay-zscore-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                    dcc.Graph(id='hammer-velocity-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                    # key-hammer-velocity-scatter-plot å·²åˆ é™¤ï¼ˆåŠŸèƒ½ä¸æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾é‡å¤ï¼‰
                    dcc.Graph(id='key-force-interaction-plot', figure=empty_fig, style={'display': 'none'}),
                    dcc.Store(id='key-force-interaction-selected-algorithms', data=[]),
                    dcc.Store(id='key-force-interaction-selected-keys', data=[]),
                    dcc.Graph(id='relative-delay-distribution-plot', figure=empty_fig, style={'display': 'none'}),
                    dcc.Graph(id='offset-alignment-plot', figure=empty_fig, style={'display': 'none'}),
                    dcc.Graph(id='delay-time-series-plot', figure=empty_fig, style={'display': 'none'}),
                    dcc.Graph(id='delay-histogram-plot', figure=empty_fig, style={'display': 'none'}),
                    html.Div([
                        dash_table.DataTable(
                            id='offset-alignment-table',
                            data=[],
                            columns=[]
                        )
                    ], style={'display': 'none'}),
                    html.Div([
                        dash_table.DataTable(
                            id='delay-histogram-detail-table',
                            data=[],
                            columns=[
                                {"name": "ç®—æ³•åç§°", "id": "algorithm_name"},
                                {"name": "æŒ‰é”®ID", "id": "key_id"},
                                {"name": "å»¶æ—¶(ms)", "id": "delay_ms"},
                                {"name": "å½•åˆ¶ç´¢å¼•", "id": "record_index"},
                                {"name": "æ’­æ”¾ç´¢å¼•", "id": "replay_index"},
                                {"name": "å½•åˆ¶å¼€å§‹(0.1ms)", "id": "record_keyon"},
                                {"name": "æ’­æ”¾å¼€å§‹(0.1ms)", "id": "replay_keyon"},
                                {"name": "æŒç»­æ—¶é—´å·®(0.1ms)", "id": "duration_offset"},
                            ]
                        )
                    ], style={'display': 'none'}),
                    html.Div(id='delay-histogram-selection-info', style={'display': 'none'})
                ])
            
            logger.info(f"âœ… å¤šç®—æ³•æ¨¡å¼åˆå§‹åŒ–å®Œæˆ")
            return upload_style, upload_area, management_style, management_area, plot_fig, report_content
            
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å¤šç®—æ³•æ¨¡å¼å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return (
                {'display': 'block'}, 
                html.Div("åˆå§‹åŒ–å¤±è´¥", style={'color': '#dc3545'}), 
                {'display': 'block'}, 
                html.Div("åˆå§‹åŒ–å¤±è´¥", style={'color': '#dc3545'}), 
                no_update, 
                no_update
            )
    
    @app.callback(
        [Output('multi-algorithm-upload-area', 'style', allow_duplicate=True),
         Output('multi-algorithm-management-area', 'style', allow_duplicate=True),
         Output('multi-algorithm-file-list', 'children'),
         Output('multi-algorithm-upload-status', 'children'),
         Output('multi-algorithm-files-store', 'data')],
        [Input('upload-multi-algorithm-data', 'contents')],
        [State('upload-multi-algorithm-data', 'filename'),
         State('session-id', 'data'),
         State('multi-algorithm-files-store', 'data')],
        prevent_initial_call=True,
        prevent_duplicate=True
    )
    def handle_multi_file_upload(contents_list, filename_list, session_id, store_data):
        """å¤„ç†å¤šæ–‡ä»¶ä¸Šä¼ ï¼Œæ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨ä¾›ç”¨æˆ·è¾“å…¥ç®—æ³•åç§°"""
        # è·å–åç«¯å®ä¾‹
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update, no_update, no_update, no_update
        
        # ç¡®ä¿å¤šç®—æ³•æ¨¡å¼å·²å¯ç”¨
        # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
        if not backend.multi_algorithm_manager:
            backend._ensure_multi_algorithm_manager()
        
        # ç¡®ä¿ä¸Šä¼ åŒºåŸŸå’Œç®¡ç†åŒºåŸŸå§‹ç»ˆæ˜¾ç¤º
        upload_style = {'display': 'block'}
        management_style = {'display': 'block'}
        
        # ä½¿ç”¨MultiFileUploadHandlerå¤„ç†æ–‡ä»¶ä¸Šä¼ 
        upload_handler = MultiFileUploadHandler()
        file_list, status_text, new_store_data = upload_handler.process_uploaded_files(contents_list, filename_list, store_data, backend)
        
        return upload_style, management_style, file_list, status_text, new_store_data
    
    @app.callback(
        Output({'type': 'algorithm-status', 'index': dash.dependencies.MATCH}, 'children'),
        [Input({'type': 'confirm-algorithm-btn', 'index': dash.dependencies.MATCH}, 'n_clicks')],
        [State({'type': 'algorithm-name-input', 'index': dash.dependencies.MATCH}, 'value'),
         State({'type': 'confirm-algorithm-btn', 'index': dash.dependencies.MATCH}, 'id'),
         State('multi-algorithm-files-store', 'data'),
         State('session-id', 'data')],
        prevent_initial_call=True
    )
    def confirm_add_algorithm(n_clicks, algorithm_name, button_id, store_data, session_id):
        """ç¡®è®¤æ·»åŠ ç®—æ³•"""
        if not n_clicks or not algorithm_name or not algorithm_name.strip():
            return html.Span("è¯·è¾“å…¥ç®—æ³•åç§°", style={'color': '#ffc107'})
        
        # è·å–åç«¯å®ä¾‹
        backend = session_manager.get_backend(session_id)
        if not backend:
            return html.Span("ä¼šè¯æ— æ•ˆ", style={'color': '#dc3545'})
        
        # ç¡®ä¿å¤šç®—æ³•æ¨¡å¼å·²å¯ç”¨
        # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
        if not backend.multi_algorithm_manager:
            backend._ensure_multi_algorithm_manager()
        
        if not store_data or 'contents' not in store_data or 'filenames' not in store_data:
            return html.Span("æ–‡ä»¶æ•°æ®ä¸¢å¤±ï¼Œè¯·é‡æ–°ä¸Šä¼ ", style={'color': '#dc3545'})
        
        try:
            # ä½¿ç”¨MultiFileUploadHandlerè·å–æ–‡ä»¶æ•°æ®
            upload_handler = MultiFileUploadHandler()
            file_id = button_id['index']
            file_data = upload_handler.get_file_data_by_id(file_id, store_data)
            
            if not file_data:
                return html.Span("æ–‡ä»¶æ•°æ®æ— æ•ˆ", style={'color': '#dc3545'})
            
            content, filename = file_data
            algorithm_name = algorithm_name.strip()
            
            # å¼‚æ­¥æ·»åŠ ç®—æ³•
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            success, error_msg = loop.run_until_complete(
                backend.add_algorithm(algorithm_name, filename, content)
            )
            loop.close()
            
            if success:
                # ç¡®ä¿æ–°æ·»åŠ çš„ç®—æ³•é»˜è®¤æ˜¾ç¤ºï¼ˆis_active åº”è¯¥å·²ç»æ˜¯ Trueï¼Œä½†ç¡®ä¿ä¸€ä¸‹ï¼‰
                algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name) if hasattr(backend, 'multi_algorithm_manager') else None
                if algorithm:
                    algorithm.is_active = True
                    logger.info(f"âœ… ç¡®ä¿ç®—æ³• '{algorithm_name}' é»˜è®¤æ˜¾ç¤º: is_active={algorithm.is_active}")
                logger.info(f"âœ… ç®—æ³• '{algorithm_name}' æ·»åŠ æˆåŠŸ")
                return html.Span("âœ… æ·»åŠ æˆåŠŸ", style={'color': '#28a745', 'fontWeight': 'bold'})
            else:
                return html.Span(f"âŒ {error_msg}", style={'color': '#dc3545'})
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ ç®—æ³•å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return html.Span(f"æ·»åŠ å¤±è´¥: {str(e)}", style={'color': '#dc3545'})
    
    @app.callback(
        Output('algorithm-list-trigger', 'data'),
        [Input({'type': 'algorithm-status', 'index': dash.dependencies.ALL}, 'children'),
         Input('confirm-migrate-existing-data-btn', 'n_clicks')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def trigger_algorithm_list_update(status_children, migrate_clicks, session_id):
        """å½“ç®—æ³•çŠ¶æ€æ”¹å˜æ—¶è§¦å‘ç®—æ³•åˆ—è¡¨æ›´æ–°"""
        import time
        # å½“ç®—æ³•çŠ¶æ€æ”¹å˜æˆ–è¿ç§»æŒ‰é’®è¢«ç‚¹å‡»æ—¶ï¼Œè§¦å‘åˆ—è¡¨æ›´æ–°
        # è¿™ä¼šåœ¨ç®—æ³•æ·»åŠ æˆåŠŸåè‡ªåŠ¨è§¦å‘ï¼Œå› ä¸º algorithm-status ä¼šæ›´æ–°
        # status_children å¯èƒ½æ˜¯ None æˆ–ç©ºåˆ—è¡¨ï¼ˆå½“æ²¡æœ‰ç®—æ³•æ—¶ï¼‰ï¼Œéœ€è¦å¤„ç†
        if status_children is None:
            status_children = []
        trigger_value = time.time()
        logger.info(f"ğŸ”„ è§¦å‘ç®—æ³•åˆ—è¡¨æ›´æ–°: trigger_value={trigger_value}, status_childrenæ•°é‡={len(status_children) if status_children else 0}")
        return trigger_value
    
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('report-content', 'children', allow_duplicate=True)],
        [Input('algorithm-list-trigger', 'data'),
         Input({'type': 'algorithm-toggle', 'index': dash.dependencies.ALL}, 'value')],
        [State('session-id', 'data')],
        prevent_duplicate=True,
        prevent_initial_call=True
    )
    def update_plot_on_algorithm_change(trigger_data, toggle_values, session_id):
        """å½“ç®—æ³•æ·»åŠ /åˆ é™¤/åˆ‡æ¢æ—¶ï¼Œè‡ªåŠ¨æ›´æ–°ç€‘å¸ƒå›¾å’ŒæŠ¥å‘Š"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update
        
        # ç¡®ä¿å¤šç®—æ³•æ¨¡å¼å·²å¯ç”¨
        # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
        if not backend.multi_algorithm_manager:
            backend._ensure_multi_algorithm_manager()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
        active_algorithms = backend.get_active_algorithms()
        if not active_algorithms:
            # æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ˜¾ç¤ºç©ºå›¾è¡¨
            empty_fig = _create_empty_figure_for_callback("è¯·è‡³å°‘æ¿€æ´»ä¸€ä¸ªç®—æ³•ä»¥æŸ¥çœ‹ç€‘å¸ƒå›¾")
            # ä½¿ç”¨ create_report_layout ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€çš„ç»„ä»¶
            empty_report = create_report_layout(backend)
            return empty_fig, empty_report
        
        try:
            # ç”Ÿæˆå¤šç®—æ³•ç€‘å¸ƒå›¾
            logger.info(f"ğŸ”„ æ›´æ–°å¤šç®—æ³•ç€‘å¸ƒå›¾ï¼Œå…± {len(active_algorithms)} ä¸ªæ¿€æ´»ç®—æ³•")
            fig = backend.generate_waterfall_plot()
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹ï¼ˆå¤šç®—æ³•æ¨¡å¼ä¸‹çš„æŠ¥å‘Šï¼‰
            report_content = create_report_layout(backend)
            
            logger.info("âœ… å¤šç®—æ³•ç€‘å¸ƒå›¾å’ŒæŠ¥å‘Šæ›´æ–°å®Œæˆ")
            return fig, report_content
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å¤šç®—æ³•ç€‘å¸ƒå›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            error_fig = _create_empty_figure_for_callback(f"æ›´æ–°å¤±è´¥: {str(e)}")
            # ä½¿ç”¨ create_report_layout ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€çš„ç»„ä»¶
            try:
                error_report = create_report_layout(backend)
            except:
                # å¦‚æœ create_report_layout ä¹Ÿå¤±è´¥ï¼Œè¿”å›åŒ…å«å¿…éœ€ç»„ä»¶çš„é”™è¯¯å¸ƒå±€
                empty_fig = {}
                error_report = html.Div([
                    html.H4("æ›´æ–°å¤±è´¥", className="text-center text-danger"),
                    html.P(f"é”™è¯¯ä¿¡æ¯: {str(e)}", className="text-center"),
                    # åŒ…å«æ‰€æœ‰å¿…éœ€çš„å›¾è¡¨ç»„ä»¶ï¼ˆéšè—ï¼‰ï¼Œç¡®ä¿å›è°ƒå‡½æ•°ä¸ä¼šæŠ¥é”™
                    dcc.Graph(id='key-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                    dcc.Graph(id='key-delay-zscore-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                    dcc.Graph(id='hammer-velocity-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                    # key-hammer-velocity-scatter-plot å·²åˆ é™¤ï¼ˆåŠŸèƒ½ä¸æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾é‡å¤ï¼‰
                    dcc.Graph(id='offset-alignment-plot', figure=empty_fig, style={'display': 'none'}),
                    html.Div([
                        dash_table.DataTable(
                            id='offset-alignment-table',
                            data=[],
                            columns=[]
                        )
                    ], style={'display': 'none'})
                ])
            return error_fig, error_report
    
    @app.callback(
        [Output('existing-data-migration-area', 'style'),
         Output('existing-data-migration-area', 'children')],
        [Input('session-id', 'data'),
         Input('confirm-migrate-existing-data-btn', 'n_clicks')],
        [State('existing-data-algorithm-name-input', 'value')],
        prevent_initial_call=True
    )
    def handle_existing_data_migration(session_id_trigger, migrate_clicks, algorithm_name):
        """å¤„ç†ç°æœ‰æ•°æ®è¿ç§»åŒºåŸŸçš„æ˜¾ç¤ºå’Œè¿ç§»æ“ä½œ"""
        logger.info(f"ğŸ”„ handle_existing_data_migration: migrate_clicks={migrate_clicks}")
        
        # ä» session_id_trigger è·å– session_idï¼ˆå®ƒå¯èƒ½æ˜¯ None æˆ–å®é™…å€¼ï¼‰
        session_id = session_id_trigger if session_id_trigger else None
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("âš ï¸ æ— æ³•è·å–backendå®ä¾‹ï¼ˆhandle_existing_data_migrationï¼‰")
            return {'display': 'none'}, None
        
        ctx = callback_context
        if not ctx.triggered:
            return {'display': 'none'}, None
        
        trigger_id = ctx.triggered[0]['prop_id']
        logger.info(f"ğŸ” è§¦å‘æº: {trigger_id}")
        
        try:
            # å¦‚æœæ˜¯ä¼šè¯åˆå§‹åŒ–è§¦å‘
            if 'session-id' in trigger_id:
                # å¤šç®—æ³•æ¨¡å¼å§‹ç»ˆå¯ç”¨
                logger.info("â„¹ï¸ å¤šç®—æ³•æ¨¡å¼å§‹ç»ˆå¯ç”¨")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰åˆ†ææ•°æ®
                has_existing_data = False
                existing_filename = None
                
                try:
                    if backend.analyzer and backend.analyzer.note_matcher and hasattr(backend.analyzer, 'matched_pairs') and len(backend.analyzer.matched_pairs) > 0:
                        has_existing_data = True
                        data_source_info = backend.get_data_source_info()
                        existing_filename = data_source_info.get('filename', 'æœªçŸ¥æ–‡ä»¶')
                        logger.info(f"âœ… æ£€æµ‹åˆ°ç°æœ‰åˆ†ææ•°æ®: {existing_filename}")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ£€æŸ¥ç°æœ‰æ•°æ®æ—¶å‡ºé”™: {e}")
                    has_existing_data = False
                
                if has_existing_data:
                    # æ˜¾ç¤ºè¿ç§»æç¤ºï¼ˆæŒ‰é’®å’Œè¾“å…¥æ¡†åœ¨å¸ƒå±€ä¸­å·²å®šä¹‰ï¼Œé€šè¿‡æ˜¾ç¤ºå®ƒä»¬ï¼‰
                    migration_area = dbc.Alert([
                        html.H6("æ£€æµ‹åˆ°ç°æœ‰åˆ†ææ•°æ®", className="mb-2", style={'fontWeight': 'bold'}),
                        html.P(f"æ–‡ä»¶: {existing_filename}", style={'fontSize': '14px', 'marginBottom': '10px'}),
                        html.P("è¯·ä¸ºè¿™ä¸ªç®—æ³•è¾“å…¥åç§°ï¼Œä»¥ä¾¿åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹è¿›è¡Œå¯¹æ¯”ï¼š", style={'fontSize': '14px', 'marginBottom': '10px'}),
                        html.Div(id='migration-components-placeholder', children=[
                            html.P("è¯·åœ¨ä¸‹æ–¹è¾“å…¥ç®—æ³•åç§°å¹¶ç‚¹å‡»ç¡®è®¤è¿ç§»æŒ‰é’®", style={'fontSize': '12px', 'color': '#6c757d'})
                        ])
                    ], color='info', className='mb-3')
                    logger.info("âœ… æ˜¾ç¤ºè¿ç§»æç¤ºåŒºåŸŸ")
                    return {'display': 'block'}, migration_area
                else:
                    logger.info("â„¹ï¸ æ²¡æœ‰ç°æœ‰æ•°æ®éœ€è¦è¿ç§»")
                    return {'display': 'none'}, None
            
            # å¦‚æœæ˜¯è¿ç§»æŒ‰é’®è§¦å‘
            elif 'confirm-migrate-existing-data-btn' in trigger_id:
                if not migrate_clicks or not algorithm_name or not algorithm_name.strip():
                    return no_update, no_update
                
                try:
                    # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
                    if not backend.multi_algorithm_manager:
                        backend._ensure_multi_algorithm_manager()
                    
                    algorithm_name = algorithm_name.strip()
                    logger.info(f"ğŸ“¤ å¼€å§‹è¿ç§»ç°æœ‰æ•°æ®åˆ°ç®—æ³•: {algorithm_name}")
                    success, error_msg = backend.migrate_existing_data_to_algorithm(algorithm_name)
                    
                    if success:
                        # éšè—è¿ç§»åŒºåŸŸ
                        logger.info("âœ… æ•°æ®è¿ç§»æˆåŠŸ")
                        return {'display': 'none'}, None
                    else:
                        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                        logger.error(f"âŒ æ•°æ®è¿ç§»å¤±è´¥: {error_msg}")
                        error_alert = dbc.Alert([
                            html.H6("è¿ç§»å¤±è´¥", className="mb-2", style={'fontWeight': 'bold', 'color': '#dc3545'}),
                            html.P(f"é”™è¯¯: {error_msg}", style={'fontSize': '14px'})
                        ], color='danger', className='mb-3')
                        return no_update, error_alert
                except Exception as e:
                    logger.error(f"âŒ è¿ç§»æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                    logger.error(traceback.format_exc())
                    error_alert = dbc.Alert([
                        html.H6("è¿ç§»å¤±è´¥", className="mb-2", style={'fontWeight': 'bold', 'color': '#dc3545'}),
                        html.P(f"å¼‚å¸¸: {str(e)}", style={'fontSize': '14px'})
                    ], color='danger', className='mb-3')
                    return no_update, error_alert
            else:
                # æœªçŸ¥è§¦å‘æº
                logger.warning(f"âš ï¸ æœªçŸ¥è§¦å‘æº: {trigger_id}")
                return {'display': 'none'}, None
                
        except Exception as e:
            logger.error(f"âŒ handle_existing_data_migration å‘ç”Ÿå¼‚å¸¸: {e}")
            logger.error(traceback.format_exc())
            return {'display': 'none'}, None
        
        return {'display': 'none'}, None
    
    @app.callback(
        [Output('algorithm-list', 'children'),
         Output('algorithm-management-status', 'children')],
        [Input('algorithm-list-trigger', 'data')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def update_algorithm_list(trigger_data, session_id):
        """æ›´æ–°ç®—æ³•åˆ—è¡¨æ˜¾ç¤º"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return [], ""
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            return [], ""
        
        # ç¡®ä¿å¤šç®—æ³•æ¨¡å¼å·²å¯ç”¨
        # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
        if not backend.multi_algorithm_manager:
            backend._ensure_multi_algorithm_manager()
        
        try:
            algorithms = backend.get_all_algorithms()
            
            if not algorithms:
                return [], html.Span("æš‚æ— ç®—æ³•ï¼Œè¯·ä¸Šä¼ æ–‡ä»¶", style={'color': '#6c757d'})
            
            algorithm_items = []
            for alg_info in algorithms:
                alg_name = alg_info['algorithm_name']  # å†…éƒ¨å”¯ä¸€æ ‡è¯†ï¼ˆç”¨äºæŸ¥æ‰¾ï¼‰
                display_name = alg_info.get('display_name', alg_name)  # æ˜¾ç¤ºåç§°ï¼ˆç”¨äºUIæ˜¾ç¤ºï¼‰
                filename = alg_info['filename']
                status = alg_info['status']
                # è·å–is_activeï¼Œå¦‚æœæœªè®¾ç½®æˆ–ä¸ºNoneï¼Œåˆ™é»˜è®¤ä¸ºTrueï¼ˆæ–°ä¸Šä¼ çš„æ–‡ä»¶åº”è¯¥é»˜è®¤æ˜¾ç¤ºï¼‰
                is_active = alg_info.get('is_active')
                if is_active is None:
                    is_active = True
                    # å¦‚æœis_activeä¸ºNoneï¼Œç¡®ä¿ç®—æ³•å¯¹è±¡ä¸­çš„is_activeä¹Ÿè¢«è®¾ç½®ä¸ºTrue
                    algorithm = backend.multi_algorithm_manager.get_algorithm(alg_name) if hasattr(backend, 'multi_algorithm_manager') else None
                    if algorithm:
                        algorithm.is_active = True
                        logger.info(f"âœ… ç¡®ä¿ç®—æ³• '{display_name}' é»˜è®¤æ˜¾ç¤º: is_active={is_active}")
                color = alg_info['color']
                is_ready = alg_info['is_ready']
                
                # çŠ¶æ€å›¾æ ‡
                if status == 'ready' and is_ready:
                    status_icon = html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '5px'})
                    status_text = "å°±ç»ª"
                elif status == 'loading':
                    status_icon = html.I(className="fas fa-spinner fa-spin", style={'color': '#17a2b8', 'marginRight': '5px'})
                    status_text = "åŠ è½½ä¸­"
                elif status == 'error':
                    status_icon = html.I(className="fas fa-exclamation-circle", style={'color': '#dc3545', 'marginRight': '5px'})
                    status_text = "é”™è¯¯"
                else:
                    status_icon = html.I(className="fas fa-clock", style={'color': '#ffc107', 'marginRight': '5px'})
                    status_text = "ç­‰å¾…ä¸­"
                
                # æ˜¾ç¤º/éšè—å¼€å…³
                toggle_switch = dbc.Switch(
                    id={'type': 'algorithm-toggle', 'index': alg_name},
                    label='æ˜¾ç¤º',
                    value=is_active,
                    style={'fontSize': '12px'}
                )
                
                algorithm_items.append(
                    dbc.Card([
                        dbc.CardBody([
                            html.Div([
                                html.Div([
                                    html.Span(display_name, style={'fontWeight': 'bold', 'fontSize': '14px', 'color': color}),
                                    html.Br(),
                                    html.Small(filename, style={'color': '#6c757d', 'fontSize': '11px'}),
                                    html.Br(),
                                    html.Small([status_icon, status_text], style={'fontSize': '11px'})
                                ], style={'flex': '1'}),
                                html.Div([
                                    toggle_switch,
                                    dbc.Button("åˆ é™¤", 
                                             id={'type': 'algorithm-delete-btn', 'index': alg_name},
                                             color='danger',
                                             size='sm',
                                             n_clicks=0,
                                             style={'marginTop': '5px', 'width': '100%'})
                                ], style={'marginLeft': '10px'})
                            ], style={'display': 'flex', 'justifyContent': 'space-between', 'alignItems': 'center'})
                        ])
                    ], className='mb-2', style={'border': f'2px solid {color}', 'borderRadius': '5px'})
                )
            
            # åˆ›å»ºç®—æ³•åˆ—è¡¨ï¼ˆä½¿ç”¨åˆ—è¡¨è€Œä¸æ˜¯Divï¼Œä¿æŒä¸€è‡´æ€§ï¼‰
            algorithm_list = algorithm_items  # ç›´æ¥è¿”å›åˆ—è¡¨ï¼ŒDashä¼šè‡ªåŠ¨å¤„ç†
            status_text = html.Span(f"å…± {len(algorithms)} ä¸ªç®—æ³•", style={'color': '#6c757d'})
            
            return algorithm_list, status_text
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç®—æ³•åˆ—è¡¨å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return [], html.Span(f"æ›´æ–°å¤±è´¥: {str(e)}", style={'color': '#dc3545'})
    
    @app.callback(
        [Output('algorithm-list', 'children', allow_duplicate=True),
         Output('algorithm-management-status', 'children', allow_duplicate=True),
         Output('algorithm-list-trigger', 'data', allow_duplicate=True),
         Output('multi-algorithm-file-list', 'children', allow_duplicate=True),
         Output('multi-algorithm-upload-status', 'children', allow_duplicate=True),
         Output('multi-algorithm-files-store', 'data', allow_duplicate=True)],
        [Input({'type': 'algorithm-toggle', 'index': dash.dependencies.ALL}, 'value'),
         Input({'type': 'algorithm-delete-btn', 'index': dash.dependencies.ALL}, 'n_clicks')],
        [State({'type': 'algorithm-toggle', 'index': dash.dependencies.ALL}, 'id'),
         State({'type': 'algorithm-delete-btn', 'index': dash.dependencies.ALL}, 'id'),
         State('session-id', 'data'),
         State('multi-algorithm-files-store', 'data')],
        prevent_duplicate=True,
        prevent_initial_call=True
    )
    def handle_algorithm_management(toggle_values, delete_clicks_list, toggle_ids, delete_ids, session_id, store_data):
        """å¤„ç†ç®—æ³•ç®¡ç†æ“ä½œï¼ˆæ˜¾ç¤º/éšè—ã€åˆ é™¤ï¼‰"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        # ç¡®ä¿å¤šç®—æ³•æ¨¡å¼å·²å¯ç”¨
        # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
        if not backend.multi_algorithm_manager:
            backend._ensure_multi_algorithm_manager()
        
        ctx = callback_context
        if not ctx.triggered:
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        trigger_id = ctx.triggered[0]['prop_id']
        
        # æ ‡è®°æ˜¯å¦åˆ é™¤äº†ç®—æ³•ï¼Œç”¨äºæ›´æ–°æ–‡ä»¶åˆ—è¡¨
        algorithm_deleted = False
        deleted_algorithm_filename = None
        
        try:
            # è§£æ trigger_idï¼Œæ ¼å¼é€šå¸¸æ˜¯ '{"type":"...","index":"..."}.property'
            import json
            trigger_prop_id = trigger_id.split('.')[0]
            try:
                trigger_data = json.loads(trigger_prop_id)
                algorithm_name = trigger_data.get('index', '')
            except (json.JSONDecodeError, KeyError):
                logger.error(f"æ— æ³•è§£æ trigger_id: {trigger_id}")
                return no_update, no_update, no_update, no_update, no_update, no_update
            
            if 'algorithm-toggle' in trigger_id:
                # æ ¹æ®å¼€å…³çš„æ–°å€¼è®¾ç½®æ˜¾ç¤º/éšè—çŠ¶æ€ï¼ˆè€Œä¸æ˜¯åˆ‡æ¢ï¼‰
                # æ‰¾åˆ°å¯¹åº”çš„å¼€å…³ç´¢å¼•å’Œå€¼
                if toggle_values and toggle_ids:
                    for i, toggle_id in enumerate(toggle_ids):
                        if toggle_id and toggle_id.get('index') == algorithm_name:
                            new_value = toggle_values[i] if i < len(toggle_values) else None
                            if new_value is not None:
                                # è·å–ç®—æ³•å¯¹è±¡
                                algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name) if hasattr(backend, 'multi_algorithm_manager') else None
                                if algorithm:
                                    # ç›´æ¥è®¾ç½®ä¸ºæ–°å€¼ï¼Œè€Œä¸æ˜¯åˆ‡æ¢
                                    if algorithm.is_active != new_value:
                                        algorithm.is_active = new_value
                                        logger.info(f"âœ… ç®—æ³• '{algorithm_name}' æ˜¾ç¤ºçŠ¶æ€è®¾ç½®ä¸º: {'æ˜¾ç¤º' if new_value else 'éšè—'}")
                                    else:
                                        logger.debug(f"â„¹ï¸ ç®—æ³• '{algorithm_name}' æ˜¾ç¤ºçŠ¶æ€æœªå˜åŒ–: {new_value}")
                            break
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„å¼€å…³ï¼Œä½¿ç”¨åˆ‡æ¢æ–¹å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                    backend.toggle_algorithm(algorithm_name)
            elif 'algorithm-delete-btn' in trigger_id:
                # åˆ é™¤ç®—æ³•
                # æ£€æŸ¥æ˜¯å¦æœ‰ç‚¹å‡»ï¼ˆn_clicks > 0ï¼‰
                if delete_clicks_list:
                    # æ‰¾åˆ°å¯¹åº”çš„æŒ‰é’®ç´¢å¼•
                    for i, delete_id in enumerate(delete_ids):
                        if delete_id and delete_id.get('index') == algorithm_name:
                            if delete_clicks_list[i] and delete_clicks_list[i] > 0:
                                # åœ¨åˆ é™¤å‰è·å–ç®—æ³•ä¿¡æ¯ï¼Œä»¥ä¾¿ä»æ–‡ä»¶åˆ—è¡¨ä¸­ç§»é™¤
                                algorithms_before = backend.get_all_algorithms()
                                for alg_info in algorithms_before:
                                    if alg_info['algorithm_name'] == algorithm_name:
                                        deleted_algorithm_filename = alg_info.get('filename', '')
                                        break
                                
                                backend.remove_algorithm(algorithm_name)
                                algorithm_deleted = True
                                break
                    else:
                        return no_update, no_update, no_update, no_update, no_update, no_update
                else:
                    return no_update, no_update, no_update, no_update, no_update, no_update
            else:
                return no_update, no_update, no_update, no_update, no_update, no_update
            
            # é‡æ–°è·å–ç®—æ³•åˆ—è¡¨
            algorithms = backend.get_all_algorithms()
            
            # æ›´æ–°æ–‡ä»¶åˆ—è¡¨ï¼šå¦‚æœåˆ é™¤äº†ç®—æ³•ï¼Œä»æ–‡ä»¶åˆ—è¡¨ä¸­ç§»é™¤å¯¹åº”çš„æ–‡ä»¶
            # æ— è®ºæ˜¯å¦åˆ é™¤äº†ç®—æ³•ï¼Œéƒ½è¦æ›´æ–°æ–‡ä»¶åˆ—è¡¨ï¼Œç¡®ä¿åªæ˜¾ç¤ºæœªæ·»åŠ çš„æ–‡ä»¶
            file_list_children = no_update
            upload_status_text = no_update
            updated_store_data = no_update
            
            # è·å–æ‰€æœ‰å·²æ·»åŠ ç®—æ³•çš„æ–‡ä»¶å
            added_filenames = set()
            for alg_info in algorithms:
                added_filenames.add(alg_info.get('filename', ''))
            
            # å¦‚æœåˆ é™¤äº†ç®—æ³•ï¼Œæˆ–è€…æœ‰store_dataï¼Œéƒ½éœ€è¦æ›´æ–°æ–‡ä»¶åˆ—è¡¨
            if algorithm_deleted or (store_data and 'filenames' in store_data):
                # ä»store_dataä¸­è·å–æ–‡ä»¶åˆ—è¡¨
                if store_data and 'contents' in store_data and 'filenames' in store_data:
                    contents_list = store_data.get('contents', [])
                    filenames_list = store_data.get('filenames', [])
                    file_ids = store_data.get('file_ids', [])
                    
                    # è¿‡æ»¤å‡ºæœªæ·»åŠ çš„æ–‡ä»¶
                    filtered_contents = []
                    filtered_filenames = []
                    filtered_file_ids = []
                    
                    for i, filename in enumerate(filenames_list):
                        if filename not in added_filenames:
                            if i < len(contents_list):
                                filtered_contents.append(contents_list[i])
                            filtered_filenames.append(filename)
                            if i < len(file_ids):
                                filtered_file_ids.append(file_ids[i])
                    
                    # æ›´æ–°store_data
                    updated_store_data = {
                        'contents': filtered_contents,
                        'filenames': filtered_filenames,
                        'file_ids': filtered_file_ids
                    }
                    
                    # ç›´æ¥ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨UIï¼Œä½¿ç”¨ç°æœ‰çš„æ–‡ä»¶IDï¼Œé¿å…é‡å¤åˆå¹¶
                    from ui.multi_file_upload_handler import MultiFileUploadHandler
                    upload_handler = MultiFileUploadHandler()
                    # ç›´æ¥ä½¿ç”¨è¿‡æ»¤åçš„æ–‡ä»¶åˆ—è¡¨ç”ŸæˆUIï¼Œä¸è°ƒç”¨process_uploaded_filesé¿å…é‡å¤åˆå¹¶
                    file_items = []
                    for i, (content, filename, file_id) in enumerate(zip(
                        filtered_contents,
                        filtered_filenames,
                        filtered_file_ids
                    )):
                        # ç¡®ä¿ä¸ä¼šæ˜¾ç¤ºå·²æ·»åŠ çš„æ–‡ä»¶ï¼ˆåŒé‡æ£€æŸ¥ï¼‰
                        if filename not in added_filenames:
                            file_card = upload_handler.create_file_card(file_id, filename)
                            file_items.append(file_card)
                    
                    file_list_children = html.Div(file_items) if file_items else []
                    # ç”Ÿæˆä¸Šä¼ çŠ¶æ€æ–‡æœ¬
                    total_files = len(filtered_filenames)
                    if total_files > 0:
                        upload_status_text = html.Span(
                            f"å…± {total_files} ä¸ªæ–‡ä»¶ï¼Œè¯·ä¸ºæ¯ä¸ªæ–‡ä»¶è¾“å…¥ç®—æ³•åç§°",
                            style={'color': '#17a2b8', 'fontWeight': 'bold'}
                        )
                    else:
                        upload_status_text = html.Span("", style={'color': '#6c757d'})
                elif algorithm_deleted:
                    # å¦‚æœåˆ é™¤äº†ç®—æ³•ä½†æ²¡æœ‰store_dataï¼Œæ¸…ç©ºæ–‡ä»¶åˆ—è¡¨
                    file_list_children = []
                    upload_status_text = html.Span("", style={'color': '#6c757d'})
                    updated_store_data = {'contents': [], 'filenames': [], 'file_ids': []}
            
            if not algorithms:
                # è¿”å›ç©ºåˆ—è¡¨å’ŒçŠ¶æ€æ–‡æœ¬ï¼Œä»¥åŠè§¦å‘æ›´æ–°
                empty_list = []  # ç©ºåˆ—è¡¨ï¼Œè€Œä¸æ˜¯ Div
                status_text = html.Span("æš‚æ— ç®—æ³•ï¼Œè¯·ä¸Šä¼ æ–‡ä»¶", style={'color': '#6c757d'})
                # å¦‚æœæ²¡æœ‰ç®—æ³•äº†ï¼Œä¹Ÿæ¸…ç©ºæ–‡ä»¶åˆ—è¡¨
                if file_list_children == no_update:
                    file_list_children = []
                if updated_store_data == no_update:
                    updated_store_data = {'contents': [], 'filenames': [], 'file_ids': []}
                if upload_status_text == no_update:
                    upload_status_text = html.Span("", style={'color': '#6c757d'})
                return empty_list, status_text, time.time(), file_list_children, upload_status_text, updated_store_data
            
            algorithm_items = []
            for alg_info in algorithms:
                alg_name = alg_info['algorithm_name']
                filename = alg_info['filename']
                status = alg_info['status']
                is_active = alg_info['is_active']
                color = alg_info['color']
                is_ready = alg_info['is_ready']
                
                if status == 'ready' and is_ready:
                    status_icon = html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '5px'})
                    status_text = "å°±ç»ª"
                elif status == 'loading':
                    status_icon = html.I(className="fas fa-spinner fa-spin", style={'color': '#17a2b8', 'marginRight': '5px'})
                    status_text = "åŠ è½½ä¸­"
                elif status == 'error':
                    status_icon = html.I(className="fas fa-exclamation-circle", style={'color': '#dc3545', 'marginRight': '5px'})
                    status_text = "é”™è¯¯"
                else:
                    status_icon = html.I(className="fas fa-clock", style={'color': '#ffc107', 'marginRight': '5px'})
                    status_text = "ç­‰å¾…ä¸­"
                
                toggle_switch = dbc.Switch(
                    id={'type': 'algorithm-toggle', 'index': alg_name},
                    label='æ˜¾ç¤º',
                    value=is_active,
                    style={'fontSize': '12px'}
                )
                
                algorithm_items.append(
                    dbc.Card([
                        dbc.CardBody([
                            html.Div([
                                html.Div([
                                    html.Span(alg_name, style={'fontWeight': 'bold', 'fontSize': '14px', 'color': color}),
                                    html.Br(),
                                    html.Small(filename, style={'color': '#6c757d', 'fontSize': '11px'}),
                                    html.Br(),
                                    html.Small([status_icon, status_text], style={'fontSize': '11px'})
                                ], style={'flex': '1'}),
                                html.Div([
                                    toggle_switch,
                                    dbc.Button("åˆ é™¤", 
                                             id={'type': 'algorithm-delete-btn', 'index': alg_name},
                                             color='danger',
                                             size='sm',
                                             n_clicks=0,
                                             style={'marginTop': '5px', 'width': '100%'})
                                ], style={'marginLeft': '10px'})
                            ], style={'display': 'flex', 'justifyContent': 'space-between', 'alignItems': 'center'})
                        ])
                    ], className='mb-2', style={'border': f'2px solid {color}', 'borderRadius': '5px'})
                )
            
            # åˆ›å»ºç®—æ³•åˆ—è¡¨ï¼ˆä½¿ç”¨åˆ—è¡¨è€Œä¸æ˜¯Divï¼Œä¿æŒä¸€è‡´æ€§ï¼‰
            algorithm_list = algorithm_items  # ç›´æ¥è¿”å›åˆ—è¡¨ï¼ŒDashä¼šè‡ªåŠ¨å¤„ç†
            status_text = html.Span(f"å…± {len(algorithms)} ä¸ªç®—æ³•", style={'color': '#6c757d'})
            
            # å¦‚æœæ²¡æœ‰æ›´æ–°ä¸Šä¼ çŠ¶æ€æ–‡æœ¬ï¼Œæ ¹æ®æ–‡ä»¶åˆ—è¡¨ç”Ÿæˆ
            if upload_status_text == no_update:
                if updated_store_data != no_update and isinstance(updated_store_data, dict):
                    total_files = len(updated_store_data.get('filenames', []))
                    if total_files > 0:
                        upload_status_text = html.Span(
                            f"å…± {total_files} ä¸ªæ–‡ä»¶ï¼Œè¯·ä¸ºæ¯ä¸ªæ–‡ä»¶è¾“å…¥ç®—æ³•åç§°",
                            style={'color': '#17a2b8', 'fontWeight': 'bold'}
                        )
                    else:
                        upload_status_text = html.Span("", style={'color': '#6c757d'})
                elif store_data and isinstance(store_data, dict):
                    total_files = len(store_data.get('filenames', []))
                    # è¿‡æ»¤æ‰å·²æ·»åŠ çš„æ–‡ä»¶
                    added_filenames = set()
                    for alg_info in algorithms:
                        added_filenames.add(alg_info.get('filename', ''))
                    filtered_count = sum(1 for f in store_data.get('filenames', []) if f not in added_filenames)
                    if filtered_count > 0:
                        upload_status_text = html.Span(
                            f"å…± {filtered_count} ä¸ªæ–‡ä»¶ï¼Œè¯·ä¸ºæ¯ä¸ªæ–‡ä»¶è¾“å…¥ç®—æ³•åç§°",
                            style={'color': '#17a2b8', 'fontWeight': 'bold'}
                        )
                    else:
                        upload_status_text = html.Span("", style={'color': '#6c757d'})
                else:
                    upload_status_text = html.Span("", style={'color': '#6c757d'})
            
            return algorithm_list, status_text, time.time(), file_list_children, upload_status_text, updated_store_data
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†ç®—æ³•ç®¡ç†æ“ä½œå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return no_update, no_update, no_update, no_update, no_update, no_update
    
    # æŒ‰é”®å»¶æ—¶åˆ†æè¡¨æ ¼ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæŒ‰é”®æ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True)],
        [Input('offset-alignment-table', 'active_cell'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('offset-alignment-table', 'data'),
         State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True,
        prevent_duplicate=True
    )
    def handle_key_table_click(active_cell, close_modal_clicks, close_btn_clicks, table_data, session_id, current_style):
        """å¤„ç†æŒ‰é”®å»¶æ—¶åˆ†æè¡¨æ ¼ç‚¹å‡»ï¼Œæ˜¾ç¤ºæŒ‰é”®æ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰"""
        from dash import callback_context
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            logger.debug("âš ï¸ æŒ‰é”®è¡¨æ ¼ç‚¹å‡»å›è°ƒï¼šæ²¡æœ‰è§¦å‘æº")
            return current_style, []
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"ğŸ”„ æŒ‰é”®è¡¨æ ¼ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            logger.info("âœ… å…³é—­æŒ‰é”®æ›²çº¿å¯¹æ¯”æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, []
        
        # å¦‚æœæ˜¯è¡¨æ ¼ç‚¹å‡»
        if trigger_id == 'offset-alignment-table':
            logger.info(f"ğŸ”„ è¡¨æ ¼ç‚¹å‡»ï¼šactive_cell={active_cell}, table_dataé•¿åº¦={len(table_data) if table_data else 0}")
            backend = session_manager.get_backend(session_id)
            if not backend:
                logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°backend")
                return current_style, []
            if not active_cell or not table_data:
                logger.warning("âš ï¸ active_cellæˆ–table_dataä¸ºç©º")
                return current_style, []
            
            try:
                # è·å–ç‚¹å‡»çš„è¡Œæ•°æ®
                row_idx = active_cell.get('row')
                if row_idx is None or row_idx >= len(table_data):
                    return current_style, []
                
                row_data = table_data[row_idx]
                algorithm_name = row_data.get('algorithm_name')
                key_id_str = row_data.get('key_id')
                
                # è·³è¿‡æ±‡æ€»è¡Œ
                if key_id_str in ['æ€»ä½“', 'æ±‡æ€»'] or not algorithm_name:
                    return current_style, []
                
                # è½¬æ¢æŒ‰é”®ID
                try:
                    key_id = int(key_id_str)
                except (ValueError, TypeError):
                    return current_style, []
                
                # è·å–æ¿€æ´»çš„ç®—æ³•åˆ—è¡¨
                active_algorithms = backend.get_active_algorithms()
                if len(active_algorithms) < 2:
                    modal_style = {
                        'display': 'block',
                        'position': 'fixed',
                        'zIndex': '9999',
                        'left': '0',
                        'top': '0',
                        'width': '100%',
                        'height': '100%',
                        'backgroundColor': 'rgba(0,0,0,0.6)',
                        'backdropFilter': 'blur(5px)'
                    }
                    return modal_style, [html.Div([
                        html.P("éœ€è¦è‡³å°‘2ä¸ªæ¿€æ´»çš„ç®—æ³•æ‰èƒ½è¿›è¡Œå¯¹æ¯”", className="text-muted text-center")
                    ])]
                
                # è·å–æ‰€æœ‰æ¿€æ´»ç®—æ³•çš„åŒ¹é…å¯¹
                algorithm_pairs_dict = {}
                all_timestamps = set()
                
                for alg in active_algorithms:
                    alg_name = alg.metadata.algorithm_name
                    pairs = backend.get_key_matched_pairs_by_algorithm(alg_name, key_id)
                    if pairs:
                        algorithm_pairs_dict[alg_name] = pairs
                        for _, _, _, _, timestamp in pairs:
                            all_timestamps.add(timestamp)
                
                if not algorithm_pairs_dict:
                    modal_style = {
                        'display': 'block',
                        'position': 'fixed',
                        'zIndex': '9999',
                        'left': '0',
                        'top': '0',
                        'width': '100%',
                        'height': '100%',
                        'backgroundColor': 'rgba(0,0,0,0.6)',
                        'backdropFilter': 'blur(5px)'
                    }
                    return modal_style, [html.Div([
                        html.P(f"æŒ‰é”®ID {key_id} åœ¨æ‰€æœ‰æ¿€æ´»ç®—æ³•ä¸­éƒ½æ²¡æœ‰åŒ¹é…æ•°æ®", className="text-muted text-center")
                    ])]
                
                # é€‰æ‹©å‰ä¸¤ä¸ªæœ‰æ•°æ®çš„ç®—æ³•è¿›è¡Œå¯¹æ¯”
                alg_names = list(algorithm_pairs_dict.keys())[:2]
                if len(alg_names) < 2:
                    # å¦‚æœåªæœ‰ä¸€ä¸ªç®—æ³•æœ‰æ•°æ®ï¼Œé€‰æ‹©å‰ä¸¤ä¸ªæ¿€æ´»çš„ç®—æ³•ï¼ˆå³ä½¿ç¬¬äºŒä¸ªæ²¡æœ‰æ•°æ®ï¼‰
                    alg_names = [alg.metadata.algorithm_name for alg in active_algorithms[:2]]
                    if alg_names[0] not in algorithm_pairs_dict:
                        alg_names[0] = list(algorithm_pairs_dict.keys())[0]
                
                alg1_name = alg_names[0]
                alg2_name = alg_names[1]
                
                alg1_pairs = algorithm_pairs_dict.get(alg1_name, [])
                alg2_pairs = algorithm_pairs_dict.get(alg2_name, [])
                
                # ç”Ÿæˆå¯¹æ¯”æ›²çº¿å›¾
                import spmid
                import plotly.graph_objects as go
                from plotly.subplots import make_subplots
                
                comparison_rows = []
                
                # ä½¿ç”¨åŒæŒ‡é’ˆæŒ‰æ—¶é—´æˆ³å¯¹é½
                # æ³¨æ„ï¼šä¸¤ä¸ªç®—æ³•å¤„ç†çš„æ˜¯å®Œå…¨ä¸åŒçš„SPMIDæ–‡ä»¶ï¼Œå„è‡ªæœ‰ç‹¬ç«‹çš„å½•åˆ¶æ•°æ®å’Œæ’­æ”¾æ•°æ®
                # - ç®—æ³•Aï¼šSPMIDæ–‡ä»¶1çš„å½•åˆ¶æ•°æ®1 vs æ’­æ”¾æ•°æ®1
                # - ç®—æ³•Bï¼šSPMIDæ–‡ä»¶2çš„å½•åˆ¶æ•°æ®2 vs æ’­æ”¾æ•°æ®2
                # å®ƒä»¬ä¹‹é—´æ²¡æœ‰ä»»ä½•å…³è”ï¼Œrecord_indexå’Œrecord_keyonéƒ½æ˜¯å„è‡ªæ–‡ä»¶å†…çš„
                # æ­¥éª¤ï¼š
                # - æå–ä¸¤ä¸ªç®—æ³•çš„æ—¶é—´æˆ³åºåˆ—ï¼ˆå•ä½ï¼š0.1msï¼Œrecord_keyonæ˜¯å„è‡ªæ–‡ä»¶å†…å½•åˆ¶æŒ‰é”®å¼€å§‹æ—¶é—´ï¼‰
                # - ä½¿ç”¨ä¸¤ä¸ªæŒ‡é’ˆåœ¨åˆå¹¶æ—¶é—´çº¿ä¸Šå‰è¿›ï¼Œå°½é‡å°†æ—¶é—´ä¸´è¿‘çš„é…å¯¹ï¼Œå¦åˆ™å•ä¾§æ˜¾ç¤º
                ALIGN_WINDOW_01MS = 200  # å¯¹é½çª—å£ï¼š200(0.1ms) = 20ms
                
                alg1_pairs_sorted = sorted(alg1_pairs, key=lambda p: p[4])
                alg2_pairs_sorted = sorted(alg2_pairs, key=lambda p: p[4])
                i, j = 0, 0
                while i < len(alg1_pairs_sorted) or j < len(alg2_pairs_sorted):
                    if i < len(alg1_pairs_sorted) and j < len(alg2_pairs_sorted):
                        t1 = alg1_pairs_sorted[i][4]
                        t2 = alg2_pairs_sorted[j][4]
                        diff = abs(t1 - t2)
                        if diff <= ALIGN_WINDOW_01MS:
                            # é…å¯¹æ˜¾ç¤º
                            comparison_rows.append((alg1_pairs_sorted[i], alg2_pairs_sorted[j], t1, t2))
                            i += 1
                            j += 1
                        elif t1 < t2:
                            # å·¦ä¾§å•ç‹¬æ˜¾ç¤º
                            comparison_rows.append((alg1_pairs_sorted[i], None, t1, None))
                            i += 1
                        else:
                            # å³ä¾§å•ç‹¬æ˜¾ç¤º
                            comparison_rows.append((None, alg2_pairs_sorted[j], None, t2))
                            j += 1
                    elif i < len(alg1_pairs_sorted):
                        t1 = alg1_pairs_sorted[i][4]
                        comparison_rows.append((alg1_pairs_sorted[i], None, t1, None))
                        i += 1
                    else:
                        t2 = alg2_pairs_sorted[j][4]
                        comparison_rows.append((None, alg2_pairs_sorted[j], None, t2))
                        j += 1
                
                # ä¸ºæ¯ä¸ªå¯¹é½é¡¹åˆ›å»ºå¯¹æ¯”å›¾
                rendered_rows = []
                for alg1_pair, alg2_pair, t1, t2 in comparison_rows:
                    if not alg1_pair and not alg2_pair:
                        continue
                    
                    # åˆ›å»ºå·¦å³å¯¹æ¯”çš„å­å›¾ï¼Œæ ‡é¢˜æ˜¾ç¤ºå„è‡ªæ—¶é—´
                    # record_keyonï¼šå„è‡ªSPMIDæ–‡ä»¶å†…å½•åˆ¶æŒ‰é”®å¼€å§‹æ—¶é—´ï¼ˆä¸¤ä¸ªæ–‡ä»¶ç‹¬ç«‹ï¼Œæ—¶é—´æˆ³æ— å…³è”ï¼‰
                    if alg1_pair and t1 is not None:
                        title1 = f"{alg1_name}<br>å½•åˆ¶æŒ‰é”®å¼€å§‹: {t1/10:.2f}ms"
                    else:
                        title1 = f"{alg1_name} (æ— æ•°æ®)"
                    
                    if alg2_pair and t2 is not None:
                        title2 = f"{alg2_name}<br>å½•åˆ¶æŒ‰é”®å¼€å§‹: {t2/10:.2f}ms"
                    else:
                        title2 = f"{alg2_name} (æ— æ•°æ®)"
                    
                    fig = make_subplots(
                        rows=1, cols=2,
                        subplot_titles=(title1, title2),
                        horizontal_spacing=0.15
                    )
                    
                    # å·¦ä¾§ï¼šç®—æ³•1çš„æ›²çº¿
                    if alg1_pair:
                        _, _, record_note1, replay_note1, _ = alg1_pair
                        if record_note1 and hasattr(record_note1, 'after_touch') and not record_note1.after_touch.empty:
                            x_at = (record_note1.after_touch.index + record_note1.offset) / 10.0
                            y_at = record_note1.after_touch.values
                            fig.add_trace(go.Scatter(x=x_at, y=y_at, mode='lines', name='å½•åˆ¶è§¦å', 
                                                    line=dict(color='blue', width=2), showlegend=False), row=1, col=1)
                        if record_note1 and hasattr(record_note1, 'hammers') and not record_note1.hammers.empty:
                            x_hm = (record_note1.hammers.index + record_note1.offset) / 10.0
                            y_hm = record_note1.hammers.values
                            fig.add_trace(go.Scatter(x=x_hm, y=y_hm, mode='markers', name='å½•åˆ¶é”¤å­',
                                                    marker=dict(color='blue', size=6), showlegend=False), row=1, col=1)
                        if replay_note1 and hasattr(replay_note1, 'after_touch') and not replay_note1.after_touch.empty:
                            x_at = (replay_note1.after_touch.index + replay_note1.offset) / 10.0
                            y_at = replay_note1.after_touch.values
                            fig.add_trace(go.Scatter(x=x_at, y=y_at, mode='lines', name='å›æ”¾è§¦å',
                                                    line=dict(color='red', width=2), showlegend=False), row=1, col=1)
                        if replay_note1 and hasattr(replay_note1, 'hammers') and not replay_note1.hammers.empty:
                            x_hm = (replay_note1.hammers.index + replay_note1.offset) / 10.0
                            y_hm = replay_note1.hammers.values
                            fig.add_trace(go.Scatter(x=x_hm, y=y_hm, mode='markers', name='å›æ”¾é”¤å­',
                                                    marker=dict(color='red', size=6), showlegend=False), row=1, col=1)
                    
                    # å³ä¾§ï¼šç®—æ³•2çš„æ›²çº¿
                    if alg2_pair:
                        _, _, record_note2, replay_note2, _ = alg2_pair
                        if record_note2 and hasattr(record_note2, 'after_touch') and not record_note2.after_touch.empty:
                            x_at = (record_note2.after_touch.index + record_note2.offset) / 10.0
                            y_at = record_note2.after_touch.values
                            fig.add_trace(go.Scatter(x=x_at, y=y_at, mode='lines', name='å½•åˆ¶è§¦å',
                                                    line=dict(color='blue', width=2), showlegend=False), row=1, col=2)
                        if record_note2 and hasattr(record_note2, 'hammers') and not record_note2.hammers.empty:
                            x_hm = (record_note2.hammers.index + record_note2.offset) / 10.0
                            y_hm = record_note2.hammers.values
                            fig.add_trace(go.Scatter(x=x_hm, y=y_hm, mode='markers', name='å½•åˆ¶é”¤å­',
                                                    marker=dict(color='blue', size=6), showlegend=False), row=1, col=2)
                        if replay_note2 and hasattr(replay_note2, 'after_touch') and not replay_note2.after_touch.empty:
                            x_at = (replay_note2.after_touch.index + replay_note2.offset) / 10.0
                            y_at = replay_note2.after_touch.values
                            fig.add_trace(go.Scatter(x=x_at, y=y_at, mode='lines', name='å›æ”¾è§¦å',
                                                    line=dict(color='red', width=2), showlegend=False), row=1, col=2)
                        if replay_note2 and hasattr(replay_note2, 'hammers') and not replay_note2.hammers.empty:
                            x_hm = (replay_note2.hammers.index + replay_note2.offset) / 10.0
                            y_hm = replay_note2.hammers.values
                            fig.add_trace(go.Scatter(x=x_hm, y=y_hm, mode='markers', name='å›æ”¾é”¤å­',
                                                    marker=dict(color='red', size=6), showlegend=False), row=1, col=2)
                    
                    # ä¸»æ ‡é¢˜
                    title_text = f"æŒ‰é”®ID {key_id} æ›²çº¿å¯¹æ¯”"
                    
                    fig.update_layout(
                        title=title_text,
                        height=400,
                        showlegend=False
                    )
                    fig.update_xaxes(title_text="æ—¶é—´ (ms)", row=1, col=1)
                    fig.update_xaxes(title_text="æ—¶é—´ (ms)", row=1, col=2)
                    fig.update_yaxes(title_text="å€¼", row=1, col=1)
                    fig.update_yaxes(title_text="å€¼", row=1, col=2)
                    
                    rendered_rows.append(
                        dbc.Row([
                            dbc.Col([
                                dcc.Graph(figure=fig, style={'height': '400px'})
                            ], width=12)
                        ], className="mb-3")
                    )
                
                if not rendered_rows:
                    modal_style = {
                        'display': 'block',
                        'position': 'fixed',
                        'zIndex': '9999',
                        'left': '0',
                        'top': '0',
                        'width': '100%',
                        'height': '100%',
                        'backgroundColor': 'rgba(0,0,0,0.6)',
                        'backdropFilter': 'blur(5px)'
                    }
                    return modal_style, [html.Div([
                        html.P(f"æŒ‰é”®ID {key_id} æ²¡æœ‰å¯æ˜¾ç¤ºçš„å¯¹æ¯”æ•°æ®", className="text-muted text-center")
                    ])]
                
                # æ˜¾ç¤ºæ¨¡æ€æ¡†
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                
                return modal_style, rendered_rows
                
            except Exception as e:
                logger.error(f"âŒ ç”ŸæˆæŒ‰é”®æ›²çº¿å¯¹æ¯”å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                return modal_style, [html.Div([
                    html.P(f"ç”Ÿæˆå¯¹æ¯”å›¾å¤±è´¥: {str(e)}", className="text-danger text-center")
                ])]
        
        # å…¶ä»–æƒ…å†µï¼Œä¿æŒå½“å‰çŠ¶æ€
        return current_style, []
    
    # ç€‘å¸ƒå›¾ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True)],
        [Input('main-plot', 'clickData'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True,
        prevent_duplicate=True
    )
    def handle_waterfall_click(click_data, close_modal_clicks, close_btn_clicks, session_id, current_style):
        """å¤„ç†ç€‘å¸ƒå›¾ç‚¹å‡»ï¼Œæ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰"""
        from dash import callback_context, no_update
        
        print("=" * 80)
        print("ğŸš€ handle_waterfall_click å›è°ƒè¢«è§¦å‘ï¼")
        print("=" * 80)
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            print("âŒ æ²¡æœ‰è§¦å‘æº")
            return current_style, []
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        print(f"ğŸ” è§¦å‘ID: {trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            print("âœ… å…³é—­æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, []
        
        # å¦‚æœæ˜¯ç€‘å¸ƒå›¾ç‚¹å‡»
        if trigger_id == 'main-plot' and click_data:
            print("ğŸ¯ æ£€æµ‹åˆ°ç€‘å¸ƒå›¾ç‚¹å‡»ï¼")
            
            backend = session_manager.get_backend(session_id)
            if not backend:
                print("âŒ backendä¸ºç©º")
                return current_style, []
            
            try:
                if 'points' not in click_data or len(click_data['points']) == 0:
                    print("âŒ clickDataä¸­æ²¡æœ‰points")
                    return current_style, []
                
                point = click_data['points'][0]
                if not point.get('customdata'):
                    print("âŒ pointä¸­æ²¡æœ‰customdata")
                    return current_style, []
                
                # æå–customdata
                raw_customdata = point['customdata']
                customdata = raw_customdata[0] if isinstance(raw_customdata, list) and len(raw_customdata) > 0 and isinstance(raw_customdata[0], list) else raw_customdata
                
                print(f"ğŸ“¦ customdata: {customdata}")
                
                if not isinstance(customdata, list) or len(customdata) < 7:
                    print(f"âŒ customdataæ ¼å¼é”™è¯¯: ç±»å‹={type(customdata)}, é•¿åº¦={len(customdata) if isinstance(customdata, list) else 'N/A'}")
                    return current_style, []
                
                # ä»customdataæå–ä¿¡æ¯ï¼š[t_on/10, t_off/10, original_key_id, value, label, index, algorithm_name]
                algorithm_name = customdata[6]
                key_id = int(customdata[2])
                data_type = customdata[4]  # 'record' æˆ– 'play'
                index = int(customdata[5])
                
                print(f"ğŸ“Š æå–çš„æ•°æ®: algorithm_name={algorithm_name}, key_id={key_id}, data_type={data_type}, index={index}")
                
                # è·å–ç®—æ³•å¯¹è±¡
                if not backend.multi_algorithm_manager:
                    backend._ensure_multi_algorithm_manager()
                algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name)
                if not algorithm or not algorithm.analyzer:
                    print("âŒ ç®—æ³•å¯¹è±¡æˆ–analyzerä¸ºç©º")
                    return current_style, []
                
                # è·å–matched_pairsï¼ˆå·²ä¿å­˜çš„é…å¯¹æ•°æ®ï¼‰
                matched_pairs = algorithm.analyzer.matched_pairs if hasattr(algorithm.analyzer, 'matched_pairs') else []
                
                # è·å–æœ‰æ•ˆæ•°æ®ï¼ˆåŒ…å«å·²é…å¯¹å’Œå¼‚å¸¸çš„æ•°æ®ï¼‰
                valid_record_data = algorithm.analyzer.valid_record_data if hasattr(algorithm.analyzer, 'valid_record_data') else []
                valid_replay_data = algorithm.analyzer.valid_replay_data if hasattr(algorithm.analyzer, 'valid_replay_data') else []
                
                # æ­¥éª¤1ï¼šå…ˆåˆ¤æ–­è¿™ä¸ªæŒ‰é”®IDï¼ˆé€šè¿‡indexï¼‰æ˜¯å¦åœ¨matched_pairsä¸­æœ‰åŒ¹é…å¯¹
                has_matched_pair = False
                record_note = None
                replay_note = None
                
                print(f"ğŸ” å¼€å§‹æŸ¥æ‰¾åŒ¹é…å¯¹: key_id={key_id}, data_type={data_type}, index={index}")
                print(f"ğŸ“Š matched_pairsæ•°é‡: {len(matched_pairs)}")
                
                # æ ¹æ®data_typeå’Œindexåœ¨matched_pairsä¸­æŸ¥æ‰¾
                if data_type == 'record':
                    # ç‚¹å‡»çš„æ˜¯å½•åˆ¶çº¿ï¼ŒæŸ¥æ‰¾r_idx == indexçš„åŒ¹é…å¯¹
                    print(f"ğŸ” åœ¨matched_pairsä¸­æŸ¥æ‰¾: r_idx == {index}")
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_idx == index and r_note.id == key_id:
                            # æ‰¾åˆ°åŒ¹é…å¯¹
                            has_matched_pair = True
                            record_note = r_note
                            replay_note = p_note
                            print(f"âœ… æ‰¾åˆ°å®Œæ•´åŒ¹é…å¯¹ï¼")
                            break
                else:
                    # ç‚¹å‡»çš„æ˜¯æ’­æ”¾çº¿ï¼ŒæŸ¥æ‰¾p_idx == indexçš„åŒ¹é…å¯¹
                    print(f"ğŸ” åœ¨matched_pairsä¸­æŸ¥æ‰¾: p_idx == {index}")
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if p_idx == index and p_note.id == key_id:
                            # æ‰¾åˆ°åŒ¹é…å¯¹
                            has_matched_pair = True
                            record_note = r_note
                            replay_note = p_note
                            print(f"âœ… æ‰¾åˆ°å®Œæ•´åŒ¹é…å¯¹ï¼")
                            break
                
                print(f"ğŸ¯ åŒ¹é…ç»“æœ: has_matched_pair={has_matched_pair}")
                
                # æ­¥éª¤2ï¼šæ ¹æ®åˆ¤æ–­ç»“æœç”Ÿæˆæ›²çº¿
                import spmid
                if has_matched_pair:
                    # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ç®—æ³•ä¸­åŒ¹é…åˆ°åŒä¸€ä¸ªå½•åˆ¶éŸ³ç¬¦çš„æ’­æ”¾éŸ³ç¬¦
                    other_algorithm_notes = []  # [(algorithm_name, play_note), ...]
                    if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                        for alg in active_algorithms:
                            if alg.metadata.algorithm_name == algorithm_name:
                                continue  # è·³è¿‡å½“å‰ç®—æ³•ï¼ˆå·²ç»ç»˜åˆ¶ï¼‰
                            
                            if not alg.analyzer or not hasattr(alg.analyzer, 'matched_pairs'):
                                continue
                            
                            alg_matched_pairs = alg.analyzer.matched_pairs
                            # æŸ¥æ‰¾åŒ¹é…åˆ°åŒä¸€ä¸ªrecord_indexçš„æ’­æ”¾éŸ³ç¬¦
                            for r_idx, p_idx, r_note, p_note in alg_matched_pairs:
                                if r_idx == index and r_note.id == key_id:
                                    other_algorithm_notes.append((alg.metadata.algorithm_name, p_note))
                                    logger.info(f"âœ… æ‰¾åˆ°ç®—æ³• '{alg.metadata.algorithm_name}' çš„åŒ¹é…æ’­æ”¾éŸ³ç¬¦")
                                    break
                    
                    # æœ‰åŒ¹é…å¯¹ï¼šç»˜åˆ¶å½•åˆ¶+æ’­æ”¾å¯¹æ¯”æ›²çº¿ï¼ˆåœ¨åŒä¸€ä¸ªæ‚¬æµ®çª—ä¸Šï¼ŒåŒ…å«å…¶ä»–ç®—æ³•çš„æ’­æ”¾æ›²çº¿ï¼‰
                    detail_figure_combined = spmid.plot_note_comparison_plotly(
                        record_note, 
                        replay_note, 
                        algorithm_name=algorithm_name,
                        other_algorithm_notes=other_algorithm_notes  # ä¼ é€’å…¶ä»–ç®—æ³•çš„æ’­æ”¾éŸ³ç¬¦
                    )
                    print(f"âœ… æŒ‰é”®ID {key_id} æœ‰åŒ¹é…å¯¹ï¼Œç»˜åˆ¶å½•åˆ¶+æ’­æ”¾å¯¹æ¯”æ›²çº¿")
                else:
                    # æ²¡æœ‰åŒ¹é…å¯¹ï¼šåªç»˜åˆ¶è¿™ä¸ªæ•°æ®ç‚¹çš„æ•°æ®ï¼ˆå¯èƒ½æ˜¯å½•åˆ¶ï¼Œä¹Ÿå¯èƒ½æ˜¯æ’­æ”¾ï¼‰
                    if data_type == 'record' and index >= 0 and index < len(valid_record_data):
                        record_note = valid_record_data[index]
                        replay_note = None
                    elif data_type == 'play' and index >= 0 and index < len(valid_replay_data):
                        record_note = None
                        replay_note = valid_replay_data[index]
                    
                    detail_figure_combined = spmid.plot_note_comparison_plotly(record_note, replay_note, algorithm_name=algorithm_name)
                    print(f"âš ï¸ æŒ‰é”®ID {key_id} æ— åŒ¹é…å¯¹ï¼Œåªç»˜åˆ¶å•ä¾§æ•°æ®")
                
                if not detail_figure_combined:
                    print("âŒ æ›²çº¿ç”Ÿæˆå¤±è´¥")
                    return current_style, []
                
                # æ˜¾ç¤ºæ¨¡æ€æ¡†
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                
                import dash.dcc as dcc
                rendered_row = dcc.Graph(figure=detail_figure_combined, style={'height': '600px'})
                
                print("âœ… æ˜¾ç¤ºæ¨¡æ€æ¡†")
                return modal_style, [rendered_row]
                
            except Exception as e:
                print(f"âŒ ç€‘å¸ƒå›¾ç‚¹å‡»å¤„ç†å¤±è´¥: {e}")
                logger.error(f"âŒ ç€‘å¸ƒå›¾ç‚¹å‡»å¤„ç†å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                print(traceback.format_exc())
                return current_style, []
        
        # å…¶ä»–æƒ…å†µï¼Œä¿æŒå½“å‰çŠ¶æ€
        return current_style, []
    
    # é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True)],
        [Input('hammer-velocity-delay-scatter-plot', 'clickData'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True,
        prevent_duplicate=True
    )
    def handle_hammer_velocity_scatter_click(click_data, close_modal_clicks, close_btn_clicks, session_id, current_style):
        """å¤„ç†é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ç‚¹å‡»ï¼Œæ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰- å‚è€ƒæŒ‰é”®ä¸å»¶æ—¶Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾çš„é€»è¾‘"""
        from dash import callback_context
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            logger.debug("âš ï¸ æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒï¼šæ²¡æœ‰è§¦å‘æº")
            return current_style, []
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"ğŸ”„ æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            logger.info("âœ… å…³é—­æŒ‰é”®æ›²çº¿å¯¹æ¯”æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, []
        
        # å¦‚æœæ˜¯æ•£ç‚¹å›¾ç‚¹å‡»
        if trigger_id == 'hammer-velocity-delay-scatter-plot':
            logger.info(f"ğŸ”„ æ•£ç‚¹å›¾ç‚¹å‡»ï¼šclick_data={click_data}")
            backend = session_manager.get_backend(session_id)
            if not backend:
                logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°backend")
                return current_style, []
            
            if not click_data or 'points' not in click_data or not click_data['points']:
                logger.warning("âš ï¸ click_dataä¸ºç©ºæˆ–æ²¡æœ‰points")
                return current_style, []
            
            try:
                # è·å–ç‚¹å‡»çš„æ•°æ®ç‚¹
                point = click_data['points'][0]
                logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡» - ç‚¹å‡»ç‚¹æ•°æ®: {point}")
                
                if not point.get('customdata'):
                    logger.warning("âš ï¸ æ•£ç‚¹å›¾ç‚¹å‡» - ç‚¹æ²¡æœ‰customdata")
                    return current_style, []
                
                # å®‰å…¨åœ°æå–customdataï¼ˆå‚è€ƒZ-Scoreæ•£ç‚¹å›¾çš„é€»è¾‘ï¼‰
                raw_customdata = point['customdata']
                logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡» - raw_customdataç±»å‹: {type(raw_customdata)}, å€¼: {raw_customdata}")
                
                if isinstance(raw_customdata, list) and len(raw_customdata) > 0:
                    customdata = raw_customdata[0] if isinstance(raw_customdata[0], list) else raw_customdata
                else:
                    customdata = raw_customdata
                
                # ç¡®ä¿customdataæ˜¯åˆ—è¡¨ç±»å‹
                if not isinstance(customdata, list):
                    logger.warning(f"âš ï¸ æ•£ç‚¹å›¾ç‚¹å‡» - customdataä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(customdata)}, å€¼: {customdata}")
                    return current_style, []
                
                logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡» - customdata: {customdata}, é•¿åº¦: {len(customdata)}")
                
                # è§£æcustomdata
                # å•ç®—æ³•æ¨¡å¼: [delay_ms, record_idx, replay_idx]
                # å¤šç®—æ³•æ¨¡å¼: [delay_ms, record_idx, replay_idx, algorithm_name]
                if len(customdata) < 3:
                    logger.warning(f"âš ï¸ customdataé•¿åº¦ä¸è¶³ï¼š{len(customdata)}")
                    return current_style, []
                
                delay_ms = customdata[0]
                record_idx = customdata[1]
                replay_idx = customdata[2]
                algorithm_name = customdata[3] if len(customdata) > 3 else None
                
                logger.info(f"ğŸ–±ï¸ æ•£ç‚¹å›¾ç‚¹å‡»: ç®—æ³•={algorithm_name}, record_idx={record_idx}, replay_idx={replay_idx}")
                
                # å¦‚æœæ˜¯å¤šç®—æ³•æ¨¡å¼ä¸”æœ‰ç®—æ³•åç§°ï¼Œä½¿ç”¨generate_multi_algorithm_scatter_detail_plot_by_indices
                if algorithm_name:
                    # å¤šç®—æ³•æ¨¡å¼ï¼šä½¿ç”¨ä¸Z-Scoreæ•£ç‚¹å›¾ç›¸åŒçš„æ–¹æ³•
                    detail_figure1, detail_figure2, detail_figure_combined = backend.generate_multi_algorithm_scatter_detail_plot_by_indices(
                        algorithm_name=algorithm_name,
                        record_index=record_idx,
                        replay_index=replay_idx
                    )
                    
                    logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - å›¾è¡¨ç”Ÿæˆç»“æœ: figure1={detail_figure1 is not None}, figure2={detail_figure2 is not None}, figure_combined={detail_figure_combined is not None}")
                    
                    if detail_figure1 and detail_figure2 and detail_figure_combined:
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        logger.info("âœ… æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - è¿”å›æ¨¡æ€æ¡†å’Œå›¾è¡¨")
                        # å°†Plotly figureå¯¹è±¡åŒ…è£…åœ¨dcc.Graphç»„ä»¶ä¸­
                        return modal_style, dcc.Graph(figure=detail_figure_combined, style={'height': '600px'})
                    else:
                        logger.warning(f"âš ï¸ æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒ - å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼Œéƒ¨åˆ†å›¾è¡¨ä¸ºNone")
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        return modal_style, [html.Div([
                            html.P("å›¾è¡¨ç”Ÿæˆå¤±è´¥", className="text-danger text-center")
                        ])]
                else:
                    # å•ç®—æ³•æ¨¡å¼ï¼šä½¿ç”¨generate_scatter_detail_plot_by_indices
                    detail_figure1, detail_figure2, detail_figure_combined = backend.generate_scatter_detail_plot_by_indices(
                        record_index=record_idx,
                        replay_index=replay_idx
                    )
                    
                    logger.info(f"ğŸ” æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒï¼ˆå•ç®—æ³•ï¼‰ - å›¾è¡¨ç”Ÿæˆç»“æœ: figure1={detail_figure1 is not None}, figure2={detail_figure2 is not None}, figure_combined={detail_figure_combined is not None}")
                    
                    if detail_figure1 and detail_figure2 and detail_figure_combined:
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        logger.info("âœ… æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒï¼ˆå•ç®—æ³•ï¼‰ - è¿”å›æ¨¡æ€æ¡†å’Œå›¾è¡¨")
                        # å°†Plotly figureå¯¹è±¡åŒ…è£…åœ¨dcc.Graphç»„ä»¶ä¸­
                        return modal_style, dcc.Graph(figure=detail_figure_combined, style={'height': '600px'})
                    else:
                        logger.warning(f"âš ï¸ æ•£ç‚¹å›¾ç‚¹å‡»å›è°ƒï¼ˆå•ç®—æ³•ï¼‰ - å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼Œéƒ¨åˆ†å›¾è¡¨ä¸ºNone")
                        modal_style = {
                            'display': 'block',
                            'position': 'fixed',
                            'zIndex': '9999',
                            'left': '0',
                            'top': '0',
                            'width': '100%',
                            'height': '100%',
                            'backgroundColor': 'rgba(0,0,0,0.6)',
                            'backdropFilter': 'blur(5px)'
                        }
                        return modal_style, [html.Div([
                            html.P("å›¾è¡¨ç”Ÿæˆå¤±è´¥", className="text-danger text-center")
                        ])]
                
            except Exception as e:
                logger.error(f"âŒ ç”Ÿæˆæ›²çº¿å¯¹æ¯”å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                return modal_style, [html.Div([
                    html.P(f"ç”Ÿæˆå¯¹æ¯”å›¾å¤±è´¥: {str(e)}", className="text-danger text-center")
                ])]
        
        # å…¶ä»–æƒ…å†µï¼Œä¿æŒå½“å‰çŠ¶æ€
        return current_style, []
    
    # ==================== æ›²çº¿å¯¹é½æµ‹è¯•å›è°ƒ ====================
    @app.callback(
        Output('curve-alignment-test-result', 'children'),
        Input('btn-test-curve-alignment', 'n_clicks'),
        State('session-id', 'data'),
        prevent_initial_call=True
    )
    def handle_test_curve_alignment(n_clicks, session_id):
        """å¤„ç†æ›²çº¿å¯¹é½æµ‹è¯•æŒ‰é’®ç‚¹å‡»"""
        if n_clicks is None or n_clicks == 0:
            return html.Div("ç‚¹å‡»æŒ‰é’®å¼€å§‹æµ‹è¯•", 
                           className="text-muted text-center",
                           style={'padding': '20px', 'fontSize': '14px'})
        
        try:
            backend = session_manager.get_backend(session_id)
            if not backend:
                return html.Div([
                    dbc.Alert("âš ï¸ æ— æ³•è·å–backendï¼Œè¯·å…ˆä¸Šä¼ æ•°æ®", color="warning")
                ])
            
            # æ‰§è¡Œæµ‹è¯•
            test_result = backend.test_curve_alignment()
            
            if test_result is None or test_result.get('status') != 'success':
                error_msg = test_result.get('message', 'æµ‹è¯•å¤±è´¥') if test_result else 'æµ‹è¯•å¤±è´¥'
                return html.Div([
                    dbc.Alert([
                        html.I(className="fas fa-exclamation-triangle me-2"),
                        html.Strong(f"æµ‹è¯•å¤±è´¥: {error_msg}")
                    ], color="danger")
                ])
            
            result = test_result['result']
            comparison_fig = test_result.get('comparison_figure')  # å¯¹é½å‰åå¯¹æ¯”å›¾ï¼ˆå‘åå…¼å®¹ï¼‰
            all_stages_fig = test_result.get('all_stages_figure')  # æ‰€æœ‰å¤„ç†é˜¶æ®µçš„å¯¹æ¯”å›¾
            
            # æ„å»ºç»“æœæ˜¾ç¤º
            children = []
            
            # æ‰€æœ‰å¤„ç†é˜¶æ®µçš„å¯¹æ¯”å›¾ï¼ˆä¸»è¦æ˜¾ç¤ºï¼‰
            if all_stages_fig is not None:
                # æ ¹æ®å­å›¾æ•°é‡åŠ¨æ€è°ƒæ•´é«˜åº¦ï¼ˆæ¯ä¸ªå­å›¾çº¦450pxï¼ŒåŠ ä¸Šé—´è·ï¼‰
                # é€šå¸¸æœ‰6ä¸ªå­å›¾ï¼ˆé˜¶æ®µ1-4ï¼Œé˜¶æ®µ5aï¼Œé˜¶æ®µ5bï¼‰ï¼Œæ‰€ä»¥æ€»é«˜åº¦çº¦2700px
                children.append(html.Div([
                    html.H6("å„å¤„ç†é˜¶æ®µæ›²çº¿å¯¹æ¯”ï¼ˆæ’­æ”¾æ›²çº¿å¯¹é½åˆ°å½•åˆ¶æ›²çº¿ï¼‰", 
                           className="mb-3",
                           style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                    dcc.Graph(figure=all_stages_fig, style={'height': '2800px', 'minHeight': '2000px'})
                ], className="mb-4"))
            
            # ç›¸ä¼¼åº¦ä¿¡æ¯
            children.append(
                html.Div([
                    html.H6("ç›¸ä¼¼åº¦ç»“æœ", className="mb-3",
                           style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                    dbc.Row([
                        dbc.Col([
                            dbc.Card([
                                dbc.CardBody([
                                    html.Small("ä¸Šå‡æ²¿ç›¸ä¼¼åº¦", className="text-muted d-block mb-1"),
                                    html.H4(f"{result.get('rising_edge_similarity', 0):.3f}", 
                                           style={'color': '#1f77b4', 'fontWeight': 'bold'})
                                ])
                            ], color="primary", outline=True)
                        ], width=4),
                        dbc.Col([
                            dbc.Card([
                                dbc.CardBody([
                                    html.Small("ä¸‹é™æ²¿ç›¸ä¼¼åº¦", className="text-muted d-block mb-1"),
                                    html.H4(f"{result.get('falling_edge_similarity', 0):.3f}", 
                                           style={'color': '#ff7f0e', 'fontWeight': 'bold'})
                                ])
                            ], color="warning", outline=True)
                        ], width=4),
                        dbc.Col([
                            dbc.Card([
                                dbc.CardBody([
                                    html.Small("æ•´ä½“ç›¸ä¼¼åº¦", className="text-muted d-block mb-1"),
                                    html.H4(f"{result.get('overall_similarity', 0):.3f}", 
                                           style={'color': '#2ca02c', 'fontWeight': 'bold'})
                                ])
                            ], color="success", outline=True)
                        ], width=4)
                    ], className="mb-3"),
                    dbc.Row([
                        dbc.Col([
                            html.Small(f"DTWè·ç¦»: {result.get('dtw_distance', 0):.3f}", 
                                      className="text-muted"),
                            html.Br(),
                            html.Small(f"æµ‹è¯•æ•°æ®: record_index={test_result.get('record_index', 'N/A')}, "
                                      f"replay_index={test_result.get('replay_index', 'N/A')}", 
                                      className="text-muted")
                        ], width=12)
                    ])
                ], className="mb-4")
            )
            
            # å¯¹é½å‰åå¯¹æ¯”å›¾
            if comparison_fig:
                children.append(
                    html.Div([
                        html.H6("å¯¹é½å‰åå¯¹æ¯”", className="mb-3",
                               style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                        dcc.Graph(
                            figure=comparison_fig,
                            style={'height': '800px'}
                        )
                    ], className="mb-4")
                )
            else:
                children.append(
                    html.Div([
                        dbc.Alert("âš ï¸ æ— æ³•ç”Ÿæˆå¯¹é½å¯¹æ¯”å›¾", color="warning")
                    ])
                )
            
            return html.Div(children)
            
        except Exception as e:
            logger.error(f"âŒ æ›²çº¿å¯¹é½æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return html.Div([
                dbc.Alert([
                    html.I(className="fas fa-exclamation-triangle me-2"),
                    html.Strong(f"æµ‹è¯•å¤±è´¥: {str(e)}")
                ], color="danger")
            ])

