"""
å›è°ƒå‡½æ•°æ¨¡å— - å¤„ç†Dashåº”ç”¨çš„æ‰€æœ‰å›è°ƒé€»è¾‘
åŒ…å«æ–‡ä»¶ä¸Šä¼ ã€å†å²è®°å½•è¡¨æ ¼äº¤äº’ç­‰å›è°ƒå‡½æ•°
"""
import base64
import json
import time
import traceback
import uuid
import math

from typing import Dict, Optional, Union, TypedDict, Tuple, List, Any
from collections import defaultdict

import pandas as pd
import numpy as np

# SPMIDå¯¼å…¥
from spmid.spmid_analyzer import SPMIDAnalyzer
import spmid


from dash import html, no_update
from dash._callback import NoUpdate
            
import dash
import dash.dependencies
import dash.dcc as dcc
import dash_bootstrap_components as dbc
from dash import Input, Output, State, ALL, callback_context, dcc, dash_table
from dash._callback_context import CallbackContext
from datetime import datetime

import plotly.graph_objects as go
from plotly.graph_objects import Figure

from scipy import stats
from ui.layout_components import create_report_layout, empty_figure, create_multi_algorithm_upload_area, create_multi_algorithm_management_area
from backend.session_manager import SessionManager
from ui.ui_processor import UIProcessor
from ui.multi_file_upload_handler import MultiFileUploadHandler
from ui.waterfall_jump_handler import WaterfallJumpHandler
from ui.delay_time_series_handler import DelayTimeSeriesHandler
from ui.relative_delay_distribution_handler import RelativeDelayDistributionHandler
from ui.delay_value_click_handler import DelayValueClickHandler
from ui.delay_histogram_click_handler import DelayHistogramClickHandler
from grade_detail_callbacks import register_all_callbacks
from utils.logger import Logger
# åç«¯ç±»å‹å¯¼å…¥
from backend.piano_analysis_backend import PianoAnalysisBackend



logger = Logger.get_logger()

# è‡ªå®šä¹‰ç±»å‹å®šä¹‰

class AlgorithmMetadata:
    """ç®—æ³•å…ƒæ•°æ®çš„ç±»å‹å®šä¹‰"""
    algorithm_name: str
    display_name: str
    filename: str

class OffsetAlignmentDataItem(TypedDict):
    """åç§»å¯¹é½æ•°æ®é¡¹çš„ç±»å‹å®šä¹‰"""
    record_index: int
    replay_index: int
    key_id: int
    record_keyon: float
    replay_keyon: float
    keyon_offset: float
    record_keyoff: float
    replay_keyoff: float
    duration_offset: float
    average_offset: float
    record_duration: float
    replay_duration: float
    duration_diff: float

class OffsetAlignmentTableItem(TypedDict):
    """åç§»å¯¹é½è¡¨æ ¼æ•°æ®é¡¹çš„ç±»å‹å®šä¹‰"""
    algorithm_name: str
    key_id: Union[int, str]
    count: int
    median: Union[float, str]
    mean: Union[float, str]
    std: Union[float, str]
    variance: Union[float, str]
    min: Union[float, str]
    max: Union[float, str]
    range: Union[float, str]
    status: str

class SPMIDNote:
    """SPMIDéŸ³ç¬¦å¯¹è±¡çš„ç±»å‹å®šä¹‰"""
    id: int
    hammers: pd.Series  # é”¤å‡»æ•°æ®ï¼Œpandas Serieså¯¹è±¡ï¼Œç´¢å¼•ä¸ºæ—¶é—´æˆ³

class AlgorithmInstance:
    """ç®—æ³•å®ä¾‹çš„ç±»å‹å®šä¹‰"""
    metadata: AlgorithmMetadata
    analyzer: Optional[SPMIDAnalyzer]  # SPMIDåˆ†æå™¨å®ä¾‹

    def is_ready(self) -> bool:
        """æ£€æŸ¥ç®—æ³•æ˜¯å¦å°±ç»ª"""
        pass

# çŠ¶æ€å­—å…¸ç±»å‹å®šä¹‰
class StateDict(TypedDict, total=False):
    """çŠ¶æ€å­—å…¸ç±»å‹å®šä¹‰"""
    has_upload: bool
    upload_content: Optional[str]
    filename: Optional[str]
    has_history: bool
    history_id: Optional[str]
    last_upload_content: Optional[str]
    last_history_id: Optional[str]

# æ–‡ä»¶ä¸Šä¼ ç»“æœæ•°æ®ç±»å‹å®šä¹‰
class UploadResultData(TypedDict):
    """æ–‡ä»¶ä¸Šä¼ æˆåŠŸæ—¶çš„ç»“æœæ•°æ®å­—å…¸"""
    filename: str
    record_count: int
    replay_count: int
    history_id: str

def _create_empty_figure_for_callback(title: str) -> Figure:
    """åˆ›å»ºç”¨äºå›è°ƒçš„ç©ºPlotly figureå¯¹è±¡"""
    fig = go.Figure()
    fig.add_annotation(
        x=0.5,
        y=0.5,
        xref="paper",
        yref="paper",
        text=title,
        showarrow=False,
        font=dict(size=16, color="gray"),
        align="center"
    )

    fig.update_layout(
        title=title,
        xaxis=dict(visible=False),
        yaxis=dict(visible=False),
        height=600,
        template='plotly_white',
        showlegend=False
    )

    return fig


def _detect_trigger_source(ctx: CallbackContext, backend: Optional[PianoAnalysisBackend],
                          contents: Optional[str], filename: Optional[str], history_id: Optional[str]) -> str:
    """
    æ£€æµ‹ç”¨æˆ·æ“ä½œçš„è§¦å‘æºï¼Œç¡®å®šéœ€è¦æ‰§è¡Œçš„å¤„ç†é€»è¾‘
    
    è§¦å‘æºä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š
    1. æ–°æ–‡ä»¶ä¸Šä¼  - æœ€é«˜ä¼˜å…ˆçº§ï¼Œä¼šé‡æ–°åŠ è½½æ•°æ®
    2. å†å²è®°å½•é€‰æ‹© - ä¸­ç­‰ä¼˜å…ˆçº§ï¼Œä¼šåˆ‡æ¢æ•°æ®æº
    3. æŒ‰é’®ç‚¹å‡» - æœ€ä½ä¼˜å…ˆçº§ï¼ŒåŸºäºå½“å‰æ•°æ®ç”Ÿæˆè§†å›¾
    
    Args:
        ctx: Dashå›è°ƒä¸Šä¸‹æ–‡ï¼ŒåŒ…å«è§¦å‘ä¿¡æ¯
        backend: åç«¯å®ä¾‹ï¼Œç”¨äºçŠ¶æ€ç®¡ç†
        contents: ä¸Šä¼ æ–‡ä»¶çš„å†…å®¹ï¼ˆbase64ç¼–ç ï¼‰
        filename: ä¸Šä¼ æ–‡ä»¶çš„æ–‡ä»¶å
        history_id: é€‰æ‹©çš„å†å²è®°å½•ID
        
    Returns:
        str: è§¦å‘æºç±»å‹ ('upload', 'history', 'waterfall', 'report', 'skip')
             - 'upload': æ–°æ–‡ä»¶ä¸Šä¼ 
             - 'history': å†å²è®°å½•é€‰æ‹©
             - 'waterfall': ç€‘å¸ƒå›¾æŒ‰é’®ç‚¹å‡»
             - 'report': æŠ¥å‘ŠæŒ‰é’®ç‚¹å‡»
             - 'skip': è·³è¿‡å¤„ç†ï¼ˆé‡å¤æ“ä½œï¼‰
    """
    # è·å–å½“å‰çŠ¶æ€ä¿¡æ¯
    current_time = time.time()
    current_state = _get_current_state(contents, filename, history_id)
    previous_state = _get_previous_state(backend)
    
    # ä»å›è°ƒä¸Šä¸‹æ–‡æ£€æµ‹è§¦å‘æº
    trigger_source = _detect_trigger_from_context(ctx, current_state, previous_state, backend, current_time)
    
    # å¦‚æœæ— æ³•ä»ä¸Šä¸‹æ–‡ç¡®å®šï¼Œåˆ™åŸºäºçŠ¶æ€å˜åŒ–æ™ºèƒ½åˆ¤æ–­
    if not trigger_source:
        trigger_source = _detect_trigger_from_state_change(current_state, previous_state, backend, current_time)
    
    # è®°å½•æœ€ç»ˆç»“æœ
    data_source = getattr(backend, '_data_source', 'none') if backend else 'none'
    logger.info(f"ğŸ” æœ€ç»ˆç¡®å®šè§¦å‘æº: {trigger_source}, å½“å‰æ•°æ®æº: {data_source}")
    return trigger_source

def _get_current_state(contents: Optional[str], filename: Optional[str], history_id: Optional[str]) -> StateDict:
    """è·å–å½“å‰çŠ¶æ€ä¿¡æ¯"""
    return {
        'has_upload': bool(contents and filename),
        'has_history': history_id is not None,
        'upload_content': contents,
        'filename': filename,
        'history_id': history_id
    }

def _get_previous_state(backend: Optional[PianoAnalysisBackend]) -> StateDict:
    """è·å–ä¸Šæ¬¡çš„çŠ¶æ€ä¿¡æ¯"""
    if not backend:
        return {
            'last_upload_content': None,
            'last_history_id': None
        }
    
    return {
        'last_upload_content': getattr(backend, '_last_upload_content', None),
        'last_history_id': getattr(backend, '_last_selected_history_id', None)
    }

def _detect_trigger_from_context(ctx: CallbackContext, current_state: StateDict, previous_state: StateDict,
                               backend: PianoAnalysisBackend, current_time: float) -> Optional[str]:
    """ä»å›è°ƒä¸Šä¸‹æ–‡æ£€æµ‹è§¦å‘æº"""
    if not ctx.triggered:
        return None
    
    recent_trigger = ctx.triggered[0]['prop_id']
    
    # æ£€æŸ¥å†å²è®°å½•é€‰æ‹©è§¦å‘
    if 'history-dropdown' in recent_trigger:
        return _handle_history_trigger(current_state, previous_state, backend, current_time)
    
    return None

def _handle_upload_trigger(current_state: StateDict, previous_state: StateDict,
                          backend: PianoAnalysisBackend, current_time: float) -> Optional[str]:
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ è§¦å‘ - å…è®¸é‡å¤ä¸Šä¼ ç›¸åŒæ–‡ä»¶ä»¥è¿›è¡Œä¸€è‡´æ€§éªŒè¯"""
    # æ³¨æ„ï¼šHTMLæ–‡ä»¶è¾“å…¥åœ¨é€‰æ‹©ç›¸åŒæ–‡ä»¶æ—¶ä¸ä¼šè§¦å‘changeäº‹ä»¶
    # æ‰€ä»¥æˆ‘ä»¬ä¸ä¾èµ–current_state['has_upload']ï¼Œè€Œæ˜¯åªè¦è§¦å‘äº†å›è°ƒå°±å¤„ç†

    # è®°å½•ä¸Šä¼ å°è¯•ï¼Œæ— è®ºæ˜¯å¦æœ‰æ–°å†…å®¹
    filename = current_state.get('filename', 'unknown')
    logger.info(f"[UPLOAD] æ–‡ä»¶ä¸Šä¼ å›è°ƒè¢«è§¦å‘: {filename}")

    # æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤éªŒè¯ï¼ˆä½¿ç”¨ç›¸åŒæ–‡ä»¶ï¼‰
    is_repeat_verification = False
    upload_content = current_state.get('upload_content')

    if not upload_content:
        # æ²¡æœ‰æ–°å†…å®¹ï¼Œä½¿ç”¨ä¸Šæ¬¡çš„å†…å®¹ï¼ˆé‡å¤éªŒè¯åœºæ™¯ï¼‰
        upload_content = previous_state.get('last_upload_content')
        if upload_content:
            is_repeat_verification = True
            logger.info(f"ğŸ”„ æ£€æµ‹åˆ°é‡å¤éªŒè¯è¯·æ±‚ï¼šä½¿ç”¨ç›¸åŒæ–‡ä»¶é‡æ–°å¤„ç†")
            logger.info(f"ğŸ¯ è¿™å°†æ˜¯æ•°æ®ä¸€è‡´æ€§éªŒè¯çš„ç¬¬ {getattr(backend, '_analysis_count', 0) + 1} æ¬¡åˆ†æ")
        else:
            logger.warning(f"[UPLOAD] æ²¡æœ‰å¯ç”¨çš„æ–‡ä»¶å†…å®¹")
            return None
    else:
        logger.info(f"ğŸ“ æ–°æ–‡ä»¶ä¸Šä¼ : {filename}")

    # è®°å½•éªŒè¯çŠ¶æ€
    if is_repeat_verification:
        backend._is_repeat_verification = True
    else:
        backend._is_repeat_verification = False

    _update_upload_state(backend, upload_content, current_time, filename)
    return 'upload'

def _handle_history_trigger(current_state: StateDict, previous_state: StateDict,
                           backend: PianoAnalysisBackend, current_time: float) -> Optional[str]:
    """å¤„ç†å†å²è®°å½•é€‰æ‹©è§¦å‘"""
    if not current_state['has_history']:
        return None
    
    # æ£€æŸ¥å†å²è®°å½•é€‰æ‹©æ˜¯å¦å‘ç”Ÿå˜åŒ–
    if current_state['history_id'] != previous_state['last_history_id']:
        _update_history_state(backend, current_state['history_id'], current_time)
        logger.info(f"[PROCESS] æ£€æµ‹åˆ°å†å²è®°å½•é€‰æ‹©å˜åŒ–: {current_state['history_id']}")
        return 'history'
    else:
        logger.warning("[WARNING] å†å²è®°å½•é€‰æ‹©æœªå˜åŒ–ï¼Œè·³è¿‡é‡å¤å¤„ç†")
        return 'skip'

def _detect_trigger_from_state_change(current_state: StateDict, previous_state: StateDict,
                                     backend: PianoAnalysisBackend, current_time: float) -> Optional[str]:
    """åŸºäºçŠ¶æ€å˜åŒ–æ™ºèƒ½æ£€æµ‹è§¦å‘æº"""
    # æ–‡ä»¶ä¸Šä¼ ç°åœ¨ç”±ç»Ÿä¸€ç®¡ç†å™¨å¤„ç†ï¼Œè¿™é‡Œåªå¤„ç†å†å²è®°å½•
    if (current_state['has_history'] and
          current_state['history_id'] != previous_state['last_history_id']):
        _update_history_state(backend, current_state['history_id'], current_time)
        logger.info(f"[PROCESS] æ™ºèƒ½æ£€æµ‹åˆ°å†å²è®°å½•é€‰æ‹©: {current_state['history_id']}")
        return 'history'
    
    return None

def _update_upload_state(backend: PianoAnalysisBackend, upload_content: str, current_time: float, filename: str = None) -> None:
    """æ›´æ–°æ–‡ä»¶ä¸Šä¼ çŠ¶æ€"""
    backend._last_upload_content = upload_content
    backend._last_upload_filename = filename or getattr(backend, '_last_upload_filename', 'unknown')
    backend._last_upload_time = current_time
    backend._data_source = 'upload'

def _update_history_state(backend: PianoAnalysisBackend, history_id: str, current_time: float) -> None:
    """æ›´æ–°å†å²è®°å½•é€‰æ‹©çŠ¶æ€"""
    backend._last_selected_history_id = history_id
    backend._last_history_time = current_time
    backend._data_source = 'history'


def _process_file_upload_result(success: bool, result_data: Optional[UploadResultData], 
                                error_msg: Optional[str], filename: Optional[str]) -> Tuple[Optional[html.Div], Optional[html.Div]]:
    """
    å¤„ç†æ–‡ä»¶ä¸Šä¼ ç»“æœå¹¶ç”ŸæˆUIå†…å®¹
    
    Args:
        success: æ–‡ä»¶ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        result_data: æˆåŠŸæ—¶çš„ç»“æœæ•°æ®å­—å…¸ï¼ŒåŒ…å«filenameã€record_countã€replay_countã€history_id
        error_msg: å¤±è´¥æ—¶çš„é”™è¯¯ä¿¡æ¯
        filename: ä¸Šä¼ çš„æ–‡ä»¶å
        
    Returns:
        Tuple[Optional[html.Div], Optional[html.Div]]: 
            - ç¬¬ä¸€ä¸ªå…ƒç´ ï¼šæˆåŠŸæ—¶çš„ä¿¡æ¯å†…å®¹ï¼ˆhtml.Divï¼‰ï¼Œå¤±è´¥æ—¶ä¸ºNone
            - ç¬¬äºŒä¸ªå…ƒç´ ï¼šå¤±è´¥æ—¶çš„é”™è¯¯å†…å®¹ï¼ˆhtml.Divï¼‰ï¼ŒæˆåŠŸæ—¶ä¸ºNone
    """
    ui_processor = UIProcessor()

    if success:
        info_content = ui_processor.create_upload_success_content(result_data)
        error_content = None
    else:
        info_content = None
        error_content = ui_processor.create_upload_error_content(filename, error_msg)

    return info_content, error_content

def _handle_upload_error(error_msg, error_content):
    """å¤„ç†ä¸Šä¼ é”™è¯¯æƒ…å†µ"""
    if error_content:
        if error_msg and ("è½¨é“" in error_msg or "track" in error_msg.lower() or "SPMIDæ–‡ä»¶åªåŒ…å«" in error_msg):
            fig = _create_empty_figure_for_callback("[ERROR] SPMIDæ–‡ä»¶åªåŒ…å« 1 ä¸ªè½¨é“ï¼Œéœ€è¦è‡³å°‘2ä¸ªè½¨é“ï¼ˆå½•åˆ¶+æ’­æ”¾ï¼‰æ‰èƒ½è¿›è¡Œåˆ†æ")
        else:
            fig = _create_empty_figure_for_callback("æ–‡ä»¶ç±»å‹ä¸ç¬¦")
        # é¡ºåº: fig, report, history_options, time_min, time_max, time_value, time_status
        return fig, error_content, no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
    else:
        fig = _create_empty_figure_for_callback("æ–‡ä»¶ä¸Šä¼ å¤±è´¥")
        error_div = html.Div([
            html.H4("æ–‡ä»¶ä¸Šä¼ å¤±è´¥", className="text-center text-danger"),
            html.P("è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æˆ–è”ç³»ç®¡ç†å‘˜ã€‚", className="text-center")
        ])
        return fig, error_div, no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"

def _handle_history_selection(history_id, backend):
    """å¤„ç†å†å²è®°å½•é€‰æ‹©æ“ä½œ"""
    logger.info(f"[PROCESS] åŠ è½½å†å²è®°å½•: {history_id}")
    
    # ä½¿ç”¨HistoryManagerå¤„ç†å†å²è®°å½•é€‰æ‹©ï¼ˆåŒ…å«çŠ¶æ€åˆå§‹åŒ–ï¼‰
    success, result_data, error_msg = backend.history_manager.process_history_selection(history_id, backend)
    
    # ä½¿ç”¨UIProcessorç”ŸæˆUIå†…å®¹
    ui_processor = UIProcessor()

    if success:
        if result_data['has_file_content']:
            # æ‰§è¡Œæ•°æ®åˆ†æ
            backend._perform_error_analysis()
            
            # è‡ªåŠ¨ç”Ÿæˆç€‘å¸ƒå›¾å’ŒæŠ¥å‘Š
            waterfall_fig = backend.generate_waterfall_plot()
            report_content = ui_processor.generate_history_report(backend, result_data['filename'], result_data['history_id'])
        else:
            # æ²¡æœ‰æ–‡ä»¶å†…å®¹ï¼Œåªæ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
            waterfall_fig = ui_processor.create_empty_figure("å†å²è®°å½•æ— æ–‡ä»¶å†…å®¹")
            report_content = ui_processor.create_history_basic_info_content(result_data)
    else:
        waterfall_fig = ui_processor.create_empty_figure("å†å²è®°å½•åŠ è½½å¤±è´¥")
        report_content = ui_processor.create_error_content("å†å²è®°å½•åŠ è½½å¤±è´¥", error_msg)
    
    if waterfall_fig and report_content:
        logger.info("[OK] å†å²è®°å½•åŠ è½½å®Œæˆï¼Œè¿”å›ç€‘å¸ƒå›¾å’ŒæŠ¥å‘Š")
        
        # è·å–é”®IDç­›é€‰ç›¸å…³æ•°æ®
        available_keys = backend.get_available_keys()
        key_options = [{'label': f'é”®ä½ {key_id}', 'value': key_id} for key_id in available_keys]
        key_status = backend.get_key_filter_status()
        
        # å°†key_statusè½¬æ¢ä¸ºå¯æ¸²æŸ“çš„å­—ç¬¦ä¸²
        if key_status['enabled']:
            key_status_text = f"å·²ç­›é€‰ {len(key_status['filtered_keys'])} ä¸ªé”®ä½ (å…± {key_status['total_available_keys']} ä¸ª)"
        else:
            key_status_text = f"æ˜¾ç¤ºå…¨éƒ¨ {key_status['total_available_keys']} ä¸ªé”®ä½"
        
        # å®Œå…¨é¿å…æ›´æ–°æ»‘å—å±æ€§ï¼Œé˜²æ­¢æ— é™é€’å½’
        time_status = backend.get_time_filter_status()
        
        # å°†time_statusè½¬æ¢ä¸ºå¯æ¸²æŸ“çš„å­—ç¬¦ä¸²
        if time_status['enabled']:
            time_status_text = f"æ—¶é—´èŒƒå›´: {time_status['start_time']:.2f}s - {time_status['end_time']:.2f}s (æ—¶é•¿: {time_status['duration']:.2f}s)"
        else:
            time_status_text = "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
        
        # å†å²è®°å½•æƒ…å†µä¸‹ï¼Œå½“å‰ç­›é€‰å€¼å–åç«¯å·²è®¾ç½®çš„filtered_keys
        kstatus = backend.get_key_filter_status()
        current_value = kstatus.get('filtered_keys', []) if kstatus else []
        return waterfall_fig, report_content, no_update, key_options, key_status_text, current_value, no_update, no_update, no_update, time_status_text
    else:
        logger.error("[ERROR] å†å²è®°å½•åŠ è½½å¤±è´¥")
        empty_fig = _create_empty_figure_for_callback("å†å²è®°å½•åŠ è½½å¤±è´¥")
        error_content = html.Div([
            html.H4("å†å²è®°å½•åŠ è½½å¤±è´¥", className="text-center text-danger"),
            html.P("è¯·å°è¯•é€‰æ‹©å…¶ä»–å†å²è®°å½•", className="text-center")
        ])
        return empty_fig, error_content, no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´", no_update


def _handle_waterfall_button(backend):
    """å¤„ç†ç€‘å¸ƒå›¾æŒ‰é’®ç‚¹å‡»"""
    current_data_source = getattr(backend, '_data_source', 'none') if backend else 'none'
    logger.info(f"[PROCESS] ç”Ÿæˆç€‘å¸ƒå›¾ï¼ˆæ•°æ®æº: {current_data_source}ï¼‰")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²åŠ è½½çš„æ•°æ® - æ”¹ä¸ºæ£€æŸ¥æ›´åŸºæœ¬çš„æ•°æ®çŠ¶æ€
    has_data = (backend.analyzer and 
                (backend.plot_generator.valid_record_data or backend.plot_generator.valid_replay_data or
                 (hasattr(backend.analyzer, 'valid_record_data') and backend.analyzer.valid_record_data) or
                 (hasattr(backend.analyzer, 'valid_replay_data') and backend.analyzer.valid_replay_data)))
    
    if has_data:
        fig = backend.generate_waterfall_plot()
        
        # è·å–å®é™…çš„æ—¶é—´èŒƒå›´å¹¶æ›´æ–°æ»‘åŠ¨æ¡
        try:
            time_range = backend.get_time_range()
            time_min, time_max = time_range
            
            # ç¡®ä¿æ—¶é—´èŒƒå›´æ˜¯æœ‰æ•ˆçš„
            if isinstance(time_min, (int, float)) and isinstance(time_max, (int, float)) and time_min < time_max:
                # åˆ›å»ºåˆç†çš„æ ‡è®°ç‚¹
                range_size = time_max - time_min
                if range_size <= 1000:
                    step = max(1, range_size // 5)
                elif range_size <= 10000:
                    step = max(10, range_size // 10)
                else:
                    step = max(100, range_size // 20)
                
                marks = {}
                for i in range(int(time_min), int(time_max) + 1, step):
                    if i == time_min or i == time_max or (i - time_min) % (step * 2) == 0:
                        marks[i] = str(i)
                
                logger.info(f"â° ç€‘å¸ƒå›¾æŒ‰é’®æ›´æ–°æ»‘åŠ¨æ¡: min={time_min}, max={time_max}, èŒƒå›´={range_size}")
                # key_value ä¸åœ¨æ­¤å›è°ƒä¸­æ›´æ–°
                return fig, no_update, no_update, time_min, time_max, [time_min, time_max], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
            else:
                logger.warning(f"[WARNING] æ—¶é—´èŒƒå›´æ— æ•ˆ: {time_range}")
                return fig, no_update, no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
        except Exception as e:
            logger.error(f"[ERROR] è·å–æ—¶é—´èŒƒå›´å¤±è´¥: {e}")
            return fig, no_update, no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´", no_update
    else:
        if current_data_source == 'history':
            empty_fig = _create_empty_figure_for_callback("è¯·é€‰æ‹©å†å²è®°å½•æˆ–ä¸Šä¼ æ–°æ–‡ä»¶")
        else:
            empty_fig = _create_empty_figure_for_callback("è¯·å…ˆä¸Šä¼ SPMIDæ–‡ä»¶")
            return empty_fig, no_update, no_update, 0, 1000, [0, 1000], "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"


def register_callbacks(app, session_manager: SessionManager, history_manager):
    """æ³¨å†Œæ‰€æœ‰å›è°ƒå‡½æ•°"""

    # å¯¼å…¥å›è°ƒæ¨¡å—
    from ui.session_callbacks import register_session_callbacks
    from ui.upload_history_callbacks import register_upload_history_callbacks
    from ui.algorithm_callbacks import register_algorithm_callbacks
    from ui.scatter_callbacks import register_scatter_callbacks

    # æ³¨å†Œä¼šè¯å’Œåˆå§‹åŒ–ç®¡ç†å›è°ƒ
    register_session_callbacks(app, session_manager, history_manager)

    # æ³¨å†Œæ–‡ä»¶ä¸Šä¼ å’Œå†å²è®°å½•ç®¡ç†å›è°ƒ
    register_upload_history_callbacks(app, session_manager)

    # æ³¨å†Œç®—æ³•ç®¡ç†å›è°ƒ
    register_algorithm_callbacks(app, session_manager)

    # æ³¨å†Œæ•£ç‚¹å›¾å›è°ƒ
    register_scatter_callbacks(app, session_manager)

    # åˆ›å»ºç€‘å¸ƒå›¾è·³è½¬å¤„ç†å™¨å®ä¾‹
    waterfall_jump_handler = WaterfallJumpHandler(session_manager)

    # åˆ›å»ºå»¶æ—¶æ—¶é—´åºåˆ—å›¾å¤„ç†å™¨å®ä¾‹
    delay_time_series_handler = DelayTimeSeriesHandler(session_manager)

    # åˆ›å»ºç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å¤„ç†å™¨å®ä¾‹
    relative_delay_distribution_handler = RelativeDelayDistributionHandler(session_manager)

    # åˆ›å»ºå»¶è¿Ÿå€¼ç‚¹å‡»å¤„ç†å™¨å®ä¾‹
    delay_value_click_handler = DelayValueClickHandler(session_manager)

    # åˆ›å»ºå»¶æ—¶ç›´æ–¹å›¾ç‚¹å‡»å¤„ç†å™¨å®ä¾‹
    delay_histogram_click_handler = DelayHistogramClickHandler(session_manager)

    # æ—¶é—´è½´ç­›é€‰å›è°ƒå‡½æ•°
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('time-filter-status', 'children', allow_duplicate=True),
         Output('time-filter-slider', 'value', allow_duplicate=True)],
        [Input('btn-apply-time-filter', 'n_clicks'),
         Input('btn-reset-time-filter', 'n_clicks')],
        [State('session-id', 'data'),
         State('time-filter-slider', 'value')],
        prevent_initial_call=True
    )
    def handle_time_filter(apply_clicks, reset_clicks, session_id, time_range):
        """å¤„ç†æ—¶é—´è½´ç­›é€‰"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update, no_update
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        if not hasattr(backend, 'all_error_notes') or not backend.all_error_notes:
            logger.warning("[WARNING] æ²¡æœ‰åˆ†ææ•°æ®ï¼Œæ— æ³•åº”ç”¨æ—¶é—´ç­›é€‰")
            return no_update, no_update, no_update
        
        # è·å–è§¦å‘ä¸Šä¸‹æ–‡
        ctx = callback_context
        if not ctx.triggered:
            return no_update, no_update, no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"â° æ—¶é—´ç­›é€‰è§¦å‘å™¨: {trigger_id}")
        
        # è·å–åŸå§‹æ—¶é—´èŒƒå›´ï¼ˆç”¨äºé‡ç½®ï¼‰
        original_time_range = backend.get_time_range()
        original_min, original_max = original_time_range
        slider_value = no_update
        
        # å¤„ç†"é‡ç½®æ—¶é—´èŒƒå›´"æŒ‰é’®
        if trigger_id == 'btn-reset-time-filter' and reset_clicks and reset_clicks > 0:
            backend.set_time_filter(None)
            logger.info("â° é‡ç½®æ—¶é—´èŒƒå›´ç­›é€‰")
            # é‡ç½®æ»‘å—åˆ°åŸå§‹èŒƒå›´
            slider_value = [int(original_min), int(original_max)]
            logger.info(f"â° é‡ç½®æ»‘å—åˆ°åŸå§‹èŒƒå›´: {slider_value}")
            
        # å¤„ç†"åº”ç”¨æ—¶é—´ç­›é€‰"æŒ‰é’®
        elif trigger_id == 'btn-apply-time-filter' and apply_clicks and apply_clicks > 0:
            if time_range and len(time_range) == 2 and time_range[0] != time_range[1]:
                # éªŒè¯æ—¶é—´èŒƒå›´çš„åˆç†æ€§
                start_time, end_time = time_range
                if start_time < end_time:
                    backend.set_time_filter(time_range)
                    logger.info(f"â° åº”ç”¨æ—¶é—´è½´ç­›é€‰: {time_range}")
                    # ä¿æŒå½“å‰æ»‘å—å€¼
                    slider_value = no_update
                else:
                    logger.warning(f"[WARNING] æ—¶é—´èŒƒå›´æ— æ•ˆ: {time_range}")
                    backend.set_time_filter(None)
                    # é‡ç½®æ»‘å—åˆ°åŸå§‹èŒƒå›´
                    slider_value = [int(original_min), int(original_max)]
            else:
                backend.set_time_filter(None)
                logger.info("â° æ¸…é™¤æ—¶é—´è½´ç­›é€‰ï¼ˆæ— æ•ˆèŒƒå›´ï¼‰")
                # é‡ç½®æ»‘å—åˆ°åŸå§‹èŒƒå›´
                slider_value = [int(original_min), int(original_max)]
        else:
            logger.warning(f"[WARNING] æœªè¯†åˆ«çš„æ—¶é—´ç­›é€‰è§¦å‘å™¨: {trigger_id}")
            return no_update, no_update, no_update
        
        try:
            # é‡æ–°ç”Ÿæˆç€‘å¸ƒå›¾
            fig = backend.generate_waterfall_plot()
            time_status = backend.get_time_filter_status()
            
            # å°†time_statusè½¬æ¢ä¸ºå¯æ¸²æŸ“çš„å­—ç¬¦ä¸²
            if time_status['enabled']:
                time_status_text = f"æ—¶é—´èŒƒå›´: {time_status['start_time']:.2f}s - {time_status['end_time']:.2f}s (æ—¶é•¿: {time_status['duration']:.2f}s)"
            else:
                time_status_text = "æ˜¾ç¤ºå…¨éƒ¨æ—¶é—´èŒƒå›´"
            
            logger.info(f"â° æ—¶é—´è½´ç­›é€‰çŠ¶æ€: {time_status}")
            
            return fig, time_status_text, slider_value
        except Exception as e:
            logger.error(f"[ERROR] æ—¶é—´ç­›é€‰åç”Ÿæˆç€‘å¸ƒå›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            
            # è¿”å›é”™è¯¯æç¤ºå›¾
            error_fig = _create_empty_figure_for_callback(f"æ—¶é—´ç­›é€‰å¤±è´¥: {str(e)}")
            return error_fig, "æ—¶é—´ç­›é€‰å‡ºé”™ï¼Œè¯·é‡è¯•", no_update


    # æ—¶é—´èŒƒå›´è¾“å…¥ç¡®è®¤å›è°ƒå‡½æ•°
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('time-range-input-status', 'children', allow_duplicate=True),
         Output('time-filter-slider', 'min', allow_duplicate=True),
         Output('time-filter-slider', 'max', allow_duplicate=True),
         Output('time-filter-slider', 'value', allow_duplicate=True),
         Output('time-filter-slider', 'marks', allow_duplicate=True)],
        [Input('btn-confirm-time-range', 'n_clicks')],
        [State('session-id', 'data'),
         State('time-range-start-input', 'value'),
         State('time-range-end-input', 'value')],
        prevent_initial_call=True
    )
    def handle_time_range_input_confirmation(n_clicks, session_id, start_time, end_time):
        """å¤„ç†æ—¶é—´èŒƒå›´è¾“å…¥ç¡®è®¤"""
        logger.info(f"[PROCESS] æ—¶é—´èŒƒå›´è¾“å…¥ç¡®è®¤å›è°ƒè¢«è§¦å‘: n_clicks={n_clicks}, start_time={start_time}, end_time={end_time}")
        
        if not n_clicks or n_clicks <= 0:
            logger.info("[WARNING] æŒ‰é’®æœªç‚¹å‡»ï¼Œè·³è¿‡å¤„ç†")
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("[WARNING] æ— æ•ˆçš„ä¼šè¯ID")
            return no_update, "æ— æ•ˆçš„ä¼šè¯ID", no_update, no_update, no_update, no_update
        
        if start_time is None or end_time is None:
            logger.warning("[WARNING] æ—¶é—´èŒƒå›´è¾“å…¥ä¸ºç©º")
            return no_update, "è¯·è¾“å…¥æœ‰æ•ˆçš„æ—¶é—´èŒƒå›´", no_update, no_update, no_update, no_update
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            logger.info(f"[PROCESS] è°ƒç”¨åç«¯æ›´æ–°æ—¶é—´èŒƒå›´: start_time={start_time}, end_time={end_time}")
            # è°ƒç”¨åç«¯æ–¹æ³•æ›´æ–°æ—¶é—´èŒƒå›´
            success, message = backend.update_time_range_from_input(start_time, end_time)
            
            if success:
                logger.info(f"[OK] åç«¯æ—¶é—´èŒƒå›´æ›´æ–°æˆåŠŸ: {message}")
                # é‡æ–°ç”Ÿæˆç€‘å¸ƒå›¾ï¼ˆä½¿ç”¨æ–°çš„æ—¶é—´èŒƒå›´ï¼‰
                fig = backend.generate_waterfall_plot()
                
                # æ›´æ–°æ»‘åŠ¨æ¡çš„èŒƒå›´å’Œå½“å‰å€¼
                new_min = int(start_time)
                new_max = int(end_time)
                new_value = [new_min, new_max]
                
                # åˆ›å»ºæ–°çš„æ ‡è®°ç‚¹
                range_size = new_max - new_min
                if range_size <= 1000:
                    step = max(1, range_size // 5)
                elif range_size <= 10000:
                    step = max(10, range_size // 10)
                else:
                    step = max(100, range_size // 20)
                
                new_marks = {}
                for i in range(new_min, new_max + 1, step):
                    if i == new_min or i == new_max or (i - new_min) % (step * 2) == 0:
                        new_marks[i] = str(i)
                
                logger.info(f"[OK] æ—¶é—´èŒƒå›´æ›´æ–°æˆåŠŸ: {message}")
                logger.info(f"â° æ›´æ–°æ»‘åŠ¨æ¡èŒƒå›´: min={new_min}, max={new_max}, value={new_value}")
                logger.info(f"â° æ–°æ ‡è®°ç‚¹: {new_marks}")
                status_message = f"[OK] {message}"
                status_style = {'color': '#28a745', 'fontWeight': 'bold'}
                
                return fig, html.Span(status_message, style=status_style), new_min, new_max, new_value, new_marks
            else:
                logger.warning(f"[WARNING] æ—¶é—´èŒƒå›´æ›´æ–°å¤±è´¥: {message}")
                status_message = f"[ERROR] {message}"
                status_style = {'color': '#dc3545', 'fontWeight': 'bold'}
                
                return no_update, html.Span(status_message, style=status_style), no_update, no_update, no_update, no_update
                
        except Exception as e:
            logger.error(f"[ERROR] æ—¶é—´èŒƒå›´è¾“å…¥ç¡®è®¤å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            
            error_message = f"[ERROR] æ—¶é—´èŒƒå›´æ›´æ–°å¤±è´¥: {str(e)}"
            error_style = {'color': '#dc3545', 'fontWeight': 'bold'}
            
            return no_update, html.Span(error_message, style=error_style), no_update, no_update, no_update, no_update


    # é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´å›è°ƒå‡½æ•°
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('time-range-input-status', 'children', allow_duplicate=True),
         Output('time-filter-slider', 'min', allow_duplicate=True),
         Output('time-filter-slider', 'max', allow_duplicate=True),
         Output('time-filter-slider', 'value', allow_duplicate=True),
         Output('time-filter-slider', 'marks', allow_duplicate=True)],
        [Input('btn-reset-display-time-range', 'n_clicks')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_reset_display_time_range(n_clicks, session_id):
        """å¤„ç†é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´"""
        if not n_clicks or n_clicks <= 0:
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            logger.warning("[WARNING] æ— æ•ˆçš„ä¼šè¯ID")
            return no_update, "æ— æ•ˆçš„ä¼šè¯ID", no_update, no_update, no_update, no_update
        
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´
            backend.reset_display_time_range()
            
            # é‡æ–°ç”Ÿæˆç€‘å¸ƒå›¾
            fig = backend.generate_waterfall_plot()
            
            # è·å–åŸå§‹æ•°æ®æ—¶é—´èŒƒå›´å¹¶é‡ç½®æ»‘åŠ¨æ¡åˆ°åŸå§‹èŒƒå›´
            original_min, original_max = backend.get_time_range()
            new_value = [int(original_min), int(original_max)]
            
            logger.info("[OK] æ˜¾ç¤ºæ—¶é—´èŒƒå›´é‡ç½®æˆåŠŸ")
            status_message = "[OK] æ˜¾ç¤ºæ—¶é—´èŒƒå›´å·²é‡ç½®åˆ°åŸå§‹æ•°æ®èŒƒå›´"
            status_style = {'color': '#28a745', 'fontWeight': 'bold'}
            
            return fig, html.Span(status_message, style=status_style), no_update, no_update, new_value, no_update
                
        except Exception as e:
            logger.error(f"[ERROR] é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            
            error_message = f"[ERROR] é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´å¤±è´¥: {str(e)}"
            error_style = {'color': '#dc3545', 'fontWeight': 'bold'}
            
            return no_update, html.Span(error_message, style=error_style), no_update, no_update, no_update, no_update

    # åç§»å¯¹é½åˆ†æ - é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('offset-alignment-plot', 'children', allow_duplicate=True),
        Output('offset-alignment-table', 'data', allow_duplicate=True),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def auto_generate_alignment_on_load(report_content, session_id):
        """æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶ï¼Œè‡ªåŠ¨ç”Ÿæˆåç§»å¯¹é½æŸ±çŠ¶å›¾ä¸è¡¨æ ¼"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update, no_update
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
            active_algorithms = backend.get_active_algorithms()
            if not active_algorithms:
                logger.debug("[DEBUG] æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡åç§»å¯¹é½åˆ†æç”Ÿæˆ")
                empty = backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
                return [dcc.Graph(figure=empty)], []
            
            result = backend.generate_offset_alignment_plot()
            table_data = backend.get_offset_alignment_data()
            
            children = []
            if isinstance(result, list):
                # å¤šå›¾æ¨¡å¼ï¼šè¿”å›å¤šä¸ªç‹¬ç«‹çš„å›¾è¡¨
                for item in result:
                    fig = item.get('figure')
                    
                    # åˆ›å»ºå•ä¸ªå›¾è¡¨çš„å®¹å™¨
                    children.append(html.Div([
                        dcc.Graph(
                            figure=fig,
                            style={'height': '500px'},
                            config={'displayModeBar': True}
                        )
                    ], className="mb-4", style={'border': '1px solid #eee', 'padding': '10px', 'borderRadius': '5px', 'backgroundColor': 'white', 'boxShadow': '0 1px 3px rgba(0,0,0,0.1)'}))
            else:
                # å•å›¾æ¨¡å¼ (Legacy)ï¼šè¿”å›å•ä¸ªå›¾è¡¨
                children.append(dcc.Graph(
                    figure=result,
                    style={'height': '800px'}
                ))
            
            logger.info("[OK] åç§»å¯¹é½åˆ†æï¼ˆè‡ªåŠ¨ï¼‰ç”ŸæˆæˆåŠŸ")
            return children, table_data
            
        except Exception as e:
            logger.error(f"[ERROR] è‡ªåŠ¨ç”Ÿæˆåç§»å¯¹é½åˆ†æå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            empty = backend.plot_generator._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
            return [dcc.Graph(figure=empty)], no_update

    # æ›´æ–°æŒ‰é”®ä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾çš„æ›²å­é€‰æ‹©å™¨é€‰é¡¹
    @app.callback(
        [Output({'type': 'key-delay-scatter-algorithm-selector', 'index': ALL}, 'options'),
         Output({'type': 'key-delay-scatter-algorithm-selector', 'index': ALL}, 'value')],
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def update_key_delay_scatter_algorithm_selector(report_content, session_id):
        backend = session_manager.get_backend(session_id)
        if not backend or not hasattr(backend, 'multi_algorithm_manager'):
            return [], []
            
        try:
            active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
            if not active_algorithms:
                return [], []
            
            options = []
            values = []
            for alg in active_algorithms:
                unique_name = alg.metadata.algorithm_name  # unique_algorithm_name
                display_name = alg.metadata.display_name    # ç”¨æˆ·è¾“å…¥çš„ç®—æ³•å
                filename = alg.metadata.filename            # åŸå§‹æ–‡ä»¶å

                # åˆ›å»ºæ›´å…·æè¿°æ€§çš„æ ‡ç­¾ï¼šç®—æ³•å (æ–‡ä»¶å)
                # ä¾‹å¦‚ï¼špid (11-21-éŸ³é˜¶æµ‹è¯•pid.spmid)
                descriptive_label = f"{display_name} ({filename})"
                options.append({'label': descriptive_label, 'value': unique_name})
                values.append(unique_name)
            
            # è¿”å›åˆ—è¡¨ä»¥åŒ¹é… Pattern Matching Output
            return [options], [values]
            
        except Exception as e:
            logger.error(f"[ERROR] æ›´æ–°æ›²å­é€‰æ‹©å™¨å¤±è´¥: {e}")
            return [], []

    def _validate_multi_algorithm_analysis(backend):
        """éªŒè¯å¤šç®—æ³•æ¨¡å¼å¹¶è·å–åˆ†æç»“æœ"""
        # ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å¼æ£€æŸ¥æ–¹æ³•
        mode, algorithm_count = backend.get_current_analysis_mode()

        if mode != "multi":
            logger.warning(f"[WARNING] å½“å‰ä¸º{mode}æ¨¡å¼ï¼Œæ— æ³•ç”Ÿæˆç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ï¼ˆéœ€è¦å¤šç®—æ³•æ¨¡å¼ï¼‰")
            return None, html.Div([
                dbc.Alert("éœ€è¦å¤šç®—æ³•æ¨¡å¼æ‰èƒ½ç”Ÿæˆç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾", color="warning")
            ])

        # è·å–åˆ†æç»“æœ
        analysis_result = backend.get_same_algorithm_relative_delay_analysis()
        if analysis_result.get('status') != 'success':
            return None, html.Div([
                dbc.Alert(analysis_result.get('message', 'åˆ†æå¤±è´¥'), color="danger")
            ])

        algorithm_groups = analysis_result.get('algorithm_groups', {})
        if not algorithm_groups:
            return None, html.Div([
                dbc.Alert("æ²¡æœ‰ç®—æ³•ç»„æ•°æ®", color="warning")
            ])

        return analysis_result, None

    def _collect_songs_data(algorithm_groups):
        """æ”¶é›†æ‰€æœ‰éœ€è¦ç»˜åˆ¶çš„æ›²å­ä¿¡æ¯"""
        all_songs = []
        for display_name, group_data in algorithm_groups.items():
            song_data = group_data.get('song_data', [])
            group_relative_delays = group_data.get('relative_delays', [])

            if not group_relative_delays:
                continue

            # æ·»åŠ æ¯ä¸ªæ›²å­
            for song_info in song_data:
                song_relative_delays = song_info.get('relative_delays', [])
                if song_relative_delays:
                    filename_display = song_info.get('filename_display', song_info.get('filename', 'æœªçŸ¥æ–‡ä»¶'))
                    all_songs.append((display_name, filename_display, song_relative_delays, None, song_info))

            # æ·»åŠ æ±‡æ€»
            all_songs.append((display_name, 'æ±‡æ€»', None, group_relative_delays, None))

        return all_songs

    def _create_overall_velocity_plot(algorithm_groups):
        """ç”Ÿæˆæ•´ä½“é”¤é€Ÿå¯¹æ¯”å›¾"""
        try:
            # æ”¶é›†æ‰€æœ‰ç®—æ³•ç»„çš„é”¤é€Ÿæ•°æ®
            all_velocity_data = _collect_velocity_data(algorithm_groups)

            if not all_velocity_data:
                return None

            # æŒ‰æŒ‰é”®IDå’Œç®—æ³•åˆ†ç»„è®¡ç®—å¹³å‡é”¤é€Ÿå·®å€¼
            key_algorithm_stats = _process_velocity_statistics(all_velocity_data)

            # è®¡ç®—æ¯ä¸ªæŒ‰é”®åœ¨æ¯ä¸ªç®—æ³•+æ›²å­ç»„åˆä¸‹çš„å¹³å‡é”¤é€Ÿå·®å€¼
            all_key_ids = sorted(key_algorithm_stats.keys())
            all_algorithm_filenames = sorted(set(item['algorithm_filename'] for item in all_velocity_data))

            plot_data = _prepare_multi_algorithm_velocity_plot_data(key_algorithm_stats, all_algorithm_filenames, all_key_ids)

            # åˆ›å»ºæ•´ä½“é”¤é€Ÿå¯¹æ¯”å›¾
            return _create_velocity_figure(plot_data)

        except Exception as e:
            logger.warning(f"ç”Ÿæˆæ•´ä½“é”¤é€Ÿå¯¹æ¯”å›¾å¤±è´¥: {e}")
            return None

    def _create_velocity_control_panel(plot_data):
        """åˆ›å»ºé”¤é€Ÿå¯¹æ¯”å›¾çš„æ§åˆ¶é¢æ¿"""
        if not plot_data:
            return html.Div("æ— æ•°æ®")

        # æå–æ‰€æœ‰ç®—æ³•+æ›²å­åç§°
        algorithm_filenames = [data['algorithm_filename'] for data in plot_data]

        # åˆ›å»ºé¢œè‰²æ˜ å°„
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']

        # åˆ›å»ºæ§åˆ¶é€‰é¡¹
        control_options = []
        for i, algorithm_filename in enumerate(algorithm_filenames):
            color = colors[i % len(colors)]
            control_options.append({
                'label': html.Div([
                    html.Span('â—', style={'color': color, 'marginRight': '8px', 'fontSize': '12px'}),
                    html.Span(algorithm_filename, style={'fontSize': '12px'})
                ], style={'display': 'flex', 'alignItems': 'center'}),
                'value': algorithm_filename
            })

        return dbc.Checklist(
            id='velocity-plot-legend-control',
            options=control_options,
            value=algorithm_filenames,  # é»˜è®¤å…¨éƒ¨é€‰ä¸­
            inline=False,
            style={'columnCount': 2, 'columnGap': '20px'}  # ä¸¤åˆ—å¸ƒå±€
        )

    def _collect_velocity_data(algorithm_groups):
        """æ”¶é›†æ‰€æœ‰ç®—æ³•ç»„çš„é”¤é€Ÿæ•°æ®"""
        all_velocity_data = []
        for display_name, group_data in algorithm_groups.items():
            song_data = group_data.get('song_data', [])
            for song_info in song_data:
                hammer_velocity_diffs = song_info.get('hammer_velocity_diffs', [])
                filename_display = song_info.get('filename_display', song_info.get('filename', 'æœªçŸ¥æ–‡ä»¶'))
                if hammer_velocity_diffs:
                    for item in hammer_velocity_diffs:
                        all_velocity_data.append({
                            'algorithm': display_name,
                            'filename': filename_display,
                            'algorithm_filename': f'{display_name} - {filename_display}',
                            'key_id': item['key_id'],
                            'velocity_diff': item['velocity_diff'],
                            'record_velocity': item['record_velocity'],
                            'replay_velocity': item['replay_velocity']
                        })
        return all_velocity_data

    def _process_velocity_statistics(all_velocity_data):
        """æŒ‰æŒ‰é”®IDå’Œç®—æ³•+æ›²å­åˆ†ç»„è®¡ç®—å¹³å‡é”¤é€Ÿå·®å€¼"""
        key_algorithm_stats = defaultdict(lambda: defaultdict(list))

        for item in all_velocity_data:
            key_id = item['key_id']
            algorithm_filename = item['algorithm_filename']
            key_algorithm_stats[key_id][algorithm_filename].append(item['velocity_diff'])

        return key_algorithm_stats

    def _prepare_multi_algorithm_velocity_plot_data(key_algorithm_stats, all_algorithm_filenames, all_key_ids):
        """ä¸ºå¤šä¸ªç®—æ³•+æ›²å­ç»„åˆå‡†å¤‡ç»˜å›¾æ•°æ®"""
        plot_data = []

        for algorithm_filename in all_algorithm_filenames:
            x_keys = []
            y_diffs = []
            hover_texts = []

            for key_id in all_key_ids:
                if algorithm_filename in key_algorithm_stats[key_id]:
                    diffs = key_algorithm_stats[key_id][algorithm_filename]
                    avg_diff = np.mean(diffs)
                    x_keys.append(str(key_id))
                    y_diffs.append(avg_diff)

                    # è®¡ç®—å¹³å‡æ’­æ”¾é”¤é€Ÿ
                    record_vel = 100  # é»˜è®¤å½•åˆ¶é”¤é€Ÿ
                    replay_vel = record_vel + avg_diff
                    hover_texts.append(f'æŒ‰é”® {key_id}<br>{algorithm_filename}<br>é”¤é€Ÿå·®å€¼: {avg_diff:.1f}<br>å½•åˆ¶é”¤é€Ÿ: {record_vel}<br>å¹³å‡æ’­æ”¾é”¤é€Ÿ: {replay_vel:.1f}')
                else:
                    x_keys.append(str(key_id))
                    y_diffs.append(0)  # æ²¡æœ‰æ•°æ®æ—¶æ˜¾ç¤º0
                    hover_texts.append(f'æŒ‰é”® {key_id}<br>{algorithm_filename}<br>æ— æ•°æ®')

            if y_diffs:  # åªæœ‰æœ‰æ•°æ®æ—¶æ‰æ·»åŠ 
                plot_data.append({
                    'algorithm_filename': algorithm_filename,
                    'x': x_keys,
                    'y': y_diffs,
                    'hovertext': hover_texts
                })

        return plot_data

    def _create_velocity_figure(plot_data):
        """åˆ›å»ºæ•´ä½“é”¤é€Ÿå¯¹æ¯”å›¾è¡¨"""
        if not plot_data:
            return None

        velocity_fig = go.Figure()

        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
        for i, data in enumerate(plot_data):
            color = colors[i % len(colors)]
            velocity_fig.add_trace(go.Bar(
                x=data['x'],
                y=data['y'],
                name=data['algorithm_filename'],
                marker=dict(color=color, opacity=0.8),
                hovertext=data['hovertext'],
                hovertemplate='%{hovertext}<extra></extra>'
            ))

        # æ·»åŠ é›¶çº¿
        velocity_fig.add_hline(
            y=0,
            line_dash="dash",
            line_color="red",
            opacity=0.7
        )

        velocity_fig.update_layout(
            title='åŒç§ç®—æ³•ä¸åŒæ›²å­çš„é”¤é€Ÿå¯¹æ¯”',
            xaxis_title='æŒ‰é”®ID',
            yaxis_title='é”¤é€Ÿå·®å€¼ (æ’­æ”¾é”¤é€Ÿ - å½•åˆ¶é”¤é€Ÿ)',
            height=500,
            template='plotly_white',
            barmode='group',  # åˆ†ç»„æŸ±çŠ¶å›¾
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1,
                bgcolor='rgba(255, 255, 255, 0.8)',
                bordercolor='rgba(0, 0, 0, 0.2)',
                borderwidth=1
            ),
            showlegend=True
        )

        # åˆ›å»ºæ§åˆ¶é¢æ¿
        control_panel = _create_velocity_control_panel(plot_data)

        # è¿”å›åŒ…å«å›¾è¡¨å’Œæ§åˆ¶é¢æ¿çš„å®¹å™¨
        return html.Div([
            html.Div([
                html.H6("å›¾æ³¨æ§åˆ¶", className="mb-2", style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                control_panel
            ], className="mb-3", style={'backgroundColor': '#f8f9fa', 'padding': '15px', 'borderRadius': '8px', 'border': '1px solid #dee2e6'}),
            dcc.Graph(
                id='overall-hammer-velocity-comparison-plot',
                figure=velocity_fig,
                config={
                    'displayModeBar': True,
                    'displaylogo': False,
                    'modeBarButtonsToRemove': ['pan2d', 'lasso2d', 'select2d'],
                    'modeBarButtonsToAdd': []
                },
                style={'height': '500px'}
            )
        ])

    def _create_subplot_figure(subplot_idx, display_name, filename_display, delays_array, base_color):
        """ä¸ºå•ä¸ªå­å›¾åˆ›å»ºå›¾è¡¨"""
        

        # ç”Ÿæˆå­å›¾æ ‡é¢˜
        if filename_display == 'æ±‡æ€»':
            subplot_title = f'{display_name} (æ±‡æ€»)'
        else:
            subplot_title = f'{display_name} - {filename_display}'

        # è®¡ç®—ç›´æ–¹å›¾æ•°æ®
        hist, bin_edges = np.histogram(delays_array, bins=50, density=False)
        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2

        # ä¸ºæ¯ä¸ªbinåˆ›å»ºcustomdata
        customdata_list = []
        for i, bin_center in enumerate(bin_centers):
            bin_left = bin_edges[i]
            bin_right = bin_edges[i + 1]
            customdata_list.append([
                subplot_idx,
                display_name,
                filename_display,
                bin_center,
                bin_left,
                bin_right
            ])

        # è®¡ç®—å¯†åº¦æ›²çº¿
        bin_width = bin_edges[1] - bin_edges[0]
        try:
            if len(delays_array) < 2 or np.std(delays_array) == 0:
                raise ValueError("Insufficient data or zero variance")
                
            kde = stats.gaussian_kde(delays_array)
            x_density = np.linspace(delays_array.min(), delays_array.max(), 200)
            # ä¿®æ­£ï¼šä¹˜ä»¥bin_width
            y_density = kde(x_density) * len(delays_array) * bin_width
        except:
            # KDEè®¡ç®—å¤±è´¥ï¼ˆå¦‚æ•°æ®ç‚¹å¤ªå°‘æˆ–å…¨ç›¸åŒï¼‰ï¼Œä¸ç»˜åˆ¶æ›²çº¿
            y_density = []
            x_density = []

        # åˆ›å»ºç‹¬ç«‹çš„å›¾è¡¨
        fig = go.Figure()

        # æ·»åŠ ç›´æ–¹å›¾
        fig.add_trace(
            go.Bar(
                x=bin_centers,
                y=hist,
                name='ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒ',
                marker=dict(
                    color=f'rgba({int(base_color[1:3], 16)}, {int(base_color[3:5], 16)}, {int(base_color[5:7], 16)}, 0.6)',
                    line=dict(color=base_color, width=1.5 if filename_display == 'æ±‡æ€»' else 1)
                ),
                opacity=0.7,
                showlegend=False,
                hovertemplate=f'ç›¸å¯¹å»¶æ—¶: %{{x:.2f}} ms<br>é¢‘æ•°: %{{y}}<extra></extra>',
                customdata=customdata_list
            )
        )

        # æ·»åŠ å¯†åº¦æ›²çº¿
        fig.add_trace(
            go.Scatter(
                x=x_density,
                y=y_density,
                mode='lines',
                name='å¯†åº¦æ›²çº¿',
                line=dict(
                    color=base_color,
                    width=3 if filename_display == 'æ±‡æ€»' else 2,
                    dash='dash' if filename_display == 'æ±‡æ€»' else 'solid'
                ),
                showlegend=False,
                hovertemplate=f'ç›¸å¯¹å»¶æ—¶: %{{x:.2f}} ms<br>å¯†åº¦: %{{y:.2f}}<extra></extra>'
            )
        )

        # è®¡ç®—ç»Ÿè®¡é‡
        mean = np.mean(delays_array)
        std = np.std(delays_array)
        median = np.median(delays_array)

        # æ·»åŠ Â±1Ïƒã€Â±2Ïƒã€Â±3ÏƒåŒºé—´
        for sigma, color in [(1, 'rgba(255, 0, 0, 0.08)'), (2, 'rgba(255, 0, 0, 0.12)'), (3, 'rgba(255, 0, 0, 0.15)')]:
            fig.add_vrect(
                x0=mean - sigma * std,
                x1=mean + sigma * std,
                fillcolor=color,
                layer="below",
                line_width=0
            )

        # æ·»åŠ å‡å€¼çº¿
        fig.add_vline(
            x=mean,
            line_dash="dash",
            line_color="green",
            line_width=1.5
        )

        # æ·»åŠ ä¸­ä½æ•°çº¿
        fig.add_vline(
            x=median,
            line_dash="dot",
            line_color="orange",
            line_width=1.5
        )

        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            title=subplot_title,
            xaxis_title='ç›¸å¯¹å»¶æ—¶ (ms)',
            yaxis_title='é¢‘æ•°',
            height=500,
            template='plotly_white',
            showlegend=False
        )

        return fig

    def _create_subplot_velocity_plot(subplot_title, song_info, subplot_idx):
        """ä¸ºå•ä¸ªå­å›¾åˆ›å»ºé”¤é€Ÿå¯¹æ¯”å›¾"""
        

        if not song_info or 'hammer_velocity_diffs' not in song_info:
            return None

        hammer_velocity_diffs = song_info['hammer_velocity_diffs']
        if not hammer_velocity_diffs:
            return None

        # æŒ‰æŒ‰é”®IDåˆ†ç»„è®¡ç®—å¹³å‡é”¤é€Ÿå·®å€¼
        key_velocity_stats = defaultdict(list)

        for item in hammer_velocity_diffs:
            key_id = item['key_id']
            key_velocity_stats[key_id].append(item['velocity_diff'])

        # è®¡ç®—æ¯ä¸ªæŒ‰é”®çš„å¹³å‡é”¤é€Ÿå·®å€¼
        key_avg_diffs = {}
        for key_id, diffs in key_velocity_stats.items():
            key_avg_diffs[key_id] = np.mean(diffs)

        if not key_avg_diffs:
            return None

        # æ’åºæŒ‰é”®ID
        sorted_keys = sorted(key_avg_diffs.keys())
        x_keys = [str(k) for k in sorted_keys]
        y_diffs = [key_avg_diffs[k] for k in sorted_keys]

        # åˆ›å»ºé”¤é€Ÿå¯¹æ¯”å›¾
        velocity_fig = go.Figure()
        velocity_fig.add_trace(go.Bar(
            x=x_keys,
            y=y_diffs,
            name='é”¤é€Ÿå·®å€¼',
            marker=dict(
                color='#ff9800',
                opacity=0.8,
                line=dict(color='#e65100', width=1)
            ),
            hovertemplate='<b>æŒ‰é”® %{x}</b><br>' +
                         'å¹³å‡é”¤é€Ÿå·®å€¼: %{y:.1f}<br>' +
                         '<b>å½•åˆ¶é”¤é€Ÿ: 100</b><br>' +
                         '<b>å¹³å‡æ’­æ”¾é”¤é€Ÿ: %{customdata:.1f}</b><extra></extra>',
            customdata=[100 + diff for diff in y_diffs]  # æ’­æ”¾é”¤é€Ÿ = å½•åˆ¶é”¤é€Ÿ + å·®å€¼
        ))

        # æ·»åŠ é›¶çº¿
        velocity_fig.add_hline(
            y=0,
            line_dash="dash",
            line_color="red",
            opacity=0.7
        )

        velocity_fig.update_layout(
            title=f'{subplot_title} - é”¤é€Ÿå¯¹æ¯”',
            xaxis_title='æŒ‰é”®ID',
            yaxis_title='é”¤é€Ÿå·®å€¼ (æ’­æ”¾é”¤é€Ÿ - å½•åˆ¶é”¤é€Ÿ)',
            height=400,
            template='plotly_white',
            showlegend=False
        )

        return dcc.Graph(
            id={'type': 'hammer-velocity-comparison-plot', 'index': subplot_idx},
            figure=velocity_fig,
            style={'height': '400px', 'marginTop': '20px'}
        )

    def _create_subplot_container(subplot_idx, fig, velocity_plot, display_name, filename_display):
        """åˆ›å»ºå®Œæ•´çš„å­å›¾å®¹å™¨"""
        # åˆ›å»ºå›¾è¡¨å’Œè¡¨æ ¼å®¹å™¨ï¼ˆä½¿ç”¨å­—å…¸å½¢å¼çš„IDä»¥æ”¯æŒPattern Matching Callbacksï¼‰
        plot_id = {'type': 'relative-delay-distribution-plot', 'index': subplot_idx}
        table_id = {'type': 'relative-delay-distribution-table', 'index': subplot_idx}
        title_id = {'type': 'relative-delay-distribution-title', 'index': subplot_idx}
        info_id = {'type': 'relative-delay-distribution-info', 'index': subplot_idx}
        container_id = {'type': 'relative-delay-distribution-container', 'index': subplot_idx}

        # æ·»åŠ ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾
        plot_elements = [
            dcc.Graph(
                id=plot_id,
                figure=fig,
                style={'height': '500px'}
            )
        ]

        # å¦‚æœæœ‰é”¤é€Ÿå¯¹æ¯”å›¾ï¼Œä¹Ÿæ·»åŠ è¿›å»
        if velocity_plot:
            plot_elements.append(velocity_plot)

        return html.Div([
            *plot_elements,
            html.P("ğŸ’¡ æç¤ºï¼šç‚¹å‡»ç›´æ–¹å›¾ä¸­çš„æŸ±çŠ¶å›¾åŒºåŸŸï¼Œå¯æŸ¥çœ‹è¯¥ç›¸å¯¹å»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹è¯¦æƒ…",
                   className="text-muted",
                   style={'fontSize': '12px', 'marginTop': '10px', 'marginBottom': '10px'}),
            html.Div([
                html.Div(id=title_id,
                        style={'marginTop': '15px', 'marginBottom': '10px',
                               'fontSize': '16px', 'fontWeight': 'bold',
                               'color': '#9c27b0', 'padding': '8px 12px',
                               'backgroundColor': '#f3e5f5', 'borderRadius': '4px',
                               'borderLeft': '4px solid #9c27b0', 'display': 'none'}),
                html.Div(id=info_id,
                        style={'marginBottom': '10px', 'fontSize': '14px', 'fontWeight': 'bold', 'color': '#2c3e50', 'display': 'none'}),
                dash_table.DataTable(
                    id=table_id,
                    columns=[
                        {"name": "ç®—æ³•åç§°", "id": "algorithm_name"},
                        {"name": "æŒ‰é”®ID", "id": "key_id"},
                        {"name": "ç›¸å¯¹å»¶æ—¶(ms)", "id": "relative_delay_ms", "type": "numeric", "format": {"specifier": ".2f"}},
                        {"name": "ç»å¯¹å»¶æ—¶(ms)", "id": "absolute_delay_ms", "type": "numeric", "format": {"specifier": ".2f"}},
                        {"name": "å½•åˆ¶ç´¢å¼•", "id": "record_index"},
                        {"name": "æ’­æ”¾ç´¢å¼•", "id": "replay_index"},
                        {"name": "å½•åˆ¶å¼€å§‹(0.1ms)", "id": "record_keyon"},
                        {"name": "æ’­æ”¾å¼€å§‹(0.1ms)", "id": "replay_keyon"},
                        {"name": "æŒç»­æ—¶é—´å·®(0.1ms)", "id": "duration_offset"},
                    ],
                    data=[],
                    page_action='none',
                    style_cell={
                        'textAlign': 'center',
                        'fontSize': '12px',
                        'fontFamily': 'Arial, sans-serif',
                        'padding': '8px',
                        'overflow': 'hidden',
                        'textOverflow': 'ellipsis',
                    },
                    style_header={
                        'backgroundColor': '#f8f9fa',
                        'fontWeight': 'bold',
                        'border': '1px solid #dee2e6',
                        'position': 'sticky',
                        'top': 0,
                        'zIndex': 1
                    },
                    style_data={
                        'whiteSpace': 'normal',
                        'height': 'auto',
                    },
                    style_table={
                        'overflowX': 'auto',
                        'overflowY': 'auto',
                        'maxHeight': '600px',
                    }
                )
            ], style={'display': 'none'}, id=container_id)
        ], className="mb-4", style={'backgroundColor': '#ffffff', 'padding': '20px', 'borderRadius': '8px', 'boxShadow': '0 2px 8px rgba(0,0,0,0.1)'})

    # é”¤é€Ÿå¯¹æ¯”å›¾æ§åˆ¶é¢æ¿å›è°ƒ
    @app.callback(
        Output('overall-hammer-velocity-comparison-plot', 'figure'),
        [Input('velocity-plot-legend-control', 'value')],
        [State('overall-hammer-velocity-comparison-plot', 'figure')],
        prevent_initial_call=True
    )
    def update_velocity_plot_visibility(selected_algorithms, current_figure):
        """æ ¹æ®æ§åˆ¶é¢æ¿çš„é€‰æ‹©æ›´æ–°é”¤é€Ÿå¯¹æ¯”å›¾çš„å¯è§æ€§"""
        if not current_figure or not current_figure.data:
            return current_figure

        # æ›´æ–°æ¯ä¸ªtraceçš„å¯è§æ€§
        for i, trace in enumerate(current_figure.data):
            algorithm_filename = trace.name
            trace.visible = algorithm_filename in selected_algorithms

        return current_figure


    # åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å›è°ƒ - æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('relative-delay-distribution-container', 'children'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_relative_delay_distribution_plot(report_content, session_id):
        """å¤„ç†åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘ï¼Œä¸ºæ¯ä¸ªå­å›¾åˆ›å»ºç‹¬ç«‹çš„å›¾è¡¨å’Œè¡¨æ ¼åŒºåŸŸ"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update

        try:
            # éªŒè¯å¤šç®—æ³•æ¨¡å¼å’Œè·å–åˆ†æç»“æœ
            analysis_result, error_div = _validate_multi_algorithm_analysis(backend)
            if error_div:
                return error_div

            algorithm_groups = analysis_result.get('algorithm_groups', {})

            # æ”¶é›†æ‰€æœ‰éœ€è¦ç»˜åˆ¶çš„æ›²å­ä¿¡æ¯
            all_songs = _collect_songs_data(algorithm_groups)

            if not all_songs:
                return html.Div([
                    dbc.Alert("æ²¡æœ‰æœ‰æ•ˆçš„ç›¸å¯¹å»¶æ—¶æ•°æ®", color="warning")
                ])
            
            # ç”Ÿæˆæ•´ä½“é”¤é€Ÿå¯¹æ¯”å›¾
            overall_velocity_plot = _create_overall_velocity_plot(algorithm_groups)

            # ä¸ºæ¯ä¸ªå­å›¾åˆ›å»ºç‹¬ç«‹çš„å›¾è¡¨å’Œè¡¨æ ¼åŒºåŸŸ
            children = []
            algorithm_color_map = {}
            color_idx = 0

            # åœ¨æœ€ä¸Šæ–¹æ·»åŠ æ•´ä½“é”¤é€Ÿå¯¹æ¯”å›¾
            if overall_velocity_plot:
                children.append(
                    html.Div([
                        html.H5("æ•´ä½“é”¤é€Ÿå¯¹æ¯”", className="mb-3",
                               style={'color': '#ff9800', 'fontWeight': 'bold', 'textAlign': 'center'}),
                        overall_velocity_plot
                    ], className="mb-4", style={'backgroundColor': '#ffffff', 'padding': '20px', 'borderRadius': '8px', 'boxShadow': '0 2px 8px rgba(0,0,0,0.1)'})
                )

            # é¢œè‰²æ–¹æ¡ˆ
            colors = [
                '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',
                '#9467bd', '#8c564b', '#e377c2', '#7f7f7f'
            ]

            for subplot_idx, (display_name, filename_display, song_relative_delays, group_relative_delays, song_info) in enumerate(all_songs, 1):
                # ç¡®å®šä½¿ç”¨çš„æ•°æ®
                if filename_display == 'æ±‡æ€»':
                    delays_array = np.array(group_relative_delays)
                else:
                    delays_array = np.array(song_relative_delays)

                if len(delays_array) == 0:
                    continue

                # è·å–æˆ–åˆ†é…é¢œè‰²
                if display_name not in algorithm_color_map:
                    algorithm_color_map[display_name] = colors[color_idx % len(colors)]
                    color_idx += 1
                base_color = algorithm_color_map[display_name]

                # ç”Ÿæˆå­å›¾æ ‡é¢˜
                if filename_display == 'æ±‡æ€»':
                    subplot_title = f'{display_name} (æ±‡æ€»)'
                else:
                    subplot_title = f'{display_name} - {filename_display}'

                # åˆ›å»ºå­å›¾å›¾è¡¨
                fig = _create_subplot_figure(subplot_idx, display_name, filename_display, delays_array, base_color)

                # ç”Ÿæˆé”¤é€Ÿå¯¹æ¯”å›¾ï¼ˆä»…å¯¹éæ±‡æ€»çš„æ›²å­ï¼‰
                velocity_plot = None
                if filename_display != 'æ±‡æ€»':
                    velocity_plot = _create_subplot_velocity_plot(subplot_title, song_info, subplot_idx)

                # åˆ›å»ºå®Œæ•´çš„å­å›¾å®¹å™¨
                subplot_container = _create_subplot_container(subplot_idx, fig, velocity_plot, display_name, filename_display)
                children.append(subplot_container)
            
            logger.info("[OK] åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ç”ŸæˆæˆåŠŸ")
            return children
            
        except Exception as e:
            logger.error(f"[ERROR] ç”Ÿæˆç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return html.Div([
                dbc.Alert(f"ç”Ÿæˆå¤±è´¥: {str(e)}", color="danger")
            ])
    
    # åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæŒ‡å®šç›¸å¯¹å»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹è¯¦æƒ…
    # ä½¿ç”¨Pattern Matching Callbackså¤„ç†åŠ¨æ€ç”Ÿæˆçš„å›¾è¡¨ç‚¹å‡»
    @app.callback(
        [Output({'type': 'relative-delay-distribution-table', 'index': dash.dependencies.MATCH}, 'data'),
         Output({'type': 'relative-delay-distribution-table', 'index': dash.dependencies.MATCH}, 'style_table'),
         Output({'type': 'relative-delay-distribution-info', 'index': dash.dependencies.MATCH}, 'children'),
         Output({'type': 'relative-delay-distribution-container', 'index': dash.dependencies.MATCH}, 'style'),
         Output({'type': 'relative-delay-distribution-title', 'index': dash.dependencies.MATCH}, 'children')],
        [Input({'type': 'relative-delay-distribution-plot', 'index': dash.dependencies.MATCH}, 'clickData')],
        [State('session-id', 'data'),
         State({'type': 'relative-delay-distribution-plot', 'index': dash.dependencies.MATCH}, 'id')],
        prevent_initial_call=True
    )
    def handle_relative_delay_distribution_click(click_data, session_id, plot_id):
        """å¤„ç†åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ç‚¹å‡»äº‹ä»¶ï¼Œæ˜¾ç¤ºè¯¥ç›¸å¯¹å»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹è¯¦æƒ…"""
        return relative_delay_distribution_handler.handle_click(click_data, session_id, plot_id)
    
    def _find_algorithm_by_indices(algorithms, record_index, replay_index, log_prefix=""):
        """[Helper] åœ¨ç®—æ³•åˆ—è¡¨ä¸­é€šè¿‡åŒ¹é…å¯¹ç´¢å¼•æŸ¥æ‰¾ç®—æ³•å®ä¾‹"""
        for alg in algorithms:
            if alg.analyzer and hasattr(alg.analyzer, 'matched_pairs'):
                for r_idx, p_idx, _, _ in alg.analyzer.matched_pairs:
                    if r_idx == record_index and p_idx == replay_index:
                        logger.info(f"{log_prefix} é€šè¿‡åŒ¹é…å¯¹æ‰¾åˆ°ç®—æ³•å®ä¾‹: {alg.metadata.algorithm_name}")
                        return alg
        return None
    
    def _find_target_algorithm_instance(backend, algorithm_name, record_index, replay_index):
        """[Helper] åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹æŸ¥æ‰¾ç›®æ ‡ç®—æ³•å®ä¾‹"""
        if not backend.multi_algorithm_mode or not backend.multi_algorithm_manager:
            return None
            
        all_algorithms = backend.multi_algorithm_manager.get_all_algorithms()
        
        # 1. é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…ç®—æ³•åç§°
        candidate_algorithms = [alg for alg in all_algorithms if alg.metadata.algorithm_name == algorithm_name]
        logger.info(f"ğŸ” æ‰¾åˆ° {len(candidate_algorithms)} ä¸ªåŒ¹é…ç®—æ³•åç§°çš„ç®—æ³•å®ä¾‹: {algorithm_name}")
        
        # 2. åœ¨å€™é€‰ç®—æ³•ä¸­é€šè¿‡åŒ¹é…å¯¹æŸ¥æ‰¾
        if candidate_algorithms:
            target_alg = _find_algorithm_by_indices(
                candidate_algorithms, record_index, replay_index,
                "[OK] åœ¨å€™é€‰ç®—æ³•ä¸­"
            )
            if target_alg:
                return target_alg

            # å¦‚æœåªæœ‰ä¸€ä¸ªå€™é€‰ä½†æœªæ‰¾åˆ°åŒ¹é…å¯¹ï¼Œåˆ™å‹‰å¼ºä½¿ç”¨
            if len(candidate_algorithms) == 1:
                logger.warning(f"[WARNING] åªæœ‰ä¸€ä¸ªå€™é€‰ç®—æ³•ä½†æœªæ‰¾åˆ°æ˜ç¡®åŒ¹é…å¯¹ï¼Œå°è¯•ä½¿ç”¨: {algorithm_name}")
                return candidate_algorithms[0]

        # 3. å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œåœ¨æ‰€æœ‰ç®—æ³•ä¸­å…¨å±€æŸ¥æ‰¾
        logger.info(f"[WARNING] ç®—æ³•åç§°åŒ¹é…å¤±è´¥ï¼Œå°è¯•å…¨å±€æŸ¥æ‰¾")
        return _find_algorithm_by_indices(
            all_algorithms, record_index, replay_index,
            "[OK] å…¨å±€æŸ¥æ‰¾"
        )

    def _get_notes_and_center_time(target_algorithm, record_index, replay_index, key_id):
        """[Helper] è·å–å½•åˆ¶/æ’­æ”¾éŸ³ç¬¦å¯¹è±¡åŠä¸­å¿ƒæ—¶é—´"""
        if not target_algorithm or not target_algorithm.analyzer:
            return None, None, None

        # ä» matched_pairs è·å–åŒ¹é…çš„éŸ³ç¬¦å¯¹
        matched_pairs = getattr(target_algorithm.analyzer, 'matched_pairs', [])
        
        for r_idx, p_idx, r_note, p_note in matched_pairs:
            if r_idx == record_index and p_idx == replay_index:
                # å¦‚æœæŒ‡å®šäº†key_idï¼Œè¿›è¡Œé¢å¤–éªŒè¯
                if key_id is not None and r_note.id != key_id:
                    continue
                        
            # è®¡ç®—ä¸­å¿ƒæ—¶é—´ï¼ˆkeyonæ—¶é—´ï¼‰
            r_offset = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
            p_offset = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
            center_time_ms = ((r_offset + p_offset) / 2.0) / 10.0

        return r_note, p_note, center_time_ms

        # å¦‚æœåœ¨ matched_pairs ä¸­æ‰¾ä¸åˆ°åŒ¹é…çš„éŸ³ç¬¦å¯¹ï¼Œç›´æ¥è¿”å›None
        return None, None, None
    
    # åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾è¯¦æƒ…è¡¨æ ¼ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºå½•åˆ¶ä¸æ’­æ”¾å¯¹æ¯”æ›²çº¿
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True)],
        [Input({'type': 'relative-delay-distribution-table', 'index': dash.dependencies.ALL}, 'active_cell'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State({'type': 'relative-delay-distribution-table', 'index': dash.dependencies.ALL}, 'data'),
         State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_relative_delay_distribution_table_click(active_cells, close_modal_clicks, close_btn_clicks, table_data_list, session_id, current_style):
        """å¤„ç†åŒç§ç®—æ³•ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾è¯¦æƒ…è¡¨æ ¼ç‚¹å‡»ï¼Œæ˜¾ç¤ºå½•åˆ¶ä¸æ’­æ”¾å¯¹æ¯”æ›²çº¿ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾"""
        # 1. æ£€æµ‹è§¦å‘æºä¸å…³é—­æ“ä½œ
        ctx = callback_context
        if not ctx.triggered:
            return current_style, [], no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            return {'display': 'none'}, [], no_update
            
        # 2. è·å– Backend
        backend = session_manager.get_backend(session_id)
        if not backend:
            return current_style, [], no_update
        
        # 3. è·å–è§¦å‘çš„è¡¨æ ¼è¡Œæ•°æ®
        try:
            triggered_table_idx = next((i for i, cell in enumerate(active_cells) if cell), None)
            if triggered_table_idx is None or triggered_table_idx >= len(table_data_list):
                return current_style, [], no_update

            table_data = table_data_list[triggered_table_idx]
            active_cell = active_cells[triggered_table_idx]

            if not active_cell or not table_data:
                return current_style, [], no_update

            row_data = table_data[active_cell.get('row')]
            record_index = int(row_data.get('record_index'))
            replay_index = int(row_data.get('replay_index'))
            key_id = int(row_data.get('key_id')) if row_data.get('key_id') != 'N/A' else None
            algorithm_name = row_data.get('algorithm_name')
            
            logger.info(f"[STATS] ç‚¹å‡»è¡Œ: rec={record_index}, rep={replay_index}, key={key_id}, alg={algorithm_name}")

            # 4. æŸ¥æ‰¾ç›®æ ‡ç®—æ³•å®ä¾‹
            if backend.multi_algorithm_mode:
                target_algorithm = _find_target_algorithm_instance(backend, algorithm_name, record_index, replay_index)
                if not target_algorithm:
                    logger.warning(f"[WARNING] æœªæ‰¾åˆ°åŒ¹é…ç®—æ³•: {algorithm_name}")
                    return current_style, [], no_update
                final_algorithm_name = target_algorithm.metadata.algorithm_name
            else:
                logger.warning("[WARNING] éå¤šç®—æ³•æ¨¡å¼æˆ–æ— æ•ˆè°ƒç”¨")
                return current_style, [], no_update
            
            # 5. è·å–éŸ³ç¬¦æ•°æ®ä¸æ—¶é—´
            record_note, replay_note, center_time_ms = _get_notes_and_center_time(target_algorithm, record_index, replay_index, key_id)
            
            if not record_note or not replay_note:
                logger.error("[ERROR] æ— æ³•è·å–éŸ³ç¬¦å¯¹è±¡")
                # å¦‚æœæœ‰center_time_msä½†æ²¡éŸ³ç¬¦ï¼Œä¹Ÿå¯ä»¥ç»§ç»­å—ï¼Ÿç›®å‰é€»è¾‘ä¼¼ä¹éœ€è¦éŸ³ç¬¦æ¥ç”»å›¾
                if center_time_ms is None:
                    return current_style, [], no_update

            # 6. ç”Ÿæˆå¯¹æ¯”æ›²çº¿å›¾
            mean_delay = 0.0
            if target_algorithm.analyzer:
                mean_delay = target_algorithm.analyzer.get_mean_error() / 10.0

            detail_figure = spmid.plot_note_comparison_plotly(
                record_note, 
                replay_note, 
                algorithm_name=final_algorithm_name,
                other_algorithm_notes=[],
                mean_delays={final_algorithm_name: mean_delay}
            )
            
            if not detail_figure:
                return current_style, [], no_update
            
            # 7. æ„å»ºè¿”å›æ•°æ®
            source_subplot_idx = triggered_table_idx + 1 # å‡è®¾ç´¢å¼•+1
            point_info = {
                'algorithm_name': final_algorithm_name,
                'record_idx': record_index,
                'replay_idx': replay_index,
                'key_id': key_id,
                'source_plot_id': 'relative-delay-distribution-plot',
                'source_subplot_idx': source_subplot_idx,
                'center_time_ms': center_time_ms
            }
            
            modal_style = {
                'display': 'block',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0', 'top': '0',
                'width': '100%', 'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            
            return modal_style, [dcc.Graph(figure=detail_figure, style={'height': '600px'})], point_info

        except Exception as e:
            logger.error(f"[ERROR] å¤„ç†è¡¨æ ¼ç‚¹å‡»å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
        return current_style, [], no_update

    # å»¶æ—¶æ—¶é—´åºåˆ—å›¾å›è°ƒ - æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        [Output('raw-delay-time-series-plot', 'figure'),
         Output('relative-delay-time-series-plot', 'figure')],
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_delay_time_series(report_content, session_id):
        """å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return [no_update, no_update]

        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
            active_algorithms = backend.get_active_algorithms()
            if not active_algorithms:
                logger.debug("[DEBUG] æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç”Ÿæˆ")
                empty_plot = backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
                return [empty_plot, empty_plot]

            result = backend.generate_delay_time_series_plot()

            # æ£€æŸ¥è¿”å›çš„æ˜¯å¦æ˜¯å­—å…¸ï¼ˆä¸¤ä¸ªå›¾è¡¨ï¼‰è¿˜æ˜¯å•ä¸ªå›¾è¡¨
            if isinstance(result, dict) and 'raw_delay_plot' in result and 'relative_delay_plot' in result:
                logger.info("[OK] å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç”ŸæˆæˆåŠŸï¼ˆåˆ†ç¦»æ¨¡å¼ï¼‰")
                return [result['raw_delay_plot'], result['relative_delay_plot']]
            else:
                # å•ç®—æ³•æ¨¡å¼ - ä¸¤ä¸ªå›¾è¡¨éƒ½æ˜¾ç¤ºç›¸åŒçš„å†…å®¹
                logger.info("[OK] å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç”ŸæˆæˆåŠŸï¼ˆå•ç®—æ³•æ¨¡å¼ï¼‰")
                return [result, result]

        except Exception as e:
            logger.error(f"[ERROR] ç”Ÿæˆå»¶æ—¶æ—¶é—´åºåˆ—å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            empty_plot = backend.plot_generator._create_empty_plot(f"ç”Ÿæˆæ—¶é—´åºåˆ—å›¾å¤±è´¥: {str(e)}")
            return [empty_plot, empty_plot]
    
    # å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»å›è°ƒ - åªå¤„ç†å…³é—­æŒ‰é’®ï¼ˆå•ç®—æ³•æ¨¡å¼ï¼‰
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True)],
        [Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_delay_time_series_click(close_modal_clicks, close_btn_clicks, current_style):
        """å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»ï¼Œæ˜¾ç¤ºéŸ³ç¬¦åˆ†ææ›²çº¿ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾"""
        """å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾æ¨¡æ€æ¡†çš„å…³é—­æŒ‰é’®ï¼ˆå•ç®—æ³•æ¨¡å¼ï¼‰"""
        logger.info("[START] handle_delay_time_series_click å…³é—­æŒ‰é’®å›è°ƒè¢«è§¦å‘")

        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            return current_style, [], no_update

        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.info(f"ğŸ” è§¦å‘ID: {trigger_id}")

        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, [], no_update

        return current_style, [], no_update
                    
    # å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»å›è°ƒ - å¤šç®—æ³•æ¨¡å¼ï¼ˆç›‘å¬æ‰€æœ‰æ—¶é—´åºåˆ—å›¾ï¼‰
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True),
         Output('raw-delay-time-series-plot', 'clickData', allow_duplicate=True),
         Output('relative-delay-time-series-plot', 'clickData', allow_duplicate=True)],
        [Input('raw-delay-time-series-plot', 'clickData'),
         Input('relative-delay-time-series-plot', 'clickData'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_delay_time_series_click_multi(raw_click_data, relative_click_data, close_modal_clicks, close_btn_clicks, session_id, current_style):
        """å¤„ç†å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç‚¹å‡»ï¼ˆå¤šç®—æ³•æ¨¡å¼ï¼‰ï¼Œæ˜¾ç¤ºéŸ³ç¬¦åˆ†ææ›²çº¿ï¼ˆæ‚¬æµ®çª—ï¼‰"""
        return delay_time_series_handler.handle_delay_time_series_click_multi(
            raw_click_data, relative_click_data, close_modal_clicks, close_btn_clicks, session_id, current_style
        )

    # æœ€å¤§/æœ€å°å»¶è¿Ÿå­—æ®µç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºå¯¹åº”æŒ‰é”®çš„æ›²çº¿å¯¹æ¯”å›¾
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True)],
        [Input({'type': 'max-delay-value', 'algorithm': dash.ALL}, 'n_clicks'),
         Input({'type': 'min-delay-value', 'algorithm': dash.ALL}, 'n_clicks'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State({'type': 'max-delay-value', 'algorithm': dash.ALL}, 'id'),
         State({'type': 'min-delay-value', 'algorithm': dash.ALL}, 'id'),
         State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_delay_value_click(max_clicks_list, min_clicks_list, close_modal_clicks, close_btn_clicks, 
                                  max_ids_list, min_ids_list, session_id, current_style):
        """å¤„ç†æœ€å¤§/æœ€å°å»¶è¿Ÿå­—æ®µç‚¹å‡»ï¼Œæ˜¾ç¤ºå¯¹åº”æŒ‰é”®çš„æ›²çº¿å¯¹æ¯”å›¾"""
        return delay_value_click_handler.handle_delay_value_click(
            max_clicks_list, min_clicks_list, close_modal_clicks, close_btn_clicks,
            max_ids_list, min_ids_list, session_id, current_style
        )
    
    # å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾å›è°ƒ - æŠ¥å‘Šå†…å®¹åŠ è½½æ—¶è‡ªåŠ¨ç”Ÿæˆ
    @app.callback(
        Output('delay-histogram-plot', 'figure'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_delay_histogram(report_content, session_id):
        """å¤„ç†å»¶æ—¶ç›´æ–¹å›¾è‡ªåŠ¨ç”Ÿæˆ - å½“æŠ¥å‘Šå†…å®¹æ›´æ–°æ—¶è§¦å‘"""
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update
        
        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•
            active_algorithms = backend.get_active_algorithms()
            if not active_algorithms:
                logger.debug("[DEBUG] æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å»¶æ—¶ç›´æ–¹å›¾ç”Ÿæˆ")
                return backend.plot_generator._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
            fig = backend.generate_delay_histogram_plot()
            logger.info("[OK] å»¶æ—¶ç›´æ–¹å›¾ç”ŸæˆæˆåŠŸ")
            return fig
        except Exception as e:
            logger.error(f"[ERROR] ç”Ÿæˆå»¶æ—¶ç›´æ–¹å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return backend.plot_generator._create_empty_plot(f"ç”Ÿæˆç›´æ–¹å›¾å¤±è´¥: {str(e)}")

    # å¯¼å‡ºå»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾æ•°æ®ä¸ºCSV
    @app.callback(
        Output('export-delay-histogram-status', 'children'),
        Input('export-delay-histogram-csv', 'n_clicks'),
        State('session-id', 'data'),
        prevent_initial_call=True
    )
    def export_delay_histogram_csv(n_clicks, session_id):
        """å¯¼å‡ºå»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾æ•°æ®ä¸ºCSVæ–‡ä»¶"""
        import os

        backend = session_manager.get_backend(session_id)
        if not backend:
            return html.Div("âŒ åç«¯æœªåˆå§‹åŒ–", style={'color': '#dc3545'})

        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
            if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                # å¤šç®—æ³•æ¨¡å¼ï¼šå¯¼å‡ºå¤šç®—æ³•æ•°æ®
                active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                if not active_algorithms:
                    return html.Div("âŒ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•", style={'color': '#dc3545'})

                csv_paths = backend.multi_algorithm_plot_generator.export_multi_algorithm_delay_histogram_data_to_csv(active_algorithms)
            else:
                # å•ç®—æ³•æ¨¡å¼ï¼šå¯¼å‡ºå•ç®—æ³•æ•°æ®
                csv_path = backend.export_delay_histogram_data_to_csv()
                csv_paths = [csv_path] if csv_path else None

            if csv_paths and len(csv_paths) > 0:
                if len(csv_paths) == 1:
                    filename = os.path.basename(csv_paths[0])
                    return html.Div([
                        html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '8px'}),
                        f"âœ… æ•°æ®å·²å¯¼å‡º: {filename}"
                    ], style={'color': '#28a745'})
                else:
                    filenames = [os.path.basename(path) for path in csv_paths]
                    return html.Div([
                        html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '8px'}),
                        f"âœ… æ•°æ®å·²å¯¼å‡º {len(csv_paths)} ä¸ªæ–‡ä»¶: {', '.join(filenames)}"
                    ], style={'color': '#28a745'})
            else:
                return html.Div("âŒ å¯¼å‡ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®", style={'color': '#dc3545'})

        except Exception as e:
            logger.error(f"å¯¼å‡ºå»¶æ—¶åˆ†å¸ƒæ•°æ®å¤±è´¥: {e}")
            return html.Div(f"âŒ å¯¼å‡ºå¼‚å¸¸: {str(e)}", style={'color': '#dc3545'})

    # å¯¼å‡ºåŒ¹é…å‰æ•°æ®ä¸ºCSVï¼ˆæµ‹è¯•åŠŸèƒ½ï¼‰
    @app.callback(
        Output('export-pre-match-status', 'children'),
        Input('export-pre-match-csv', 'n_clicks'),
        State('session-id', 'data'),
        prevent_initial_call=True
    )
    def export_pre_match_csv(n_clicks, session_id):
        """å¯¼å‡ºåŒ¹é…å‰çš„æ•°æ®ä¸ºCSVæ–‡ä»¶ï¼ˆæµ‹è¯•åŠŸèƒ½ï¼‰"""
        import os

        backend = session_manager.get_backend(session_id)
        if not backend:
            return html.Div("âŒ åç«¯æœªåˆå§‹åŒ–", style={'color': '#dc3545'})

        try:
            # æ£€æŸ¥å½“å‰æ¨¡å¼
            if hasattr(backend, 'multi_algorithm_mode') and backend.multi_algorithm_mode:
                # å¤šç®—æ³•æ¨¡å¼
                active_algorithms = backend.get_active_algorithms()
                if not active_algorithms:
                    return html.Div("âŒ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•", style={'color': '#dc3545'})

                csv_paths = backend.multi_algorithm_plot_generator.export_multi_algorithm_pre_match_data_to_csv(active_algorithms)
            else:
                # å•ç®—æ³•æ¨¡å¼
                csv_paths = backend.export_pre_match_data_to_csv()
                if csv_paths and not isinstance(csv_paths, list):
                    csv_paths = [csv_paths]  # ç»Ÿä¸€è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼

            if csv_paths:
                if len(csv_paths) > 1:
                    # å¤šæ–‡ä»¶æƒ…å†µ
                    filenames = [os.path.basename(path) for path in csv_paths]
                    return html.Div([
                        html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '8px'}),
                        f"âœ… åŒ¹é…å‰æ•°æ®å·²å¯¼å‡º {len(csv_paths)} ä¸ªæ–‡ä»¶: {', '.join(filenames)}"
                    ], style={'color': '#28a745'})
                else:
                    # å•æ–‡ä»¶æƒ…å†µ
                    filename = os.path.basename(csv_paths[0])
                    return html.Div([
                        html.I(className="fas fa-check-circle", style={'color': '#28a745', 'marginRight': '8px'}),
                        f"âœ… åŒ¹é…å‰æ•°æ®å·²å¯¼å‡º: {filename}"
                    ], style={'color': '#28a745'})
            else:
                return html.Div("âŒ å¯¼å‡ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®", style={'color': '#dc3545'})

        except Exception as e:
            logger.error(f"å¯¼å‡ºåŒ¹é…å‰æ•°æ®å¤±è´¥: {e}")
            return html.Div(f"âŒ å¯¼å‡ºå¼‚å¸¸: {str(e)}", style={'color': '#dc3545'})


    # å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæŒ‡å®šå»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹è¯¦æƒ…
    @app.callback(
        [Output('delay-histogram-detail-table', 'data'),
         Output('delay-histogram-detail-table', 'style_table'),
         Output('delay-histogram-selection-info', 'children')],
        [Input('delay-histogram-plot', 'clickData')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_delay_histogram_click(click_data, session_id):
        """å¤„ç†å»¶æ—¶ç›´æ–¹å›¾ç‚¹å‡»äº‹ä»¶ï¼Œæ˜¾ç¤ºè¯¥å»¶æ—¶èŒƒå›´å†…çš„æ•°æ®ç‚¹è¯¦æƒ…"""
        return delay_histogram_click_handler.handle_delay_histogram_click(click_data, session_id)
    
    # å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾è¯¦æƒ…è¡¨æ ¼ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºå½•åˆ¶ä¸æ’­æ”¾å¯¹æ¯”æ›²çº¿
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True)],
        [Input('delay-histogram-detail-table', 'active_cell'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('delay-histogram-detail-table', 'data'),
         State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_delay_histogram_table_click(active_cell, close_modal_clicks, close_btn_clicks, table_data, session_id, current_style):
        """å¤„ç†å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾è¯¦æƒ…è¡¨æ ¼ç‚¹å‡»ï¼Œæ˜¾ç¤ºå½•åˆ¶ä¸æ’­æ”¾å¯¹æ¯”æ›²çº¿ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾"""
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            return current_style, [], no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.debug(f"[DEBUG] å»¶æ—¶ç›´æ–¹å›¾è¡¨æ ¼ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            logger.info("[OK] å…³é—­æŒ‰é”®æ›²çº¿å¯¹æ¯”æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, [], no_update
        
        # å¦‚æœæ˜¯è¡¨æ ¼ç‚¹å‡»
        if trigger_id == 'delay-histogram-detail-table':
            backend = session_manager.get_backend(session_id)
            if not backend:
                logger.warning("[WARNING] æ²¡æœ‰æ‰¾åˆ°backend")
                return current_style, [], no_update
            
            if not active_cell or not table_data:
                logger.warning("[WARNING] active_cellæˆ–table_dataä¸ºç©º")
                return current_style, [], no_update
            
            try:
                # è·å–ç‚¹å‡»çš„è¡Œæ•°æ®
                row_idx = active_cell.get('row')
                if row_idx is None or row_idx >= len(table_data):
                    logger.warning(f"[WARNING] è¡Œç´¢å¼•è¶…å‡ºèŒƒå›´: row_idx={row_idx}, table_dataé•¿åº¦={len(table_data)}")
                    return current_style, [], no_update
                
                row_data = table_data[row_idx]
                record_index = row_data.get('record_index')
                replay_index = row_data.get('replay_index')
                key_id = row_data.get('key_id')  # è·å–æŒ‰é”®IDç”¨äºéªŒè¯
                algorithm_name = row_data.get('algorithm_name')  # å¯èƒ½ä¸º Noneï¼ˆå•ç®—æ³•æ¨¡å¼ï¼‰
                
                logger.info(f"[STATS] ç‚¹å‡»çš„è¡Œæ•°æ®: record_index={record_index}, replay_index={replay_index}, key_id={key_id}, algorithm_name={algorithm_name}")
                print(f"[STATS] ç‚¹å‡»çš„è¡Œæ•°æ®: record_index={record_index}, replay_index={replay_index}, key_id={key_id}, algorithm_name={algorithm_name}")
                
                # æ£€æŸ¥ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
                if record_index == 'N/A' or replay_index == 'N/A' or record_index is None or replay_index is None:
                    logger.warning("[WARNING] ç´¢å¼•æ— æ•ˆ")
                    return current_style, [], no_update
                
                try:
                    record_index = int(record_index)
                    replay_index = int(replay_index)
                    if key_id and key_id != 'N/A':
                        key_id = int(key_id)
                    else:
                        key_id = None
                except (ValueError, TypeError) as e:
                    logger.warning(f"[WARNING] æ— æ³•è½¬æ¢ç´¢å¼•æˆ–key_id: record_index={record_index}, replay_index={replay_index}, key_id={key_id}, error={e}")
                    return current_style, [], no_update
                
                # è·å–å¯¹åº”çš„éŸ³ç¬¦æ•°æ® - å¿…é¡»ä»matched_pairsä¸­è·å–ï¼Œç¡®ä¿æ˜¯é…å¯¹çš„
                record_note = None
                replay_note = None
                center_time_ms = None  # ç”¨äºè·³è½¬çš„æ—¶é—´ä¿¡æ¯
                
                # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼ä¸”æä¾›äº†ç®—æ³•åç§°
                if backend.multi_algorithm_mode and backend.multi_algorithm_manager and algorithm_name and algorithm_name != 'N/A':
                    # å¤šç®—æ³•æ¨¡å¼ï¼šä»æŒ‡å®šç®—æ³•è·å–æ•°æ®
                    active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                    target_algorithm = None
                    for alg in active_algorithms:
                        if alg.metadata.algorithm_name == algorithm_name:
                            target_algorithm = alg
                            break
                    
                    if not target_algorithm or not target_algorithm.analyzer:
                        logger.warning(f"[WARNING] æœªæ‰¾åˆ°ç®—æ³•: {algorithm_name}")
                        return current_style, [], no_update
                    
                    # ä»matched_pairsä¸­æŸ¥æ‰¾åŒ¹é…å¯¹ï¼Œç¡®ä¿record_indexå’Œreplay_indexå¯¹åº”åŒä¸€ä¸ªåŒ¹é…å¯¹
                    matched_pairs = target_algorithm.analyzer.matched_pairs if hasattr(target_algorithm.analyzer, 'matched_pairs') else []
                    if not matched_pairs:
                        logger.warning("[WARNING] ç®—æ³•æ²¡æœ‰åŒ¹é…å¯¹æ•°æ®")
                        return current_style, [], no_update
                    
                    # æŸ¥æ‰¾åŒ¹é…å¯¹ï¼šrecord_indexå’Œreplay_indexå¿…é¡»åŒæ—¶åŒ¹é…
                    found_pair = False
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_idx == record_index and p_idx == replay_index:
                            # éªŒè¯key_idï¼ˆå¦‚æœæä¾›äº†ï¼‰
                            if key_id is not None and r_note.id != key_id:
                                logger.warning(f"[WARNING] key_idä¸åŒ¹é…: è¡¨æ ¼ä¸­çš„key_id={key_id}, åŒ¹é…å¯¹ä¸­çš„key_id={r_note.id}")
                                continue
                            record_note = r_note
                            replay_note = p_note
                            found_pair = True
                            logger.info(f"[OK] ä»matched_pairsä¸­æ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}, key_id={r_note.id}")
                            print(f"[OK] ä»matched_pairsä¸­æ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}, key_id={r_note.id}")
                            
                            # è®¡ç®—keyonæ—¶é—´ï¼Œç”¨äºè·³è½¬
                            try:
                                record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
                                replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
                                center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
                            except Exception as e:
                                logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                                # å¤‡ç”¨æ–¹æ¡ˆï¼šä» offset_data è·å–
                                if target_algorithm.analyzer.note_matcher:
                                    try:
                                        offset_data = target_algorithm.analyzer.note_matcher.get_offset_alignment_data()
                                        if offset_data:
                                            for item in offset_data:
                                                if item.get('record_index') == record_index and item.get('replay_index') == replay_index:
                                                    record_keyon = item.get('record_keyon', 0)
                                                    replay_keyon = item.get('replay_keyon', 0)
                                                    if record_keyon and replay_keyon:
                                                        center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                                                        break
                                    except Exception as e2:
                                        logger.warning(f"[WARNING] ä»offset_dataè·å–æ—¶é—´ä¿¡æ¯å¤±è´¥: {e2}")
                            
                            break
                    
                    if not found_pair:
                        logger.warning(f"[WARNING] æœªæ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}")
                        return current_style, [], no_update
                    
                    # ä½¿ç”¨ç®—æ³•åç§°
                    final_algorithm_name = algorithm_name
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    if not backend.analyzer:
                        logger.warning("[WARNING] æ²¡æœ‰åˆ†æå™¨")
                        return current_style, [], no_update
                    
                    # ä»matched_pairsä¸­æŸ¥æ‰¾åŒ¹é…å¯¹
                    matched_pairs = backend.analyzer.matched_pairs if hasattr(backend.analyzer, 'matched_pairs') else []
                    if not matched_pairs:
                        logger.warning("[WARNING] æ²¡æœ‰åŒ¹é…å¯¹æ•°æ®")
                        return current_style, [], no_update
                    
                    # æŸ¥æ‰¾åŒ¹é…å¯¹ï¼šrecord_indexå’Œreplay_indexå¿…é¡»åŒæ—¶åŒ¹é…
                    found_pair = False
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_idx == record_index and p_idx == replay_index:
                            # éªŒè¯key_idï¼ˆå¦‚æœæä¾›äº†ï¼‰
                            if key_id is not None and r_note.id != key_id:
                                logger.warning(f"[WARNING] key_idä¸åŒ¹é…: è¡¨æ ¼ä¸­çš„key_id={key_id}, åŒ¹é…å¯¹ä¸­çš„key_id={r_note.id}")
                                continue
                            record_note = r_note
                            replay_note = p_note
                            found_pair = True
                            logger.info(f"[OK] ä»matched_pairsä¸­æ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}, key_id={r_note.id}")
                            print(f"[OK] ä»matched_pairsä¸­æ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}, key_id={r_note.id}")
                            
                            # è®¡ç®—keyonæ—¶é—´ï¼Œç”¨äºè·³è½¬
                            try:
                                record_keyon = r_note.after_touch.index[0] + r_note.offset if hasattr(r_note, 'after_touch') and not r_note.after_touch.empty else r_note.offset
                                replay_keyon = p_note.after_touch.index[0] + p_note.offset if hasattr(p_note, 'after_touch') and not p_note.after_touch.empty else p_note.offset
                                center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
                            except Exception as e:
                                logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                                # å¤‡ç”¨æ–¹æ¡ˆï¼šä» offset_data è·å–
                                if backend.analyzer.note_matcher:
                                    try:
                                        offset_data = backend.analyzer.note_matcher.get_offset_alignment_data()
                                        if offset_data:
                                            for item in offset_data:
                                                if item.get('record_index') == record_index and item.get('replay_index') == replay_index:
                                                    record_keyon = item.get('record_keyon', 0)
                                                    replay_keyon = item.get('replay_keyon', 0)
                                                    if record_keyon and replay_keyon:
                                                        center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                                                        break
                                    except Exception as e2:
                                        logger.warning(f"[WARNING] ä»offset_dataè·å–æ—¶é—´ä¿¡æ¯å¤±è´¥: {e2}")
                            
                            break
                    
                    if not found_pair:
                        logger.warning(f"[WARNING] æœªæ‰¾åˆ°åŒ¹é…å¯¹: record_index={record_index}, replay_index={replay_index}")
                        return current_style, [], no_update
                    
                    # å•ç®—æ³•æ¨¡å¼ï¼Œalgorithm_name å¯èƒ½ä¸º None
                    final_algorithm_name = algorithm_name if algorithm_name and algorithm_name != 'N/A' else None
                
                # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ç®—æ³•ä¸­åŒ¹é…åˆ°åŒä¸€ä¸ªå½•åˆ¶éŸ³ç¬¦çš„æ’­æ”¾éŸ³ç¬¦
                other_algorithm_notes = []  # [(algorithm_name, play_note), ...]
                if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                    active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                    for alg in active_algorithms:
                        if alg.metadata.algorithm_name == final_algorithm_name:
                            continue  # è·³è¿‡å½“å‰ç®—æ³•ï¼ˆå·²ç»ç»˜åˆ¶ï¼‰
                        
                        if not alg.analyzer or not hasattr(alg.analyzer, 'matched_pairs'):
                            continue
                        
                        matched_pairs = alg.analyzer.matched_pairs
                        # æŸ¥æ‰¾åŒ¹é…åˆ°åŒä¸€ä¸ªrecord_indexçš„æ’­æ”¾éŸ³ç¬¦
                        for r_idx, p_idx, r_note, p_note in matched_pairs:
                            if r_idx == record_index:
                                other_algorithm_notes.append((alg.metadata.algorithm_name, p_note))
                                logger.info(f"[OK] æ‰¾åˆ°ç®—æ³• '{alg.metadata.algorithm_name}' çš„åŒ¹é…æ’­æ”¾éŸ³ç¬¦")
                                break
                
                # æŒ‰é”®å»¶æ—¶æ•£ç‚¹å›¾ä½¿ç”¨ç®—æ³•å¹³å‡è¯¯å·®ä½œä¸ºå»¶æ—¶åŸºå‡†
                mean_delays = {}
                if backend.multi_algorithm_mode and backend.multi_algorithm_manager and final_algorithm_name:
                    # å¤šç®—æ³•æ¨¡å¼
                    algorithm = backend.multi_algorithm_manager.get_algorithm(final_algorithm_name)
                    if algorithm and algorithm.analyzer:
                        mean_error_0_1ms = algorithm.analyzer.get_mean_error()
                        mean_delays[final_algorithm_name] = mean_error_0_1ms / 10.0
                    else:
                        logger.error(f"[ERROR] æ— æ³•è·å–ç®—æ³• '{final_algorithm_name}' çš„å¹³å‡å»¶æ—¶")
                        return current_style, [], no_update
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    if backend.analyzer:
                        mean_error_0_1ms = backend.analyzer.get_mean_error()
                        mean_delays[final_algorithm_name or 'default'] = mean_error_0_1ms / 10.0
                    else:
                        logger.error("[ERROR] æ— æ³•è·å–å•ç®—æ³•æ¨¡å¼çš„å¹³å‡å»¶æ—¶")
                        return current_style, [], no_update, no_update
                
                # ç”Ÿæˆå¯¹æ¯”æ›²çº¿å›¾ï¼ˆåŒ…å«å…¶ä»–ç®—æ³•çš„æ’­æ”¾æ›²çº¿ï¼‰
                detail_figure_combined = spmid.plot_note_comparison_plotly(
                    record_note, 
                    replay_note, 
                    algorithm_name=final_algorithm_name,
                    other_algorithm_notes=other_algorithm_notes,  # ä¼ é€’å…¶ä»–ç®—æ³•çš„æ’­æ”¾éŸ³ç¬¦
                    mean_delays=mean_delays
                )
                
                if not detail_figure_combined:
                    logger.error("[ERROR] æ›²çº¿ç”Ÿæˆå¤±è´¥")
                    return current_style, [], no_update, no_update
                
                logger.info(f"[OK] æˆåŠŸç”Ÿæˆå¯¹æ¯”æ›²çº¿: record_index={record_index}, replay_index={replay_index}")
                print(f"[OK] æˆåŠŸç”Ÿæˆå¯¹æ¯”æ›²çº¿: record_index={record_index}, replay_index={replay_index}")
                
                # å­˜å‚¨å½“å‰ç‚¹å‡»çš„æ•°æ®ç‚¹ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æŒ‰é’®
                point_info = {
                    'algorithm_name': final_algorithm_name,
                    'record_idx': record_index,
                    'replay_idx': replay_index,
                    'key_id': key_id,
                    'source_plot_id': 'delay-histogram-detail-table',  # è®°å½•æ¥æºå›¾è¡¨ID
                    'center_time_ms': center_time_ms  # é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯
                }
                
                # æ˜¾ç¤ºæ¨¡æ€æ¡†
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                
                # åˆ›å»ºæ¨¡æ€æ¡†å†…å®¹ï¼ˆåªåŒ…å«å›¾è¡¨ï¼ŒæŒ‰é’®å·²åœ¨å¸ƒå±€ä¸­å®šä¹‰ï¼‰
                # ä½¿ç”¨ä¸ handle_waterfall_click ç›¸åŒçš„æ ¼å¼
                rendered_row = dcc.Graph(figure=detail_figure_combined, style={'height': '600px'})
                
                return modal_style, [rendered_row], point_info
                
            except Exception as e:
                logger.error(f"[ERROR] å¤„ç†å»¶æ—¶ç›´æ–¹å›¾è¡¨æ ¼ç‚¹å‡»å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                return current_style, [], no_update
        
        return current_style, [], no_update

    # ==================== å¤šç®—æ³•å¯¹æ¯”æ¨¡å¼å›è°ƒ ====================
    
    # å¤šç®—æ³•æ¨¡å¼åˆå§‹åŒ–å›è°ƒ - åœ¨ä¼šè¯åˆå§‹åŒ–æ—¶è‡ªåŠ¨è§¦å‘
    @app.callback(
        [Output('multi-algorithm-upload-area', 'style', allow_duplicate=True),
         Output('multi-algorithm-upload-area', 'children'),
         Output('multi-algorithm-management-area', 'style', allow_duplicate=True),
         Output('multi-algorithm-management-area', 'children'),
         Output('main-plot', 'figure', allow_duplicate=True),
         Output('report-content', 'children', allow_duplicate=True)],
        [Input('session-id', 'data')],
        prevent_initial_call='initial_duplicate',
        prevent_duplicate=True
    )
    def initialize_multi_algorithm_mode(session_id):
        """åˆå§‹åŒ–å¤šç®—æ³•æ¨¡å¼ - ç¡®ä¿ä¸Šä¼ åŒºåŸŸå’Œç®¡ç†åŒºåŸŸæ˜¾ç¤º"""
        logger.info(f"[PROCESS] åˆå§‹åŒ–å¤šç®—æ³•æ¨¡å¼: session_id={session_id}")
        
        if not session_id:
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        session_id, backend = session_manager.get_or_create_backend(session_id)
        if not backend:
            logger.warning("[WARNING] æ— æ³•è·å–backendå®ä¾‹")
            return no_update, no_update, no_update, no_update, no_update, no_update
        
        try:
            # å¤šç®—æ³•æ¨¡å¼å§‹ç»ˆå¯ç”¨
            # ç¡®ä¿multi_algorithm_managerå·²åˆå§‹åŒ–
            if not backend.multi_algorithm_manager:
                backend._ensure_multi_algorithm_manager()
            has_existing_data = False
            existing_filename = None
            logger.info("[OK] å¤šç®—æ³•æ¨¡å¼å·²å°±ç»ª")
            
            success = True
            if success:
                upload_style = {'display': 'block'}
                try:
                    upload_area = create_multi_algorithm_upload_area()
                    logger.info("[OK] åˆ›å»ºå¤šç®—æ³•ä¸Šä¼ åŒºåŸŸæˆåŠŸ")
                except Exception as e:
                    logger.error(f"[ERROR] åˆ›å»ºå¤šç®—æ³•ä¸Šä¼ åŒºåŸŸå¤±è´¥: {e}")
                    upload_area = html.Div("ä¸Šä¼ åŒºåŸŸåˆ›å»ºå¤±è´¥", style={'color': '#dc3545'})
                
                management_style = {'display': 'block'}
                try:
                    management_area = create_multi_algorithm_management_area()
                    logger.info("[OK] åˆ›å»ºå¤šç®—æ³•ç®¡ç†åŒºåŸŸæˆåŠŸ")
                except Exception as e:
                    logger.error(f"[ERROR] åˆ›å»ºå¤šç®—æ³•ç®¡ç†åŒºåŸŸå¤±è´¥: {e}")
                    management_area = html.Div("ç®¡ç†åŒºåŸŸåˆ›å»ºå¤±è´¥", style={'color': '#dc3545'})
            else:
                upload_style = {'display': 'block'}  # å³ä½¿å¤±è´¥ä¹Ÿæ˜¾ç¤ºï¼Œè®©ç”¨æˆ·çŸ¥é“æœ‰é—®é¢˜
                upload_area = html.Div("å¤šç®—æ³•æ¨¡å¼å¯ç”¨å¤±è´¥", style={'color': '#dc3545'})
                management_style = {'display': 'block'}
                management_area = html.Div("å¤šç®—æ³•æ¨¡å¼å¯ç”¨å¤±è´¥", style={'color': '#dc3545'})
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œæ›´æ–°ç€‘å¸ƒå›¾
            plot_fig = no_update
            report_content = no_update
            
            active_algorithms = backend.get_active_algorithms()
            # è¿›ä¸€æ­¥æ£€æŸ¥ï¼šåªæœ‰ç®—æ³•çœŸæ­£æœ‰æ•°æ®ï¼ˆanalyzerå­˜åœ¨ä¸”æœ‰matched_pairsï¼‰æ‰ç”Ÿæˆå›¾å½¢
            algorithms_with_data = []
            for alg in active_algorithms:
                if alg.analyzer and hasattr(alg.analyzer, 'matched_pairs') and alg.analyzer.matched_pairs:
                    algorithms_with_data.append(alg)
            
            if algorithms_with_data:
                try:
                    logger.info(f"[PROCESS] æ›´æ–°ç€‘å¸ƒå›¾ï¼Œå…± {len(algorithms_with_data)} ä¸ªæœ‰æ•°æ®çš„æ¿€æ´»ç®—æ³•")
                    plot_fig = backend.generate_waterfall_plot()
                    report_content = create_report_layout(backend)
                except Exception as e:
                    logger.error(f"[ERROR] æ›´æ–°ç€‘å¸ƒå›¾å¤±è´¥: {e}")
                    plot_fig = _create_empty_figure_for_callback(f"æ›´æ–°å¤±è´¥: {str(e)}")
                    # ä½¿ç”¨ create_report_layout ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€çš„ç»„ä»¶
                    try:
                        report_content = create_report_layout(backend)
                    except:
                        # å¦‚æœ create_report_layout ä¹Ÿå¤±è´¥ï¼Œè¿”å›åŒ…å«å¿…éœ€ç»„ä»¶çš„é”™è¯¯å¸ƒå±€
                        empty_fig = {}
                        report_content = html.Div([
                            html.H4("æ›´æ–°å¤±è´¥", className="text-center text-danger"),
                            html.P(f"é”™è¯¯ä¿¡æ¯: {str(e)}", className="text-center"),
                            # åŒ…å«æ‰€æœ‰å¿…éœ€çš„å›¾è¡¨ç»„ä»¶ï¼ˆéšè—ï¼‰ï¼Œç¡®ä¿å›è°ƒå‡½æ•°ä¸ä¼šæŠ¥é”™
                            dcc.Graph(id='key-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                            dcc.Graph(id='key-delay-zscore-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                            dcc.Graph(id='hammer-velocity-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                            html.Div(id='offset-alignment-plot', style={'display': 'none'}),
                            html.Div([
                                dash_table.DataTable(
                                    id='offset-alignment-table',
                                    data=[],
                                    columns=[]
                                )
                            ], style={'display': 'none'})
                        ])
            else:
                # æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•æ—¶ï¼Œä¸è°ƒç”¨ create_report_layoutï¼Œç›´æ¥è¿”å›ç©ºå¸ƒå±€
                # é¿å…åœ¨æ²¡æœ‰æ•°æ®æ—¶æ‰§è¡Œä¸å¿…è¦çš„æ“ä½œ
                logger.info("[INFO] æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å›¾å½¢ç”Ÿæˆï¼Œè¿”å›ç©ºå¸ƒå±€")
                empty_fig = {}
                report_content = html.Div([
                        html.H4("æš‚æ— æ•°æ®", className="text-center text-muted"),
                        html.P("è¯·è‡³å°‘æ¿€æ´»ä¸€ä¸ªç®—æ³•ä»¥æŸ¥çœ‹åˆ†ææŠ¥å‘Š", className="text-center text-muted"),
                        # åŒ…å«æ‰€æœ‰å¿…éœ€çš„å›¾è¡¨ç»„ä»¶ï¼ˆéšè—ï¼‰ï¼Œç¡®ä¿å›è°ƒå‡½æ•°ä¸ä¼šæŠ¥é”™
                        dcc.Graph(id='key-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                        dcc.Graph(id='key-delay-zscore-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                        dcc.Graph(id='hammer-velocity-delay-scatter-plot', figure=empty_fig, style={'display': 'none'}),
                        # key-hammer-velocity-scatter-plot å·²åˆ é™¤ï¼ˆåŠŸèƒ½ä¸æŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾é‡å¤ï¼‰
                        dcc.Graph(id='key-force-interaction-plot', figure=empty_fig, style={'display': 'none'}),
                        dcc.Graph(id='relative-delay-distribution-plot', figure=empty_fig, style={'display': 'none'}),
                        html.Div(id='offset-alignment-plot', style={'display': 'none'}),
                        dcc.Graph(id='delay-time-series-plot', figure=empty_fig, style={'display': 'none'}),
                        dcc.Graph(id='delay-histogram-plot', figure=empty_fig, style={'display': 'none'}),
                        html.Div([
                            dash_table.DataTable(
                                id='offset-alignment-table',
                                data=[],
                                columns=[]
                            )
                        ], style={'display': 'none'}),
                        html.Div([
                            dash_table.DataTable(
                                id='delay-histogram-detail-table',
                                data=[],
                                columns=[
                                    {"name": "ç®—æ³•åç§°", "id": "algorithm_name"},
                                    {"name": "æŒ‰é”®ID", "id": "key_id"},
                                    {"name": "å»¶æ—¶(ms)", "id": "delay_ms"},
                                    {"name": "å½•åˆ¶ç´¢å¼•", "id": "record_index"},
                                    {"name": "æ’­æ”¾ç´¢å¼•", "id": "replay_index"},
                                    {"name": "å½•åˆ¶å¼€å§‹(0.1ms)", "id": "record_keyon"},
                                    {"name": "æ’­æ”¾å¼€å§‹(0.1ms)", "id": "replay_keyon"},
                                    {"name": "æŒç»­æ—¶é—´å·®(0.1ms)", "id": "duration_offset"},
                                ]
                            )
                        ], style={'display': 'none'}),
                        html.Div(id='delay-histogram-selection-info', style={'display': 'none'})
                        ])
            
            logger.info(f"[OK] å¤šç®—æ³•æ¨¡å¼åˆå§‹åŒ–å®Œæˆ")
            return upload_style, upload_area, management_style, management_area, plot_fig, report_content
            
        except Exception as e:
            logger.error(f"[ERROR] åˆå§‹åŒ–å¤šç®—æ³•æ¨¡å¼å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return (
                {'display': 'block'}, 
                html.Div("åˆå§‹åŒ–å¤±è´¥", style={'color': '#dc3545'}), 
                {'display': 'block'}, 
                html.Div("åˆå§‹åŒ–å¤±è´¥", style={'color': '#dc3545'}), 
                no_update, 
                no_update
            )
    

    
    
    
    
    
    # æ›´æ–°å•é”®é€‰æ‹©å™¨çš„é€‰é¡¹
    @app.callback(
        Output('single-key-selector', 'options'),
        [Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def update_single_key_selector_options(report_content, session_id):
        backend = session_manager.get_backend(session_id)
        if not backend or not hasattr(backend, 'multi_algorithm_manager'):
            return []
            
        try:
            active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
            if not active_algorithms:
                return []
                
            all_keys = set()
            for alg in active_algorithms:
                if alg.analyzer and alg.analyzer.note_matcher:
                    offset_data = alg.analyzer.note_matcher.get_offset_alignment_data()
                    if offset_data:
                        for item in offset_data:
                            if item.get('key_id') is not None:
                                all_keys.add(item.get('key_id'))
                                
            sorted_keys = sorted(list(all_keys))
            return [{'label': f'Key {k}', 'value': k} for k in sorted_keys]
            
        except Exception as e:
            logger.error(f"[ERROR] æ›´æ–°å•é”®é€‰æ‹©å™¨å¤±è´¥: {e}")
            return []

    # å•é”®å¤šæ›²å»¶æ—¶å¯¹æ¯”å›¾è‡ªåŠ¨ç”Ÿæˆå›è°ƒ
    @app.callback(
        Output('single-key-delay-comparison-plot', 'figure'),
        [Input('single-key-selector', 'value'),
         Input('report-content', 'children')],
        [State('session-id', 'data')],
        prevent_initial_call=True
    )
    def handle_generate_single_key_comparison_plot(key_id, report_content, session_id):
        backend = session_manager.get_backend(session_id)
        if not backend:
            return no_update

        if not key_id:
            # è¿”å›ç©ºå›¾è¡¨æç¤º
            return {
                "layout": {
                    "xaxis": {"visible": False},
                    "yaxis": {"visible": False},
                    "annotations": [
                        {
                            "text": "è¯·é€‰æ‹©ä¸€ä¸ªæŒ‰é”®è¿›è¡Œåˆ†æ",
                            "xref": "paper",
                            "yref": "paper",
                            "showarrow": False,
                            "font": {"size": 20},
                            "x": 0.5,
                            "y": 0.5
                        }
                    ]
                }
            }
            
        try:
            fig = backend.generate_single_key_delay_comparison_plot(key_id)
            return fig
        except Exception as e:
            logger.error(f"[ERROR] ç”Ÿæˆå•é”®å¯¹æ¯”å›¾å¤±è´¥: {e}")
            return backend.plot_generator._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")

    # æŒ‰é”®å»¶æ—¶åˆ†æè¡¨æ ¼ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæŒ‰é”®æ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True)],
        [Input('offset-alignment-table', 'active_cell'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State('offset-alignment-table', 'data'),
         State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_key_table_click(active_cell, close_modal_clicks, close_btn_clicks, table_data, session_id, current_style):
        """å¤„ç†æŒ‰é”®å»¶æ—¶åˆ†æè¡¨æ ¼ç‚¹å‡»ï¼Œæ˜¾ç¤ºæŒ‰é”®æ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾"""
        
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            logger.debug("[WARNING] æŒ‰é”®è¡¨æ ¼ç‚¹å‡»å›è°ƒï¼šæ²¡æœ‰è§¦å‘æº")
            return current_style, [], no_update
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        logger.debug(f"[DEBUG] æŒ‰é”®è¡¨æ ¼ç‚¹å‡»å›è°ƒè§¦å‘ï¼štrigger_id={trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal', 'close-key-curves-modal-btn']:
            logger.info("[OK] å…³é—­æŒ‰é”®æ›²çº¿å¯¹æ¯”æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, [], no_update
        
        # å¦‚æœæ˜¯è¡¨æ ¼ç‚¹å‡»
        if trigger_id == 'offset-alignment-table':
            logger.info(f"[PROCESS] è¡¨æ ¼ç‚¹å‡»ï¼šactive_cell={active_cell}, table_dataé•¿åº¦={len(table_data) if table_data else 0}")
            backend = session_manager.get_backend(session_id)
            if not backend:
                logger.warning("[WARNING] æ²¡æœ‰æ‰¾åˆ°backend")
                return current_style, [], no_update
            if not active_cell or not table_data:
                logger.warning("[WARNING] active_cellæˆ–table_dataä¸ºç©º")
                return current_style, [], no_update
            
            try:
                # è·å–ç‚¹å‡»çš„è¡Œæ•°æ®
                row_idx = active_cell.get('row')
                if row_idx is None or row_idx >= len(table_data):
                    return current_style, [], no_update
                
                row_data = table_data[row_idx]
                algorithm_name = row_data.get('algorithm_name')
                key_id_str = row_data.get('key_id')
                
                # è·³è¿‡æ±‡æ€»è¡Œ
                if key_id_str in ['æ€»ä½“', 'æ±‡æ€»'] or not algorithm_name:
                    return current_style, [], no_update
                
                # è½¬æ¢æŒ‰é”®ID
                try:
                    key_id = int(key_id_str)
                except (ValueError, TypeError):
                    return current_style, [], no_update
                
                # æ£€æŸ¥æ˜¯å¦åœ¨å¤šç®—æ³•æ¨¡å¼
                if not backend.multi_algorithm_mode or not backend.multi_algorithm_manager:
                    logger.info("[INFO] ä¸åœ¨å¤šç®—æ³•æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºæ›²çº¿å¯¹æ¯”å›¾")
                    return current_style, [], no_update
                
                # è·å–æ¿€æ´»çš„ç®—æ³•åˆ—è¡¨
                active_algorithms = backend.get_active_algorithms()
                if len(active_algorithms) < 2:
                    modal_style = {
                        'display': 'block',
                        'position': 'fixed',
                        'zIndex': '9999',
                        'left': '0',
                        'top': '0',
                        'width': '100%',
                        'height': '100%',
                        'backgroundColor': 'rgba(0,0,0,0.6)',
                        'backdropFilter': 'blur(5px)'
                    }
                    return modal_style, [html.Div([
                        html.P("éœ€è¦è‡³å°‘2ä¸ªæ¿€æ´»çš„ç®—æ³•æ‰èƒ½è¿›è¡Œå¯¹æ¯”", className="text-muted text-center")
                    ])], no_update
                
                # è·å–æ‰€æœ‰æ¿€æ´»ç®—æ³•çš„åŒ¹é…å¯¹
                algorithm_pairs_dict = {}
                all_timestamps = set()
                
                for alg in active_algorithms:
                    alg_name = alg.metadata.algorithm_name
                    pairs = backend.get_key_matched_pairs_by_algorithm(alg_name, key_id)
                    if pairs:
                        algorithm_pairs_dict[alg_name] = pairs
                        for _, _, _, _, timestamp in pairs:
                            all_timestamps.add(timestamp)
                
                if not algorithm_pairs_dict:
                    modal_style = {
                        'display': 'block',
                        'position': 'fixed',
                        'zIndex': '9999',
                        'left': '0',
                        'top': '0',
                        'width': '100%',
                        'height': '100%',
                        'backgroundColor': 'rgba(0,0,0,0.6)',
                        'backdropFilter': 'blur(5px)'
                    }
                    return modal_style, [html.Div([
                        html.P(f"æŒ‰é”®ID {key_id} åœ¨æ‰€æœ‰æ¿€æ´»ç®—æ³•ä¸­éƒ½æ²¡æœ‰åŒ¹é…æ•°æ®", className="text-muted text-center")
                    ])], no_update
                
                # é€‰æ‹©å‰ä¸¤ä¸ªæœ‰æ•°æ®çš„ç®—æ³•è¿›è¡Œå¯¹æ¯”
                alg_names = list(algorithm_pairs_dict.keys())[:2]
                if len(alg_names) < 2:
                    # å¦‚æœåªæœ‰ä¸€ä¸ªç®—æ³•æœ‰æ•°æ®ï¼Œé€‰æ‹©å‰ä¸¤ä¸ªæ¿€æ´»çš„ç®—æ³•ï¼ˆå³ä½¿ç¬¬äºŒä¸ªæ²¡æœ‰æ•°æ®ï¼‰
                    alg_names = [alg.metadata.algorithm_name for alg in active_algorithms[:2]]
                    if alg_names[0] not in algorithm_pairs_dict:
                        alg_names[0] = list(algorithm_pairs_dict.keys())[0]
                
                alg1_name = alg_names[0]
                alg2_name = alg_names[1]
                
                alg1_pairs = algorithm_pairs_dict.get(alg1_name, [])
                alg2_pairs = algorithm_pairs_dict.get(alg2_name, [])
                
                # ç”Ÿæˆå¯¹æ¯”æ›²çº¿å›¾
                from plotly.subplots import make_subplots
                
                comparison_rows = []
                
                # ä½¿ç”¨åŒæŒ‡é’ˆæŒ‰æ—¶é—´æˆ³å¯¹é½
                # æ³¨æ„ï¼šä¸¤ä¸ªç®—æ³•å¤„ç†çš„æ˜¯å®Œå…¨ä¸åŒçš„SPMIDæ–‡ä»¶ï¼Œå„è‡ªæœ‰ç‹¬ç«‹çš„å½•åˆ¶æ•°æ®å’Œæ’­æ”¾æ•°æ®
                # - ç®—æ³•Aï¼šSPMIDæ–‡ä»¶1çš„å½•åˆ¶æ•°æ®1 vs æ’­æ”¾æ•°æ®1
                # - ç®—æ³•Bï¼šSPMIDæ–‡ä»¶2çš„å½•åˆ¶æ•°æ®2 vs æ’­æ”¾æ•°æ®2
                # å®ƒä»¬ä¹‹é—´æ²¡æœ‰ä»»ä½•å…³è”ï¼Œrecord_indexå’Œrecord_keyonéƒ½æ˜¯å„è‡ªæ–‡ä»¶å†…çš„
                # æ­¥éª¤ï¼š
                # - æå–ä¸¤ä¸ªç®—æ³•çš„æ—¶é—´æˆ³åºåˆ—ï¼ˆå•ä½ï¼š0.1msï¼Œrecord_keyonæ˜¯å„è‡ªæ–‡ä»¶å†…å½•åˆ¶æŒ‰é”®å¼€å§‹æ—¶é—´ï¼‰
                # - ä½¿ç”¨ä¸¤ä¸ªæŒ‡é’ˆåœ¨åˆå¹¶æ—¶é—´çº¿ä¸Šå‰è¿›ï¼Œå°½é‡å°†æ—¶é—´ä¸´è¿‘çš„é…å¯¹ï¼Œå¦åˆ™å•ä¾§æ˜¾ç¤º
                ALIGN_WINDOW_01MS = 200  # å¯¹é½çª—å£ï¼š200(0.1ms) = 20ms
                
                alg1_pairs_sorted = sorted(alg1_pairs, key=lambda p: p[4])
                alg2_pairs_sorted = sorted(alg2_pairs, key=lambda p: p[4])
                i, j = 0, 0
                while i < len(alg1_pairs_sorted) or j < len(alg2_pairs_sorted):
                    if i < len(alg1_pairs_sorted) and j < len(alg2_pairs_sorted):
                        t1 = alg1_pairs_sorted[i][4]
                        t2 = alg2_pairs_sorted[j][4]
                        diff = abs(t1 - t2)
                        if diff <= ALIGN_WINDOW_01MS:
                            # é…å¯¹æ˜¾ç¤º
                            comparison_rows.append((alg1_pairs_sorted[i], alg2_pairs_sorted[j], t1, t2))
                            i += 1
                            j += 1
                        elif t1 < t2:
                            # å·¦ä¾§å•ç‹¬æ˜¾ç¤º
                            comparison_rows.append((alg1_pairs_sorted[i], None, t1, None))
                            i += 1
                        else:
                            # å³ä¾§å•ç‹¬æ˜¾ç¤º
                            comparison_rows.append((None, alg2_pairs_sorted[j], None, t2))
                            j += 1
                    elif i < len(alg1_pairs_sorted):
                        t1 = alg1_pairs_sorted[i][4]
                        comparison_rows.append((alg1_pairs_sorted[i], None, t1, None))
                        i += 1
                    else:
                        t2 = alg2_pairs_sorted[j][4]
                        comparison_rows.append((None, alg2_pairs_sorted[j], None, t2))
                        j += 1
                
                # ä¸ºæ¯ä¸ªå¯¹é½é¡¹åˆ›å»ºå¯¹æ¯”å›¾
                rendered_rows = []
                for alg1_pair, alg2_pair, t1, t2 in comparison_rows:
                    if not alg1_pair and not alg2_pair:
                        continue
                    
                    # åˆ›å»ºå·¦å³å¯¹æ¯”çš„å­å›¾ï¼Œæ ‡é¢˜æ˜¾ç¤ºå„è‡ªæ—¶é—´
                    # record_keyonï¼šå„è‡ªSPMIDæ–‡ä»¶å†…å½•åˆ¶æŒ‰é”®å¼€å§‹æ—¶é—´ï¼ˆä¸¤ä¸ªæ–‡ä»¶ç‹¬ç«‹ï¼Œæ—¶é—´æˆ³æ— å…³è”ï¼‰
                    if alg1_pair and t1 is not None:
                        title1 = f"{alg1_name}<br>å½•åˆ¶æŒ‰é”®å¼€å§‹: {t1/10:.2f}ms"
                    else:
                        title1 = f"{alg1_name} (æ— æ•°æ®)"
                    
                    if alg2_pair and t2 is not None:
                        title2 = f"{alg2_name}<br>å½•åˆ¶æŒ‰é”®å¼€å§‹: {t2/10:.2f}ms"
                    else:
                        title2 = f"{alg2_name} (æ— æ•°æ®)"
                    
                    fig = make_subplots(
                        rows=1, cols=2,
                        subplot_titles=(title1, title2),
                        horizontal_spacing=0.15
                    )
                    
                    # å·¦ä¾§ï¼šç®—æ³•1çš„æ›²çº¿
                    if alg1_pair:
                        _, _, record_note1, replay_note1, _ = alg1_pair
                        if record_note1 and hasattr(record_note1, 'after_touch') and not record_note1.after_touch.empty:
                            x_at = (record_note1.after_touch.index + record_note1.offset) / 10.0
                            y_at = record_note1.after_touch.values
                            fig.add_trace(go.Scatter(x=x_at, y=y_at, mode='lines', name='å½•åˆ¶è§¦å', 
                                                    line=dict(color='blue', width=2), showlegend=False), row=1, col=1)
                        if record_note1 and hasattr(record_note1, 'hammers') and not record_note1.hammers.empty:
                            x_hm = (record_note1.hammers.index + record_note1.offset) / 10.0
                            y_hm = record_note1.hammers.values
                            fig.add_trace(go.Scatter(x=x_hm, y=y_hm, mode='markers', name='å½•åˆ¶é”¤å­',
                                                    marker=dict(color='blue', size=6), showlegend=False), row=1, col=1)
                        if replay_note1 and hasattr(replay_note1, 'after_touch') and not replay_note1.after_touch.empty:
                            x_at = (replay_note1.after_touch.index + replay_note1.offset) / 10.0
                            y_at = replay_note1.after_touch.values
                            fig.add_trace(go.Scatter(x=x_at, y=y_at, mode='lines', name='å›æ”¾è§¦å',
                                                    line=dict(color='red', width=2), showlegend=False), row=1, col=1)
                        if replay_note1 and hasattr(replay_note1, 'hammers') and not replay_note1.hammers.empty:
                            x_hm = (replay_note1.hammers.index + replay_note1.offset) / 10.0
                            y_hm = replay_note1.hammers.values
                            fig.add_trace(go.Scatter(x=x_hm, y=y_hm, mode='markers', name='å›æ”¾é”¤å­',
                                                    marker=dict(color='red', size=6), showlegend=False), row=1, col=1)
                    
                    # å³ä¾§ï¼šç®—æ³•2çš„æ›²çº¿
                    if alg2_pair:
                        _, _, record_note2, replay_note2, _ = alg2_pair
                        if record_note2 and hasattr(record_note2, 'after_touch') and not record_note2.after_touch.empty:
                            x_at = (record_note2.after_touch.index + record_note2.offset) / 10.0
                            y_at = record_note2.after_touch.values
                            fig.add_trace(go.Scatter(x=x_at, y=y_at, mode='lines', name='å½•åˆ¶è§¦å',
                                                    line=dict(color='blue', width=2), showlegend=False), row=1, col=2)
                        if record_note2 and hasattr(record_note2, 'hammers') and not record_note2.hammers.empty:
                            x_hm = (record_note2.hammers.index + record_note2.offset) / 10.0
                            y_hm = record_note2.hammers.values
                            fig.add_trace(go.Scatter(x=x_hm, y=y_hm, mode='markers', name='å½•åˆ¶é”¤å­',
                                                    marker=dict(color='blue', size=6), showlegend=False), row=1, col=2)
                        if replay_note2 and hasattr(replay_note2, 'after_touch') and not replay_note2.after_touch.empty:
                            x_at = (replay_note2.after_touch.index + replay_note2.offset) / 10.0
                            y_at = replay_note2.after_touch.values
                            fig.add_trace(go.Scatter(x=x_at, y=y_at, mode='lines', name='å›æ”¾è§¦å',
                                                    line=dict(color='red', width=2), showlegend=False), row=1, col=2)
                        if replay_note2 and hasattr(replay_note2, 'hammers') and not replay_note2.hammers.empty:
                            x_hm = (replay_note2.hammers.index + replay_note2.offset) / 10.0
                            y_hm = replay_note2.hammers.values
                            fig.add_trace(go.Scatter(x=x_hm, y=y_hm, mode='markers', name='å›æ”¾é”¤å­',
                                                    marker=dict(color='red', size=6), showlegend=False), row=1, col=2)
                    
                    # ä¸»æ ‡é¢˜
                    title_text = f"æŒ‰é”®ID {key_id} æ›²çº¿å¯¹æ¯”"
                    
                    fig.update_layout(
                        title=title_text,
                        height=400,
                        showlegend=False
                    )
                    fig.update_xaxes(title_text="æ—¶é—´ (ms)", row=1, col=1)
                    fig.update_xaxes(title_text="æ—¶é—´ (ms)", row=1, col=2)
                    fig.update_yaxes(title_text="å€¼", row=1, col=1)
                    fig.update_yaxes(title_text="å€¼", row=1, col=2)
                    
                    rendered_rows.append(
                        dbc.Row([
                            dbc.Col([
                                dcc.Graph(figure=fig, style={'height': '400px'})
                            ], width=12)
                        ], className="mb-3")
                    )
                
                if not rendered_rows:
                    modal_style = {
                        'display': 'block',
                        'position': 'fixed',
                        'zIndex': '9999',
                        'left': '0',
                        'top': '0',
                        'width': '100%',
                        'height': '100%',
                        'backgroundColor': 'rgba(0,0,0,0.6)',
                        'backdropFilter': 'blur(5px)'
                    }
                    return modal_style, [html.Div([
                        html.P(f"æŒ‰é”®ID {key_id} æ²¡æœ‰å¯æ˜¾ç¤ºçš„å¯¹æ¯”æ•°æ®", className="text-muted text-center")
                    ])], no_update
                
                # è®¡ç®—æ—¶é—´ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æ—¶ç›´æ¥ä½¿ç”¨
                center_time_ms = None
                record_idx = None
                replay_idx = None
                first_algorithm_name = None
                
                try:
                    # è·å–ç¬¬ä¸€ä¸ªåŒ¹é…å¯¹ç”¨äºè·³è½¬
                    if alg1_pairs:
                        first_pair = alg1_pairs[0]
                        record_idx, replay_idx, record_note, replay_note, _ = first_pair
                        first_algorithm_name = alg1_name
                        
                        if record_note and replay_note:
                            try:
                                # è®¡ç®—keyonæ—¶é—´
                                record_keyon = record_note.after_touch.index[0] + record_note.offset if hasattr(record_note, 'after_touch') and not record_note.after_touch.empty else record_note.offset
                                replay_keyon = replay_note.after_touch.index[0] + replay_note.offset if hasattr(replay_note, 'after_touch') and not replay_note.after_touch.empty else replay_note.offset
                                center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0  # è½¬æ¢ä¸ºms
                                logger.info(f"[OK] è®¡ç®—å¾—åˆ°center_time_ms: {center_time_ms}ms")
                            except Exception as e:
                                logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                                # å¤‡ç”¨æ–¹æ¡ˆï¼šä» offset_data è·å–
                                try:
                                    algorithm = backend.multi_algorithm_manager.get_algorithm(alg1_name)
                                    if algorithm and algorithm.analyzer and algorithm.analyzer.note_matcher:
                                        offset_data = algorithm.analyzer.note_matcher.get_offset_alignment_data()
                                        if offset_data:
                                            for item in offset_data:
                                                if item.get('record_index') == record_idx and item.get('replay_index') == replay_idx:
                                                    record_keyon = item.get('record_keyon', 0)
                                                    replay_keyon = item.get('replay_keyon', 0)
                                                    if record_keyon and replay_keyon:
                                                        center_time_ms = ((record_keyon + replay_keyon) / 2.0) / 10.0
                                                        logger.info(f"[OK] ä»offset_dataè·å–center_time_ms: {center_time_ms}ms")
                                                        break
                                except Exception as e2:
                                    logger.warning(f"[WARNING] ä»offset_dataè·å–æ—¶é—´ä¿¡æ¯å¤±è´¥: {e2}")
                except Exception as e:
                    logger.warning(f"[WARNING] è·å–è·³è½¬ä¿¡æ¯å¤±è´¥: {e}")
                
                # å­˜å‚¨å½“å‰ç‚¹å‡»çš„æ•°æ®ç‚¹ä¿¡æ¯ï¼Œç”¨äºè·³è½¬æŒ‰é’®
                point_info = {
                    'algorithm_name': first_algorithm_name,
                    'record_idx': record_idx,
                    'replay_idx': replay_idx,
                    'key_id': key_id,
                    'source_plot_id': 'offset-alignment-table',  # è®°å½•æ¥æºè¡¨æ ¼ID
                    'center_time_ms': center_time_ms  # é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯
                }
                
                # æ˜¾ç¤ºæ¨¡æ€æ¡†
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                
                return modal_style, rendered_rows, point_info
                
            except Exception as e:
                logger.error(f"[ERROR] ç”ŸæˆæŒ‰é”®æ›²çº¿å¯¹æ¯”å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                return modal_style, [html.Div([
                    html.P(f"ç”Ÿæˆå¯¹æ¯”å›¾å¤±è´¥: {str(e)}", className="text-danger text-center")
                ])], no_update
        
        # å…¶ä»–æƒ…å†µï¼Œä¿æŒå½“å‰çŠ¶æ€
        return current_style, [], no_update
    
    # ç€‘å¸ƒå›¾ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰
    @app.callback(
        [Output('waterfall-curves-modal', 'style'),
         Output('waterfall-curves-comparison-container', 'children')],
        [Input('main-plot', 'clickData'),
         Input('close-waterfall-curves-modal', 'n_clicks'),
         Input('close-waterfall-curves-modal-btn', 'n_clicks')],
        [State('session-id', 'data'),
         State('waterfall-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_waterfall_click(click_data, close_modal_clicks, close_btn_clicks, session_id, current_style):
        """å¤„ç†ç€‘å¸ƒå›¾ç‚¹å‡»ï¼Œæ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰"""
        
        
        
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            print("[ERROR] æ²¡æœ‰è§¦å‘æº")
            return current_style, []
        
        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
        print(f"ğŸ” è§¦å‘ID: {trigger_id}")
        
        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-waterfall-curves-modal', 'close-waterfall-curves-modal-btn']:
            print("[OK] å…³é—­ç€‘å¸ƒå›¾æ›²çº¿æ¨¡æ€æ¡†")
            modal_style = {
                'display': 'none',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }
            return modal_style, []
        
        # å¦‚æœæ˜¯ç€‘å¸ƒå›¾ç‚¹å‡»
        if trigger_id == 'main-plot' and click_data:
            print("[TARGET] æ£€æµ‹åˆ°ç€‘å¸ƒå›¾ç‚¹å‡»ï¼")
            
            backend = session_manager.get_backend(session_id)
            if not backend:
                print("[ERROR] backendä¸ºç©º")
                return current_style, []
            
            try:
                if 'points' not in click_data or len(click_data['points']) == 0:
                    print("[ERROR] clickDataä¸­æ²¡æœ‰points")
                    return current_style, []
                
                point = click_data['points'][0]
                
                # ä¼˜å…ˆä»customdataè·å–ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»åæ ‡è·å–
                algorithm_name = None
                key_id = None
                data_type = None
                index = None
                
                if point.get('customdata'):
                    # æœ‰customdataï¼šç‚¹å‡»åˆ°äº†èµ·å§‹æ—¶é—´
                    raw_customdata = point['customdata']
                    customdata = raw_customdata[0] if isinstance(raw_customdata, list) and len(raw_customdata) > 0 and isinstance(raw_customdata[0], list) else raw_customdata
                else:
                    # æ²¡æœ‰customdataï¼Œè®¾ç½®ä¸ºç©º
                    customdata = None
                
                print(f"[DATA] customdata: {customdata}")

                if isinstance(customdata, list) and len(customdata) >= 7:
                    # ä»customdataæå–ä¿¡æ¯ï¼š[t_on/10, t_off/10, original_key_id, value, label, index, algorithm_name]
                    algorithm_name = customdata[6]
                    key_id = int(customdata[2])
                    data_type = customdata[4]  # 'record' æˆ– 'play'
                    index = int(customdata[5])
                    print(f"[STATS] ä»customdataæå–: algorithm_name={algorithm_name}, key_id={key_id}, data_type={data_type}, index={index}")
                
                # å¦‚æœæ²¡æœ‰customdataï¼Œä»ç‚¹å‡»åæ ‡æŸ¥æ‰¾å¯¹åº”çš„éŸ³ç¬¦
                if not algorithm_name or key_id is None or index is None:
                    # è·å–ç‚¹å‡»çš„åæ ‡
                    click_x = point.get('x')  # æ—¶é—´ï¼ˆmsï¼‰
                    click_y = point.get('y')  # æŒ‰é”®ID
                    
                    if click_x is None or click_y is None:
                        print("[ERROR] æ— æ³•ä»åæ ‡è·å–ç‚¹å‡»ä½ç½®")
                        return current_style, []
                    
                    print(f"[LOCATION] ä»åæ ‡è·å–: x={click_x}ms, y={click_y}")
                    
                    # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ï¼Œéœ€è¦æ ¹æ®yåæ ‡åˆ¤æ–­æ˜¯å“ªä¸ªç®—æ³•
                    if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                        algorithm_y_range = 100  # æ¯ä¸ªç®—æ³•åç§»100ä¸ªå•ä½
                        
                        # æ ¹æ®yåæ ‡æ‰¾åˆ°å¯¹åº”çš„ç®—æ³•å’Œå®é™…æŒ‰é”®ID
                        for alg_idx, alg in enumerate(active_algorithms):
                            alg_y_offset = alg_idx * algorithm_y_range
                            if alg_y_offset <= click_y < alg_y_offset + algorithm_y_range:
                                algorithm_name = alg.metadata.algorithm_name
                                key_id = int(click_y - alg_y_offset)
                                print(f"[OK] æ‰¾åˆ°ç®—æ³•: {algorithm_name}, å®é™…æŒ‰é”®ID: {key_id}")
                                break
                    else:
                        # å•ç®—æ³•æ¨¡å¼
                        key_id = int(click_y)
                        algorithm_name = None
                    
                    if not algorithm_name and backend.multi_algorithm_mode:
                        print("[ERROR] æ— æ³•ç¡®å®šç®—æ³•")
                        return current_style, []
                    
                    # æ ¹æ®æ—¶é—´å’ŒæŒ‰é”®IDæŸ¥æ‰¾å¯¹åº”çš„éŸ³ç¬¦
                # è·å–ç®—æ³•å¯¹è±¡
                    if not backend.multi_algorithm_manager:
                        backend._ensure_multi_algorithm_manager()
                    
                    if algorithm_name:
                        algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name)
                    else:
                        # å•ç®—æ³•æ¨¡å¼
                        algorithm = None
                        if backend.analyzer:
                            # ä½¿ç”¨offset_dataæŸ¥æ‰¾
                            if backend.analyzer.note_matcher:
                                offset_data = backend.analyzer.note_matcher.get_offset_alignment_data()
                                if offset_data:
                                    # æŸ¥æ‰¾æ—¶é—´èŒƒå›´å†…çš„éŸ³ç¬¦
                                    click_time_01ms = click_x * 10  # è½¬æ¢ä¸º0.1mså•ä½
                                    for item in offset_data:
                                        item_key_id = item.get('key_id')
                                        # ç¡®ä¿key_idç±»å‹ä¸€è‡´
                                        try:
                                            item_key_id = int(item_key_id) if item_key_id is not None else None
                                        except (ValueError, TypeError):
                                            continue
                                        
                                        record_keyon = item.get('record_keyon', 0)
                                        record_keyoff = item.get('record_keyoff', 0)
                                        # å¦‚æœæ²¡æœ‰record_keyoffï¼Œä½¿ç”¨record_keyon + record_duration
                                        if record_keyoff == 0:
                                            record_duration = item.get('record_duration', 0)
                                            record_keyoff = record_keyon + record_duration
                                        
                                        if item_key_id == key_id and record_keyon <= click_time_01ms <= record_keyoff:
                                            index = item.get('record_index')
                                            data_type = 'record'
                                            print(f"[OK] å•ç®—æ³•æ¨¡å¼: æ‰¾åˆ°éŸ³ç¬¦ index={index}, data_type={data_type}, æ—¶é—´èŒƒå›´: {record_keyon/10:.1f}ms - {record_keyoff/10:.1f}ms, ç‚¹å‡»æ—¶é—´: {click_time_01ms/10:.1f}ms")
                                            break
                    
                    if algorithm_name and not algorithm:
                        print("[ERROR] æ— æ³•è·å–ç®—æ³•å¯¹è±¡")
                        return current_style, []
                    
                    # å¤šç®—æ³•æ¨¡å¼ï¼šä»offset_dataæŸ¥æ‰¾
                    if algorithm_name and algorithm and algorithm.analyzer and algorithm.analyzer.note_matcher:
                        offset_data = algorithm.analyzer.note_matcher.get_offset_alignment_data()
                        if offset_data:
                            click_time_01ms = click_x * 10  # è½¬æ¢ä¸º0.1mså•ä½
                            for item in offset_data:
                                item_key_id = item.get('key_id')
                                # ç¡®ä¿key_idç±»å‹ä¸€è‡´
                                try:
                                    item_key_id = int(item_key_id) if item_key_id is not None else None
                                except (ValueError, TypeError):
                                    continue
                                
                                record_keyon = item.get('record_keyon', 0)
                                record_keyoff = item.get('record_keyoff', 0)
                                # å¦‚æœæ²¡æœ‰record_keyoffï¼Œä½¿ç”¨record_keyon + record_duration
                                if record_keyoff == 0:
                                    record_duration = item.get('record_duration', 0)
                                    record_keyoff = record_keyon + record_duration
                                
                                if item_key_id == key_id and record_keyon <= click_time_01ms <= record_keyoff:
                                    index = item.get('record_index')
                                    data_type = 'record'
                                    print(f"[OK] å¤šç®—æ³•æ¨¡å¼: æ‰¾åˆ°éŸ³ç¬¦ index={index}, data_type={data_type}, æ—¶é—´èŒƒå›´: {record_keyon/10:.1f}ms - {record_keyoff/10:.1f}ms, ç‚¹å‡»æ—¶é—´: {click_time_01ms/10:.1f}ms")
                                    break
                
                if key_id is None or index is None:
                    print(f"[ERROR] æ— æ³•ç¡®å®šæŒ‰é”®ä¿¡æ¯: key_id={key_id}, index={index}")
                    print(f"ğŸ” è°ƒè¯•ä¿¡æ¯: click_x={point.get('x')}, click_y={point.get('y')}, algorithm_name={algorithm_name}")
                    if not point.get('customdata'):
                        print(f"[WARNING] æ²¡æœ‰customdataï¼Œå°è¯•ä»åæ ‡æŸ¥æ‰¾å¤±è´¥")
                    return current_style, []
                
                print(f"[STATS] æœ€ç»ˆæå–çš„æ•°æ®: algorithm_name={algorithm_name}, key_id={key_id}, data_type={data_type}, index={index}")
                
                # è·å–ç®—æ³•å¯¹è±¡
                algorithm = None
                if backend.multi_algorithm_mode:
                    if not algorithm_name:
                        print("[ERROR] å¤šç®—æ³•æ¨¡å¼ä¸‹æ— æ³•ç¡®å®šç®—æ³•åç§°")
                        return current_style, []
                if not backend.multi_algorithm_manager:
                    backend._ensure_multi_algorithm_manager()
                algorithm = None
                if backend.multi_algorithm_manager:
                    algorithm = backend.multi_algorithm_manager.get_algorithm(algorithm_name)
                    print(f"[DEBUG] æŸ¥æ‰¾ç®—æ³•: algorithm_name='{algorithm_name}', algorithm={algorithm is not None}")
                    if algorithm:
                        print(f"[DEBUG] ç®—æ³•çŠ¶æ€: is_active={algorithm.is_active}, is_ready={algorithm.is_ready()}, analyzer={algorithm.analyzer is not None}")
                    if not algorithm or not algorithm.analyzer:
                        print(f"[ERROR] ç®—æ³•å¯¹è±¡æˆ–analyzerä¸ºç©º: algorithm={algorithm is not None}, analyzer={algorithm.analyzer is not None if algorithm else None}")

                        # è°ƒè¯•ï¼šåˆ—å‡ºæ‰€æœ‰å¯ç”¨ç®—æ³•
                        all_algorithms = backend.multi_algorithm_manager.get_all_algorithms()
                        print(f"[DEBUG] æ‰€æœ‰å¯ç”¨ç®—æ³•: {[alg.metadata.algorithm_name for alg in all_algorithms]}")

                        # å¦‚æœæ˜¯å¤šç®—æ³•æ¨¡å¼ä½†æ‰¾ä¸åˆ°ç®—æ³•ï¼Œå°è¯•å•ç®—æ³•æ¨¡å¼
                        if backend.analyzer:
                            print("[INFO] å°è¯•ä½¿ç”¨å•ç®—æ³•æ¨¡å¼")
                            algorithm = None  # æ ‡è®°ä¸ºå•ç®—æ³•æ¨¡å¼
                        else:
                            return current_style, []
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    if not backend.analyzer:
                        print("[ERROR] analyzerä¸ºç©º")
                        return current_style, []
                    algorithm = None  # å•ç®—æ³•æ¨¡å¼ä¸‹ä¸éœ€è¦algorithmå¯¹è±¡
                
                # è·å–matched_pairsï¼ˆå·²ä¿å­˜çš„é…å¯¹æ•°æ®ï¼‰
                if algorithm is not None:
                    # å¤šç®—æ³•æ¨¡å¼
                    matched_pairs = algorithm.analyzer.matched_pairs if hasattr(algorithm.analyzer, 'matched_pairs') else []
                    valid_record_data = algorithm.analyzer.valid_record_data if hasattr(algorithm.analyzer, 'valid_record_data') else []
                    valid_replay_data = algorithm.analyzer.valid_replay_data if hasattr(algorithm.analyzer, 'valid_replay_data') else []
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    matched_pairs = backend.analyzer.matched_pairs if hasattr(backend.analyzer, 'matched_pairs') else []
                    valid_record_data = backend.analyzer.valid_record_data if hasattr(backend.analyzer, 'valid_record_data') else []
                    valid_replay_data = backend.analyzer.valid_replay_data if hasattr(backend.analyzer, 'valid_replay_data') else []
                
                # æ­¥éª¤1ï¼šå…ˆåˆ¤æ–­è¿™ä¸ªæŒ‰é”®IDï¼ˆé€šè¿‡indexï¼‰æ˜¯å¦åœ¨matched_pairsä¸­æœ‰åŒ¹é…å¯¹
                has_matched_pair = False
                record_note = None
                replay_note = None
                
                print(f"ğŸ” å¼€å§‹æŸ¥æ‰¾åŒ¹é…å¯¹: key_id={key_id}, data_type={data_type}, index={index}")
                print(f"[STATS] matched_pairsæ•°é‡: {len(matched_pairs)}")
                
                # æ ¹æ®data_typeå’Œindexåœ¨matched_pairsä¸­æŸ¥æ‰¾
                if data_type == 'record':
                    # ç‚¹å‡»çš„æ˜¯å½•åˆ¶çº¿ï¼ŒæŸ¥æ‰¾r_idx == indexçš„åŒ¹é…å¯¹
                    print(f"ğŸ” åœ¨matched_pairsä¸­æŸ¥æ‰¾: r_idx == {index}")
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if r_idx == index and r_note.id == key_id:
                            # æ‰¾åˆ°åŒ¹é…å¯¹
                            has_matched_pair = True
                            record_note = r_note
                            replay_note = p_note
                            print(f"[OK] æ‰¾åˆ°å®Œæ•´åŒ¹é…å¯¹ï¼")
                            break
                else:
                    # ç‚¹å‡»çš„æ˜¯æ’­æ”¾çº¿ï¼ŒæŸ¥æ‰¾p_idx == indexçš„åŒ¹é…å¯¹
                    print(f"ğŸ” åœ¨matched_pairsä¸­æŸ¥æ‰¾: p_idx == {index}")
                    for r_idx, p_idx, r_note, p_note in matched_pairs:
                        if p_idx == index and p_note.id == key_id:
                            # æ‰¾åˆ°åŒ¹é…å¯¹
                            has_matched_pair = True
                            record_note = r_note
                            replay_note = p_note
                            print(f"[OK] æ‰¾åˆ°å®Œæ•´åŒ¹é…å¯¹ï¼")
                            break
                
                print(f"[TARGET] åŒ¹é…ç»“æœ: has_matched_pair={has_matched_pair}")
                
                # æ­¥éª¤2ï¼šæ ¹æ®åŒ¹é…ç»“æœç”Ÿæˆæ›²çº¿
                if has_matched_pair:
                    # è·å–å½“å‰ç®—æ³•çš„display_nameï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦æ˜¯åŒç§ç®—æ³•çš„ä¸åŒæ›²å­
                    current_display_name = None
                    if algorithm and algorithm.metadata:
                        current_display_name = algorithm.metadata.display_name

                    # åœ¨å¤šç®—æ³•æ¨¡å¼ä¸‹ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ç®—æ³•ä¸­åŒ¹é…åˆ°åŒä¸€ä¸ªå½•åˆ¶éŸ³ç¬¦çš„æ’­æ”¾éŸ³ç¬¦
                    # ä½†æ˜¯ï¼Œå¯¹äºåŒç§ç®—æ³•çš„ä¸åŒæ›²å­ï¼ˆç›¸åŒdisplay_nameï¼‰ï¼Œä¸æ·»åŠ å…¶ä»–ç®—æ³•çš„æ›²çº¿
                    other_algorithm_notes = []  # [(algorithm_name, play_note), ...]
                    if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                        active_algorithms = backend.multi_algorithm_manager.get_active_algorithms()
                        for alg in active_algorithms:
                            if alg.metadata.algorithm_name == algorithm_name:
                                continue  # è·³è¿‡å½“å‰ç®—æ³•ï¼ˆå·²ç»ç»˜åˆ¶ï¼‰

                            # å¦‚æœæ˜¯åŒç§ç®—æ³•çš„ä¸åŒæ›²å­ï¼ˆç›¸åŒdisplay_nameï¼‰ï¼Œè·³è¿‡
                            if current_display_name and alg.metadata.display_name == current_display_name:
                                logger.info(f"[SKIP] è·³è¿‡åŒç§ç®—æ³•çš„ä¸åŒæ›²å­: {alg.metadata.algorithm_name} (display_name={alg.metadata.display_name})")
                                continue

                            if not alg.analyzer or not hasattr(alg.analyzer, 'matched_pairs'):
                                continue

                            alg_matched_pairs = alg.analyzer.matched_pairs
                            # æŸ¥æ‰¾åŒ¹é…åˆ°åŒä¸€ä¸ªrecord_indexçš„æ’­æ”¾éŸ³ç¬¦
                            for r_idx, p_idx, r_note, p_note in alg_matched_pairs:
                                if r_idx == index and r_note.id == key_id:
                                    other_algorithm_notes.append((alg.metadata.algorithm_name, p_note))
                                    logger.info(f"[OK] æ‰¾åˆ°ç®—æ³• '{alg.metadata.algorithm_name}' çš„åŒ¹é…æ’­æ”¾éŸ³ç¬¦")
                                    break

                    # æœ‰åŒ¹é…å¯¹ï¼šç»˜åˆ¶å½•åˆ¶+æ’­æ”¾å¯¹æ¯”æ›²çº¿
                    # å¯¹äºåŒç§ç®—æ³•çš„ä¸åŒæ›²å­ï¼Œother_algorithm_notesä¸ºç©ºï¼Œåªæ˜¾ç¤ºå½•åˆ¶å’Œæ’­æ”¾æ›²çº¿

                    # è®¡ç®—å„ç®—æ³•çš„å¹³å‡å»¶æ—¶
                    mean_delays = {}
                    if not algorithm or not algorithm.analyzer:
                        print(f"[ERROR] ç®—æ³•å¯¹è±¡æˆ–åˆ†æå™¨ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—å¹³å‡å»¶æ—¶")
                        return current_style, []

                    mean_error_0_1ms = algorithm.analyzer.get_mean_error()
                    mean_delays[algorithm_name] = mean_error_0_1ms / 10.0  # è½¬æ¢ä¸ºæ¯«ç§’

                    # ä¸ºå…¶ä»–ç®—æ³•ä¹Ÿè®¡ç®—å¹³å‡å»¶æ—¶
                    for other_alg_name, _ in other_algorithm_notes:
                        if backend.multi_algorithm_mode and backend.multi_algorithm_manager:
                            other_alg = None
                            for alg in backend.multi_algorithm_manager.get_active_algorithms():
                                if alg.metadata.algorithm_name == other_alg_name:
                                    other_alg = alg
                                    break
                            if other_alg and other_alg.analyzer:
                                other_mean_error_0_1ms = other_alg.analyzer.get_mean_error()
                                mean_delays[other_alg_name] = other_mean_error_0_1ms / 10.0  # è½¬æ¢ä¸ºæ¯«ç§’
                            else:
                                print(f"[ERROR] å…¶ä»–ç®—æ³• '{other_alg_name}' å¯¹è±¡æˆ–åˆ†æå™¨ä¸ºç©º")
                                return current_style, []

                    detail_figure_combined = spmid.plot_note_comparison_plotly(
                        record_note,
                        replay_note,
                        algorithm_name=algorithm_name,
                        other_algorithm_notes=other_algorithm_notes,  # å¯¹äºåŒç§ç®—æ³•çš„ä¸åŒæ›²å­ï¼Œè¿™æ˜¯ç©ºåˆ—è¡¨
                        mean_delays=mean_delays
                    )
                    print(f"[OK] æŒ‰é”®ID {key_id} æœ‰åŒ¹é…å¯¹ï¼Œç»˜åˆ¶å½•åˆ¶+æ’­æ”¾å¯¹æ¯”æ›²çº¿ï¼ˆåŒç§ç®—æ³•ä¸åŒæ›²å­æ—¶ä¸æ˜¾ç¤ºå…¶ä»–ç®—æ³•æ›²çº¿ï¼‰")
                else:
                    # æ²¡æœ‰åŒ¹é…å¯¹ï¼šåªç»˜åˆ¶è¿™ä¸ªæ•°æ®ç‚¹çš„æ•°æ®ï¼ˆå¯èƒ½æ˜¯å½•åˆ¶ï¼Œä¹Ÿå¯èƒ½æ˜¯æ’­æ”¾ï¼‰
                    # å¯¹äºåŒ¹é…å¤±è´¥çš„éŸ³ç¬¦ï¼Œéœ€è¦ä»åŸå§‹æ•°æ®ä¸­æŸ¥æ‰¾æ­£ç¡®çš„éŸ³ç¬¦å¯¹è±¡
                    print(f"[INFO] æœªæ‰¾åˆ°åŒ¹é…å¯¹ï¼Œå°è¯•æŸ¥æ‰¾åŒ¹é…å¤±è´¥çš„éŸ³ç¬¦æ•°æ®")

                    # é¦–å…ˆå°è¯•ç›´æ¥ç´¢å¼•
                    found_note = False
                    if data_type == 'record' and index >= 0 and index < len(valid_record_data):
                        record_note = valid_record_data[index]
                        replay_note = None
                        # éªŒè¯æŒ‰é”®IDæ˜¯å¦åŒ¹é…
                        if hasattr(record_note, 'id') and record_note.id == key_id:
                            found_note = True
                            print(f"[OK] é€šè¿‡ç›´æ¥ç´¢å¼•æ‰¾åˆ°å½•åˆ¶éŸ³ç¬¦: index={index}, key_id={key_id}")
                        else:
                            record_note = None
                            print(f"[WARNING] ç›´æ¥ç´¢å¼•çš„å½•åˆ¶éŸ³ç¬¦key_idä¸åŒ¹é…: æœŸæœ›{key_id}, å®é™…{record_note.id if record_note else 'N/A'}")

                    elif data_type == 'play' and index >= 0 and index < len(valid_replay_data):
                        record_note = None
                        replay_note = valid_replay_data[index]
                        # éªŒè¯æŒ‰é”®IDæ˜¯å¦åŒ¹é…
                        if hasattr(replay_note, 'id') and replay_note.id == key_id:
                            found_note = True
                            print(f"[OK] é€šè¿‡ç›´æ¥ç´¢å¼•æ‰¾åˆ°æ’­æ”¾éŸ³ç¬¦: index={index}, key_id={key_id}")
                        else:
                            replay_note = None
                            print(f"[WARNING] ç›´æ¥ç´¢å¼•çš„æ’­æ”¾éŸ³ç¬¦key_idä¸åŒ¹é…: æœŸæœ›{key_id}, å®é™…{replay_note.id if replay_note else 'N/A'}")

                    # å¦‚æœç›´æ¥ç´¢å¼•å¤±è´¥ï¼Œå°è¯•é€šè¿‡key_idéå†æŸ¥æ‰¾
                    if not found_note:
                        print(f"[INFO] ç›´æ¥ç´¢å¼•å¤±è´¥ï¼Œå°è¯•é€šè¿‡key_idéå†æŸ¥æ‰¾")
                        if data_type == 'record':
                            for i, note in enumerate(valid_record_data):
                                if hasattr(note, 'id') and note.id == key_id:
                                    record_note = note
                                    replay_note = None
                                    found_note = True
                                    print(f"[OK] é€šè¿‡éå†æ‰¾åˆ°å½•åˆ¶éŸ³ç¬¦: array_index={i}, key_id={key_id}")
                                    break
                        elif data_type == 'play':
                            for i, note in enumerate(valid_replay_data):
                                if hasattr(note, 'id') and note.id == key_id:
                                    record_note = None
                                    replay_note = note
                                    found_note = True
                                    print(f"[OK] é€šè¿‡éå†æ‰¾åˆ°æ’­æ”¾éŸ³ç¬¦: array_index={i}, key_id={key_id}")
                                    break

                    # å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ï¼Œå°è¯•ä»é”™è¯¯æ•°æ®ä¸­æŸ¥æ‰¾ï¼ˆä¸¢é”¤ã€å¤šé”¤ï¼‰
                    if not found_note:
                        print(f"[INFO] åœ¨æœ‰æ•ˆæ•°æ®ä¸­æœªæ‰¾åˆ°ï¼Œå°è¯•ä»é”™è¯¯æ•°æ®ä¸­æŸ¥æ‰¾")
                        # è·å–é”™è¯¯æ•°æ®
                        drop_hammers = getattr(algorithm.analyzer if algorithm else backend.analyzer, 'drop_hammers', [])
                        multi_hammers = getattr(algorithm.analyzer if algorithm else backend.analyzer, 'multi_hammers', [])

                        # æ£€æŸ¥ä¸¢é”¤æ•°æ®
                        for error_note in drop_hammers:
                            if hasattr(error_note, 'infos') and error_note.infos:
                                for note_info in error_note.infos:
                                    if hasattr(note_info, 'keyId') and note_info.keyId == key_id:
                                        # å¯¹äºä¸¢é”¤ï¼Œåªæ˜¾ç¤ºå½•åˆ¶æ•°æ®
                                        if data_type == 'record':
                                            # å°è¯•ä»valid_record_dataä¸­æ‰¾åˆ°å¯¹åº”çš„éŸ³ç¬¦
                                            for note in valid_record_data:
                                                if hasattr(note, 'id') and note.id == key_id:
                                                    record_note = note
                                                    replay_note = None
                                                    found_note = True
                                                    print(f"[OK] ä»ä¸¢é”¤æ•°æ®ä¸­æ‰¾åˆ°å½•åˆ¶éŸ³ç¬¦: key_id={key_id}")
                                                    break
                                        break
                            if found_note:
                                break

                        # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œæ£€æŸ¥å¤šé”¤æ•°æ®
                        if not found_note:
                            for error_note in multi_hammers:
                                if hasattr(error_note, 'infos') and error_note.infos:
                                    for note_info in error_note.infos:
                                        if hasattr(note_info, 'keyId') and note_info.keyId == key_id:
                                            # å¯¹äºå¤šé”¤ï¼Œåªæ˜¾ç¤ºæ’­æ”¾æ•°æ®
                                            if data_type == 'play':
                                                # å°è¯•ä»valid_replay_dataä¸­æ‰¾åˆ°å¯¹åº”çš„éŸ³ç¬¦
                                                for note in valid_replay_data:
                                                    if hasattr(note, 'id') and note.id == key_id:
                                                        record_note = None
                                                        replay_note = note
                                                        found_note = True
                                                        print(f"[OK] ä»å¤šé”¤æ•°æ®ä¸­æ‰¾åˆ°æ’­æ”¾éŸ³ç¬¦: key_id={key_id}")
                                                        break
                                            break
                                if found_note:
                                    break

                    if not found_note:
                        print(f"[ERROR] æ— æ³•æ‰¾åˆ°ä»»ä½•åŒ¹é…çš„éŸ³ç¬¦æ•°æ®: key_id={key_id}, data_type={data_type}")
                        return current_style, []

                    # è®¡ç®—å¹³å‡å»¶æ—¶ï¼ˆå¯¹äºåŒ¹é…å¤±è´¥çš„éŸ³ç¬¦ï¼Œä½¿ç”¨0ä½œä¸ºå¹³å‡å»¶æ—¶ï¼Œä¸è¿›è¡Œåç§»ï¼‰
                    mean_delays = {algorithm_name: 0.0}  # ä¸è¿›è¡Œæ—¶é—´è½´åç§»

                    detail_figure_combined = spmid.plot_note_comparison_plotly(
                        record_note, replay_note,
                        algorithm_name=algorithm_name,
                        mean_delays=mean_delays
                    )
                    print(f"[OK] åŒ¹é…å¤±è´¥çš„æŒ‰é”®ID {key_id} æ‰¾åˆ°éŸ³ç¬¦æ•°æ®ï¼Œåªç»˜åˆ¶å•ä¾§æ›²çº¿ï¼ˆæ— åç§»ï¼‰")
                
                if not detail_figure_combined:
                    print("[ERROR] æ›²çº¿ç”Ÿæˆå¤±è´¥")
                    return current_style, []
                
                # æ˜¾ç¤ºæ¨¡æ€æ¡†
                modal_style = {
                    'display': 'block',
                    'position': 'fixed',
                    'zIndex': '9999',
                    'left': '0',
                    'top': '0',
                    'width': '100%',
                    'height': '100%',
                    'backgroundColor': 'rgba(0,0,0,0.6)',
                    'backdropFilter': 'blur(5px)'
                }
                

                
                # ç”Ÿæˆå…¨è¿‡ç¨‹å¤„ç†å›¾
                processing_stages_figure = None
                if backend.force_curve_analyzer and record_note and replay_note:
                    try:
                        comparison_result = backend.force_curve_analyzer.compare_curves(record_note, replay_note)
                        if comparison_result:
                            processing_stages_figure = backend.force_curve_analyzer.visualize_all_processing_stages(comparison_result)
                    except Exception as e:
                        print(f"[ERROR] ç”Ÿæˆå…¨è¿‡ç¨‹å¤„ç†å›¾å¤±è´¥: {e}")

                # æ„å»ºæ¨¡æ€æ¡†å†…å®¹ï¼šä½¿ç”¨Tabså±•ç¤ºå¯¹æ¯”å›¾å’Œå…¨è¿‡ç¨‹å›¾
                modal_content = [
                    dcc.Tabs([
                        dcc.Tab(label='æ›²çº¿å¯¹æ¯”', children=[
                            dcc.Graph(
                                figure=detail_figure_combined, 
                                style={'height': '700px'},
                                config={'scrollZoom': True, 'displayModeBar': True}
                            )
                        ]),
                        dcc.Tab(label='å¤„ç†å…¨è¿‡ç¨‹', children=[
                            html.Div(
                                style={'height': '85vh', 'overflowY': 'auto', 'padding': '10px'},
                                children=[
                            dcc.Graph(
                                figure=processing_stages_figure if processing_stages_figure else go.Figure(),
                                        style={'height': f"{processing_stages_figure.layout.height}px"} if processing_stages_figure and processing_stages_figure.layout.height else {'height': '2000px'},
                                        config={'scrollZoom': True, 'displayModeBar': True, 'responsive': True}
                            ) if processing_stages_figure else html.Div("æ— æ³•ç”Ÿæˆå¤„ç†å…¨è¿‡ç¨‹å›¾ï¼ˆå¯èƒ½åªæœ‰å•ä¾§æ•°æ®ï¼‰", className="text-center p-3 text-muted")
                                ]
                            )
                        ])
                    ])
                ]
                
                rendered_row = html.Div(modal_content)
                
                print("[OK] æ˜¾ç¤ºæ¨¡æ€æ¡†")
                return modal_style, [rendered_row]
                
            except Exception as e:
                logger.error(f"[ERROR] ç€‘å¸ƒå›¾ç‚¹å‡»å¤„ç†å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                print(traceback.format_exc())
                return current_style, []
        
        # å…¶ä»–æƒ…å†µï¼Œä¿æŒå½“å‰çŠ¶æ€
        return current_style, []

    # è·³è½¬åˆ°ç€‘å¸ƒå›¾æŒ‰é’®å›è°ƒ
    @app.callback(
        [Output('main-plot', 'figure', allow_duplicate=True),
         Output('main-tabs', 'value', allow_duplicate=True),
         Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('jump-source-plot-id', 'data', allow_duplicate=True)],
        [Input('jump-to-waterfall-btn', 'n_clicks'),
         Input('jump-to-waterfall-btn-from-modal', 'n_clicks')],
        [State('session-id', 'data'),
         State('current-clicked-point-info', 'data')],
        prevent_initial_call=True
    )
    def handle_jump_to_waterfall(n_clicks, n_clicks_from_modal, session_id, point_info):
        """å¤„ç†è·³è½¬åˆ°ç€‘å¸ƒå›¾æŒ‰é’®ç‚¹å‡»"""
        return waterfall_jump_handler.handle_jump_to_waterfall(n_clicks or n_clicks_from_modal, session_id, point_info)
    
    # è¿”å›æŠ¥å‘Šç•Œé¢æŒ‰é’®å›è°ƒ
    @app.callback(
        [Output('main-tabs', 'value', allow_duplicate=True),
         Output('scroll-to-plot-trigger', 'data', allow_duplicate=True),
         Output('grade-detail-section-scroll-trigger', 'data', allow_duplicate=True)],
        [Input('btn-return-to-report', 'n_clicks')],
        [State('jump-source-plot-id', 'data')],
        prevent_initial_call=True
    )
    def handle_return_to_report(n_clicks, source_plot_id):
        """å¤„ç†è¿”å›æŠ¥å‘Šç•Œé¢æŒ‰é’®ç‚¹å‡»ï¼Œå¹¶è§¦å‘æ»šåŠ¨åˆ°æ¥æºå›¾è¡¨"""
        if n_clicks and n_clicks > 0:
            logger.info(f"[PROCESS] è¿”å›æŠ¥å‘Šç•Œé¢ï¼Œæ¥æºå›¾è¡¨: {source_plot_id}")
            
            # å¦‚æœæ˜¯ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if isinstance(source_plot_id, dict):
                # ä»point_infoä¸­è·å–å­å›¾ç´¢å¼•
                # source_plot_id å¯èƒ½åŒ…å«å­å›¾ç´¢å¼•ä¿¡æ¯
                if source_plot_id.get('type') == 'relative-delay-distribution-plot':
                    subplot_idx = source_plot_id.get('index')
                    if subplot_idx is not None:
                        # è¿”å›åŒ…å«å­å›¾ç´¢å¼•çš„æ»šåŠ¨æ•°æ®
                        scroll_data = {
                            'plot_type': 'relative-delay-distribution',
                            'subplot_index': int(subplot_idx)  # ç¡®ä¿æ˜¯æ•´æ•°
                        }
                        return 'report-tab', scroll_data, no_update
                # å…¶ä»–æƒ…å†µï¼Œè¿”å›åŸå§‹æ•°æ®ï¼ˆä½†éœ€è¦ç¡®ä¿æ˜¯JSONå¯åºåˆ—åŒ–çš„ï¼‰
                return 'report-tab', source_plot_id, no_update
            elif isinstance(source_plot_id, str) and source_plot_id == 'relative-delay-distribution-plot':
                # éœ€è¦ä»point_infoä¸­è·å–å­å›¾ç´¢å¼•
                # ä½†ç”±äºè¿™é‡Œæ²¡æœ‰point_infoï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼è·å–
                # æš‚æ—¶è¿”å›ä¸€ä¸ªé€šç”¨çš„æ»šåŠ¨æ•°æ®ï¼Œè®©å®¢æˆ·ç«¯å›è°ƒå¤„ç†
                scroll_data = {
                    'plot_type': 'relative-delay-distribution',
                    'subplot_index': None  # å®¢æˆ·ç«¯ä¼šå°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯è§çš„å­å›¾
                }
                return 'report-tab', scroll_data, no_update
            elif source_plot_id == 'grade-detail-curves-modal':
                # ä»è¯„çº§ç»Ÿè®¡æ¨¡æ€æ¡†è·³è½¬å›æ¥ï¼Œæ»šåŠ¨åˆ°è¯„çº§ç»Ÿè®¡åŒºåŸŸ
                section_scroll_data = {'scroll_to': 'grade_detail_section'}
                logger.info("[PROCESS] ä»è¯„çº§ç»Ÿè®¡è·³è½¬å›æ¥ï¼Œè§¦å‘åŒºåŸŸæ»šåŠ¨")
                return 'report-tab', no_update, section_scroll_data
            elif source_plot_id in ['error-table-drop', 'error-table-multi']:
                # ä»é”™è¯¯è¡¨æ ¼æ¨¡æ€æ¡†è·³è½¬å›æ¥ï¼Œæ»šåŠ¨åˆ°å¯¹åº”çš„é”™è¯¯è¡¨æ ¼åŒºåŸŸ
                error_table_scroll_data = {'scroll_to': 'error_table_section', 'table_type': source_plot_id.split('-')[-1]}
                logger.info(f"[PROCESS] ä»{source_plot_id}è·³è½¬å›æ¥ï¼Œè§¦å‘é”™è¯¯è¡¨æ ¼åŒºåŸŸæ»šåŠ¨")
                return 'report-tab', no_update, error_table_scroll_data
            elif source_plot_id in ['raw-delay-time-series-plot', 'relative-delay-time-series-plot']:
                # ä»å»¶æ—¶æ—¶é—´åºåˆ—å›¾è·³è½¬å›æ¥ï¼Œæ»šåŠ¨åˆ°å¯¹åº”çš„æ—¶é—´åºåˆ—å›¾åŒºåŸŸ
                time_series_scroll_data = {'scroll_to': 'delay_time_series_section', 'plot_type': source_plot_id}
                logger.info(f"[PROCESS] ä»{source_plot_id}è·³è½¬å›æ¥ï¼Œè§¦å‘æ—¶é—´åºåˆ—å›¾åŒºåŸŸæ»šåŠ¨")
                return 'report-tab', no_update, time_series_scroll_data
            else:
                # æ™®é€šå›¾è¡¨ï¼Œç›´æ¥è¿”å›IDï¼ˆå­—ç¬¦ä¸²ï¼‰
                if source_plot_id:
                    return 'report-tab', str(source_plot_id), no_update
                else:
                    return 'report-tab', None, no_update

            return no_update, no_update, no_update
    
    # å®¢æˆ·ç«¯å›è°ƒï¼šæ»šåŠ¨åˆ°æŒ‡å®šå›¾è¡¨
    app.clientside_callback(
        """
        function(scroll_data) {
            if (scroll_data === null || scroll_data === undefined) {
                return window.dash_clientside.no_update;
            }
            
            try {
                // å¦‚æœæ˜¯ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾çš„æ»šåŠ¨æ•°æ®ï¼ˆå¯¹è±¡æ ¼å¼ï¼‰
                if (typeof scroll_data === 'object' && scroll_data !== null && scroll_data.plot_type === 'relative-delay-distribution') {
                    const subplotIndex = scroll_data.subplot_index;
                    // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ ‡ç­¾é¡µåˆ‡æ¢å®Œæˆ
                    setTimeout(function() {
                        try {
                            // æŸ¥æ‰¾æ‰€æœ‰ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾çš„å­å›¾å®¹å™¨
                            // å­å›¾å®¹å™¨çš„ç»“æ„ï¼šæ¯ä¸ªå­å›¾éƒ½åœ¨ä¸€ä¸ªDivä¸­ï¼ŒåŒ…å«Graphå…ƒç´ 
                            const allContainers = document.querySelectorAll('[id*="relative-delay-distribution"]');
                            let targetElement = null;
                            
                            // å¦‚æœæŒ‡å®šäº†å­å›¾ç´¢å¼•ï¼Œå°è¯•æ‰¾åˆ°å¯¹åº”çš„å­å›¾
                            if (subplotIndex) {
                                // æŸ¥æ‰¾åŒ…å«æŒ‡å®šç´¢å¼•çš„å­å›¾å®¹å™¨
                                // ç”±äºPattern Matching Callbacksï¼ŒIDæ ¼å¼æ˜¯åŠ¨æ€çš„
                                // æˆ‘ä»¬éœ€è¦é€šè¿‡éå†æ‰€æœ‰å®¹å™¨æ¥æ‰¾åˆ°å¯¹åº”çš„å­å›¾
                                let currentIndex = 1;
                                allContainers.forEach(function(container) {
                                    // æ£€æŸ¥æ˜¯å¦æ˜¯å›¾è¡¨å®¹å™¨ï¼ˆåŒ…å«Graphå…ƒç´ ï¼‰
                                    const graphElement = container.querySelector('.js-plotly-plot');
                                    if (graphElement && currentIndex === subplotIndex) {
                                        targetElement = container;
                                    }
                                    if (graphElement) {
                                        currentIndex++;
                                    }
                                });
                            }
                            
                            // å¦‚æœæ‰¾åˆ°äº†ç›®æ ‡å…ƒç´ ï¼Œæ»šåŠ¨åˆ°å®ƒ
                            if (targetElement) {
                                const elementPosition = targetElement.getBoundingClientRect().top + window.pageYOffset;
                                const offsetPosition = elementPosition - 100;
                                window.scrollTo({
                                    top: offsetPosition,
                                    behavior: 'smooth'
                                });
                            } else if (allContainers.length > 0) {
                                // å¦‚æœæ‰¾ä¸åˆ°ï¼Œæ»šåŠ¨åˆ°ç¬¬ä¸€ä¸ªå¯è§çš„ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å­å›¾
                                const firstContainer = allContainers[0];
                                const elementPosition = firstContainer.getBoundingClientRect().top + window.pageYOffset;
                                const offsetPosition = elementPosition - 100;
                                window.scrollTo({
                                    top: offsetPosition,
                                    behavior: 'smooth'
                                });
                            }
                        } catch (e) {
                            console.error('æ»šåŠ¨åˆ°ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å¤±è´¥:', e);
                        }
                    }, 300);
                    return window.dash_clientside.no_update;
                }
                
                // æ™®é€šå›¾è¡¨IDï¼ˆå­—ç¬¦ä¸²ï¼‰
                if (typeof scroll_data === 'string') {
                    const plot_id = scroll_data;
                    // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ ‡ç­¾é¡µåˆ‡æ¢å®Œæˆ
                    setTimeout(function() {
                        try {
                            // æŸ¥æ‰¾å¯¹åº”çš„å›¾è¡¨å…ƒç´ 
                            const plotElement = document.getElementById(plot_id);
                            if (plotElement) {
                                // æ»šåŠ¨åˆ°å›¾è¡¨ä½ç½®ï¼Œå¹¶æ·»åŠ ä¸€äº›åç§»é‡ï¼ˆå‘ä¸Šåç§»100pxï¼Œé¿å…è¢«é¡¶éƒ¨å¯¼èˆªæ é®æŒ¡ï¼‰
                                const elementPosition = plotElement.getBoundingClientRect().top + window.pageYOffset;
                                const offsetPosition = elementPosition - 100;
                                
                                window.scrollTo({
                                    top: offsetPosition,
                                    behavior: 'smooth'  // å¹³æ»‘æ»šåŠ¨
                                });
                            }
                        } catch (e) {
                            console.error('æ»šåŠ¨åˆ°å›¾è¡¨å¤±è´¥:', e);
                        }
                    }, 300);  // å»¶è¿Ÿ300msï¼Œç¡®ä¿DOMæ›´æ–°å®Œæˆ
                }
            } catch (e) {
                console.error('å®¢æˆ·ç«¯å›è°ƒé”™è¯¯:', e);
            }
            
            return window.dash_clientside.no_update;
        }
        """,
        Output('scroll-to-plot-trigger', 'data', allow_duplicate=True),
        Input('scroll-to-plot-trigger', 'data'),
        prevent_initial_call=True
    )
    
    # å®¢æˆ·ç«¯å›è°ƒï¼šæ»šåŠ¨åˆ°ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾çš„å¯¹åº”å­å›¾ä½ç½®
    app.clientside_callback(
        """
        function(scroll_data) {
            if (!scroll_data || !scroll_data.subplot_index) {
                return window.dash_clientside.no_update;
            }
            
            const subplotIndex = scroll_data.subplot_index;
            const graphElement = document.getElementById('relative-delay-distribution-plot');
            if (!graphElement) {
                return window.dash_clientside.no_update;
            }
            
            // è®¡ç®—å­å›¾çš„ä½ç½®ï¼ˆæ¯ä¸ªå­å›¾é«˜åº¦çº¦500pxï¼‰
            const baseHeightPerSubplot = 500;
            const subplotTop = (subplotIndex - 1) * baseHeightPerSubplot;
            
            // è·å–å›¾è¡¨å…ƒç´ çš„ä½ç½®
            setTimeout(function() {
                const graphRect = graphElement.getBoundingClientRect();
                const absoluteGraphTop = graphRect.top + window.pageYOffset;
                const targetScrollTop = absoluteGraphTop + subplotTop;
                
                // æ»šåŠ¨åˆ°å¯¹åº”å­å›¾ä½ç½®
                window.scrollTo({
                    top: targetScrollTop,
                    behavior: 'smooth'
                });
                
                // å»¶è¿Ÿåæ»šåŠ¨åˆ°è¡¨æ ¼ä½ç½®
                setTimeout(function() {
                    const tableContainer = document.getElementById('relative-delay-distribution-table-container');
                    if (tableContainer) {
                        const tableRect = tableContainer.getBoundingClientRect();
                        const absoluteTableTop = tableRect.top + window.pageYOffset;
                        const offset = 100;
                        window.scrollTo({
                            top: absoluteTableTop - offset,
                            behavior: 'smooth'
                        });
                    }
                }, 500);
            }, 300);
            
            return window.dash_clientside.no_update;
        }
        """,
        Output('relative-delay-distribution-scroll-trigger', 'data', allow_duplicate=True),
        Input('relative-delay-distribution-scroll-trigger', 'data'),
        prevent_initial_call=True
    )

    # å®¢æˆ·ç«¯å›è°ƒï¼šè¯„çº§ç»Ÿè®¡è¿”å›æ—¶æ»šåŠ¨åˆ°å¯¹åº”è¡Œ
    app.clientside_callback(
        """
        function(scroll_data) {
            if (!scroll_data || !scroll_data.table_index || scroll_data.row_index === undefined) {
                return window.dash_clientside.no_update;
            }

            const tableIndex = scroll_data.table_index;
            const rowIndex = scroll_data.row_index;

            // æŸ¥æ‰¾å¯¹åº”çš„è¡¨æ ¼
            const tableSelector = `[data-dash-component-id*="grade-detail-datatable"][data-dash-component-id*="${tableIndex}"]`;
            const tableElement = document.querySelector(tableSelector);

            if (!tableElement) {
                console.warn('Grade detail table not found:', tableSelector);
                return window.dash_clientside.no_update;
            }

            // æ¨¡æ‹Ÿç‚¹å‡»å¯¹åº”è¡Œæ¥æ¿€æ´»å®ƒ
            setTimeout(function() {
                try {
                    // æ„é€ è¡¨æ ¼è¡Œçš„é€‰æ‹©å™¨
                    // Dashè¡¨æ ¼çš„è¡Œé€šå¸¸æœ‰ç‰¹å®šçš„ç±»åå’Œç»“æ„
                    const tableBody = tableElement.querySelector('.dash-table-body');
                    if (tableBody) {
                        const rows = tableBody.querySelectorAll('.dash-table-row');
                        if (rows && rows.length > rowIndex) {
                            const targetRow = rows[rowIndex];

                            // æ»šåŠ¨åˆ°ç›®æ ‡è¡Œ
                            targetRow.scrollIntoView({
                                behavior: 'smooth',
                                block: 'center'
                            });

                            // è§¦å‘è¡Œçš„ç‚¹å‡»äº‹ä»¶æ¥æ¿€æ´»å®ƒ
                            // æ³¨æ„ï¼šè¿™å¯èƒ½éœ€è¦æ ¹æ®Dashè¡¨æ ¼çš„å…·ä½“å®ç°è¿›è¡Œè°ƒæ•´
                            setTimeout(function() {
                                // å°è¯•è®¾ç½®active_cellï¼ˆå¦‚æœå¯èƒ½çš„è¯ï¼‰
                                // è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
                                console.log('Scrolled to grade detail table row:', rowIndex);
                            }, 300);
                        } else {
                            console.warn('Target row not found in grade detail table:', rowIndex);
                        }
                    }
                } catch (error) {
                    console.error('Error scrolling to grade detail table row:', error);
                }
            }, 500);  // ç­‰å¾…æ¨¡æ€æ¡†æ˜¾ç¤ºåå†æ»šåŠ¨

            return window.dash_clientside.no_update;
        }
        """,
        Output('grade-detail-return-scroll-trigger', 'data', allow_duplicate=True),
        Input('grade-detail-return-scroll-trigger', 'data'),
        prevent_initial_call=True
    )

    # å®¢æˆ·ç«¯å›è°ƒï¼šæ»šåŠ¨åˆ°è¯„çº§ç»Ÿè®¡åŒºåŸŸ
    app.clientside_callback(
        """
        function(scroll_data) {
            if (!scroll_data) {
                return window.dash_clientside.no_update;
            }

            if (scroll_data.scroll_to === 'grade_detail_section') {
                // æŸ¥æ‰¾è¯„çº§ç»Ÿè®¡åŒºåŸŸ
                // ä¼˜å…ˆæŸ¥æ‰¾æœ‰ç‰¹å®šIDçš„å¡ç‰‡
                let targetElement = document.getElementById('grade-statistics-card');

                if (!targetElement) {
                    // å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šIDï¼ŒæŸ¥æ‰¾æ‰€æœ‰å¡ç‰‡ï¼Œå¯»æ‰¾åŒ…å«"åŒ¹é…è´¨é‡è¯„çº§ç»Ÿè®¡"çš„æ ‡é¢˜
                    const allCards = document.querySelectorAll('.card');
                    for (let card of allCards) {
                        const header = card.querySelector('h4');
                        if (header && header.textContent && header.textContent.includes('åŒ¹é…è´¨é‡è¯„çº§ç»Ÿè®¡')) {
                            targetElement = card;
                            console.log('Found grade detail card by title:', header.textContent);
                            break;
                        }
                    }
                }

                // å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«grade-detailçš„å…ƒç´ 
                if (!targetElement) {
                    const gradeDetailElements = document.querySelectorAll('[id*="grade-detail"]');
                    if (gradeDetailElements.length > 0) {
                        // å‘ä¸ŠæŸ¥æ‰¾æœ€è¿‘çš„å¡ç‰‡å®¹å™¨
                        targetElement = gradeDetailElements[0].closest('.card') || gradeDetailElements[0];
                        console.log('Found grade detail element by fallback');
                    }
                }

                if (targetElement) {
                    setTimeout(function() {
                        try {
                            // æ»šåŠ¨åˆ°è¯„çº§ç»Ÿè®¡åŒºåŸŸ
                            targetElement.scrollIntoView({
                                behavior: 'smooth',
                                block: 'start',
                                inline: 'nearest'
                            });

                            console.log('Scrolled to grade detail section successfully');
                        } catch (error) {
                            console.error('Error scrolling to grade detail section:', error);
                        }
                    }, 500);  // ç­‰å¾…æ›´é•¿æ—¶é—´è®©é¡µé¢å®Œå…¨åŠ è½½
                } else {
                    console.warn('Grade detail section not found. Available cards:');
                    const cards = document.querySelectorAll('.card');
                    for (let card of cards) {
                        const header = card.querySelector('h4');
                        if (header) {
                            console.warn('Card header:', header.textContent);
                        }
                    }
                }
            } else if (scroll_data.scroll_to === 'error_table_section') {
                // æŸ¥æ‰¾é”™è¯¯è¡¨æ ¼åŒºåŸŸ
                const tableType = scroll_data.table_type; // 'drop' æˆ– 'multi'
                let targetElement = null;

                if (tableType === 'drop') {
                    // æŸ¥æ‰¾ä¸¢é”¤è¡¨æ ¼
                    const dropTables = document.querySelectorAll('[id*="drop-hammers-table"]');
                    if (dropTables.length > 0) {
                        targetElement = dropTables[0].closest('.card') || dropTables[0];
                        console.log('Found drop hammers table');
                    }
                } else if (tableType === 'multi') {
                    // æŸ¥æ‰¾å¤šé”¤è¡¨æ ¼
                    const multiTables = document.querySelectorAll('[id*="multi-hammers-table"]');
                    if (multiTables.length > 0) {
                        targetElement = multiTables[0].closest('.card') || multiTables[0];
                        console.log('Found multi hammers table');
                    }
                }

                if (targetElement) {
                    setTimeout(function() {
                        try {
                            // æ»šåŠ¨åˆ°é”™è¯¯è¡¨æ ¼åŒºåŸŸ
                            targetElement.scrollIntoView({
                                behavior: 'smooth',
                                block: 'start',
                                inline: 'nearest'
                            });

                            console.log(`Scrolled to ${tableType} hammers table section successfully`);
                        } catch (error) {
                            console.error(`Error scrolling to ${tableType} hammers table section:`, error);
                        }
                    }, 500);
                } else {
                    console.warn(`${tableType} hammers table section not found`);
                }
            } else if (scroll_data.scroll_to === 'delay_time_series_section') {
                // æŸ¥æ‰¾å»¶æ—¶æ—¶é—´åºåˆ—å›¾åŒºåŸŸ
                const plotType = scroll_data.plot_type; // 'raw-delay-time-series-plot' æˆ– 'relative-delay-time-series-plot'
                let targetElement = null;

                // æ ¹æ®å›¾è¡¨ç±»å‹æŸ¥æ‰¾å¯¹åº”çš„å›¾è¡¨
                if (plotType === 'raw-delay-time-series-plot') {
                    // æŸ¥æ‰¾åŸå§‹å»¶æ—¶æ—¶é—´åºåˆ—å›¾
                    targetElement = document.getElementById('raw-delay-time-series-plot');
                    if (targetElement) {
                        // å‘ä¸ŠæŸ¥æ‰¾æœ€è¿‘çš„å¡ç‰‡å®¹å™¨
                        targetElement = targetElement.closest('.card') || targetElement;
                        console.log('Found raw delay time series plot');
                    }
                } else if (plotType === 'relative-delay-time-series-plot') {
                    // æŸ¥æ‰¾ç›¸å¯¹å»¶æ—¶æ—¶é—´åºåˆ—å›¾
                    targetElement = document.getElementById('relative-delay-time-series-plot');
                    if (targetElement) {
                        // å‘ä¸ŠæŸ¥æ‰¾æœ€è¿‘çš„å¡ç‰‡å®¹å™¨
                        targetElement = targetElement.closest('.card') || targetElement;
                        console.log('Found relative delay time series plot');
                    }
                }

                // å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šå›¾è¡¨ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«æ—¶é—´åºåˆ—å›¾æ ‡é¢˜çš„å¡ç‰‡
                if (!targetElement) {
                    const allCards = document.querySelectorAll('.card');
                    for (let card of allCards) {
                        const header = card.querySelector('h6');
                        if (header && header.textContent) {
                            if (plotType === 'raw-delay-time-series-plot' &&
                                header.textContent.includes('åŸå§‹å»¶æ—¶æ—¶é—´åºåˆ—å›¾')) {
                                targetElement = card;
                                console.log('Found raw delay time series card by title');
                                break;
                            } else if (plotType === 'relative-delay-time-series-plot' &&
                                     header.textContent.includes('ç›¸å¯¹å»¶æ—¶æ—¶é—´åºåˆ—å›¾')) {
                                targetElement = card;
                                console.log('Found relative delay time series card by title');
                                break;
                            }
                        }
                    }
                }

                if (targetElement) {
                    setTimeout(function() {
                        try {
                            // æ»šåŠ¨åˆ°æ—¶é—´åºåˆ—å›¾åŒºåŸŸ
                            targetElement.scrollIntoView({
                                behavior: 'smooth',
                                block: 'start',
                                inline: 'nearest'
                            });

                            console.log(`Scrolled to ${plotType} successfully`);
                        } catch (error) {
                            console.error(`Error scrolling to ${plotType}:`, error);
                        }
                    }, 500);  // ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
                } else {
                    console.warn(`${plotType} not found. Available cards:`);
                    const cards = document.querySelectorAll('.card');
                    for (let card of cards) {
                        const header = card.querySelector('h6');
                        if (header) {
                            console.warn('Card header:', header.textContent);
                        }
                    }
                }
            }

            return window.dash_clientside.no_update;
        }
        """,
        Output('grade-detail-section-scroll-trigger', 'data', allow_duplicate=True),
        Input('grade-detail-section-scroll-trigger', 'data'),
        prevent_initial_call=True
    )



    # ==================== æ›²çº¿å¯¹é½æµ‹è¯•å›è°ƒ ====================
    @app.callback(
        Output('curve-alignment-test-result', 'children'),
        Input('btn-test-curve-alignment', 'n_clicks'),
        State('session-id', 'data'),
        prevent_initial_call=True
    )
    def handle_test_curve_alignment(n_clicks, session_id):
        """å¤„ç†æ›²çº¿å¯¹é½æµ‹è¯•æŒ‰é’®ç‚¹å‡»"""
        if n_clicks is None or n_clicks == 0:
            return html.Div("ç‚¹å‡»æŒ‰é’®å¼€å§‹æµ‹è¯•", 
                           className="text-muted text-center",
                           style={'padding': '20px', 'fontSize': '14px'})
        
        try:
            backend = session_manager.get_backend(session_id)
            if not backend:
                return html.Div([
                    dbc.Alert("[WARNING] æ— æ³•è·å–backendï¼Œè¯·å…ˆä¸Šä¼ æ•°æ®", color="warning")
                ])
            
            # æ‰§è¡Œæµ‹è¯•
            test_result = backend.test_curve_alignment()
            
            if test_result is None or test_result.get('status') != 'success':
                error_msg = test_result.get('message', 'æµ‹è¯•å¤±è´¥') if test_result else 'æµ‹è¯•å¤±è´¥'
                return html.Div([
                    dbc.Alert([
                        html.I(className="fas fa-exclamation-triangle me-2"),
                        html.Strong(f"æµ‹è¯•å¤±è´¥: {error_msg}")
                    ], color="danger")
                ])
            
            result = test_result['result']
            comparison_fig = test_result.get('comparison_figure')  # å¯¹é½å‰åå¯¹æ¯”å›¾ï¼ˆå‘åå…¼å®¹ï¼‰
            all_stages_fig = test_result.get('all_stages_figure')  # æ‰€æœ‰å¤„ç†é˜¶æ®µçš„å¯¹æ¯”å›¾ (å…¼å®¹æ—§ç‰ˆ)
            individual_stage_figures = test_result.get('individual_stage_figures', []) # æ–°ç‰ˆç‹¬ç«‹å›¾è¡¨åˆ—è¡¨
            
            # æ„å»ºç»“æœæ˜¾ç¤º
            children = []
            
            # æ¸²æŸ“æ‰€æœ‰å¤„ç†é˜¶æ®µçš„å›¾è¡¨
            # ä¼˜å…ˆä½¿ç”¨æ–°çš„ç‹¬ç«‹å›¾è¡¨åˆ—è¡¨
            if individual_stage_figures:
                children.append(html.H6("å„å¤„ç†é˜¶æ®µæ›²çº¿å¯¹æ¯”ï¼ˆæ’­æ”¾æ›²çº¿å¯¹é½åˆ°å½•åˆ¶æ›²çº¿ï¼‰", 
                           className="mb-3",
                           style={'color': '#2c3e50', 'fontWeight': 'bold'}))
                
                for stage_info in individual_stage_figures:
                    title = stage_info.get('title', 'æœªçŸ¥é˜¶æ®µ')
                    fig = stage_info.get('figure')
                    
                    if fig:
                        children.append(html.Div([
                            html.H6(title, className="mt-4 mb-2", style={'fontSize': '14px', 'fontWeight': 'bold', 'color': '#555'}),
                            dcc.Graph(
                                figure=fig, 
                                config={'displayModeBar': True}
                            )
                        ], className="mb-2"))
            
            # å¦‚æœæ²¡æœ‰æ–°ç‰ˆå›¾è¡¨ï¼Œå›é€€åˆ°æ—§ç‰ˆå¤§å›¾
            elif all_stages_fig is not None:
                children.append(html.Div([
                    html.H6("å„å¤„ç†é˜¶æ®µæ›²çº¿å¯¹æ¯”ï¼ˆæ’­æ”¾æ›²çº¿å¯¹é½åˆ°å½•åˆ¶æ›²çº¿ï¼‰", 
                           className="mb-3",
                           style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                    dcc.Graph(figure=all_stages_fig, style={'height': '2800px', 'minHeight': '2000px'})
                ], className="mb-4"))
            
            # ç›¸ä¼¼åº¦ä¿¡æ¯
            children.append(
                html.Div([
                    html.H6("ç›¸ä¼¼åº¦ç»“æœ", className="mb-3",
                           style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                    dbc.Row([
                        dbc.Col([
                            dbc.Card([
                                dbc.CardBody([
                                    html.Small("ä¸Šå‡æ²¿ç›¸ä¼¼åº¦", className="text-muted d-block mb-1"),
                                    html.H4(f"{result.get('rising_edge_similarity', 0):.3f}", 
                                           style={'color': '#1f77b4', 'fontWeight': 'bold'})
                                ])
                            ], color="primary", outline=True)
                        ], width=4),
                        dbc.Col([
                            dbc.Card([
                                dbc.CardBody([
                                    html.Small("ä¸‹é™æ²¿ç›¸ä¼¼åº¦", className="text-muted d-block mb-1"),
                                    html.H4(f"{result.get('falling_edge_similarity', 0):.3f}", 
                                           style={'color': '#ff7f0e', 'fontWeight': 'bold'})
                                ])
                            ], color="warning", outline=True)
                        ], width=4),
                        dbc.Col([
                            dbc.Card([
                                dbc.CardBody([
                                    html.Small("æ•´ä½“ç›¸ä¼¼åº¦", className="text-muted d-block mb-1"),
                                    html.H4(f"{result.get('overall_similarity', 0):.3f}", 
                                           style={'color': '#2ca02c', 'fontWeight': 'bold'})
                                ])
                            ], color="success", outline=True)
                        ], width=4)
                    ], className="mb-3"),
                ], className="mb-4")
            )

            # ç‰¹å¾é‡åŒ–åˆ†æè¡¨æ ¼
            record_feat = result.get('record_features', {})
            replay_feat = result.get('replay_features', {})
            feat_diff = result.get('feature_comparison', {})
            
            if record_feat and replay_feat:
                import pandas as pd
                
                # å‡†å¤‡è¡¨æ ¼æ•°æ®
                table_data = [
                    {
                        "æŒ‡æ ‡": "å³°å€¼åŠ›åº¦ (Peak)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('peak_value', 0):.1f}", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('peak_value', 0):.1f}", 
                        "å·®å¼‚": f"{feat_diff.get('peak_diff', 0):.1f}",
                        "è¯´æ˜": "Max Value"
                    },
                    {
                        "æŒ‡æ ‡": "å³°å€¼æ—¶é—´ (Time)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('peak_time', 0):.1f}ms", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('peak_time', 0):.1f}ms", 
                        "å·®å¼‚": f"{feat_diff.get('peak_time_lag', 0):.1f}ms",
                        "è¯´æ˜": "Time Lag"
                    },
                    {
                        "æŒ‡æ ‡": "ä¸Šå‡æ—¶é—´ (Rise Time)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('rise_time_ms', 0):.1f}ms", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('rise_time_ms', 0):.1f}ms", 
                        "å·®å¼‚": f"{feat_diff.get('rise_time_diff', 0):.1f}ms",
                        "è¯´æ˜": "10% -> 90%"
                    },
                    {
                        "æŒ‡æ ‡": "ä¸Šå‡æ–œç‡ (Rise Slope)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('rise_slope', 0):.2f}", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('rise_slope', 0):.2f}", 
                        "å·®å¼‚": f"{replay_feat.get('rise_slope', 0) - record_feat.get('rise_slope', 0):.2f}",
                        "è¯´æ˜": "Value / ms"
                    },
                    {
                        "æŒ‡æ ‡": "ä¸‹é™æ—¶é—´ (Fall Time)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('fall_time_ms', 0):.1f}ms", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('fall_time_ms', 0):.1f}ms", 
                        "å·®å¼‚": f"{feat_diff.get('fall_time_diff', 0):.1f}ms",
                        "è¯´æ˜": "90% -> 10%"
                    },
                    {
                        "æŒ‡æ ‡": "ä¸‹é™æ–œç‡ (Fall Slope)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('fall_slope', 0):.2f}", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('fall_slope', 0):.2f}", 
                        "å·®å¼‚": f"{replay_feat.get('fall_slope', 0) - record_feat.get('fall_slope', 0):.2f}",
                        "è¯´æ˜": "Value / ms"
                    },
                    {
                        "æŒ‡æ ‡": "æŠ–åŠ¨åº¦ (Jitter RMSE)", 
                        "å½•åˆ¶å€¼": f"{record_feat.get('jitter', 0):.2f}", 
                        "æ’­æ”¾å€¼": f"{replay_feat.get('jitter', 0):.2f}", 
                        "å·®å¼‚": f"x{feat_diff.get('jitter_ratio', 0):.2f}",
                        "è¯´æ˜": "Raw - Smooth"
                    }
                ]
                
                table_header = [
                    html.Thead(html.Tr([html.Th(col) for col in ["æŒ‡æ ‡", "å½•åˆ¶å€¼", "æ’­æ”¾å€¼", "å·®å¼‚", "è¯´æ˜"]]))
                ]
                table_body = [
                    html.Tbody([
                        html.Tr([
                            html.Td(row["æŒ‡æ ‡"], style={'fontWeight': 'bold'}),
                            html.Td(row["å½•åˆ¶å€¼"]),
                            html.Td(row["æ’­æ”¾å€¼"]),
                            html.Td(row["å·®å¼‚"], style={'color': 'red' if 'x' in row['å·®å¼‚'] and float(row['å·®å¼‚'][1:]) > 2 else 'black'}),
                            html.Td(row["è¯´æ˜"], style={'fontSize': '0.85em', 'color': '#666'})
                        ]) for row in table_data
                    ])
                ]
                
                children.append(html.Div([
                    html.H6("ç‰©ç†ç‰¹å¾é‡åŒ–åˆ†æ", className="mb-3", style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                    dbc.Table(table_header + table_body, bordered=True, hover=True, striped=True, className="mb-4")
                ]))

            
            # å…¶ä»–ä¿¡æ¯
            children.append(html.Div([
                    dbc.Row([
                        dbc.Col([
                            html.Small(f"DTWè·ç¦»: {result.get('dtw_distance', 0):.3f}", 
                                      className="text-muted"),
                            html.Br(),
                            html.Small(f"æµ‹è¯•æ•°æ®: record_index={test_result.get('record_index', 'N/A')}, "
                                      f"replay_index={test_result.get('replay_index', 'N/A')}", 
                                      className="text-muted")
                        ], width=12)
                    ])
                ], className="mb-4")
            )
            
            # å¯¹é½å‰åå¯¹æ¯”å›¾
            if comparison_fig:
                children.append(
                    html.Div([
                        html.H6("å¯¹é½å‰åå¯¹æ¯”", className="mb-3",
                               style={'color': '#2c3e50', 'fontWeight': 'bold'}),
                        dcc.Graph(
                            figure=comparison_fig,
                            style={'height': '800px'}
                        )
                    ], className="mb-4")
                )
            else:
                children.append(
                    html.Div([
                        dbc.Alert("[WARNING] æ— æ³•ç”Ÿæˆå¯¹é½å¯¹æ¯”å›¾", color="warning")
                    ])
                )
            
            return html.Div(children)
            
        except Exception as e:
            logger.error(f"[ERROR] æ›²çº¿å¯¹é½æµ‹è¯•å¤±è´¥: {e}")
            
            logger.error(traceback.format_exc())
            return html.Div([
                dbc.Alert([
                    html.I(className="fas fa-exclamation-triangle me-2"),
                    html.Strong(f"æµ‹è¯•å¤±è´¥: {str(e)}")
                ], color="danger")
            ])

    # ä¸¢é”¤å’Œå¤šé”¤è¡¨æ ¼ç‚¹å‡»å›è°ƒ - æ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾
    @app.callback(
        [Output('key-curves-modal', 'style', allow_duplicate=True),
         Output('key-curves-comparison-container', 'children', allow_duplicate=True),
         Output('current-clicked-point-info', 'data', allow_duplicate=True)],
        [Input({'type': 'drop-hammers-table', 'index': dash.ALL}, 'active_cell'),
         Input({'type': 'multi-hammers-table', 'index': dash.ALL}, 'active_cell'),
         Input('close-key-curves-modal', 'n_clicks'),
         Input('close-key-curves-modal-btn', 'n_clicks')],
        [State({'type': 'drop-hammers-table', 'index': dash.ALL}, 'data'),
         State({'type': 'multi-hammers-table', 'index': dash.ALL}, 'data'),
         State('session-id', 'data'),
         State('key-curves-modal', 'style')],
        prevent_initial_call=True
    )
    def handle_error_tables_click(active_cells_multi_drop, active_cells_multi_multi, close_modal_clicks, close_btn_clicks,
                                 data_multi_drop, data_multi_multi, session_id, current_style):
        """å¤„ç†ä¸¢é”¤å’Œå¤šé”¤è¡¨æ ¼ç‚¹å‡»ï¼Œæ˜¾ç¤ºæ›²çº¿å¯¹æ¯”ï¼ˆæ‚¬æµ®çª—ï¼‰å¹¶æ”¯æŒè·³è½¬åˆ°ç€‘å¸ƒå›¾"""
        # æ£€æµ‹è§¦å‘æº
        ctx = callback_context
        if not ctx.triggered:
            return current_style, [], no_update

        trigger_id = ctx.triggered[0]['prop_id']
        trigger_value = ctx.triggered[0].get('value')

        # å¦‚æœç‚¹å‡»äº†å…³é—­æŒ‰é’®ï¼Œéšè—æ¨¡æ€æ¡†
        if trigger_id in ['close-key-curves-modal.n_clicks', 'close-key-curves-modal-btn.n_clicks']:
            return {'display': 'none'}, [], no_update

        # å¤„ç†è¡¨æ ¼ç‚¹å‡»
        table_type = None
        active_cell = None
        table_data = None
        algorithm_name = None

        # è§£æè§¦å‘æº
        if 'drop-hammers-table' in trigger_id:
            table_type = 'drop'
        elif 'multi-hammers-table' in trigger_id:
            table_type = 'multi'

        if not table_type:
            return current_style, [], no_update

        # è·å–å¯¹åº”çš„æ•°æ®å’Œactive_cell
        try:
            # è§£æID
            id_parts = json.loads(trigger_id.split('.')[0])
            algorithm_name = id_parts.get('index', 'single')  # é»˜è®¤å•ç®—æ³•æ¨¡å¼

            # æ ¹æ®è¡¨æ ¼ç±»å‹è·å–å¯¹åº”çš„æ•°æ®
            if table_type == 'drop':
                # æ‰¾åˆ°å¯¹åº”çš„active_cellå’Œdata
                table_index = None
                for i, cell in enumerate(active_cells_multi_drop):
                    if cell is not None:
                        table_index = i
                        active_cell = cell
                        table_data = data_multi_drop[i] if i < len(data_multi_drop) else None
                        break
            else:  # multi
                # æ‰¾åˆ°å¯¹åº”çš„active_cellå’Œdata
                table_index = None
                for i, cell in enumerate(active_cells_multi_multi):
                    if cell is not None:
                        table_index = i
                        active_cell = cell
                        table_data = data_multi_multi[i] if i < len(data_multi_multi) else None
                        break

        except (json.JSONDecodeError, KeyError, IndexError):
            return current_style, [], no_update

        if not active_cell or not table_data:
            return current_style, [], no_update

        # è·å–åç«¯å®ä¾‹
        backend = session_manager.get_backend(session_id)
        if not backend:
            return current_style, [], no_update

        try:
            # è·å–ç‚¹å‡»çš„è¡Œæ•°æ®
            row_idx = active_cell.get('row')
            if row_idx is None or row_idx >= len(table_data):
                return current_style, [], no_update

            row_data = table_data[row_idx]

            # è·å–éŸ³ç¬¦ä¿¡æ¯
            data_type = row_data.get('data_type')
            key_id_str = row_data.get('keyId')
            global_index = row_data.get('index')

            if key_id_str == 'æ— åŒ¹é…':
                # è¿™æ˜¯æ²¡æœ‰æ•°æ®çš„è¡Œï¼Œè·³è¿‡
                return current_style, [], no_update
            
            # è½¬æ¢key_idä¸ºæ•´æ•°
            try:
                key_id = int(key_id_str) if isinstance(key_id_str, (int, float, str)) and str(key_id_str).isdigit() else None
                if key_id is None:
                    logger.warning(f"[WARNING] æ— æ³•è½¬æ¢keyIdä¸ºæ•´æ•°: {key_id_str}")
                    return current_style, [], no_update
            except (ValueError, TypeError):
                logger.warning(f"[WARNING] keyIdè½¬æ¢å¤±è´¥: {key_id_str}")
                return current_style, [], no_update

            # æ ¹æ®è¡¨æ ¼ç±»å‹ç¡®å®šæ•°æ®ç±»å‹
            if table_type == 'drop':
                # ä¸¢é”¤ï¼šåªæœ‰å½•åˆ¶æ•°æ®
                available_data = 'record'
                data_label = 'å½•åˆ¶'
            else:  # multi
                # å¤šé”¤ï¼šåªæœ‰æ’­æ”¾æ•°æ®
                available_data = 'replay'
                data_label = 'æ’­æ”¾'

            # æŸ¥æ‰¾å¯¹åº”çš„éŸ³ç¬¦æ•°æ®
            # å¯¹äºä¸¢é”¤/å¤šé”¤ï¼Œåº”è¯¥ä½¿ç”¨initial_valid_record_data/initial_valid_replay_data
            # å¹¶ä¸”ä½¿ç”¨global_indexï¼ˆå³è¡¨æ ¼ä¸­çš„indexå­—æ®µï¼‰ä½œä¸ºæ•°ç»„ç´¢å¼•
            note_data = None
            
            # ç¡®ä¿global_indexæ˜¯æ•´æ•°ç±»å‹
            try:
                if isinstance(global_index, str):
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢
                    if global_index == 'æ— åŒ¹é…':
                        return current_style, [], no_update
                    global_index = int(global_index)
            except (ValueError, TypeError):
                logger.warning(f"[WARNING] æ— æ³•è½¬æ¢global_index: {global_index}")
                return current_style, [], no_update
            
            if algorithm_name == 'single':
                # å•ç®—æ³•æ¨¡å¼
                if available_data == 'record':
                    # ä¸¢é”¤ï¼šä½¿ç”¨initial_valid_record_data
                    initial_data = getattr(backend.analyzer, 'initial_valid_record_data', None)
                else:
                    # å¤šé”¤ï¼šä½¿ç”¨initial_valid_replay_data
                    initial_data = getattr(backend.analyzer, 'initial_valid_replay_data', None)

                if initial_data:
                    # ä¼˜å…ˆé€šè¿‡key_idæŸ¥æ‰¾éŸ³ç¬¦æ•°æ®ï¼Œç¡®ä¿ä¸è¡¨æ ¼æ˜¾ç¤ºä¸€è‡´
                    logger.info(f"[DEBUG] å•ç®—æ³•æ¨¡å¼é€šè¿‡key_idæŸ¥æ‰¾éŸ³ç¬¦æ•°æ®: {key_id}")
                    for i, note in enumerate(initial_data):
                        if getattr(note, 'id', None) == key_id:
                            note_data = note
                            logger.info(f"[DEBUG] å•ç®—æ³•æ¨¡å¼é€šè¿‡key_idæŸ¥æ‰¾æˆåŠŸ: ç´¢å¼•{i}, key_id={key_id}")
                            break

                    # å¦‚æœé€šè¿‡key_idæ²¡æ‰¾åˆ°ï¼Œé™çº§ä½¿ç”¨ç´¢å¼•æŸ¥æ‰¾ï¼ˆå‘åå…¼å®¹ï¼‰
                    if not note_data and 0 <= global_index < len(initial_data):
                        candidate_note = initial_data[global_index]
                        candidate_key_id = getattr(candidate_note, 'id', None)
                        if candidate_key_id == key_id:
                            # ç´¢å¼•æŸ¥æ‰¾æˆåŠŸä¸”key_idåŒ¹é…
                            note_data = candidate_note
                            logger.info(f"[DEBUG] å•ç®—æ³•æ¨¡å¼ç´¢å¼•æŸ¥æ‰¾æˆåŠŸä¸”key_idåŒ¹é…: global_index={global_index}, key_id={key_id}")
                        else:
                            logger.warning(f"[WARNING] å•ç®—æ³•æ¨¡å¼ç´¢å¼•ä½ç½®çš„key_idä¸åŒ¹é…: æœŸæœ›{key_id}, å®é™…{candidate_key_id}, è·³è¿‡ç»˜åˆ¶")
            else:
                # å¤šç®—æ³•æ¨¡å¼
                active_algorithms = backend.get_active_algorithms()
                logger.info(f"[DEBUG] å¤šç®—æ³•æ¨¡å¼æŸ¥æ‰¾ - ç®—æ³•åç§°: {algorithm_name}, æ´»åŠ¨ç®—æ³•æ•°é‡: {len(active_algorithms)}")
                logger.info(f"[DEBUG] æ´»åŠ¨ç®—æ³•åˆ—è¡¨: {[f'{alg.metadata.algorithm_name}(active={alg.is_active}, ready={alg.is_ready()})' for alg in active_algorithms]}")

                # é¦–å…ˆå°è¯•åœ¨æ´»åŠ¨ç®—æ³•ä¸­æŸ¥æ‰¾
                target_algorithm = next((alg for alg in active_algorithms if alg.metadata.algorithm_name == algorithm_name), None)

                # å¦‚æœåœ¨æ´»åŠ¨ç®—æ³•ä¸­æ²¡æ‰¾åˆ°ï¼Œå°è¯•åœ¨æ‰€æœ‰ç®—æ³•ä¸­æŸ¥æ‰¾ï¼ˆå¯èƒ½æœ‰æœªæ¿€æ´»çš„ç®—æ³•ï¼‰
                if not target_algorithm:
                    all_algorithms = backend.multi_algorithm_manager.algorithms.values() if backend.multi_algorithm_manager else []
                    target_algorithm = next((alg for alg in all_algorithms if alg.metadata.algorithm_name == algorithm_name), None)
                    if target_algorithm:
                        logger.warning(f"[WARNING] åœ¨éæ´»åŠ¨ç®—æ³•ä¸­æ‰¾åˆ°ç›®æ ‡ç®—æ³•: {algorithm_name}, æ¿€æ´»çŠ¶æ€: {target_algorithm.is_active}")
                    else:
                        logger.error(f"[ERROR] åœ¨æ‰€æœ‰ç®—æ³•ä¸­éƒ½æœªæ‰¾åˆ°ç›®æ ‡ç®—æ³•: {algorithm_name}")
                        all_names = [alg.metadata.algorithm_name for alg in all_algorithms] if all_algorithms else []
                        logger.error(f"[ERROR] æ‰€æœ‰å¯ç”¨ç®—æ³•: {all_names}")

                if not target_algorithm:
                    logger.error(f"[ERROR] æœªæ‰¾åˆ°åŒ¹é…çš„ç®—æ³•å®ä¾‹: {algorithm_name}")
                    logger.error(f"[ERROR] å¯ç”¨ç®—æ³•: {[alg.metadata.algorithm_name for alg in active_algorithms]}")
                    return current_style, [], no_update

                if not target_algorithm.analyzer:
                    logger.error(f"[ERROR] ç›®æ ‡ç®—æ³•æ²¡æœ‰åˆ†æå™¨: {algorithm_name}")
                    return current_style, [], no_update

                logger.info(f"[DEBUG] æ‰¾åˆ°ç›®æ ‡ç®—æ³•: {target_algorithm.metadata.algorithm_name}")

                # å°è¯•é€šè¿‡ç´¢å¼•ç›´æ¥æŸ¥æ‰¾éŸ³ç¬¦æ•°æ®
                note_data = None
                initial_data = None

                if available_data == 'record':
                    # ä¸¢é”¤ï¼šä½¿ç”¨initial_valid_record_data
                    initial_data = getattr(target_algorithm.analyzer, 'initial_valid_record_data', None)
                    data_type_name = "initial_valid_record_data"
                else:
                    # å¤šé”¤ï¼šä½¿ç”¨initial_valid_replay_data
                    initial_data = getattr(target_algorithm.analyzer, 'initial_valid_replay_data', None)
                    data_type_name = "initial_valid_replay_data"

                logger.info(f"[DEBUG] {data_type_name} - æ•°æ®é•¿åº¦: {len(initial_data) if initial_data else 0}, ç´¢å¼•: {global_index}")

                if initial_data:
                    # ä¼˜å…ˆé€šè¿‡key_idæŸ¥æ‰¾éŸ³ç¬¦æ•°æ®ï¼Œç¡®ä¿ä¸è¡¨æ ¼æ˜¾ç¤ºä¸€è‡´
                    logger.info(f"[DEBUG] é€šè¿‡key_idæŸ¥æ‰¾éŸ³ç¬¦æ•°æ®: {key_id}")
                    for i, note in enumerate(initial_data):
                        if getattr(note, 'id', None) == key_id:
                            note_data = note
                            logger.info(f"[DEBUG] é€šè¿‡key_idæŸ¥æ‰¾æˆåŠŸ: ç´¢å¼•{i}, key_id={key_id}")
                            break

                    # å¦‚æœé€šè¿‡key_idæ²¡æ‰¾åˆ°ï¼Œé™çº§ä½¿ç”¨ç´¢å¼•æŸ¥æ‰¾ï¼ˆå‘åå…¼å®¹ï¼‰
                    if not note_data and 0 <= global_index < len(initial_data):
                        candidate_note = initial_data[global_index]
                        candidate_key_id = getattr(candidate_note, 'id', None)
                        if candidate_key_id == key_id:
                            # ç´¢å¼•æŸ¥æ‰¾æˆåŠŸä¸”key_idåŒ¹é…
                            note_data = candidate_note
                            logger.info(f"[DEBUG] ç´¢å¼•æŸ¥æ‰¾æˆåŠŸä¸”key_idåŒ¹é…: global_index={global_index}, key_id={key_id}")
                        else:
                            logger.warning(f"[WARNING] ç´¢å¼•ä½ç½®çš„key_idä¸åŒ¹é…: æœŸæœ›{key_id}, å®é™…{candidate_key_id}, è·³è¿‡ç»˜åˆ¶")

                    if not note_data:
                        logger.error(f"[ERROR] æ— æ³•æ‰¾åˆ°åŒ¹é…çš„éŸ³ç¬¦æ•°æ®: key_id={key_id}, ç´¢å¼•={global_index}, æ•°æ®é•¿åº¦={len(initial_data)}")
                        return current_style, [], no_update
                else:
                    logger.error(f"[ERROR] æ²¡æœ‰æ‰¾åˆ°{data_type_name}æ•°æ®")
                    return current_style, [], no_update

            if not note_data:
                return current_style, [], no_update

            # ç¡®ä¿key_idä¸note_dataä¸­çš„idä¸€è‡´
            actual_key_id = getattr(note_data, 'id', key_id)
            if actual_key_id != key_id:
                logger.info(f"ğŸ” key_idä¸ä¸€è‡´: è¡¨æ ¼ä¸­={key_id}, note_dataä¸­={actual_key_id}, ä½¿ç”¨note_dataä¸­çš„å€¼")
                key_id = actual_key_id

            # ç”Ÿæˆæ›²çº¿å›¾ï¼ˆåªæ˜¾ç¤ºæœ‰æ•°æ®çš„éƒ¨åˆ†ï¼‰
            fig = _create_single_data_curve_figure(note_data, key_id, data_label, algorithm_name)

            # è®¡ç®—æ—¶é—´ä¿¡æ¯ï¼Œç”¨äºè·³è½¬åˆ°ç€‘å¸ƒå›¾
            center_time_ms = None
            record_idx = None
            replay_idx = None
            
            try:
                # å¯¹äºä¸¢é”¤ï¼šåªæœ‰å½•åˆ¶æ•°æ®ï¼Œrecord_idxå°±æ˜¯global_indexï¼ˆåœ¨initial_valid_record_dataä¸­çš„ç´¢å¼•ï¼‰
                # å¯¹äºå¤šé”¤ï¼šåªæœ‰æ’­æ”¾æ•°æ®ï¼Œreplay_idxå°±æ˜¯global_indexï¼ˆåœ¨initial_valid_replay_dataä¸­çš„ç´¢å¼•ï¼‰
                if table_type == 'drop':
                    # ä¸¢é”¤ï¼šåªæœ‰å½•åˆ¶æ•°æ®
                    record_idx = global_index  # åœ¨initial_valid_record_dataä¸­çš„ç´¢å¼•
                    replay_idx = None  # ä¸¢é”¤æ²¡æœ‰æ’­æ”¾æ•°æ®
                    
                    # ä»è¡¨æ ¼æ•°æ®ä¸­è·å–keyOnæ—¶é—´ï¼ˆå·²ç»æ˜¯mså•ä½ï¼‰
                    try:
                        key_on_str = row_data.get('keyOn', '')
                        if key_on_str and key_on_str != 'æ— åŒ¹é…':
                            center_time_ms = float(key_on_str)
                        else:
                            # å¤‡ç”¨æ–¹æ¡ˆï¼šä»note_dataè®¡ç®—
                            if note_data and hasattr(note_data, 'after_touch') and not note_data.after_touch.empty:
                                center_time_ms = (note_data.after_touch.index[0] + note_data.offset) / 10.0
                            elif note_data and hasattr(note_data, 'hammers') and not note_data.hammers.empty:
                                center_time_ms = (note_data.hammers.index[0] + note_data.offset) / 10.0
                            elif note_data and hasattr(note_data, 'offset'):
                                center_time_ms = note_data.offset / 10.0
                    except (ValueError, TypeError):
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                        if note_data and hasattr(note_data, 'after_touch') and not note_data.after_touch.empty:
                            center_time_ms = (note_data.after_touch.index[0] + note_data.offset) / 10.0
                        elif note_data and hasattr(note_data, 'hammers') and not note_data.hammers.empty:
                            center_time_ms = (note_data.hammers.index[0] + note_data.offset) / 10.0
                        elif note_data and hasattr(note_data, 'offset'):
                            center_time_ms = note_data.offset / 10.0
                else:  # multi
                    # å¤šé”¤ï¼šåªæœ‰æ’­æ”¾æ•°æ®
                    record_idx = None  # å¤šé”¤æ²¡æœ‰å½•åˆ¶æ•°æ®
                    replay_idx = global_index  # åœ¨initial_valid_replay_dataä¸­çš„ç´¢å¼•
                    
                    # ä»è¡¨æ ¼æ•°æ®ä¸­è·å–keyOnæ—¶é—´ï¼ˆå·²ç»æ˜¯mså•ä½ï¼‰
                    try:
                        key_on_str = row_data.get('keyOn', '')
                        if key_on_str and key_on_str != 'æ— åŒ¹é…':
                            center_time_ms = float(key_on_str)
                        else:
                            # å¤‡ç”¨æ–¹æ¡ˆï¼šä»note_dataè®¡ç®—
                            if note_data and hasattr(note_data, 'after_touch') and not note_data.after_touch.empty:
                                center_time_ms = (note_data.after_touch.index[0] + note_data.offset) / 10.0
                            elif note_data and hasattr(note_data, 'hammers') and not note_data.hammers.empty:
                                center_time_ms = (note_data.hammers.index[0] + note_data.offset) / 10.0
                            elif note_data and hasattr(note_data, 'offset'):
                                center_time_ms = note_data.offset / 10.0
                    except (ValueError, TypeError):
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                        if note_data and hasattr(note_data, 'after_touch') and not note_data.after_touch.empty:
                            center_time_ms = (note_data.after_touch.index[0] + note_data.offset) / 10.0
                        elif note_data and hasattr(note_data, 'hammers') and not note_data.hammers.empty:
                            center_time_ms = (note_data.hammers.index[0] + note_data.offset) / 10.0
                        elif note_data and hasattr(note_data, 'offset'):
                            center_time_ms = note_data.offset / 10.0
            except Exception as e:
                logger.warning(f"[WARNING] è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
                logger.error(traceback.format_exc())

            # å‡†å¤‡è·³è½¬ä¿¡æ¯
            clicked_info = {
                'key_id': key_id,
                'algorithm_name': algorithm_name,
                'data_type': data_type,
                'global_index': global_index,
                'available_data': available_data,  # æ ‡è®°æœ‰å“ªäº›æ•°æ®å¯ç”¨
                'source_plot_id': f'error-table-{table_type}',  # æ ‡è¯†æ¥æºæ˜¯é”™è¯¯è¡¨æ ¼
                'record_idx': record_idx,  # å½•åˆ¶æ•°æ®ç´¢å¼•
                'replay_idx': replay_idx,  # æ’­æ”¾æ•°æ®ç´¢å¼•
                'center_time_ms': center_time_ms  # é¢„å…ˆè®¡ç®—çš„æ—¶é—´ä¿¡æ¯
            }

            # æ˜¾ç¤ºæ¨¡æ€æ¡† - ä½¿ç”¨ä¸å…¶ä»–å›è°ƒå‡½æ•°ä¸€è‡´çš„æ ·å¼ï¼Œé¿å…åµŒå¥—
            modal_style = {
                'display': 'block',
                'position': 'fixed',
                'zIndex': '9999',
                'left': '0',
                'top': '0',
                'width': '100%',
                'height': '100%',
                'backgroundColor': 'rgba(0,0,0,0.6)',
                'backdropFilter': 'blur(5px)'
            }

            # ç›´æ¥è¿”å›å›¾å½¢ï¼Œä¸æ·»åŠ é¢å¤–çš„å®¹å™¨åŒ…è£¹ï¼Œé¿å…å¤šä½™çš„æ¡†
            return modal_style, [dcc.Graph(figure=fig, style={'height': '500px'})], clicked_info

        except Exception as e:
            logger.error(f"[ERROR] å¤„ç†é”™è¯¯è¡¨æ ¼ç‚¹å‡»å¤±è´¥: {e}")
            return current_style, [], no_update

    def _create_single_data_curve_figure(note_data, key_id, data_label, algorithm_name):
        """åˆ›å»ºåªæ˜¾ç¤ºå•ä¾§æ•°æ®çš„æ›²çº¿å›¾"""
        from plotly.subplots import make_subplots

        try:
            # åˆ›å»ºå­å›¾
            fig = make_subplots(
                rows=1, cols=1,
                subplot_titles=[f'æŒ‰é”® {key_id} - {data_label}æ•°æ®æ›²çº¿ ({algorithm_name})']
            )

            # æå–æ•°æ®
            if hasattr(note_data, 'after_touch') and note_data.after_touch is not None and len(note_data.after_touch.index) > 0:
                # ä½¿ç”¨after_touchæ•°æ®
                time_data = note_data.after_touch.index
                value_data = note_data.after_touch.values if hasattr(note_data.after_touch, 'values') else [0] * len(time_data)
            elif hasattr(note_data, 'hammers') and note_data.hammers is not None and len(note_data.hammers.index) > 0:
                # ä½¿ç”¨hammersæ•°æ®
                time_data = note_data.hammers.index
                value_data = note_data.hammers.values if hasattr(note_data.hammers, 'values') else [0] * len(time_data)
            else:
                # æ²¡æœ‰å¯ç”¨æ•°æ®
                fig.add_annotation(
                    text="æ— å¯ç”¨æ•°æ®",
                    xref="paper", yref="paper",
                    x=0.5, y=0.5,
                    showarrow=False
                )
                return fig

            # è½¬æ¢ä¸ºæ¯«ç§’
            time_ms = [t / 10.0 for t in time_data]

            # æ·»åŠ æ›²çº¿
            fig.add_trace(
                go.Scatter(
                    x=time_ms,
                    y=value_data,
                    mode='lines+markers',
                    name=f'{data_label}æ•°æ®',
                    line=dict(color='blue', width=2),
                    marker=dict(size=6, color='blue')
                ),
                row=1, col=1
            )

            # æ›´æ–°å¸ƒå±€
            fig.update_layout(
                height=400,
                showlegend=True,
                legend=dict(
                    orientation="h",
                    yanchor="bottom",
                    y=1.02,
                    xanchor="right",
                    x=1
                ),
                hovermode='x unified'
            )

            # æ›´æ–°åæ ‡è½´æ ‡ç­¾
            fig.update_xaxes(title_text="æ—¶é—´ (ms)", row=1, col=1)
            fig.update_yaxes(title_text="è§¦åå€¼", row=1, col=1)

            return fig

        except Exception as e:
            logger.error(f"[ERROR] åˆ›å»ºå•ä¾§æ•°æ®æ›²çº¿å›¾å¤±è´¥: {e}")
            # è¿”å›é”™è¯¯å›¾è¡¨
            error_fig = go.Figure()
            error_fig.add_annotation(
                text=f"ç”Ÿæˆæ›²çº¿å›¾å¤±è´¥: {str(e)}",
                xref="paper", yref="paper",
                x=0.5, y=0.5,
                showarrow=False
            )
            return error_fig

    # å•ç®—æ³•æ¨¡å¼é”™è¯¯è¡¨æ ¼æ•°æ®å¡«å……å›è°ƒ
    # æ³¨å†Œè¯„çº§ç»Ÿè®¡è¯¦æƒ…å›è°ƒ
    register_all_callbacks(app, session_manager)


