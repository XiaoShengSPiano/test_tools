#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¤šæ–‡ä»¶ä¸Šä¼ å¤„ç†å™¨

è´Ÿè´£å¤„ç†å¤šç®—æ³•æ¨¡å¼ä¸‹çš„æ–‡ä»¶ä¸Šä¼ é€»è¾‘ï¼ŒåŒ…æ‹¬æ–‡ä»¶åˆ—è¡¨ç”Ÿæˆã€æ–‡ä»¶IDç®¡ç†ç­‰ã€‚
"""

import time
import traceback
from typing import List, Dict, Any, Tuple, Optional
import dash_bootstrap_components as dbc
from dash import html, no_update
from utils.logger import Logger

logger = Logger.get_logger()


class MultiFileUploadHandler:
    """
    å¤šæ–‡ä»¶ä¸Šä¼ å¤„ç†å™¨ç±»
    
    è´Ÿè´£å¤„ç†å¤šç®—æ³•æ¨¡å¼ä¸‹çš„æ–‡ä»¶ä¸Šä¼ ï¼ŒåŒ…æ‹¬ï¼š
    - æ–‡ä»¶åˆ—è¡¨ç”Ÿæˆ
    - æ–‡ä»¶IDç®¡ç†
    - æ–°æ–‡ä»¶æ£€æµ‹
    - æ–‡ä»¶æ•°æ®å­˜å‚¨
    """
    
    def __init__(self):
        """åˆå§‹åŒ–å¤šæ–‡ä»¶ä¸Šä¼ å¤„ç†å™¨"""
        logger.info("âœ… MultiFileUploadHandleråˆå§‹åŒ–å®Œæˆ")
    
    def normalize_file_lists(self, contents_list: Any, filename_list: Any) -> Tuple[List[str], List[str]]:
        """
        è§„èŒƒåŒ–æ–‡ä»¶åˆ—è¡¨
        
        Args:
            contents_list: æ–‡ä»¶å†…å®¹åˆ—è¡¨ï¼ˆå¯èƒ½æ˜¯å•ä¸ªå€¼æˆ–åˆ—è¡¨ï¼‰
            filename_list: æ–‡ä»¶ååˆ—è¡¨ï¼ˆå¯èƒ½æ˜¯å•ä¸ªå€¼æˆ–åˆ—è¡¨ï¼‰
            
        Returns:
            Tuple[List[str], List[str]]: (è§„èŒƒåŒ–åçš„å†…å®¹åˆ—è¡¨, è§„èŒƒåŒ–åçš„æ–‡ä»¶ååˆ—è¡¨)
        """
        # å¤„ç†ç©ºå€¼æƒ…å†µ
        if not contents_list:
            contents_list = []
        if not filename_list:
            filename_list = []
        
        # ç¡®ä¿æ˜¯åˆ—è¡¨ç±»å‹
        if not isinstance(contents_list, list):
            contents_list = [contents_list] if contents_list else []
        if not isinstance(filename_list, list):
            filename_list = [filename_list] if filename_list else []
        
        return contents_list, filename_list
    
    def generate_file_id(self, timestamp: int, index: int) -> str:
        """
        ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶ID
        
        Args:
            timestamp: æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
            index: æ–‡ä»¶ç´¢å¼•
            
        Returns:
            str: æ–‡ä»¶IDï¼ˆæ ¼å¼: file-{timestamp}-{index}ï¼‰
        """
        return f"file-{timestamp}-{index}"
    
    def create_file_card(self, file_id: str, filename: str) -> dbc.Card:
        """
        åˆ›å»ºæ–‡ä»¶å¡ç‰‡UIç»„ä»¶
        
        Args:
            file_id: æ–‡ä»¶ID
            filename: æ–‡ä»¶å
            
        Returns:
            dbc.Card: æ–‡ä»¶å¡ç‰‡ç»„ä»¶
        """
        return dbc.Card([
            dbc.CardBody([
                dbc.Row([
                    dbc.Col([
                        html.Div([
                            html.I(className="fas fa-file", 
                                  style={'color': '#007bff', 'marginRight': '8px'}),
                            html.Span(filename, style={'fontWeight': 'bold', 'fontSize': '14px'})
                        ])
                    ], width=8),
                    dbc.Col([
                        dbc.Input(
                            id={'type': 'algorithm-name-input', 'index': file_id},
                            type='text',
                            placeholder='è¾“å…¥ç®—æ³•åç§°',
                            style={'fontSize': '12px', 'marginBottom': '5px'},
                            debounce=True
                        ),
                        dbc.Button(
                            "ç¡®è®¤æ·»åŠ ",
                            id={'type': 'confirm-algorithm-btn', 'index': file_id},
                            color='success',
                            size='sm',
                            n_clicks=0,
                            style={'width': '100%'}
                        )
                    ], width=4)
                ]),
                html.Div(
                    id={'type': 'algorithm-status', 'index': file_id},
                    style={'fontSize': '11px', 'marginTop': '5px', 'color': '#6c757d'}
                )
            ])
        ], className='mb-2', style={'border': '1px solid #dee2e6', 'borderRadius': '5px'})
    
    def process_uploaded_files(
        self, 
        contents_list: List[str], 
        filename_list: List[str], 
        existing_store_data: Optional[Dict[str, Any]] = None,
        backend: Optional[Any] = None
    ) -> Tuple[html.Div, html.Span, Dict[str, Any]]:
        """
        å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼Œç”Ÿæˆæ–‡ä»¶åˆ—è¡¨UIå’Œæ›´æ–°åçš„storeæ•°æ®
        
        Args:
            contents_list: æ–‡ä»¶å†…å®¹åˆ—è¡¨
            filename_list: æ–‡ä»¶ååˆ—è¡¨
            existing_store_data: ç°æœ‰çš„storeæ•°æ®
            
        Returns:
            Tuple[html.Div, html.Span, Dict]: (æ–‡ä»¶åˆ—è¡¨UI, çŠ¶æ€æ–‡æœ¬, æ›´æ–°åçš„storeæ•°æ®)
        """
        # è§„èŒƒåŒ–æ–‡ä»¶åˆ—è¡¨
        contents_list, filename_list = self.normalize_file_lists(contents_list, filename_list)
        
        if not contents_list or not filename_list:
            return no_update, no_update, no_update
        
        try:
            # ä½¿ç”¨æ—¶é—´æˆ³åˆ›å»ºå”¯ä¸€ID
            timestamp = int(time.time() * 1000)  # æ¯«ç§’çº§æ—¶é—´æˆ³
            
            # åˆ›å»ºæ–°çš„storeæ•°æ®
            new_store_data = {
                'contents': [],
                'filenames': [],
                'file_ids': []  # å­˜å‚¨æ–‡ä»¶IDæ˜ å°„
            }
            
            # è·å–å·²å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
            processed_files = set()
            if existing_store_data and isinstance(existing_store_data, dict):
                processed_files = set(existing_store_data.get('filenames', []))
            
            # åˆ›å»ºæ–‡ä»¶å¡ç‰‡åˆ—è¡¨ - ç»Ÿä¸€ä¸Šä¼ ç®¡ç†å™¨å·²å¤„ç†é‡å¤æ£€æµ‹ï¼Œè¿™é‡Œæ€»æ˜¯å¤„ç†
            file_items = []
            for i, (content, filename) in enumerate(zip(contents_list, filename_list)):
                file_id = self.generate_file_id(timestamp, i)
                file_card = self.create_file_card(file_id, filename)
                file_items.append(file_card)

                # æ·»åŠ åˆ°æ–°çš„storeæ•°æ®
                new_store_data['contents'].append(content)
                new_store_data['filenames'].append(filename)
                new_store_data['file_ids'].append(file_id)

                logger.info(f"ğŸ“„ æ·»åŠ æ–‡ä»¶åˆ°å¤šç®—æ³•å¤„ç†é˜Ÿåˆ—: {filename}")
            
            if not file_items:
                # æ²¡æœ‰æ–‡ä»¶
                status_text = html.Span("æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶", style={'color': '#ffc107'})
                return no_update, status_text, no_update
            
            # åˆå¹¶åˆ°ç°æœ‰çš„store_dataï¼ˆä¿ç•™ä¹‹å‰æœªå¤„ç†çš„æ–‡ä»¶ï¼‰
            if existing_store_data and isinstance(existing_store_data, dict):
                existing_contents = existing_store_data.get('contents', [])
                existing_filenames = existing_store_data.get('filenames', [])
                existing_file_ids = existing_store_data.get('file_ids', [])
                
                # è·å–æ‰€æœ‰å·²æ·»åŠ ç®—æ³•çš„æ–‡ä»¶åï¼Œè¿‡æ»¤æ‰å·²æ·»åŠ çš„æ–‡ä»¶
                added_filenames = set()
                if backend and hasattr(backend, 'get_all_algorithms'):
                    try:
                        algorithms = backend.get_all_algorithms()
                        for alg_info in algorithms:
                            added_filenames.add(alg_info.get('filename', ''))
                    except Exception as e:
                        logger.warning(f"âš ï¸ è·å–å·²æ·»åŠ ç®—æ³•åˆ—è¡¨å¤±è´¥: {e}")
                
                # è¿‡æ»¤æ‰å·²æ·»åŠ çš„æ–‡ä»¶ï¼Œåªä¿ç•™æœªæ·»åŠ çš„æ–‡ä»¶
                filtered_existing_contents = []
                filtered_existing_filenames = []
                filtered_existing_file_ids = []
                
                for i, filename in enumerate(existing_filenames):
                    if filename not in added_filenames:
                        if i < len(existing_contents):
                            filtered_existing_contents.append(existing_contents[i])
                        filtered_existing_filenames.append(filename)
                        if i < len(existing_file_ids):
                            filtered_existing_file_ids.append(existing_file_ids[i])
                
                # åˆå¹¶æ–°æ–‡ä»¶å’Œè¿‡æ»¤åçš„æ—§æ–‡ä»¶
                new_store_data['contents'] = filtered_existing_contents + new_store_data['contents']
                new_store_data['filenames'] = filtered_existing_filenames + new_store_data['filenames']
                new_store_data['file_ids'] = filtered_existing_file_ids + new_store_data['file_ids']
                
                # ä¸ºæ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…æ‹¬ä¹‹å‰ä¸Šä¼ çš„ï¼Œä½†å·²è¿‡æ»¤æ‰å·²æ·»åŠ çš„ï¼‰åˆ›å»ºæ–‡ä»¶å¡ç‰‡
                all_file_items = []
                for i, (content, filename, file_id) in enumerate(zip(
                    new_store_data['contents'],
                    new_store_data['filenames'],
                    new_store_data['file_ids']
                )):
                    # å†æ¬¡æ£€æŸ¥ï¼Œç¡®ä¿ä¸ä¼šæ˜¾ç¤ºå·²æ·»åŠ çš„æ–‡ä»¶
                    if filename not in added_filenames:
                        file_card = self.create_file_card(file_id, filename)
                        all_file_items.append(file_card)
                
                file_list = html.Div(all_file_items)
                total_files = len(new_store_data['filenames'])
                new_files_count = len(file_items)
                if new_files_count > 0:
                    status_text = html.Span(
                        f"å·²ä¸Šä¼  {new_files_count} ä¸ªæ–°æ–‡ä»¶ï¼ˆå…± {total_files} ä¸ªæ–‡ä»¶ï¼‰ï¼Œè¯·ä¸ºæ¯ä¸ªæ–‡ä»¶è¾“å…¥ç®—æ³•åç§°", 
                        style={'color': '#17a2b8', 'fontWeight': 'bold'}
                    )
                else:
                    status_text = html.Span(
                        f"å…± {total_files} ä¸ªæ–‡ä»¶ï¼Œè¯·ä¸ºæ¯ä¸ªæ–‡ä»¶è¾“å…¥ç®—æ³•åç§°", 
                        style={'color': '#17a2b8', 'fontWeight': 'bold'}
                    )
            else:
                # æ²¡æœ‰ç°æœ‰æ•°æ®ï¼Œåªæ˜¾ç¤ºæ–°æ–‡ä»¶
                file_list = html.Div(file_items)
                status_text = html.Span(
                    f"å·²ä¸Šä¼  {len(file_items)} ä¸ªæ–°æ–‡ä»¶ï¼Œè¯·ä¸ºæ¯ä¸ªæ–‡ä»¶è¾“å…¥ç®—æ³•åç§°", 
                    style={'color': '#17a2b8', 'fontWeight': 'bold'}
                )
            
            return file_list, status_text, new_store_data
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†å¤šæ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
            
            logger.error(traceback.format_exc())
            error_text = html.Span(f"å¤„ç†å¤±è´¥: {str(e)}", style={'color': '#dc3545'})
            return no_update, error_text, no_update
    
    def extract_file_index_from_id(
        self, 
        file_id: str, 
        file_ids: List[str]
    ) -> Optional[int]:
        """
        ä»æ–‡ä»¶IDä¸­æå–æ–‡ä»¶ç´¢å¼•
        
        Args:
            file_id: æ–‡ä»¶IDï¼ˆæ ¼å¼: file-{timestamp}-{index} æˆ– file-{index}ï¼‰
            file_ids: æ–‡ä»¶IDåˆ—è¡¨
            
        Returns:
            Optional[int]: æ–‡ä»¶ç´¢å¼•ï¼Œå¦‚æœæ— æ³•è§£æåˆ™è¿”å›None
        """
        # é¦–å…ˆå°è¯•é€šè¿‡file_idsåˆ—è¡¨æŸ¥æ‰¾
        if file_id in file_ids:
            return file_ids.index(file_id)
        
        # å…¼å®¹æ—§æ ¼å¼ï¼šfile-{i} å’Œæ–°æ ¼å¼ï¼šfile-{timestamp}-{i}
        try:
            if file_id.startswith('file-'):
                parts = file_id.split('-')
                if len(parts) >= 3:
                    # æ–°æ ¼å¼ï¼šfile-{timestamp}-{i}
                    return int(parts[2])
                elif len(parts) == 2:
                    # æ—§æ ¼å¼ï¼šfile-{i}
                    return int(parts[1])
            return None
        except (ValueError, IndexError):
            logger.warning(f"æ— æ³•è§£ææ–‡ä»¶ID: {file_id}")
            return None
    
    def get_file_data_by_id(
        self, 
        file_id: str, 
        store_data: Dict[str, Any]
    ) -> Optional[Tuple[str, str]]:
        """
        æ ¹æ®æ–‡ä»¶IDè·å–æ–‡ä»¶å†…å®¹å’Œæ–‡ä»¶å
        
        Args:
            file_id: æ–‡ä»¶ID
            store_data: storeæ•°æ®å­—å…¸
            
        Returns:
            Optional[Tuple[str, str]]: (æ–‡ä»¶å†…å®¹, æ–‡ä»¶å)ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å›None
        """
        if not store_data or 'contents' not in store_data or 'filenames' not in store_data:
            return None
        
        contents_list = store_data.get('contents', [])
        filename_list = store_data.get('filenames', [])
        file_ids = store_data.get('file_ids', [])
        
        # æå–æ–‡ä»¶ç´¢å¼•
        file_index = self.extract_file_index_from_id(file_id, file_ids)
        
        if file_index is None:
            return None
        
        if file_index >= len(contents_list) or file_index >= len(filename_list):
            return None
        
        return contents_list[file_index], filename_list[file_index]

