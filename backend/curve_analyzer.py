
"""
æ›²çº¿åˆ†æå™¨ - ä½¿ç”¨DTWç®—æ³•å¯¹é½after_touchæ›²çº¿

é¢å‘å¯¹è±¡è®¾è®¡ï¼Œä¸“æ³¨äºDTWå¯¹é½ç®—æ³•
"""
import traceback
from typing import List, Tuple, Dict, Any, Optional, Callable
import numpy as np
from scipy.interpolate import interp1d
from scipy.ndimage import gaussian_filter1d
from dtw import dtw
from utils.logger import Logger

logger = Logger.get_logger()


class DTWCurveAligner:
    """
    DTWæ›²çº¿å¯¹é½å™¨ - ä½¿ç”¨DTWç®—æ³•å¯¹é½ä¸¤æ¡after_touchæ›²çº¿
    
    å¯¹é½æµç¨‹ï¼š
    1. æå–after_touchæ•°æ®ï¼ˆæ—¶é—´å’Œæ·±åº¦å€¼ï¼‰
    2. å½’ä¸€åŒ–å’Œå¯¹æ•°å˜æ¢
    3. ä½¿ç”¨DTWæ‰¾åˆ°å¯¹é½è·¯å¾„
    4. æ ¹æ®å¯¹é½è·¯å¾„é‡æ–°é‡‡æ ·æ›²çº¿ï¼Œä½¿ä¸¤æ¡æ›²çº¿å¯¹é½
    5. è‡ªåŠ¨å¤„ç†åˆå§‹æŠ–åŠ¨å’Œå±€éƒ¨æ—¶é—´æ‰­æ›²
    """
    
    def __init__(self, 
                 sampling_rate_ms: float = 1.0,
                 time_range_threshold_ms: float = 1000.0,
                 window_size_ratio: float = 0.5,
                 distance_metric: str = 'manhattan',
                 smooth_sigma: float = 1.0):
        """
        åˆå§‹åŒ–DTWæ›²çº¿å¯¹é½å™¨
        
        Args:
            sampling_rate_ms: é‡é‡‡æ ·æ—¶é—´é—´éš”ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤1ms
            time_range_threshold_ms: æ—¶é—´èŒƒå›´å·®å¼‚é˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰ï¼Œè¶…è¿‡æ­¤å€¼è®¤ä¸ºä¸åŒ¹é…
            window_size_ratio: DTWçª—å£å¤§å°æ¯”ä¾‹ï¼ˆç›¸å¯¹äºæœ€å¤§æŒç»­æ—¶é—´ï¼‰ï¼Œé»˜è®¤0.5ï¼ˆ50%ï¼‰
            distance_metric: è·ç¦»åº¦é‡æ–¹å¼ï¼Œå¯é€‰ï¼š
                - 'euclidean': æ¬§å¼è·ç¦»ï¼ˆé»˜è®¤ï¼Œå¯¹æŠ–åŠ¨æ•æ„Ÿï¼‰
                - 'manhattan': æ›¼å“ˆé¡¿è·ç¦»ï¼ˆL1è·ç¦»ï¼Œå¯¹æŠ–åŠ¨æ›´é²æ£’ï¼‰
                - 'chebyshev': åˆ‡æ¯”é›ªå¤«è·ç¦»ï¼ˆå…³æ³¨æœ€å¤§å·®å¼‚ï¼‰
                - 'gradient': åŸºäºæ¢¯åº¦çš„è·ç¦»ï¼ˆå…³æ³¨å˜åŒ–è¶‹åŠ¿ï¼Œå¯¹æŠ–åŠ¨æœ€é²æ£’ï¼‰
            smooth_sigma: é«˜æ–¯å¹³æ»‘å‚æ•°ï¼ˆæ ‡å‡†å·®ï¼‰ï¼Œç”¨äºå‡å°‘æŠ–åŠ¨å½±å“ï¼Œ0è¡¨ç¤ºä¸å¹³æ»‘
        """
        self.sampling_rate_ms = sampling_rate_ms
        self.time_range_threshold_ms = time_range_threshold_ms
        self.window_size_ratio = window_size_ratio
        self.distance_metric = distance_metric
        self.smooth_sigma = smooth_sigma
    
    def align_curves(self, 
                    record_note, 
                    replay_note) -> Optional[Dict[str, Any]]:
        """
        å¯¹é½ä¸¤æ¡after_touchæ›²çº¿
        
        Args:
            record_note: å½•åˆ¶éŸ³ç¬¦å¯¹è±¡
            replay_note: æ’­æ”¾éŸ³ç¬¦å¯¹è±¡
        
        Returns:
            Dict[str, Any]: å¯¹é½ç»“æœï¼ŒåŒ…å«ï¼š
                - time_points: å¯¹é½åçš„æ—¶é—´ç‚¹æ•°ç»„ï¼ˆmsï¼‰
                - record_curve: å¯¹é½åçš„å½•åˆ¶æ›²çº¿å€¼
                - replay_curve: å¯¹é½åçš„æ’­æ”¾æ›²çº¿å€¼
                - alignment_path: DTWå¯¹é½è·¯å¾„ [(i, j), ...]
                - alignment_method: å¯¹é½æ–¹æ³•ï¼ˆ'dtw'ï¼‰
                - before_alignment: å¯¹é½å‰çš„æ•°æ®ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
                å¦‚æœå¯¹é½å¤±è´¥åˆ™è¿”å›None
        """
        try:
            # 1. æå–after_touchæ•°æ®
            record_data = self._extract_curve_data(record_note)
            replay_data = self._extract_curve_data(replay_note)
            
            if record_data is None or replay_data is None:
                return None
            
            record_times, record_values = record_data
            replay_times, replay_values = replay_data
            
            # 2. æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
            if not self._validate_curve_data(record_times, record_values, replay_times, replay_values):
                return None
            
            # 3. ä¿å­˜å¯¹é½å‰çš„æ•°æ®ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
            before_alignment = {
                'record_times': record_times.copy(),
                'record_values': record_values.copy(),
                'replay_times': replay_times.copy(),
                'replay_values': replay_values.copy()
            }
            
            # 4. é¢„å¤„ç†ï¼šå½’ä¸€åŒ–å’Œå¯¹æ•°å˜æ¢
            record_values_processed = self._preprocess_curve(record_values)
            replay_values_processed = self._preprocess_curve(replay_values)
            
            # 5. å¹³æ»‘å¤„ç†ï¼ˆå‡å°‘æŠ–åŠ¨å½±å“ï¼‰
            if self.smooth_sigma > 0:
                record_values_processed = self._smooth_curve(record_values_processed)
                replay_values_processed = self._smooth_curve(replay_values_processed)
            
            # 6. ä½¿ç”¨DTWæ‰¾åˆ°å¯¹é½è·¯å¾„
            alignment_result = self._perform_dtw_alignment(
                record_times, record_values_processed,
                replay_times, replay_values_processed
            )
            
            if alignment_result is None:
                logger.warning("âš ï¸ DTWå¯¹é½å¤±è´¥")
                return None
            
            alignment_path = alignment_result['alignment_path']
            dtw_distance = alignment_result['dtw_distance']
            
            # 7. æ ¹æ®å¯¹é½è·¯å¾„é‡æ–°é‡‡æ ·æ›²çº¿ï¼Œä½¿ä¸¤æ¡æ›²çº¿å¯¹é½
            aligned_result = self._resample_by_alignment_path(
                record_times, record_values_processed,
                replay_times, replay_values_processed,
                alignment_path
            )
            
            if aligned_result is None:
                logger.warning("âš ï¸ æ ¹æ®å¯¹é½è·¯å¾„é‡æ–°é‡‡æ ·å¤±è´¥")
                return None
            
            return {
                'time_points': aligned_result['time_points'],
                'record_curve': aligned_result['record_curve'],
                'replay_curve': aligned_result['replay_curve'],
                'alignment_path': alignment_path,
                'dtw_distance': dtw_distance,
                'alignment_method': 'dtw',
                'before_alignment': before_alignment
            }
            
        except Exception as e:
            logger.error(f"âŒ æ›²çº¿å¯¹é½å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return None
    
    def _extract_curve_data(self, note) -> Optional[Tuple[np.ndarray, np.ndarray]]:
        """
        æå–after_touchæ›²çº¿æ•°æ®
        
        Args:
            note: éŸ³ç¬¦å¯¹è±¡
        
        Returns:
            Tuple[np.ndarray, np.ndarray]: (æ—¶é—´æ•°ç»„, å€¼æ•°ç»„)ï¼Œå•ä½ï¼šms
            å¦‚æœæå–å¤±è´¥åˆ™è¿”å›None
        """
        try:
            if not hasattr(note, 'after_touch') or note.after_touch is None or note.after_touch.empty:
                logger.warning("âš ï¸ éŸ³ç¬¦æ²¡æœ‰after_touchæ•°æ®")
                return None
            
            # æå–æ—¶é—´å’Œå€¼
            # after_touch.indexæ˜¯ç›¸å¯¹æ—¶é—´ï¼ˆ0.1mså•ä½ï¼‰ï¼Œnote.offsetæ˜¯ç»å¯¹åç§»ï¼ˆ0.1mså•ä½ï¼‰
            times = (note.after_touch.index + note.offset) / 10.0  # è½¬æ¢ä¸ºms
            values = note.after_touch.values
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            times = np.array(times)
            values = np.array(values)
            
            # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
            if len(times) == 0 or len(values) == 0:
                logger.warning("âš ï¸ after_touchæ•°æ®ä¸ºç©º")
                return None
            
            if len(times) != len(values):
                logger.warning(f"âš ï¸ æ—¶é—´å’Œå€¼æ•°ç»„é•¿åº¦ä¸åŒ¹é…: times={len(times)}, values={len(values)}")
                return None
            
            return times, values
            
        except Exception as e:
            logger.error(f"âŒ æå–æ›²çº¿æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _validate_curve_data(self,
                             record_times: np.ndarray,
                             record_values: np.ndarray,
                             replay_times: np.ndarray,
                             replay_values: np.ndarray) -> bool:
        """
        éªŒè¯æ›²çº¿æ•°æ®æœ‰æ•ˆæ€§
        
        Args:
            record_times: å½•åˆ¶æ—¶é—´æ•°ç»„
            record_values: å½•åˆ¶å€¼æ•°ç»„
            replay_times: æ’­æ”¾æ—¶é—´æ•°ç»„
            replay_values: æ’­æ”¾å€¼æ•°ç»„
        
        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        # æ£€æŸ¥æ•°æ®ç‚¹æ•°é‡
        if len(record_times) < 2 or len(replay_times) < 2:
            logger.warning("âš ï¸ æ›²çº¿æ•°æ®ç‚¹ä¸è¶³ï¼ˆå°‘äº2ä¸ªç‚¹ï¼‰")
            return False
        
        # æ£€æŸ¥æ—¶é—´èŒƒå›´å·®å¼‚
        record_duration = record_times[-1] - record_times[0]
        replay_duration = replay_times[-1] - replay_times[0]
        max_duration = max(record_duration, replay_duration)
        
        if max_duration <= 0:
            logger.warning("âš ï¸ æ›²çº¿æŒç»­æ—¶é—´æ— æ•ˆ")
            return False
        
        time_diff = abs(record_duration - replay_duration)
        threshold = max(self.time_range_threshold_ms, max_duration * 0.5)
        
        if time_diff > threshold:
            logger.warning(f"âš ï¸ æ—¶é—´èŒƒå›´å·®å¼‚è¿‡å¤§: å½•åˆ¶={record_duration:.1f}ms, æ’­æ”¾={replay_duration:.1f}ms, å·®å¼‚={time_diff:.1f}ms, é˜ˆå€¼={threshold:.1f}ms")
            return False
        
        # æ£€æŸ¥NaNå’ŒInf
        if np.any(~np.isfinite(record_times)) or np.any(~np.isfinite(record_values)):
            logger.warning("âš ï¸ å½•åˆ¶æ›²çº¿åŒ…å«NaNæˆ–Infå€¼")
            return False
        
        if np.any(~np.isfinite(replay_times)) or np.any(~np.isfinite(replay_values)):
            logger.warning("âš ï¸ æ’­æ”¾æ›²çº¿åŒ…å«NaNæˆ–Infå€¼")
            return False
        
        return True
    
    def _preprocess_curve(self, values: np.ndarray) -> np.ndarray:
        """
        é¢„å¤„ç†æ›²çº¿ï¼šå½’ä¸€åŒ–å’Œå¯¹æ•°å˜æ¢
        
        Args:
            values: åŸå§‹æ›²çº¿å€¼
        
        Returns:
            np.ndarray: é¢„å¤„ç†åçš„æ›²çº¿å€¼ï¼ˆ0-1èŒƒå›´ï¼‰
        """
        # 1. å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        normalized = self._normalize_values(values)
        
        # 2. åº”ç”¨å¯¹æ•°å˜æ¢ï¼ˆlog1p = log(1+x)ï¼‰
        log_values = np.log1p(normalized)
        
        # 3. é‡æ–°å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        normalized_log = self._normalize_values(log_values)
        
        return normalized_log
    
    def _normalize_values(self, values: np.ndarray) -> np.ndarray:
        """
        å½’ä¸€åŒ–å€¼åˆ°0-1èŒƒå›´
        
        Args:
            values: åŸå§‹å€¼æ•°ç»„
        
        Returns:
            np.ndarray: å½’ä¸€åŒ–åçš„å€¼æ•°ç»„ï¼ˆ0-1èŒƒå›´ï¼‰
        """
        if len(values) == 0:
            return values
        
        values = np.array(values)
        min_val = np.min(values)
        max_val = np.max(values)
        
        if max_val > min_val:
            normalized = (values - min_val) / (max_val - min_val)
        else:
            # æ‰€æœ‰å€¼ç›¸åŒï¼Œå½’ä¸€åŒ–ä¸º0
            normalized = np.zeros_like(values)
        
        # å¤„ç†NaNå’ŒInf
        normalized = np.nan_to_num(normalized, nan=0.0, posinf=1.0, neginf=0.0)
        
        return normalized
    
    def _smooth_curve(self, values: np.ndarray) -> np.ndarray:
        """
        ä½¿ç”¨é«˜æ–¯æ»¤æ³¢å¹³æ»‘æ›²çº¿ï¼Œå‡å°‘æŠ–åŠ¨å½±å“
        
        Args:
            values: æ›²çº¿å€¼æ•°ç»„
        
        Returns:
            np.ndarray: å¹³æ»‘åçš„æ›²çº¿å€¼
        """
        if len(values) < 3 or self.smooth_sigma <= 0:
            return values
        
        try:
            smoothed = gaussian_filter1d(values, sigma=self.smooth_sigma)
            # å¤„ç†NaNå’ŒInf
            smoothed = np.nan_to_num(smoothed, nan=0.0, posinf=1.0, neginf=0.0)
            return smoothed
        except Exception as e:
            logger.warning(f"âš ï¸ æ›²çº¿å¹³æ»‘å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹å€¼")
            return values
    
    def _perform_dtw_alignment(self,
                               record_times: np.ndarray,
                               record_values: np.ndarray,
                               replay_times: np.ndarray,
                               replay_values: np.ndarray) -> Optional[Dict[str, Any]]:
        """
        æ‰§è¡ŒDTWå¯¹é½ï¼Œæ‰¾åˆ°å¯¹é½è·¯å¾„
        
        æ³¨æ„ï¼šDTWå¯¹é½åªä½¿ç”¨å€¼ç»´åº¦ï¼ˆæ›²çº¿æ·±åº¦å€¼ï¼‰ï¼Œæ—¶é—´å¯¹é½ç”±DTWè·¯å¾„æœ¬èº«å¤„ç†ã€‚
        è¿™æ ·å¯ä»¥é¿å…æ—¶é—´ç»´åº¦åœ¨è·ç¦»è®¡ç®—ä¸­å ä¸»å¯¼åœ°ä½ã€‚
        
        Args:
            record_times: å½•åˆ¶æ—¶é—´ç‚¹ï¼ˆmsï¼‰- ä»…ç”¨äºè®°å½•ï¼Œä¸å‚ä¸è·ç¦»è®¡ç®—
            record_values: å½•åˆ¶æ›²çº¿å€¼ï¼ˆå·²é¢„å¤„ç†ï¼‰
            replay_times: æ’­æ”¾æ—¶é—´ç‚¹ï¼ˆmsï¼‰- ä»…ç”¨äºè®°å½•ï¼Œä¸å‚ä¸è·ç¦»è®¡ç®—
            replay_values: æ’­æ”¾æ›²çº¿å€¼ï¼ˆå·²é¢„å¤„ç†ï¼‰
        
        Returns:
            Dict[str, Any]: DTWå¯¹é½ç»“æœï¼ŒåŒ…å«ï¼š
                - alignment_path: å¯¹é½è·¯å¾„ [(i, j), ...]
                - dtw_distance: DTWè·ç¦»
            å¦‚æœå¯¹é½å¤±è´¥åˆ™è¿”å›None
        """
        try:
            # æ ¹æ®è·ç¦»åº¦é‡ç±»å‹å‡†å¤‡æ•°æ®
            if self.distance_metric == 'gradient':
                # åŸºäºæ¢¯åº¦çš„è·ç¦»ï¼šä½¿ç”¨ä¸€é˜¶å·®åˆ†ï¼ˆå˜åŒ–è¶‹åŠ¿ï¼‰
                record_features = self._compute_gradient(record_values)
                replay_features = self._compute_gradient(replay_values)
            else:
                # å…¶ä»–è·ç¦»åº¦é‡ï¼šç›´æ¥ä½¿ç”¨å€¼
                record_features = record_values
                replay_features = replay_values
            
            # å°†å€¼é‡å¡‘ä¸ºåˆ—å‘é‡ï¼ˆDTWåº“è¦æ±‚ï¼‰
            record_features_2d = record_features.reshape(-1, 1)
            replay_features_2d = replay_features.reshape(-1, 1)
            
            # è·å–è·ç¦»åº¦é‡å­—ç¬¦ä¸²ï¼ˆdtwåº“æ”¯æŒï¼š'euclidean', 'manhattan', 'squared_euclidean'ç­‰ï¼‰
            dist_method_str = self._get_distance_method_string()
            
            # å…ˆå°è¯•æ— çª—å£çº¦æŸçš„DTWï¼ˆæ›´çµæ´»ï¼Œèƒ½å¤„ç†æ›´å¤§çš„æ—¶é—´æ‰­æ›²ï¼‰
            try:
                alignment = dtw(
                    record_features_2d, 
                    replay_features_2d, 
                    keep_internals=True,
                    distance_only=False,
                    dist_method=dist_method_str
                )
                alignment_path = list(zip(alignment.index1, alignment.index2))
                dtw_distance = alignment.distance
                
                logger.debug(f"âœ… DTWå¯¹é½æˆåŠŸï¼ˆæ— çª—å£ï¼Œ{self.distance_metric}è·ç¦»ï¼‰: è·¯å¾„é•¿åº¦={len(alignment_path)}, è·ç¦»={dtw_distance:.2f}")
                
                return {
                    'alignment_path': alignment_path,
                    'dtw_distance': dtw_distance
                }
                
            except Exception as e1:
                logger.warning(f"âš ï¸ DTWå¯¹é½å¤±è´¥ï¼ˆæ— çª—å£ï¼‰: {e1}")
                
                # å°è¯•ä½¿ç”¨çª—å£çº¦æŸï¼ˆé™åˆ¶å¯¹é½èŒƒå›´ï¼Œé¿å…è¿‡åº¦æ‰­æ›²ï¼‰
                try:
                    max_duration = max(
                        record_times[-1] - record_times[0],
                        replay_times[-1] - replay_times[0]
                    )
                    window_size = min(int(max_duration * self.window_size_ratio), 500)  # æœ€å¤§500ms
                    
                    alignment = dtw(
                        record_features_2d,
                        replay_features_2d,
                        keep_internals=True,
                        distance_only=False,
                        dist_method=dist_method_str,
                        window_type='sakoechiba',
                        window_args={'window_size': window_size}
                    )
                    alignment_path = list(zip(alignment.index1, alignment.index2))
                    dtw_distance = alignment.distance
                    
                    logger.debug(f"âœ… DTWå¯¹é½æˆåŠŸï¼ˆçª—å£={window_size}msï¼Œ{self.distance_metric}è·ç¦»ï¼‰: è·¯å¾„é•¿åº¦={len(alignment_path)}, è·ç¦»={dtw_distance:.2f}")
                    
                    return {
                        'alignment_path': alignment_path,
                        'dtw_distance': dtw_distance
                    }
                    
                except Exception as e2:
                    logger.warning(f"âš ï¸ DTWå¯¹é½å¤±è´¥ï¼ˆæœ‰çª—å£ï¼‰: {e2}")
                    return None
                    
        except Exception as e:
            logger.error(f"âŒ DTWå¯¹é½æ‰§è¡Œå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return None
    
    def _compute_gradient(self, values: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—æ›²çº¿çš„ä¸€é˜¶å·®åˆ†ï¼ˆæ¢¯åº¦ï¼‰ï¼Œç”¨äºåŸºäºå˜åŒ–è¶‹åŠ¿çš„è·ç¦»åº¦é‡
        
        Args:
            values: æ›²çº¿å€¼æ•°ç»„
        
        Returns:
            np.ndarray: æ¢¯åº¦æ•°ç»„ï¼ˆé•¿åº¦å‡1ï¼‰
        """
        if len(values) < 2:
            return np.array([0.0])
        
        # è®¡ç®—ä¸€é˜¶å·®åˆ†
        gradient = np.diff(values)
        
        # å½’ä¸€åŒ–æ¢¯åº¦ï¼ˆé¿å…é‡çº²é—®é¢˜ï¼‰
        if np.max(np.abs(gradient)) > 1e-10:
            gradient = gradient / np.max(np.abs(gradient))
        
        # å¤„ç†è¾¹ç•Œï¼šåœ¨ä¸¤ç«¯è¡¥0ï¼Œä¿æŒé•¿åº¦ä¸€è‡´
        gradient_padded = np.concatenate([[0.0], gradient, [0.0]])
        
        return gradient_padded
    
    def _get_distance_method_string(self) -> str:
        """
        æ ¹æ®è·ç¦»åº¦é‡ç±»å‹è¿”å›dtwåº“æ”¯æŒçš„è·ç¦»åº¦é‡å­—ç¬¦ä¸²
        
        dtwåº“æ”¯æŒçš„è·ç¦»åº¦é‡ï¼š
        - 'euclidean': æ¬§å¼è·ç¦»ï¼ˆL2ï¼‰
        - 'manhattan': æ›¼å“ˆé¡¿è·ç¦»ï¼ˆL1ï¼‰
        - 'squared_euclidean': å¹³æ–¹æ¬§å¼è·ç¦»
        
        æ³¨æ„ï¼šå¯¹äº'gradient'å’Œ'chebyshev'ï¼Œæˆ‘ä»¬é€šè¿‡æ•°æ®é¢„å¤„ç†æ¥å®ç°
        ï¼ˆgradientåœ¨æ•°æ®å‡†å¤‡é˜¶æ®µå·²å¤„ç†ï¼Œchebyshevä½¿ç”¨manhattanä½œä¸ºè¿‘ä¼¼ï¼‰
        
        Returns:
            str: dtwåº“æ”¯æŒçš„è·ç¦»åº¦é‡å­—ç¬¦ä¸²
        """
        if self.distance_metric == 'manhattan':
            return 'manhattan'
        elif self.distance_metric == 'gradient':
            # æ¢¯åº¦è·ç¦»ï¼šæ•°æ®å·²ç»è½¬æ¢ä¸ºæ¢¯åº¦ï¼Œä½¿ç”¨manhattanè·ç¦»è®¡ç®—æ¢¯åº¦å·®å¼‚
            return 'manhattan'
        elif self.distance_metric == 'chebyshev':
            # åˆ‡æ¯”é›ªå¤«è·ç¦»ï¼šdtwåº“ä¸æ”¯æŒï¼Œä½¿ç”¨manhattanä½œä¸ºè¿‘ä¼¼ï¼ˆå¯¹æŠ–åŠ¨ä¹Ÿè¾ƒé²æ£’ï¼‰
            return 'manhattan'
        else:
            # é»˜è®¤ï¼šæ¬§å¼è·ç¦»
            return 'euclidean'
    
    def _resample_by_alignment_path(self,
                                    record_times: np.ndarray,
                                    record_values: np.ndarray,
                                    replay_times: np.ndarray,
                                    replay_values: np.ndarray,
                                    alignment_path: List[Tuple[int, int]]) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®DTWå¯¹é½è·¯å¾„é‡æ–°é‡‡æ ·æ›²çº¿ï¼Œä½¿ä¸¤æ¡æ›²çº¿å¯¹é½
        
        å¯¹é½ç­–ç•¥ï¼š
        1. æ ¹æ®å¯¹é½è·¯å¾„ï¼Œæ‰¾åˆ°å¯¹é½åçš„æ—¶é—´ç‚¹
        2. å¯¹æ¯æ¡æ›²çº¿è¿›è¡Œæ’å€¼ï¼Œå¾—åˆ°å¯¹é½åçš„å€¼
        3. è‡ªåŠ¨å¤„ç†åˆå§‹æŠ–åŠ¨å’Œå±€éƒ¨æ—¶é—´æ‰­æ›²
        
        Args:
            record_times: å½•åˆ¶æ—¶é—´ç‚¹ï¼ˆmsï¼‰
            record_values: å½•åˆ¶æ›²çº¿å€¼ï¼ˆå·²é¢„å¤„ç†ï¼‰
            replay_times: æ’­æ”¾æ—¶é—´ç‚¹ï¼ˆmsï¼‰
            replay_values: æ’­æ”¾æ›²çº¿å€¼ï¼ˆå·²é¢„å¤„ç†ï¼‰
            alignment_path: DTWå¯¹é½è·¯å¾„ [(i, j), ...]
        
        Returns:
            Dict[str, Any]: å¯¹é½åçš„ç»“æœï¼ŒåŒ…å«ï¼š
                - time_points: å¯¹é½åçš„æ—¶é—´ç‚¹æ•°ç»„ï¼ˆmsï¼‰
                - record_curve: å¯¹é½åçš„å½•åˆ¶æ›²çº¿å€¼
                - replay_curve: å¯¹é½åçš„æ’­æ”¾æ›²çº¿å€¼
            å¦‚æœé‡æ–°é‡‡æ ·å¤±è´¥åˆ™è¿”å›None
        """
        try:
            if not alignment_path:
                logger.warning("âš ï¸ å¯¹é½è·¯å¾„ä¸ºç©º")
                return None
            
            # 1. æ ¹æ®å¯¹é½è·¯å¾„æ„å»ºå¯¹é½åçš„æ—¶é—´ç‚¹
            # ç­–ç•¥ï¼šä½¿ç”¨å¯¹é½è·¯å¾„ä¸­å¯¹åº”çš„æ—¶é—´ç‚¹ï¼Œå–å¹³å‡å€¼æˆ–ä½¿ç”¨ç»Ÿä¸€é‡‡æ ·
            aligned_time_points = []
            aligned_record_values = []
            aligned_replay_values = []
            
            for i, j in alignment_path:
                if i < len(record_times) and j < len(replay_times):
                    # ä½¿ç”¨å¯¹é½è·¯å¾„ä¸­å¯¹åº”çš„æ—¶é—´ç‚¹
                    # å¯ä»¥å–å¹³å‡å€¼ï¼Œæˆ–è€…ä½¿ç”¨å½•åˆ¶æ—¶é—´ä½œä¸ºåŸºå‡†
                    # è¿™é‡Œä½¿ç”¨å½•åˆ¶æ—¶é—´ä½œä¸ºåŸºå‡†ï¼Œå› ä¸ºå½•åˆ¶æ˜¯å‚è€ƒæ ‡å‡†
                    aligned_time = record_times[i]
                    aligned_time_points.append(aligned_time)
                    aligned_record_values.append(record_values[i])
                    aligned_replay_values.append(replay_values[j])
            
            if len(aligned_time_points) < 2:
                logger.warning("âš ï¸ å¯¹é½åçš„æ—¶é—´ç‚¹ä¸è¶³")
                return None
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            aligned_time_points = np.array(aligned_time_points)
            aligned_record_values = np.array(aligned_record_values)
            aligned_replay_values = np.array(aligned_replay_values)
            
            # 2. åˆ›å»ºç»Ÿä¸€çš„æ—¶é—´é‡‡æ ·ç‚¹ï¼ˆç”¨äºæœ€ç»ˆè¾“å‡ºï¼‰
            # ä½¿ç”¨å¯¹é½åçš„æ—¶é—´èŒƒå›´ï¼ŒæŒ‰é‡‡æ ·ç‡é‡æ–°é‡‡æ ·
            min_time = np.min(aligned_time_points)
            max_time = np.max(aligned_time_points)
            uniform_time_points = np.arange(
                min_time,
                max_time + self.sampling_rate_ms,
                self.sampling_rate_ms
            )
            
            # 3. æ’å€¼åˆ°ç»Ÿä¸€æ—¶é—´ç‚¹
            # ç”±äºå¯¹é½è·¯å¾„å¯èƒ½ä¸æ˜¯ä¸¥æ ¼å•è°ƒçš„ï¼Œéœ€è¦å…ˆå¤„ç†é‡å¤æ—¶é—´ç‚¹
            record_curve = self._interpolate_to_uniform_time(
                aligned_time_points, aligned_record_values, uniform_time_points
            )
            replay_curve = self._interpolate_to_uniform_time(
                aligned_time_points, aligned_replay_values, uniform_time_points
            )
            
            return {
                'time_points': uniform_time_points,
                'record_curve': record_curve,
                'replay_curve': replay_curve
            }
            
        except Exception as e:
            logger.error(f"âŒ æ ¹æ®å¯¹é½è·¯å¾„é‡æ–°é‡‡æ ·å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return None
    
    def _interpolate_to_uniform_time(self,
                                     original_times: np.ndarray,
                                     original_values: np.ndarray,
                                     target_times: np.ndarray) -> np.ndarray:
        """
        æ’å€¼æ›²çº¿åˆ°ç»Ÿä¸€æ—¶é—´ç‚¹
        
        Args:
            original_times: åŸå§‹æ—¶é—´ç‚¹ï¼ˆå¯èƒ½ä¸å•è°ƒï¼‰
            original_values: åŸå§‹å€¼
            target_times: ç›®æ ‡æ—¶é—´ç‚¹ï¼ˆå‡åŒ€é‡‡æ ·ï¼‰
        
        Returns:
            np.ndarray: æ’å€¼åçš„å€¼æ•°ç»„
        """
        try:
            # å¤„ç†é‡å¤æ—¶é—´ç‚¹ï¼šå–å¹³å‡å€¼
            unique_times = []
            unique_values = []
            
            # æŒ‰æ—¶é—´æ’åº
            sort_idx = np.argsort(original_times)
            sorted_times = original_times[sort_idx]
            sorted_values = original_values[sort_idx]
            
            # åˆå¹¶ç›¸åŒæ—¶é—´ç‚¹çš„å€¼ï¼ˆå–å¹³å‡å€¼ï¼‰
            i = 0
            while i < len(sorted_times):
                current_time = sorted_times[i]
                time_group = [sorted_values[i]]
                
                # æ”¶é›†ç›¸åŒæ—¶é—´ç‚¹çš„æ‰€æœ‰å€¼
                j = i + 1
                while j < len(sorted_times) and abs(sorted_times[j] - current_time) < 1e-6:
                    time_group.append(sorted_values[j])
                    j += 1
                
                # å–å¹³å‡å€¼
                unique_times.append(current_time)
                unique_values.append(np.mean(time_group))
                
                i = j
            
            unique_times = np.array(unique_times)
            unique_values = np.array(unique_values)
            
            if len(unique_times) < 2:
                # æ•°æ®ç‚¹ä¸è¶³ï¼Œè¿”å›é›¶æ•°ç»„
                return np.zeros_like(target_times)
            
            # æ£€æŸ¥NaNå’ŒInf
            valid_mask = np.isfinite(unique_times) & np.isfinite(unique_values)
            if not np.all(valid_mask):
                unique_times = unique_times[valid_mask]
                unique_values = unique_values[valid_mask]
            
            if len(unique_times) < 2:
                return np.zeros_like(target_times)
            
            # çº¿æ€§æ’å€¼
            interp_func = interp1d(
                unique_times,
                unique_values,
                kind='linear',
                fill_value=0.0,
                bounds_error=False,
                assume_sorted=True
            )
            
            interpolated = interp_func(target_times)
            
            # å¤„ç†NaNå’ŒInf
            interpolated = np.nan_to_num(interpolated, nan=0.0, posinf=1.0, neginf=0.0)
            
            return interpolated
            
        except Exception as e:
            logger.error(f"âŒ æ›²çº¿æ’å€¼å¤±è´¥: {e}")
            return np.zeros_like(target_times)


class CurvePair:
    """
    æ›²çº¿å¯¹ç±» - å°è£…ä¸€å¯¹å½•åˆ¶å’Œæ’­æ”¾æ›²çº¿çš„å¯¹é½ç»“æœ
    """
    
    def __init__(self, record_note, replay_note, record_idx: int, replay_idx: int):
        """
        åˆå§‹åŒ–æ›²çº¿å¯¹
        
        Args:
            record_note: å½•åˆ¶éŸ³ç¬¦å¯¹è±¡
            replay_note: æ’­æ”¾éŸ³ç¬¦å¯¹è±¡
            record_idx: å½•åˆ¶ç´¢å¼•
            replay_idx: æ’­æ”¾ç´¢å¼•
        """
        self.record_note = record_note
        self.replay_note = replay_note
        self.record_idx = record_idx
        self.replay_idx = replay_idx
        self.key_id = record_note.id if record_note else None
        
        # å¯¹é½ç»“æœ
        self.alignment_result: Optional[Dict[str, Any]] = None
        self.alignment_status: str = "pending"  # pending, success, failed
    
    def get_alignment_result(self) -> Optional[Dict[str, Any]]:
        """è·å–å¯¹é½ç»“æœ"""
        return self.alignment_result
    
    def get_result_dict(self) -> Dict[str, Any]:
        """è·å–ç»“æœå­—å…¸ï¼ˆç”¨äºåºåˆ—åŒ–ï¼‰"""
        return {
            'record_idx': self.record_idx,
            'replay_idx': self.replay_idx,
            'key_id': self.key_id,
            'status': self.alignment_status,
            'alignment_result': self.alignment_result
        }


class CurveAnalyzer:
    """
    æ›²çº¿åˆ†æå™¨ - ä¸»ç±»ï¼Œåè°ƒæ›²çº¿å¯¹é½
    """
    
    def __init__(self,
                 sampling_rate_ms: float = 1.0,
                 time_range_threshold_ms: float = 1000.0):
        """
        åˆå§‹åŒ–æ›²çº¿åˆ†æå™¨
        
        Args:
            sampling_rate_ms: é‡é‡‡æ ·æ—¶é—´é—´éš”ï¼ˆæ¯«ç§’ï¼‰
            time_range_threshold_ms: æ—¶é—´èŒƒå›´å·®å¼‚é˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
        """
        self.aligner = DTWCurveAligner(
            sampling_rate_ms=sampling_rate_ms,
            time_range_threshold_ms=time_range_threshold_ms
        )
    
    def align_pairs(self,
                   matched_pairs: List[Tuple[int, int, Any, Any]]) -> List[CurvePair]:
        """
        å¯¹é½åŒ¹é…å¯¹åˆ—è¡¨
        
        Args:
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [(record_idx, replay_idx, record_note, replay_note), ...]
        
        Returns:
            List[CurvePair]: å¯¹é½ç»“æœåˆ—è¡¨
        """
        results = []
        
        logger.info(f"ğŸ”„ å¼€å§‹å¯¹é½ {len(matched_pairs)} å¯¹æ›²çº¿...")
        
        success_count = 0
        for record_idx, replay_idx, record_note, replay_note in matched_pairs:
            pair = CurvePair(record_note, replay_note, record_idx, replay_idx)
            
            try:
                # æ‰§è¡Œå¯¹é½
                alignment_result = self.aligner.align_curves(record_note, replay_note)
                
                if alignment_result is None:
                    pair.alignment_status = "failed"
                    logger.debug(f"âš ï¸ å¯¹é½å¤±è´¥: record_idx={record_idx}, replay_idx={replay_idx}")
                else:
                    pair.alignment_result = alignment_result
                    pair.alignment_status = "success"
                    success_count += 1
                    
            except Exception as e:
                logger.error(f"âŒ å¯¹é½é…å¯¹å¤±è´¥ (record_idx={record_idx}, replay_idx={replay_idx}): {e}")
                pair.alignment_status = "failed"
            
            results.append(pair)
        
        logger.info(f"âœ… å¯¹é½å®Œæˆ: æˆåŠŸ={success_count}/{len(matched_pairs)}, å¤±è´¥={len(matched_pairs) - success_count}")
        
        return results
    
    def get_alignment_statistics(self, curve_pairs: List[CurvePair]) -> Dict[str, Any]:
        """
        è·å–å¯¹é½ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            curve_pairs: æ›²çº¿å¯¹åˆ—è¡¨
        
        Returns:
            Dict[str, Any]: ç»Ÿè®¡ç»“æœ
        """
        successful_pairs = [p for p in curve_pairs if p.alignment_status == "success"]
        
        if not successful_pairs:
            return {
                'total_pairs': len(curve_pairs),
                'successful_pairs': 0,
                'failed_pairs': len(curve_pairs),
                'success_rate': 0.0
            }
        
        # è®¡ç®—å¹³å‡DTWè·ç¦»
        dtw_distances = []
        for pair in successful_pairs:
            if pair.alignment_result and 'dtw_distance' in pair.alignment_result:
                dtw_distances.append(pair.alignment_result['dtw_distance'])
        
        avg_dtw_distance = float(np.mean(dtw_distances)) if dtw_distances else 0.0
        
        return {
            'total_pairs': len(curve_pairs),
            'successful_pairs': len(successful_pairs),
            'failed_pairs': len(curve_pairs) - len(successful_pairs),
            'success_rate': len(successful_pairs) / len(curve_pairs) * 100.0,
            'average_dtw_distance': avg_dtw_distance
        }

