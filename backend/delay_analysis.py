"""
å»¶æ—¶å…³ç³»åˆ†ææ¨¡å—
è´Ÿè´£åˆ†æå»¶æ—¶ä¸æŒ‰é”®ã€å»¶æ—¶ä¸é”¤é€Ÿä¹‹é—´çš„å…³ç³»
"""

import math
import traceback
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Any, Optional
from collections import defaultdict
from scipy import stats
from scipy.stats import f_oneway
from statsmodels.stats.multicomp import pairwise_tukeyhsd
from utils.logger import Logger

logger = Logger.get_logger()


class DelayAnalysis:
    """å»¶æ—¶å…³ç³»åˆ†æå™¨ - åˆ†æå»¶æ—¶ä¸æŒ‰é”®ã€å»¶æ—¶ä¸é”¤é€Ÿä¹‹é—´çš„å…³ç³»"""
    
    def __init__(self, analyzer=None):
        """
        åˆå§‹åŒ–å»¶æ—¶åˆ†æå™¨
        
        Args:
            analyzer: SPMIDAnalyzerå®ä¾‹
        """
        self.analyzer = analyzer
    
    def analyze_key_force_interaction(self) -> Dict[str, Any]:
        """
        ç”ŸæˆæŒ‰é”®ä¸åŠ›åº¦çš„äº¤äº’æ•ˆåº”å›¾æ•°æ®

        ç”ŸæˆæŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾æ‰€éœ€çš„æ•°æ®ï¼Œç”¨äºå¯è§†åŒ–åˆ†ææŒ‰é”®å’ŒåŠ›åº¦å¯¹å»¶æ—¶çš„è”åˆå½±å“ã€‚

        Returns:
            Dict[str, Any]: åˆ†æç»“æœï¼ŒåŒ…å«ï¼š
                - interaction_plot_data: äº¤äº’æ•ˆåº”å›¾æ•°æ®
                - status: çŠ¶æ€æ ‡è¯†
        """
        try:
            if not self.analyzer or not self.analyzer.note_matcher:
                logger.warning("åˆ†æå™¨æˆ–åŒ¹é…å™¨ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡ŒæŒ‰é”®-åŠ›åº¦äº¤äº’åˆ†æ")
                return self._create_empty_interaction_result("åˆ†æå™¨ä¸å­˜åœ¨")

            matched_pairs = self.analyzer.note_matcher.get_matched_pairs()
            offset_data = self.analyzer.note_matcher.get_offset_alignment_data()
            
            if not matched_pairs or not offset_data:
                logger.warning("âš ï¸ æ²¡æœ‰åŒ¹é…æ•°æ®ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
                return self._create_empty_interaction_result("æ²¡æœ‰åŒ¹é…æ•°æ®")
            
            # æå–æ•°æ®ï¼šæŒ‰é”®IDã€é”¤é€Ÿã€å»¶æ—¶ã€ç´¢å¼•
            key_force_delay_data = self._extract_key_force_delay_data(matched_pairs, offset_data)
            
            if not key_force_delay_data:
                logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„æŒ‰é”®-åŠ›åº¦-å»¶æ—¶æ•°æ®")
                return self._create_empty_interaction_result("æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
            
            # å‡†å¤‡æ•°æ®åˆ—è¡¨
            # itemæ ¼å¼: (key_id, replay_velocity, delay_ms, record_idx, replay_idx)
            key_ids_list = [item[0] for item in key_force_delay_data]
            replay_velocities_list = [item[1] for item in key_force_delay_data]
            delays_list = [item[2] for item in key_force_delay_data]
            record_indices_list = [item[3] for item in key_force_delay_data]
            replay_indices_list = [item[4] for item in key_force_delay_data]
            
            # ç”Ÿæˆäº¤äº’æ•ˆåº”å›¾æ•°æ®ï¼ˆåŒ…å«ç´¢å¼•ä¿¡æ¯ï¼‰
            interaction_plot_data = self._generate_interaction_plot_data(
                key_ids_list, replay_velocities_list, delays_list,
                record_indices_list, replay_indices_list
            )
            
            logger.info("æŒ‰é”®-åŠ›åº¦äº¤äº’åˆ†æå®Œæˆ")
            
            return {
                'interaction_plot_data': interaction_plot_data,
                'status': 'success'
            }
            
        except Exception as e:
            logger.error(f"æŒ‰é”®-åŠ›åº¦äº¤äº’åˆ†æå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return self._create_empty_interaction_result(f"åˆ†æå¤±è´¥: {str(e)}")
    
    def _extract_key_force_delay_data(self, matched_pairs: List[Tuple], 
                                      offset_data: List[Dict[str, Any]]) -> List[Tuple[int, float, float, int, int]]:
        """
        ä»åŒ¹é…å¯¹å’Œåç§»æ•°æ®ä¸­æå–æŒ‰é”®IDã€åŠ›åº¦ï¼ˆé”¤é€Ÿï¼‰ã€å»¶æ—¶æ•°æ®
        
        Args:
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨
            offset_data: åç§»å¯¹é½æ•°æ®åˆ—è¡¨
            
        Returns:
            List[Tuple]: [(key_id, replay_velocity, delay_ms, record_idx, replay_idx), ...]
                - key_id: æŒ‰é”®ID
                - replay_velocity: æ’­æ”¾é”¤é€Ÿå€¼
                - delay_ms: å»¶æ—¶ï¼ˆå•ä½ï¼šmsï¼Œå¸¦ç¬¦å·ï¼‰
                - record_idx: å½•åˆ¶éŸ³ç¬¦ç´¢å¼•
                - replay_idx: å›æ”¾éŸ³ç¬¦ç´¢å¼•
        """
        # åˆ›å»ºåŒ¹é…å¯¹ç´¢å¼•åˆ°åç§»æ•°æ®çš„æ˜ å°„
        offset_map = {}
        for item in offset_data:
            record_idx = item.get('record_index')
            replay_idx = item.get('replay_index')
            if record_idx is not None and replay_idx is not None:
                offset_map[(record_idx, replay_idx)] = item
        
        result = []
        
        for record_note, replay_note in matched_pairs:
            # Lookup needs offsets because NoteMatcher.get_offset_alignment_data uses offsets
            lookup_record_idx = record_note.offset
            lookup_replay_idx = replay_note.offset
            
            # Result needs UUIDs as per user request
            record_uuid = record_note.uuid
            replay_uuid = replay_note.uuid

            # è·å–æŒ‰é”®ID
            key_id = record_note.id
            
            # æå–æ’­æ”¾éŸ³ç¬¦çš„é”¤é€Ÿï¼ˆç¬¬ä¸€ä¸ªé”¤é€Ÿå€¼ï¼‰
            replay_velocity = replay_note.first_hammer_velocity
            
            if replay_velocity is None or replay_velocity <= 0:
                continue
            
            # è·å–å»¶æ—¶
            keyon_offset = None
            if (lookup_record_idx, lookup_replay_idx) in offset_map:
                keyon_offset = offset_map[(lookup_record_idx, lookup_replay_idx)].get('keyon_offset', 0)
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥è®¡ç®—
                try:
                    record_keyon, _ = self.analyzer.note_matcher._calculate_note_times(record_note)
                    replay_keyon, _ = self.analyzer.note_matcher._calculate_note_times(replay_note)
                    keyon_offset = replay_keyon - record_keyon
                except:
                    continue
            
            if keyon_offset is not None:
                # è½¬æ¢ä¸ºmså•ä½ï¼ˆå¸¦ç¬¦å·ï¼‰
                delay_ms = keyon_offset / 10.0
                result.append((key_id, float(replay_velocity), delay_ms, record_uuid, replay_uuid))
        
        return result
    
    def _generate_interaction_plot_data(self, key_ids: List[int], replay_velocities: List[float], 
                                       delays: List[float], record_indices: List[int] = None,
                                       replay_indices: List[int] = None) -> Dict[str, Any]:
        """
        ç”ŸæˆæŒ‰é”®-åŠ›åº¦äº¤äº’æ•ˆåº”å›¾æ•°æ®ï¼ˆä½¿ç”¨ç›¸å¯¹å»¶æ—¶ï¼‰

        æ¨ªè½´ï¼šlogâ‚â‚€(æ’­æ”¾é”¤é€Ÿ)ï¼ˆç”¨äºåˆ†æï¼‰
        çºµè½´ï¼šç›¸å¯¹å»¶æ—¶ï¼ˆå»¶æ—¶ - å¹³å‡å»¶æ—¶ï¼‰
        
        Args:
            key_ids: æŒ‰é”®IDåˆ—è¡¨
            replay_velocities: æ’­æ”¾é”¤é€Ÿåˆ—è¡¨
            delays: å»¶æ—¶åˆ—è¡¨ï¼ˆå•ä½ï¼šmsï¼‰
            record_indices: å½•åˆ¶éŸ³ç¬¦ç´¢å¼•åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            replay_indices: å›æ”¾éŸ³ç¬¦ç´¢å¼•åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Dict[str, Any]: äº¤äº’æ•ˆåº”å›¾æ•°æ®ï¼ŒåŒ…å«æ¯ä¸ªæŒ‰é”®çš„æ•°æ®
        """
        try:
            from collections import defaultdict

            # ä½¿ç”¨é¢„è®¡ç®—çš„æ•´ä½“å¹³å‡å»¶æ—¶ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
            if hasattr(self, 'analyzer') and self.analyzer and hasattr(self.analyzer, 'get_mean_error'):
                mean_delay_0_1ms = self.analyzer.get_mean_error()
                mean_delay = mean_delay_0_1ms / 10.0  # è½¬æ¢ä¸ºæ¯«ç§’
            else:
                # å¤‡ç”¨è®¡ç®—ï¼ˆå¦‚æœé¢„è®¡ç®—ä¸å¯ç”¨ï¼‰
                mean_delay = np.mean(delays) if delays else 0
            logger.info(f"ğŸ“Š æ•´ä½“å¹³å‡å»¶æ—¶: {mean_delay:.2f}ms")
            
            # è®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼ˆå»¶æ—¶ - å¹³å‡å»¶æ—¶ï¼‰
            relative_delays = [delay - mean_delay for delay in delays]
            
            # æŒ‰æŒ‰é”®åˆ†ç»„
            key_groups = defaultdict(lambda: {'forces': [], 'delays': [], 'absolute_delays': [],
                                               'record_indices': [], 'replay_indices': []})
            for i, (key_id, replay_vel, rel_delay, abs_delay) in enumerate(zip(key_ids, replay_velocities, relative_delays, delays)):
                # 'forces'å­˜å‚¨æ’­æ”¾é”¤é€Ÿ
                # 'delays'å­˜å‚¨ç›¸å¯¹å»¶æ—¶
                # 'absolute_delays'å­˜å‚¨åŸå§‹å»¶æ—¶
                key_groups[key_id]['forces'].append(replay_vel)
                key_groups[key_id]['delays'].append(rel_delay)
                key_groups[key_id]['absolute_delays'].append(abs_delay)
                if record_indices and i < len(record_indices):
                    key_groups[key_id]['record_indices'].append(record_indices[i])
                if replay_indices and i < len(replay_indices):
                    key_groups[key_id]['replay_indices'].append(replay_indices[i])
            
            interaction_data = {}
            
            for key_id in sorted(key_groups.keys()):
                replay_vels_key = key_groups[key_id]['forces']
                relative_delays_key = key_groups[key_id]['delays']  # ç›¸å¯¹å»¶æ—¶
                absolute_delays_key = key_groups[key_id]['absolute_delays']  # åŸå§‹å»¶æ—¶
                record_indices_key = key_groups[key_id].get('record_indices', [])
                replay_indices_key = key_groups[key_id].get('replay_indices', [])
                
                if len(replay_vels_key) < 1:
                    continue
                
                # åˆå§‹åŒ–å›å½’æ•°æ®ä¸ºé»˜è®¤å€¼
                slope = 0.0
                intercept = 0.0
                r_value = 0.0
                p_value = 1.0 # Default to 1.0 if no regression
                
                interaction_data[key_id] = {
                    'forces': replay_vels_key,
                    'delays': relative_delays_key,  # ç›¸å¯¹å»¶æ—¶
                    'absolute_delays': absolute_delays_key,  # åŸå§‹å»¶æ—¶
                    'record_indices': record_indices_key,
                    'replay_indices': replay_indices_key,
                    'mean_delay': float(mean_delay),  # æ•´ä½“å¹³å‡å»¶æ—¶
                    'regression_line': {
                        'force': [],
                        'delay': [],
                        'slope': float(slope),
                        'intercept': float(intercept),
                        'r_value': float(r_value)
                    },
                    'r_squared': float(r_value ** 2), # Calculate r_squared from r_value
                    'p_value': float(p_value),
                    'sample_count': len(replay_vels_key)
                }
            
            return {
                'key_data': interaction_data,
                'mean_delay': float(mean_delay),
                'message': f'ç”Ÿæˆ {len(interaction_data)} ä¸ªæŒ‰é”®çš„äº¤äº’æ•ˆåº”å›¾æ•°æ®ï¼ˆä½¿ç”¨ç›¸å¯¹å»¶æ—¶ï¼‰'
            }
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆäº¤äº’æ•ˆåº”å›¾æ•°æ®å¤±è´¥: {e}")
            return {
                'key_data': {},
                'message': f'ç”Ÿæˆäº¤äº’æ•ˆåº”å›¾æ•°æ®å¤±è´¥: {str(e)}'
            }
    
    def _create_empty_interaction_result(self, message: str) -> Dict[str, Any]:
        """åˆ›å»ºç©ºçš„äº¤äº’æ•ˆåº”åˆ†æç»“æœ"""
        return {
            'status': 'error',
            'message': message,
            'interaction_plot_data': {}
        }