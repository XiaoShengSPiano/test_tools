#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é‡æ„åçš„é’¢ç´åˆ†æåç«¯API
ä½¿ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œå°†åŸæ¥çš„å¤§ç±»æ‹†åˆ†ä¸ºå¤šä¸ªä¸“é—¨çš„æ¨¡å—
"""

import os
import tempfile
import pandas as pd
import numpy as np
from typing import Optional, Tuple, Dict, Any, List
from utils.logger import Logger

# SPMIDç›¸å…³å¯¼å…¥
from spmid.spmid_analyzer import SPMIDAnalyzer

# å¯¼å…¥å„ä¸ªæ¨¡å—
from .data_manager import DataManager
from .plot_generator import PlotGenerator
from .data_filter import DataFilter
from .time_filter import TimeFilter
from .table_data_generator import TableDataGenerator
from .history_manager import HistoryManager

logger = Logger.get_logger()


class PianoAnalysisBackend:

    def __init__(self, session_id=None, history_manager=None):
        """
        åˆå§‹åŒ–é’¢ç´åˆ†æåç«¯
        
        Args:
            session_id: ä¼šè¯IDï¼Œç”¨äºæ ‡è¯†ä¸åŒçš„åˆ†æä¼šè¯
            history_manager: å…¨å±€å†å²ç®¡ç†å™¨å®ä¾‹
        """
        self.session_id = session_id
        
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        self.data_manager = DataManager()
        self.data_filter = DataFilter()
        self.plot_generator = PlotGenerator(self.data_filter)
        self.time_filter = TimeFilter()
        self.table_generator = TableDataGenerator()
        
        # ä½¿ç”¨å…¨å±€çš„å†å²ç®¡ç†å™¨å®ä¾‹
        self.history_manager = history_manager
        
        # åˆå§‹åŒ–åˆ†æå™¨å®ä¾‹
        self.analyzer = SPMIDAnalyzer()
        
        
        logger.info(f"âœ… PianoAnalysisBackendåˆå§‹åŒ–å®Œæˆ (Session: {session_id})")

    
    # ==================== æ•°æ®ç®¡ç†ç›¸å…³æ–¹æ³• ====================
    
    def clear_data_state(self) -> None:
        """æ¸…ç†æ‰€æœ‰æ•°æ®çŠ¶æ€"""
        self.data_manager.clear_data_state()
        self.plot_generator.set_data()
        self.data_filter.set_data(None, None)
        self.table_generator.set_data()
        self.analyzer = None
        logger.info("âœ… æ‰€æœ‰æ•°æ®çŠ¶æ€å·²æ¸…ç†")
    
    def set_upload_data_source(self, filename: str) -> None:
        """è®¾ç½®ä¸Šä¼ æ•°æ®æºä¿¡æ¯"""
        self.data_manager.set_upload_data_source(filename)
    
    def set_history_data_source(self, history_id: str, filename: str) -> None:
        """è®¾ç½®å†å²æ•°æ®æºä¿¡æ¯"""
        self.data_manager.set_history_data_source(history_id, filename)
    
    def get_data_source_info(self) -> Dict[str, Any]:
        """è·å–æ•°æ®æºä¿¡æ¯"""
        return self.data_manager.get_data_source_info()
    
    def process_file_upload(self, contents, filename):
        """
        å¤„ç†æ–‡ä»¶ä¸Šä¼  - ç»Ÿä¸€çš„æ–‡ä»¶ä¸Šä¼ å…¥å£
        
        Args:
            contents: ä¸Šä¼ æ–‡ä»¶çš„å†…å®¹ï¼ˆbase64ç¼–ç ï¼‰
            filename: ä¸Šä¼ æ–‡ä»¶çš„æ–‡ä»¶å
            
        Returns:
            tuple: (info_content, error_content, error_msg)
        """
        return self.data_manager.process_file_upload(contents, filename, self.history_manager)
    
    def process_history_selection(self, history_id):
        """
        å¤„ç†å†å²è®°å½•é€‰æ‹© - ç»Ÿä¸€çš„å†å²è®°å½•å…¥å£
        
        Args:
            history_id: å†å²è®°å½•ID
            
        Returns:
            tuple: (success, result_data, error_msg)
        """
        return self.history_manager.process_history_selection(history_id, self)
    
    def load_spmid_data(self, spmid_bytes: bytes) -> bool:
        """
        åŠ è½½SPMIDæ•°æ®
        
        Args:
            spmid_bytes: SPMIDæ–‡ä»¶å­—èŠ‚æ•°æ®
            
        Returns:
            bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            # ä½¿ç”¨æ•°æ®ç®¡ç†å™¨åŠ è½½æ•°æ®
            success = self.data_manager.load_spmid_data(spmid_bytes)
            
            if success:
                # åŒæ­¥æ•°æ®åˆ°å„ä¸ªæ¨¡å—
                self._sync_data_to_modules()
                logger.info("âœ… SPMIDæ•°æ®åŠ è½½æˆåŠŸ")
            else:
                logger.error("âŒ SPMIDæ•°æ®åŠ è½½å¤±è´¥")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ SPMIDæ•°æ®åŠ è½½å¼‚å¸¸: {e}")
            return False
            
    def _sync_data_to_modules(self) -> None:
        """åŒæ­¥æ•°æ®åˆ°å„ä¸ªæ¨¡å—"""
        # è·å–æ•°æ®
        record_data = self.data_manager.get_record_data()
        replay_data = self.data_manager.get_replay_data()
        valid_record_data = self.data_manager.get_valid_record_data()
        valid_replay_data = self.data_manager.get_valid_replay_data()
        
        # åŒæ­¥åˆ°å„ä¸ªæ¨¡å—
        self.plot_generator.set_data(valid_record_data, valid_replay_data, analyzer=self.analyzer)
        self.data_filter.set_data(valid_record_data, valid_replay_data)
        self.time_filter.set_data(valid_record_data, valid_replay_data)
        
        # å¦‚æœæœ‰åˆ†æå™¨ï¼ŒåŒæ­¥åˆ†æç»“æœ
        if self.analyzer:
            self._sync_analysis_results()
    
    def _sync_analysis_results(self) -> None:
        """åŒæ­¥åˆ†æç»“æœåˆ°å„ä¸ªæ¨¡å—"""
        if not self.analyzer:
            return
        
        try:
            # è·å–åˆ†æç»“æœ
            multi_hammers = getattr(self.analyzer, 'multi_hammers', [])
            drop_hammers = getattr(self.analyzer, 'drop_hammers', [])
            silent_hammers = getattr(self.analyzer, 'silent_hammers', [])
            invalid_notes_table_data = getattr(self.analyzer, 'invalid_notes_table_data', {})
            matched_pairs = getattr(self.analyzer, 'matched_pairs', [])
            
            # åˆå¹¶æ‰€æœ‰é”™è¯¯éŸ³ç¬¦
            all_error_notes = multi_hammers + drop_hammers + silent_hammers
            
            # è®¾ç½®all_error_noteså±æ€§ä¾›UIå±‚ä½¿ç”¨
            self.all_error_notes = all_error_notes
            
            # åŒæ­¥åˆ°å„ä¸ªæ¨¡å—
            valid_record_data = getattr(self.analyzer, 'valid_record_data', [])
            valid_replay_data = getattr(self.analyzer, 'valid_replay_data', [])
            self.data_filter.set_data(valid_record_data, valid_replay_data)
            
            # è·å–æœ‰æ•ˆæ•°æ®
            valid_record_data = self.data_manager.get_valid_record_data()
            valid_replay_data = self.data_manager.get_valid_replay_data()
            
            self.plot_generator.set_data(valid_record_data, valid_replay_data, matched_pairs, analyzer=self.analyzer)
            
            # åŒæ­¥åˆ°TimeFilter
            self.time_filter.set_data(valid_record_data, valid_replay_data)
            
            self.table_generator.set_data(
                valid_record_data=valid_record_data,
                valid_replay_data=valid_replay_data,
                multi_hammers=multi_hammers,
                drop_hammers=drop_hammers,
                silent_hammers=silent_hammers,
                all_error_notes=all_error_notes,
                invalid_notes_table_data=invalid_notes_table_data,
                matched_pairs=matched_pairs,
                analyzer=self.analyzer
            )
            
            logger.info("âœ… åˆ†æç»“æœåŒæ­¥å®Œæˆ")

        except Exception as e:
            logger.error(f"åŒæ­¥åˆ†æç»“æœå¤±è´¥: {e}")
    
    # ==================== æ—¶é—´å¯¹é½åˆ†æç›¸å…³æ–¹æ³• ====================
    
    # def spmid_offset_alignment(self) -> Tuple[pd.DataFrame, np.ndarray]:
    #     """æ‰§è¡ŒSPMIDåç§»é‡å¯¹é½åˆ†æ"""
    #     if not self.analyzer:
    #         logger.error("æ²¡æœ‰å¯ç”¨çš„åˆ†æå™¨å®ä¾‹")
    #         return pd.DataFrame(), np.array([])
        
    #     # ä»åˆ†æå™¨è·å–åç§»ç»Ÿè®¡ä¿¡æ¯
    #     offset_stats = self.analyzer.get_offset_statistics()
        
    #     # åˆ›å»ºDataFrame
    #     df_stats = pd.DataFrame([{
    #         'total_pairs': offset_stats.get('total_pairs', 0),
    #         'keyon_avg_offset': offset_stats.get('keyon_offset_stats', {}).get('average', 0.0),
    #         'keyon_max_offset': offset_stats.get('keyon_offset_stats', {}).get('max', 0.0),
    #         'keyon_min_offset': offset_stats.get('keyon_offset_stats', {}).get('min', 0.0),
    #         'keyon_std_offset': offset_stats.get('keyon_offset_stats', {}).get('std', 0.0),
    #         'keyoff_avg_offset': offset_stats.get('keyoff_offset_stats', {}).get('average', 0.0),
    #         'keyoff_max_offset': offset_stats.get('keyoff_offset_stats', {}).get('max', 0.0),
    #         'keyoff_min_offset': offset_stats.get('keyoff_offset_stats', {}).get('min', 0.0),
    #         'keyoff_std_offset': offset_stats.get('keyoff_offset_stats', {}).get('std', 0.0)
    #     }])
        
    #     # åˆ›å»ºåç§»æ•°ç»„
    #     offset_data = self.analyzer.get_offset_alignment_data()
    #     all_offsets_array = np.array([item['average_offset'] for item in offset_data])
        
    #     return df_stats, all_offsets_array
    
    # TODO
    def get_global_average_delay(self) -> float:
        """
        è·å–æ•´é¦–æ›²å­çš„å¹³å‡æ—¶å»¶ï¼ˆåŸºäºå·²é…å¯¹æ•°æ®ï¼‰
        
        Returns:
            float: å¹³å‡æ—¶å»¶ï¼ˆ0.1mså•ä½ï¼‰
        """
        if not self.analyzer:
            return 0.0
        
        # ä¿æŒå†…éƒ¨å•ä½ä¸º0.1msï¼Œç”±UIå±‚è´Ÿè´£æ˜¾ç¤ºæ—¶æ¢ç®—ä¸ºms
        average_delay_0_1ms = self.analyzer.get_global_average_delay()
        return average_delay_0_1ms
    
    def get_offset_alignment_data(self) -> List[Dict[str, Any]]:
        """è·å–åç§»å¯¹é½æ•°æ® - è½¬æ¢ä¸ºDataTableæ ¼å¼ï¼ŒåŒ…å«æ— æ•ˆéŸ³ç¬¦åˆ†æ"""
        
        try:
            # ä»åˆ†æå™¨è·å–åç§»æ•°æ®
            offset_data = self.analyzer.get_offset_alignment_data()
            invalid_offset_data = self.analyzer.get_invalid_notes_offset_analysis()
            
            # æŒ‰æŒ‰é”®IDåˆ†ç»„å¹¶è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            from collections import defaultdict
            import numpy as np
            
            # æŒ‰æŒ‰é”®IDåˆ†ç»„æœ‰æ•ˆåŒ¹é…çš„åç§»æ•°æ®ï¼ˆåªä½¿ç”¨keyon_offsetï¼‰
            key_groups = defaultdict(list)
            for item in offset_data:
                key_id = item.get('key_id', 'N/A')
                keyon_offset_abs = abs(item.get('keyon_offset', 0))  # åªä½¿ç”¨keyon_offset
                key_groups[key_id].append(keyon_offset_abs)
            
            # æŒ‰æŒ‰é”®IDåˆ†ç»„æ— æ•ˆéŸ³ç¬¦æ•°æ®
            invalid_key_groups = defaultdict(list)
            for item in invalid_offset_data:
                key_id = item.get('key_id', 'N/A')
                invalid_key_groups[key_id].append(item)
            
            # è½¬æ¢ä¸ºDataTableæ ¼å¼
            table_data = []
            
            # å¤„ç†æœ‰æ•ˆåŒ¹é…çš„æŒ‰é”®
            for key_id, offsets in key_groups.items():
                if offsets:
                    median_val = np.median(offsets)
                    mean_val = np.mean(offsets)
                    std_val = np.std(offsets)
                    
                table_data.append({
                        'key_id': key_id,
                        'count': len(offsets),
                        'median': f"{median_val/10:.2f}ms",
                        'mean': f"{mean_val/10:.2f}ms",
                        'std': f"{std_val/10:.2f}ms",
                        'status': 'matched'
                    })
            
            # å¤„ç†æ— æ•ˆéŸ³ç¬¦çš„æŒ‰é”®
            for key_id, invalid_items in invalid_key_groups.items():
                if key_id not in key_groups:  # åªå¤„ç†æ²¡æœ‰æœ‰æ•ˆåŒ¹é…çš„æŒ‰é”®
                    record_count = sum(1 for item in invalid_items if item.get('data_type') == 'record')
                    replay_count = sum(1 for item in invalid_items if item.get('data_type') == 'replay')
                    
                    table_data.append({
                        'key_id': key_id,
                        'count': len(invalid_items),
                        'median': "N/A",
                        'mean': "N/A",
                        'std': "N/A",
                        'status': f'invalid (R:{record_count}, P:{replay_count})'
                    })
            
            if not table_data:
                return [{
                    'key_id': "æ— æ•°æ®",
                    'count': 0,
                    'median': "N/A",
                    'mean': "N/A",
                    'std': "N/A",
                    'status': 'no_data'
                }]
            
            return table_data
            
        except Exception as e:
            logger.error(f"è·å–åç§»å¯¹é½æ•°æ®å¤±è´¥: {e}")
            return [{
                'key_id': "é”™è¯¯",
                'count': 0,
                'median': "N/A",
                'mean': "N/A",
                'std': "N/A",
                'status': 'error'
            }]
    
    
    def generate_offset_alignment_plot(self) -> Any:
        """ç”Ÿæˆåç§»å¯¹é½åˆ†ææŸ±çŠ¶å›¾ - é”®ä½ä¸ºæ¨ªåæ ‡ï¼Œä¸­ä½æ•°ã€å‡å€¼ã€æ ‡å‡†å·®ä¸ºçºµåæ ‡ï¼Œåˆ†3ä¸ªå­å›¾æ˜¾ç¤º"""
        
        try:
            # è·å–åç§»å¯¹é½åˆ†ææ•°æ®
            alignment_data = self.get_offset_alignment_data()
            
            if not alignment_data:
                logger.warning("âš ï¸ æ²¡æœ‰åç§»å¯¹é½åˆ†ææ•°æ®ï¼Œæ— æ³•ç”ŸæˆæŸ±çŠ¶å›¾")
                return self.plot_generator._create_empty_plot("æ²¡æœ‰åç§»å¯¹é½åˆ†ææ•°æ®")
            
            # æå–æ•°æ®ç”¨äºç»˜å›¾
            key_ids = []
            median_values = []
            mean_values = []
            std_values = []
            status_list = []
            
            for item in alignment_data:
                key_id = item['key_id']
                # ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å€¼ï¼Œå»é™¤å•ä½
                median_str = item['median'].replace('ms', '') if isinstance(item['median'], str) else str(item['median'])
                mean_str = item['mean'].replace('ms', '') if isinstance(item['mean'], str) else str(item['mean'])
                std_str = item['std'].replace('ms', '') if isinstance(item['std'], str) else str(item['std'])
                status = item['status']
                
                try:
                    # è·³è¿‡æ— æ•ˆçš„key_id
                    if key_id == 'æ— æ•°æ®' or key_id == 'é”™è¯¯' or not str(key_id).isdigit():
                        continue
                    
                    key_ids.append(int(key_id))
                    median_values.append(float(median_str))
                    mean_values.append(float(mean_str))
                    std_values.append(float(std_str))
                    status_list.append(status)
                except (ValueError, TypeError) as e:
                    logger.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆæ•°æ®: {e}")
                    continue
            
            if not key_ids:
                logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„åç§»å¯¹é½æ•°æ®ï¼Œæ— æ³•ç”ŸæˆæŸ±çŠ¶å›¾")
                return self.plot_generator._create_empty_plot("æ²¡æœ‰æœ‰æ•ˆçš„åç§»å¯¹é½æ•°æ®")
            
            # åˆ›å»ºPlotlyå›¾è¡¨ - 3ä¸ªå­å›¾åˆ†åˆ«æ˜¾ç¤ºæŸ±çŠ¶å›¾
            import plotly.graph_objects as go
            from plotly.subplots import make_subplots
            
            fig = make_subplots(
                rows=3, cols=1,
                subplot_titles=('ä¸­ä½æ•°åç§»', 'å‡å€¼åç§»', 'æ ‡å‡†å·®'),
                vertical_spacing=0.08,
                row_heights=[0.33, 0.33, 0.34]
            )
            
            # æ ¹æ®çŠ¶æ€è®¾ç½®ä¸åŒçš„é¢œè‰²
            matched_indices = [i for i, status in enumerate(status_list) if status == 'matched']
            unmatched_indices = [i for i, status in enumerate(status_list) if status == 'unmatched']
            
            # æ·»åŠ åŒ¹é…æ•°æ®çš„ä¸­ä½æ•°æŸ±çŠ¶å›¾
            if matched_indices:
                matched_key_ids = [key_ids[i] for i in matched_indices]
                matched_median = [median_values[i] for i in matched_indices]
                matched_mean = [mean_values[i] for i in matched_indices]
                matched_std = [std_values[i] for i in matched_indices]
                
                fig.add_trace(
                    go.Bar(
                        x=matched_key_ids,
                        y=matched_median,
                        name='åŒ¹é…-ä¸­ä½æ•°',
                        marker_color='#1f77b4',
                        opacity=0.8,
                        width=1.0,
                        text=[f'{val:.2f}' for val in matched_median],
                        textposition='outside',
                        textfont=dict(size=20),
                        hovertemplate='é”®ä½: %{x}<br>ä¸­ä½æ•°: %{y:.2f}ms<br>çŠ¶æ€: åŒ¹é…<extra></extra>',
                        showlegend=False
                    ),
                    row=1, col=1
                )
                
                fig.add_trace(
                    go.Bar(
                        x=matched_key_ids,
                        y=matched_mean,
                        name='åŒ¹é…-å‡å€¼',
                        marker_color='#ff7f0e',
                        opacity=0.8,
                        width=1.0,
                        text=[f'{val:.2f}' for val in matched_mean],
                        textposition='outside',
                        textfont=dict(size=20),
                        hovertemplate='é”®ä½: %{x}<br>å‡å€¼: %{y:.2f}ms<br>çŠ¶æ€: åŒ¹é…<extra></extra>',
                        showlegend=False
                    ),
                    row=2, col=1
                )
                
                fig.add_trace(
                    go.Bar(
                        x=matched_key_ids,
                        y=matched_std,
                        name='åŒ¹é…-æ ‡å‡†å·®',
                        marker_color='#2ca02c',
                        opacity=0.8,
                        width=1.0,
                        text=[f'{val:.2f}' for val in matched_std],
                        textposition='outside',
                        textfont=dict(size=20),
                        hovertemplate='é”®ä½: %{x}<br>æ ‡å‡†å·®: %{y:.2f}ms<br>çŠ¶æ€: åŒ¹é…<extra></extra>',
                        showlegend=False
                    ),
                    row=3, col=1
                )
            
            # æ·»åŠ æœªåŒ¹é…æ•°æ®çš„ä¸­ä½æ•°æŸ±çŠ¶å›¾
            if unmatched_indices:
                unmatched_key_ids = [key_ids[i] for i in unmatched_indices]
                unmatched_median = [median_values[i] for i in unmatched_indices]
                unmatched_mean = [mean_values[i] for i in unmatched_indices]
                unmatched_std = [std_values[i] for i in unmatched_indices]
                
                fig.add_trace(
                    go.Bar(
                        x=unmatched_key_ids,
                        y=unmatched_median,
                        name='æœªåŒ¹é…-ä¸­ä½æ•°',
                        marker_color='#d62728',
                        opacity=0.8,
                        width=1.0,
                        text=[f'{val:.2f}' for val in unmatched_median],
                        textposition='outside',
                        textfont=dict(size=20),
                        hovertemplate='é”®ä½: %{x}<br>ä¸­ä½æ•°: %{y:.2f}ms<br>çŠ¶æ€: æœªåŒ¹é…<extra></extra>',
                        showlegend=False
                    ),
                    row=1, col=1
                )
                
                fig.add_trace(
                    go.Bar(
                        x=unmatched_key_ids,
                        y=unmatched_mean,
                        name='æœªåŒ¹é…-å‡å€¼',
                        marker_color='#9467bd',
                        opacity=0.8,
                        width=1.0,
                        text=[f'{val:.2f}' for val in unmatched_mean],
                        textposition='outside',
                        textfont=dict(size=20),
                        hovertemplate='é”®ä½: %{x}<br>å‡å€¼: %{y:.2f}ms<br>çŠ¶æ€: æœªåŒ¹é…<extra></extra>',
                        showlegend=False
                    ),
                    row=2, col=1
                )
                
                fig.add_trace(
                    go.Bar(
                        x=unmatched_key_ids,
                        y=unmatched_std,
                        name='æœªåŒ¹é…-æ ‡å‡†å·®',
                        marker_color='#8c564b',
                        opacity=0.8,
                        width=1.0,
                        text=[f'{val:.2f}' for val in unmatched_std],
                        textposition='outside',
                        textfont=dict(size=20),
                        hovertemplate='é”®ä½: %{x}<br>æ ‡å‡†å·®: %{y:.2f}ms<br>çŠ¶æ€: æœªåŒ¹é…<extra></extra>',
                        showlegend=False
                    ),
                    row=3, col=1
                )
            
            # æ›´æ–°å¸ƒå±€
            fig.update_layout(
                title={
                    'text': 'åç§»å¯¹é½åˆ†ææŸ±çŠ¶å›¾',
                    'x': 0.5,
                    'xanchor': 'center',
                    'font': {'size': 28}
                },
                height=1200,
                showlegend=False,
                margin=dict(l=100, r=100, t=150, b=120)
            )
            
            # æ›´æ–°åæ ‡è½´
            fig.update_xaxes(title_text="é”®ä½ID", row=3, col=1)
            fig.update_yaxes(title_text="ä¸­ä½æ•°åç§» (ms)", row=1, col=1)
            fig.update_yaxes(title_text="å‡å€¼åç§» (ms)", row=2, col=1)
            fig.update_yaxes(title_text="æ ‡å‡†å·® (ms)", row=3, col=1)
            
            logger.info(f"âœ… åç§»å¯¹é½åˆ†ææŸ±çŠ¶å›¾ç”ŸæˆæˆåŠŸï¼ŒåŒ…å« {len(key_ids)} ä¸ªé”®ä½ï¼ˆåŒ¹é…: {len(matched_indices)}, æœªåŒ¹é…: {len(unmatched_indices)}ï¼‰")
            return fig
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆåç§»å¯¹é½åˆ†ææŸ±çŠ¶å›¾å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return self.plot_generator._create_empty_plot(f"ç”ŸæˆæŸ±çŠ¶å›¾å¤±è´¥: {str(e)}")

    # ==================== ç»˜å›¾ç›¸å…³æ–¹æ³• ====================
    
    def generate_waterfall_plot(self) -> Any:
        """ç”Ÿæˆç€‘å¸ƒå›¾"""
        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†æç»“æœ
        if not self.analyzer:
            logger.error("åˆ†æå™¨ä¸å­˜åœ¨ï¼Œæ— æ³•ç”Ÿæˆç€‘å¸ƒå›¾")
            return self.plot_generator._create_empty_plot("åˆ†æå™¨ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
        has_valid_data = (hasattr(self.analyzer, 'valid_record_data') and self.analyzer.valid_record_data and
                         hasattr(self.analyzer, 'valid_replay_data') and self.analyzer.valid_replay_data)
        
        if not has_valid_data:
            logger.error("æ²¡æœ‰æœ‰æ•ˆçš„åˆ†ææ•°æ®ï¼Œæ— æ³•ç”Ÿæˆç€‘å¸ƒå›¾")
            return self.plot_generator._create_empty_plot("æ²¡æœ‰æœ‰æ•ˆçš„åˆ†ææ•°æ®")
        
        # ç¡®ä¿æ•°æ®å·²åŒæ­¥åˆ°PlotGenerator
        if not self.plot_generator.valid_record_data or not self.plot_generator.valid_replay_data:
            logger.info("ğŸ”„ åŒæ­¥æ•°æ®åˆ°PlotGenerator")
            self._sync_analysis_results()
        
        return self.plot_generator.generate_waterfall_plot(self.time_filter)
    
    def generate_watefall_conbine_plot(self, key_on: float, key_off: float, key_id: int) -> Tuple[Any, Any, Any]:
        """ç”Ÿæˆç€‘å¸ƒå›¾å¯¹æ¯”å›¾"""
        return self.plot_generator.generate_watefall_conbine_plot(key_on, key_off, key_id)
    
    def generate_watefall_conbine_plot_by_index(self, index: int, is_record: bool) -> Tuple[Any, Any, Any]:
        """æ ¹æ®ç´¢å¼•ç”Ÿæˆç€‘å¸ƒå›¾å¯¹æ¯”å›¾"""
        return self.plot_generator.generate_watefall_conbine_plot_by_index(index, is_record)
    
    def get_note_image_base64(self, global_index: int) -> str:
        """è·å–éŸ³ç¬¦å›¾åƒBase64ç¼–ç """
        return self.plot_generator.get_note_image_base64(global_index)
    
    # ==================== æ•°æ®è¿‡æ»¤ç›¸å…³æ–¹æ³• ====================
    
    def get_available_keys(self) -> List[int]:
        """è·å–å¯ç”¨æŒ‰é”®åˆ—è¡¨"""
        return self.data_filter.get_available_keys()
    
    def set_key_filter(self, key_ids: List[int]) -> None:
        """è®¾ç½®æŒ‰é”®è¿‡æ»¤"""
        self.data_filter.set_key_filter(key_ids)
    
    def get_key_filter_status(self) -> Dict[str, Any]:
        """è·å–æŒ‰é”®è¿‡æ»¤çŠ¶æ€"""
        return self.data_filter.get_key_filter_status()
    
    def set_time_filter(self, time_range: Optional[Tuple[float, float]]) -> None:
        """è®¾ç½®æ—¶é—´èŒƒå›´è¿‡æ»¤"""
        self.time_filter.set_time_filter(time_range)
    
    def get_time_filter_status(self) -> Dict[str, Any]:
        """è·å–æ—¶é—´è¿‡æ»¤çŠ¶æ€"""
        return self.time_filter.get_time_filter_status()
    
    def get_time_range(self) -> Tuple[float, float]:
        """è·å–æ—¶é—´èŒƒå›´ä¿¡æ¯"""
        return self.time_filter.get_time_range()
    
    def get_display_time_range(self) -> Tuple[float, float]:
        """è·å–æ˜¾ç¤ºæ—¶é—´èŒƒå›´"""
        return self.time_filter.get_display_time_range()
    
    def update_time_range_from_input(self, start_time: float, end_time: float) -> Tuple[bool, str]:
        """ä»è¾“å…¥æ›´æ–°æ—¶é—´èŒƒå›´"""
        success = self.time_filter.update_time_range_from_input(start_time, end_time)
        if success:
            return True, "æ—¶é—´èŒƒå›´æ›´æ–°æˆåŠŸ"
        else:
            return False, "æ—¶é—´èŒƒå›´æ›´æ–°å¤±è´¥"
    
    def get_time_range_info(self) -> Dict[str, Any]:
        """è·å–æ—¶é—´èŒƒå›´è¯¦ç»†ä¿¡æ¯"""
        return self.time_filter.get_time_range_info()
    
    def reset_display_time_range(self) -> None:
        """é‡ç½®æ˜¾ç¤ºæ—¶é—´èŒƒå›´"""
        self.time_filter.reset_display_time_range()
    
    def get_filtered_data(self) -> Dict[str, Any]:
        """è·å–è¿‡æ»¤åçš„æ•°æ®"""
        return self.data_filter.get_filtered_data()
    
    # ==================== è¡¨æ ¼æ•°æ®ç›¸å…³æ–¹æ³• ====================
    
    def get_summary_info(self) -> Dict[str, Any]:
        """è·å–æ‘˜è¦ä¿¡æ¯"""
        return self.table_generator.get_summary_info()
    
    def get_invalid_notes_table_data(self) -> Dict[str, Any]:
        """è·å–æ— æ•ˆéŸ³ç¬¦è¡¨æ ¼æ•°æ®"""
        return self.table_generator.get_invalid_notes_table_data()
    
    def get_error_table_data(self, error_type: str) -> List[Dict[str, Any]]:
        """è·å–é”™è¯¯è¡¨æ ¼æ•°æ®"""
        return self.table_generator.get_error_table_data(error_type)
    
    
    # ==================== å†…éƒ¨æ–¹æ³• ====================
    
    def _perform_error_analysis(self) -> None:
        """æ‰§è¡Œé”™è¯¯åˆ†æ"""
        try:
            # æ‰§è¡Œåˆ†æ
            record_data = self.data_manager.get_record_data()
            replay_data = self.data_manager.get_replay_data()
            
            if not record_data or not replay_data:
                logger.error("æ•°æ®ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œé”™è¯¯åˆ†æ")
                return
            
            analysis_result = self.analyzer.analyze(record_data, replay_data)
        
            # è§£åŒ…åˆ†æç»“æœ
            self.analyzer.multi_hammers, self.analyzer.drop_hammers, self.analyzer.silent_hammers, \
            self.analyzer.valid_record_data, self.analyzer.valid_replay_data, \
            self.analyzer.invalid_notes_table_data, self.analyzer.matched_pairs = analysis_result
            
            # åŒæ­¥æ•°æ®åˆ°æ•°æ®ç®¡ç†å™¨
            self.data_manager.set_analysis_results(
                self.analyzer.valid_record_data, 
                self.analyzer.valid_replay_data
            )
            
            # åŒæ­¥åˆ†æç»“æœåˆ°å„ä¸ªæ¨¡å—
            self._sync_analysis_results()
            
            logger.info("âœ… é”™è¯¯åˆ†æå®Œæˆ")

        except Exception as e:
            logger.error(f"é”™è¯¯åˆ†æå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
    
