#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ–‡ä»¶ä¸Šä¼ æœåŠ¡ - ç»Ÿä¸€çš„æ–‡ä»¶ä¸Šä¼ å¤„ç†é€»è¾‘

é‡æ„ç›®æ ‡ï¼š
- ç»Ÿä¸€æ–‡ä»¶ä¸Šä¼ å…¥å£
"""

import traceback
import asyncio
import base64
import time
import datetime
from backend.spmid_loader import SPMIDLoader
from typing import Tuple, Optional
from utils.logger import Logger


logger = Logger.get_logger()


class FileUploadService:
    """
    æ–‡ä»¶ä¸Šä¼ æœåŠ¡ - ç»Ÿä¸€å¤„ç†æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ é€»è¾‘
    
    æ ¸å¿ƒèŒè´£ï¼š
    1. æ–‡ä»¶å†…å®¹è§£ç å’ŒéªŒè¯
    2. ç®—æ³•åç§°éªŒè¯
    3. è°ƒç”¨ multi_algorithm_manager æ·»åŠ ç®—æ³•
    4. è‡ªåŠ¨æ¿€æ´»æ–°æ·»åŠ çš„ç®—æ³•
    """
    
    def __init__(self, multi_algorithm_manager, history_manager=None):
        """
        åˆå§‹åŒ–æ–‡ä»¶ä¸Šä¼ æœåŠ¡

        Args:
            multi_algorithm_manager: MultiAlgorithmManager å®ä¾‹
            history_manager: SQLiteHistoryManager å®ä¾‹ (V3)
        """
        self.multi_algorithm_manager = multi_algorithm_manager
        self.history_manager = history_manager
        logger.debug("[DEBUG] FileUploadService åˆå§‹åŒ–å®Œæˆ")
    
    async def add_file_as_algorithm(
        self,
        file_content_bytes: bytes,
        filename: str,
        algorithm_name: str,
        motor_type: str = "D3",
        algorithm_type: str = "PID",
        piano_type: str = "Grand",
        creation_time: Optional[int] = None
    ) -> Tuple[bool, str]:
        """
        å°†æ–‡ä»¶æ·»åŠ ä¸ºç®—æ³•ï¼ˆç»Ÿä¸€å…¥å£ï¼‰

        Args:
            file_content_bytes: æ–‡ä»¶å†…å®¹ï¼ˆäºŒè¿›åˆ¶æ•°æ®ï¼‰
            filename: æ–‡ä»¶å
            algorithm_name: ç”¨æˆ·æŒ‡å®šçš„ç®—æ³•åç§°
            motor_type: ç”µæœºç±»å‹
            algorithm_type: ç®—æ³•ç±»å‹
            piano_type: é’¢ç´å‹å·

        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
        """
        try:
            logger.debug(f"[DEBUG] å¼€å§‹å¤„ç†æ–‡ä»¶: {filename}, ç®—æ³•æ˜¾ç¤ºå: {algorithm_name}")
            logger.debug(f"[DEBUG] å…ƒæ•°æ®: ç”µæœº={motor_type}, ç®—æ³•={algorithm_type}, é’¢ç´={piano_type}")

            # éªŒè¯ç®—æ³•å
            is_valid, error_msg = self._validate_algorithm_name(algorithm_name)
            if not is_valid:
                logger.warning(f"ç®—æ³•åéªŒè¯å¤±è´¥: {error_msg}")
                return False, error_msg

            # éªŒè¯æ–‡ä»¶å†…å®¹
            if not file_content_bytes or len(file_content_bytes) == 0:
                error_msg = "æ–‡ä»¶å†…å®¹ä¸ºç©º"
                logger.error(error_msg)
                return False, error_msg

            # 1. è®¡ç®—æ–‡ä»¶ MD5
            import hashlib
            file_md5 = hashlib.md5(file_content_bytes).hexdigest()
            logger.debug(f"[DEBUG] æ–‡ä»¶ MD5: {file_md5}")

            # 2. æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å­˜åœ¨ (å¦‚æœæ˜¯æ–°ä¸Šä¼ ï¼Œæˆ‘ä»¬é€šå¸¸è¿˜æ˜¯é‡æ–°è§£æä»¥ç¡®ä¿æœ€æ–°ï¼Œæˆ–è€…ä»DBè¯»)
            # è¿™é‡Œæˆ‘ä»¬é€‰æ‹©è§£æ SPMID è·å¾— OptimizedNoteï¼Œç„¶åå­˜å…¥æ•°æ®åº“
            
            # åŠ è½½ SPMID æ•°æ®
            logger.debug("è§£æ SPMID æ–‡ä»¶...")
            
            # æˆ‘ä»¬éœ€è¦è·å–åŸå§‹çš„ OptimizedNote åˆ—è¡¨ä»¥ä¾¿å­˜å…¥ Parquet
            from spmid.spmid_reader import OptimizedSPMidReader
            reader = OptimizedSPMidReader(file_content_bytes)
            if reader.track_count < 2:
                return False, f"SPMID æ–‡ä»¶éŸ³è½¨ä¸è¶³: {reader.track_count}"
            
            # è·å–æ‰€æœ‰éŸ³è½¨ (List[List[OptimizedNote]])
            all_tracks = [reader.get_track(i) for i in range(reader.track_count)]
            
            # 3. ä¿å­˜åˆ°å†å²è®°å½• (å¦‚æœä¸å­˜åœ¨)
            if self.history_manager:
                # è·å–æ–‡ä»¶æœ€åä¿®æ”¹æ—¶é—´ (User Request: ä»…ä½¿ç”¨æ­¤æ—¶é—´)
                if creation_time:
                    try:
                        ts = creation_time / 1000.0 if creation_time > 2e11 else creation_time
                        file_date = datetime.datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S")
                    except Exception as e:
                        logger.warning(f"è§£ææ–‡ä»¶ä¿®æ”¹æ—¶é—´å¤±è´¥: {e}")
                        file_date = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                else:
                    file_date = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                
                logger.debug(f"ğŸ’¾ ä½¿ç”¨æ–‡ä»¶æ—¥æœŸ: {file_date}")
                
                # save_record ä¼šè‡ªåŠ¨å¤„ç†å»é‡å’Œ Parquet å­˜å‚¨
                record_id = self.history_manager.save_record(
                    filename=algorithm_name,
                    file_md5=file_md5,
                    motor_type=motor_type,
                    algorithm=algorithm_type,
                    piano_type=piano_type,
                    file_date=file_date,
                    track_data=all_tracks
                )
                if record_id:
                    logger.debug(f"âœ… è®°å½•å·²åŒæ­¥åˆ°æ•°æ®åº“: ID={record_id}")
                else:
                    logger.debug(f"â„¹ï¸ æ•°æ®åº“ä¸­å·²å­˜åœ¨ç›¸åŒæ–‡ä»¶ï¼Œè®°å½•å·²æ›´æ–°æˆ–è·³è¿‡")

            # 4. ç»§ç»­åŸæ¥çš„å†…å­˜åˆ†ææµç¨‹ (ä½¿ç”¨ SPMIDLoader å°† OptimizedNote è½¬æ¢ä¸º Note)
            loader = SPMIDLoader()
            # æ³¨æ„ï¼šSPMIDLoader.load_spmid_data å†…éƒ¨ä¼šé‡æ–°åˆ›å»º readerï¼Œè™½ç„¶æœ‰ç‚¹å†—ä½™ä½†ä¿è¯äº†å…¼å®¹æ€§é€»è¾‘ï¼ˆå¦‚è¿‡æ»¤ï¼‰
            load_success = loader.load_spmid_data(file_content_bytes)

            if not load_success:
                error_msg = "SPMID æ–‡ä»¶è§£æå¤±è´¥ï¼ˆåŠ è½½é˜¶æ®µï¼‰"
                logger.error(error_msg)
                return False, error_msg

            # è·å–æ•°æ®
            record_data = loader.get_record_data()
            replay_data = loader.get_replay_data()
            filter_collector = loader.get_filter_collector()

            if not record_data or not replay_data:
                error_msg = "SPMID æ•°æ®ä¸ºç©º"
                logger.error(error_msg)
                return False, error_msg

            logger.info(f"   éŸ³ç¬¦æ•°é‡: å½•åˆ¶={len(record_data)}, æ’­æ”¾={len(replay_data)}")

            # æ·»åŠ ç®—æ³•åˆ°ç®¡ç†å™¨
            success, result = await self.multi_algorithm_manager.add_algorithm_async(
                algorithm_name,
                filename,
                record_data,   # List[Note]
                replay_data,   # List[Note]
                filter_collector  # FilterCollector (åŒ…å«åŠ è½½é˜¶æ®µçš„è¿‡æ»¤ä¿¡æ¯)
            )

            if not success:
                logger.error(f"ç®—æ³•æ·»åŠ å¤±è´¥: {result}")
                return False, result

            # success=True æ—¶ï¼Œresult æ˜¯ unique_algorithm_name
            unique_algorithm_name = result

            # è‡ªåŠ¨æ¿€æ´»ç®—æ³•
            algorithm = self.multi_algorithm_manager.get_algorithm(unique_algorithm_name)
            if algorithm:
                algorithm.is_active = True
                logger.info(f"ç®—æ³• '{algorithm_name}' å·²è‡ªåŠ¨æ¿€æ´»")
            else:
                logger.warning(f"ç®—æ³• '{algorithm_name}' æ·»åŠ æˆåŠŸï¼Œä½†æ— æ³•æ¿€æ´»")

            return True, ""

        except Exception as e:
            error_msg = f"æ–‡ä»¶ä¸Šä¼ å¤„ç†å¼‚å¸¸: {str(e)}"
            logger.error(error_msg)
            logger.error(traceback.format_exc())
            return False, error_msg
    
    def _validate_algorithm_name(self, algorithm_name: str) -> Tuple[bool, str]:
        """
        éªŒè¯ç®—æ³•åç§°
        
        Args:
            algorithm_name: ç®—æ³•åç§°
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        if not algorithm_name or not algorithm_name.strip():
            return False, "ç®—æ³•åç§°ä¸èƒ½ä¸ºç©º"
        
        algorithm_name = algorithm_name.strip()
        
        # æ£€æŸ¥ç®—æ³•åæ˜¯å¦å·²å­˜åœ¨
        if self.multi_algorithm_manager:
            existing_algorithm = self.multi_algorithm_manager.get_algorithm(algorithm_name)
            if existing_algorithm:
                return False, f"ç®—æ³•åç§° '{algorithm_name}' å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨å…¶ä»–åç§°"
        
        return True, ""
    
    @staticmethod
    def decode_base64_file_content(file_content: str) -> Optional[bytes]:
        """
        è§£ç  base64 æ–‡ä»¶å†…å®¹ï¼ˆé™æ€æ–¹æ³•ï¼Œä¾›UIå±‚ä½¿ç”¨ï¼‰
        
        ç»Ÿä¸€å¤„ç† base64 è§£ç é€»è¾‘ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
        1. "data:application/octet-stream;base64,{base64_data}"
        2. "{base64_data}"
        
        Args:
            file_content: base64 ç¼–ç çš„æ–‡ä»¶å†…å®¹
            
        Returns:
            Optional[bytes]: è§£ç åçš„äºŒè¿›åˆ¶æ•°æ®ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            if not file_content:
                return None
            
            # å¤„ç† "data:mime;base64,data" æ ¼å¼
            if ',' in file_content:
                file_content = file_content.split(',', 1)[1]
            
            # è§£ç  base64
            decoded_bytes = base64.b64decode(file_content)
            
            logger.debug(f"[DEBUG] æ–‡ä»¶å†…å®¹è§£ç æˆåŠŸï¼Œå¤§å°: {len(decoded_bytes)} å­—èŠ‚")
            return decoded_bytes
            
        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶å†…å®¹è§£ç å¤±è´¥: {e}")
            return None
    
    def validate_file_upload(self, file_content: str, filename: str) -> Tuple[bool, str]:
        """
        éªŒè¯æ–‡ä»¶ä¸Šä¼ ï¼ˆç”¨äºUIå±‚çš„é¢„éªŒè¯ï¼‰
        
        Args:
            file_content: æ–‡ä»¶å†…å®¹
            filename: æ–‡ä»¶å
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        # éªŒè¯æ–‡ä»¶å
        if not filename or not filename.strip():
            return False, "æ–‡ä»¶åä¸èƒ½ä¸ºç©º"
        
        if not filename.lower().endswith('.spmid'):
            return False, "åªæ”¯æŒ .spmid æ–‡ä»¶"
        
        # éªŒè¯æ–‡ä»¶å†…å®¹
        if not file_content:
            return False, "æ–‡ä»¶å†…å®¹ä¸ºç©º"
        
        return True, ""

