#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç€‘å¸ƒå›¾ç”Ÿæˆå™¨æ¨¡å— - é‡æ„ç‰ˆæœ¬
è´Ÿè´£ç”ŸæˆåŒ…å«æ‰€æœ‰æ•°æ®ï¼ˆé…å¯¹æŒ‰é”®ã€ä¸¢é”¤ã€å¤šé”¤ï¼‰çš„ç€‘å¸ƒå›¾
ä¸¥æ ¼éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼Œå°†å¤§å‡½æ•°æ‹†åˆ†ä¸ºå¤šä¸ªå°å‡½æ•°
"""

from typing import Any, Dict, List, Optional, Tuple
from utils.logger import Logger
import plotly.graph_objects as go
import numpy as np

logger = Logger.get_logger()


class WaterfallPlotGenerator:
    """ç€‘å¸ƒå›¾ç”Ÿæˆå™¨ - è´Ÿè´£ç”ŸæˆåŒ…å«æ‰€æœ‰æ•°æ®çš„ç€‘å¸ƒå›¾"""

    def __init__(self):
        """åˆå§‹åŒ–ç€‘å¸ƒå›¾ç”Ÿæˆå™¨"""
        self._setup_color_scheme()

    def _setup_color_scheme(self) -> None:
        """è®¾ç½®é¢œè‰²æ–¹æ¡ˆ"""
        # é…å¯¹æŒ‰é”®çš„é¢œè‰²
        self.matched_color = 'rgba(70, 130, 180, 0.8)'  # é’¢è“è‰²
        # ä¸¢é”¤æŒ‰é”®çš„é¢œè‰²
        self.drop_hammer_color = 'rgba(220, 20, 60, 0.8)'  # æ·±çº¢è‰²
        # å¤šé”¤æŒ‰é”®çš„é¢œè‰²
        self.multi_hammer_color = 'rgba(255, 140, 0, 0.8)'  # æ·±æ©™è‰²

    def generate_comprehensive_waterfall_plot(self,
                                             analyzer,
                                             time_filter=None,
                                             key_filter=None) -> Any:
        """
        ç”ŸæˆåŒ…å«æ‰€æœ‰æ•°æ®çš„ç€‘å¸ƒå›¾ - åŒ…æ‹¬é…å¯¹æ•°æ®ã€ä¸¢é”¤å’Œå¤šé”¤æ•°æ®

        Args:
            analyzer: SPMIDAnalyzerå®ä¾‹ï¼ŒåŒ…å«note_matcherå’Œé”™è¯¯æ£€æµ‹ç»“æœ
            time_filter: æ—¶é—´è¿‡æ»¤å™¨
            key_filter: æŒ‰é”®è¿‡æ»¤å™¨

        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        try:
            # ä¿å­˜è¿‡æ»¤å™¨å‚æ•°ä¾›åç»­æ–¹æ³•ä½¿ç”¨
            self._key_filter = key_filter
            self._time_filter = time_filter

            # æ”¶é›†æ‰€æœ‰æ•°æ® - åŒ…æ‹¬é…å¯¹æ•°æ®ã€ä¸¢é”¤å’Œå¤šé”¤
            all_data = self._collect_all_comprehensive_data(analyzer, time_filter, key_filter)

            # ç”Ÿæˆå›¾è¡¨
            fig = self._create_waterfall_figure(all_data)

            logger.info("âœ… åŒ…å«æ‰€æœ‰æ•°æ®çš„ç€‘å¸ƒå›¾ç”ŸæˆæˆåŠŸ")
            return fig

        except Exception as e:
            logger.error(f"ç”ŸæˆåŒ…å«æ‰€æœ‰æ•°æ®çš„ç€‘å¸ƒå›¾å¤±è´¥: {e}")
            return self._create_error_figure(f"ç”Ÿæˆç€‘å¸ƒå›¾å¤±è´¥: {str(e)}")

    def _collect_all_waterfall_data(self,
                                   initial_valid_record_data: List,
                                   initial_valid_replay_data: List,
                                   matched_pairs: List,
                                   drop_hammers: List,
                                   multi_hammers: List,
                                   time_filter=None,
                                   key_filter=None) -> Dict[str, List]:
        """
        æ”¶é›†æ‰€æœ‰ç±»å‹çš„ç€‘å¸ƒå›¾æ•°æ®

        ç­–ç•¥ï¼šç›´æ¥ä½¿ç”¨matched_pairsä¸­çš„noteå¯¹è±¡ï¼Œä»¥åŠdrop_hammers/multi_hammersä¸­çš„ErrorNote
        è¿™æ˜¯æœ€ç®€å•å’Œæœ€ç›´æ¥çš„æ–¹æ³•ï¼Œä¸è¯„ä»·ç­‰çº§å¤„ç†é€»è¾‘ä¸€è‡´

        Args:
            initial_valid_record_data: åŸå§‹å½•åˆ¶æ•°æ®ï¼ˆç”¨äºè·å–ä¸¢é”¤å¤šé”¤çš„å®Œæ•´noteå¯¹è±¡ï¼‰
            initial_valid_replay_data: åŸå§‹æ’­æ”¾æ•°æ®ï¼ˆç”¨äºè·å–ä¸¢é”¤å¤šé”¤çš„å®Œæ•´noteå¯¹è±¡ï¼‰
            matched_pairs: é…å¯¹çš„æŒ‰é”®æ•°æ®
            drop_hammers: ä¸¢é”¤æŒ‰é”®æ•°æ®
            multi_hammers: å¤šé”¤æŒ‰é”®æ•°æ®
            time_filter: æ—¶é—´è¿‡æ»¤å™¨
            key_filter: æŒ‰é”®è¿‡æ»¤å™¨

        Returns:
            Dict[str, List]: åˆ†ç±»çš„æ•°æ®å­—å…¸
        """
        # ç›´æ¥åˆ†ç±»æ”¶é›†æ•°æ®
        classified_data = {
            'matched': [],
            'drop_hammers': [],
            'multi_hammers': []
        }

        # 1. å¤„ç†é…å¯¹æ•°æ® - ç›´æ¥ä½¿ç”¨matched_pairsä¸­çš„noteå¯¹è±¡
        if matched_pairs:
            for record_idx, replay_idx, record_note, replay_note in matched_pairs:
                # æ£€æŸ¥æ˜¯å¦ç¬¦åˆè¿‡æ»¤æ¡ä»¶
                if self._should_include_note(record_note, time_filter, key_filter):
                    bars = self._extract_note_bars(record_note, 'record')
                    for bar in bars:
                        bar['data_type'] = 'matched'
                        bar['source_index'] = record_idx
                        classified_data['matched'].append(bar)

                if self._should_include_note(replay_note, time_filter, key_filter):
                    bars = self._extract_note_bars(replay_note, 'replay')
                    for bar in bars:
                        bar['data_type'] = 'matched'
                        bar['source_index'] = replay_idx
                        classified_data['matched'].append(bar)

        # 2. å¤„ç†ä¸¢é”¤æ•°æ® - ä»åŸå§‹å½•åˆ¶æ•°æ®ä¸­è·å–noteå¯¹è±¡
        if drop_hammers:
            for error_note in drop_hammers:
                if hasattr(error_note, 'global_index') and error_note.global_index >= 0:
                    try:
                        note = initial_valid_record_data[error_note.global_index]
                        if self._should_include_note(note, time_filter, key_filter):
                            bars = self._extract_note_bars(note, 'record')
                            for bar in bars:
                                bar['data_type'] = 'drop_hammer'
                                bar['source_index'] = error_note.global_index
                                bar['error_reason'] = getattr(error_note, 'reason', '')
                                classified_data['drop_hammers'].append(bar)
                    except (IndexError, AttributeError):
                        logger.warning(f"å¤„ç†ä¸¢é”¤æ•°æ®å¤±è´¥ (ç´¢å¼•{error_note.global_index}): ä½¿ç”¨ErrorNoteä¿¡æ¯")
                        # å¦‚æœæ— æ³•ä»åŸå§‹æ•°æ®è·å–ï¼Œä½¿ç”¨ErrorNoteçš„åŸºæœ¬ä¿¡æ¯
                        if hasattr(error_note, 'infos') and error_note.infos:
                            note_info = error_note.infos[0]
                            bar = {
                                't_on': note_info.keyOn,
                                't_off': note_info.keyOff,
                                'key_id': note_info.keyId,
                                'value': 0.5,
                                'label': 'record',
                                'data_type': 'drop_hammer',
                                'source_index': error_note.global_index,
                                'error_reason': getattr(error_note, 'reason', '')
                            }
                            classified_data['drop_hammers'].append(bar)

        # 3. å¤„ç†å¤šé”¤æ•°æ® - ä»åŸå§‹æ’­æ”¾æ•°æ®ä¸­è·å–noteå¯¹è±¡
        if multi_hammers:
            for error_note in multi_hammers:
                if hasattr(error_note, 'global_index') and error_note.global_index >= 0:
                    try:
                        note = initial_valid_replay_data[error_note.global_index]
                        if self._should_include_note(note, time_filter, key_filter):
                            bars = self._extract_note_bars(note, 'replay')
                            for bar in bars:
                                bar['data_type'] = 'multi_hammer'
                                bar['source_index'] = error_note.global_index
                                bar['error_reason'] = getattr(error_note, 'reason', '')
                                classified_data['multi_hammers'].append(bar)
                    except (IndexError, AttributeError):
                        logger.warning(f"å¤„ç†å¤šé”¤æ•°æ®å¤±è´¥ (ç´¢å¼•{error_note.global_index}): ä½¿ç”¨ErrorNoteä¿¡æ¯")
                        # å¦‚æœæ— æ³•ä»åŸå§‹æ•°æ®è·å–ï¼Œä½¿ç”¨ErrorNoteçš„åŸºæœ¬ä¿¡æ¯
                        if hasattr(error_note, 'infos') and error_note.infos:
                            note_info = error_note.infos[0]
                            bar = {
                                't_on': note_info.keyOn,
                                't_off': note_info.keyOff,
                                'key_id': note_info.keyId,
                                'value': 0.5,
                                'label': 'replay',
                                'data_type': 'multi_hammer',
                                'source_index': error_note.global_index,
                                'error_reason': getattr(error_note, 'reason', '')
                            }
                            classified_data['multi_hammers'].append(bar)

        return classified_data

    def _collect_all_comprehensive_data(self, analyzer, time_filter=None, key_filter=None) -> Dict[str, List]:
        """
        æ”¶é›†æ‰€æœ‰ç€‘å¸ƒå›¾æ•°æ®ï¼šé…å¯¹æ•°æ® + ä¸¢é”¤ + å¤šé”¤

        Args:
            analyzer: SPMIDAnalyzerå®ä¾‹
            time_filter: æ—¶é—´è¿‡æ»¤å™¨
            key_filter: æŒ‰é”®è¿‡æ»¤å™¨

        Returns:
            Dict[str, List]: æŒ‰è¯„çº§åˆ†ç±»çš„æ•°æ®å­—å…¸
        """
        # åˆå§‹åŒ–è¯„çº§åˆ†ç±»æ•°æ®ç»“æ„
        graded_data = {
            'correct': [],    # ä¼˜ç§€: è¯¯å·® â‰¤ 20ms
            'minor': [],      # è‰¯å¥½: 20ms < è¯¯å·® â‰¤ 30ms
            'moderate': [],   # ä¸€èˆ¬: 30ms < è¯¯å·® â‰¤ 50ms
            'large': [],      # è¾ƒå·®: 50ms < è¯¯å·® â‰¤ 1000ms
            'severe': [],     # ä¸¥é‡: è¯¯å·® > 1000ms
            'major': []       # å¤±è´¥: æ— åŒ¹é…ï¼ˆä¸¢é”¤/å¤šé”¤ï¼‰
        }

        # è·å–åŸå§‹æ•°æ®ç”¨äºæå–ä¸¢é”¤å’Œå¤šé”¤çš„éŸ³ç¬¦å¯¹è±¡
        initial_valid_record_data = getattr(analyzer, 'initial_valid_record_data', [])
        initial_valid_replay_data = getattr(analyzer, 'initial_valid_replay_data', [])

        # 1. å¤„ç†é…å¯¹æ•°æ®ï¼ˆä»match_resultsï¼‰
        if hasattr(analyzer, 'note_matcher') and analyzer.note_matcher:
            note_matcher = analyzer.note_matcher
            if hasattr(note_matcher, 'match_results'):
                for result in note_matcher.match_results:
                    # è·å–å¯¹åº”çš„éŸ³ç¬¦å¯¹è±¡
                    try:
                        record_note = note_matcher._record_data[result.record_index]
                        replay_note = note_matcher._replay_data[result.replay_index]
                    except (IndexError, AttributeError):
                        logger.warning(f"âš ï¸ æ— æ³•è·å–éŸ³ç¬¦å¯¹è±¡: record_index={result.record_index}, replay_index={result.replay_index}")
                        continue

                    # æ£€æŸ¥æ˜¯å¦ç¬¦åˆè¿‡æ»¤æ¡ä»¶
                    if not (self._should_include_note(record_note, time_filter, key_filter) and
                            self._should_include_note(replay_note, time_filter, key_filter)):
                        continue

                    # æ ¹æ®åŒ¹é…ç»“æœè¿›è¡Œè¯„çº§åˆ†ç±»
                    if result.is_success:
                        # æˆåŠŸåŒ¹é…ï¼šæ ¹æ®è¯¯å·®èŒƒå›´è¯„çº§
                        if hasattr(result, 'offset_data') and result.offset_data:
                            error_abs = abs(result.offset_data.get('corrected_offset', 0))
                            error_ms = error_abs / 10.0  # è½¬æ¢ä¸ºms

                            if error_ms <= 20:
                                grade_key = 'correct'
                            elif error_ms <= 30:
                                grade_key = 'minor'
                            elif error_ms <= 50:
                                grade_key = 'moderate'
                            elif error_ms <= 1000:
                                grade_key = 'large'
                            else:
                                grade_key = 'severe'
                        else:
                            grade_key = 'moderate'  # é»˜è®¤ä¸€èˆ¬è¯„çº§

                        # æ·»åŠ å½•åˆ¶éŸ³ç¬¦çš„æ¡å½¢
                        record_bars = self._extract_note_bars(record_note, 'record')
                        for bar in record_bars:
                            bar['grade'] = grade_key
                            bar['error_ms'] = error_ms if 'error_ms' in locals() else 0
                            graded_data[grade_key].append(bar)

                        # æ·»åŠ æ’­æ”¾éŸ³ç¬¦çš„æ¡å½¢
                        replay_bars = self._extract_note_bars(replay_note, 'replay')
                        for bar in replay_bars:
                            bar['grade'] = grade_key
                            bar['error_ms'] = error_ms if 'error_ms' in locals() else 0
                            graded_data[grade_key].append(bar)

                    else:
                        # åŒ¹é…å¤±è´¥ï¼šå½’ä¸ºmajorè¯„çº§
                        # æ·»åŠ å½•åˆ¶éŸ³ç¬¦çš„æ¡å½¢ï¼ˆä¸¢é”¤æƒ…å†µï¼‰
                        record_bars = self._extract_note_bars(record_note, 'record')
                        for bar in record_bars:
                            bar['grade'] = 'major'
                            bar['error_ms'] = float('inf')
                            bar['match_status'] = 'failed'
                            graded_data['major'].append(bar)

                        # æ·»åŠ æ’­æ”¾éŸ³ç¬¦çš„æ¡å½¢ï¼ˆå¤šé”¤æƒ…å†µï¼‰
                        replay_bars = self._extract_note_bars(replay_note, 'replay')
                        for bar in replay_bars:
                            bar['grade'] = 'major'
                            bar['error_ms'] = float('inf')
                            bar['match_status'] = 'failed'
                            graded_data['major'].append(bar)

        # 2. å¤„ç†ä¸¢é”¤æ•°æ®
        drop_hammers = getattr(analyzer, 'drop_hammers', [])
        if drop_hammers:
            for error_note in drop_hammers:
                if hasattr(error_note, 'global_index') and error_note.global_index >= 0:
                    try:
                        note = initial_valid_record_data[error_note.global_index]
                        if self._should_include_note(note, time_filter, key_filter):
                            bars = self._extract_note_bars(note, 'record')
                            for bar in bars:
                                bar['grade'] = 'major'
                                bar['error_ms'] = float('inf')
                                bar['data_type'] = 'drop_hammer'
                                bar['source_index'] = error_note.global_index
                                bar['error_reason'] = getattr(error_note, 'reason', '')
                                graded_data['major'].append(bar)
                    except (IndexError, AttributeError):
                        logger.warning(f"å¤„ç†ä¸¢é”¤æ•°æ®å¤±è´¥ (ç´¢å¼•{error_note.global_index}): ä½¿ç”¨ErrorNoteä¿¡æ¯")
                        # å¦‚æœæ— æ³•ä»åŸå§‹æ•°æ®è·å–ï¼Œä½¿ç”¨ErrorNoteçš„åŸºæœ¬ä¿¡æ¯
                        if hasattr(error_note, 'infos') and error_note.infos:
                            note_info = error_note.infos[0]
                            bar = {
                                't_on': note_info.keyOn,
                                't_off': note_info.keyOff,
                                'key_id': note_info.keyId,
                                'value': 0.5,
                                'label': 'record',
                                'grade': 'major',
                                'error_ms': float('inf'),
                                'data_type': 'drop_hammer',
                                'source_index': error_note.global_index,
                                'error_reason': getattr(error_note, 'reason', '')
                            }
                            graded_data['major'].append(bar)

        # 3. å¤„ç†å¤šé”¤æ•°æ®
        multi_hammers = getattr(analyzer, 'multi_hammers', [])
        if multi_hammers:
            for error_note in multi_hammers:
                if hasattr(error_note, 'global_index') and error_note.global_index >= 0:
                    try:
                        note = initial_valid_replay_data[error_note.global_index]
                        if self._should_include_note(note, time_filter, key_filter):
                            bars = self._extract_note_bars(note, 'replay')
                            for bar in bars:
                                bar['grade'] = 'major'
                                bar['error_ms'] = float('inf')
                                bar['data_type'] = 'multi_hammer'
                                bar['source_index'] = error_note.global_index
                                bar['error_reason'] = getattr(error_note, 'reason', '')
                                graded_data['major'].append(bar)
                    except (IndexError, AttributeError):
                        logger.warning(f"å¤„ç†å¤šé”¤æ•°æ®å¤±è´¥ (ç´¢å¼•{error_note.global_index}): ä½¿ç”¨ErrorNoteä¿¡æ¯")
                        # å¦‚æœæ— æ³•ä»åŸå§‹æ•°æ®è·å–ï¼Œä½¿ç”¨ErrorNoteçš„åŸºæœ¬ä¿¡æ¯
                        if hasattr(error_note, 'infos') and error_note.infos:
                            note_info = error_note.infos[0]
                            bar = {
                                't_on': note_info.keyOn,
                                't_off': note_info.keyOff,
                                'key_id': note_info.keyId,
                                'value': 0.5,
                                'label': 'replay',
                                'grade': 'major',
                                'error_ms': float('inf'),
                                'data_type': 'multi_hammer',
                                'source_index': error_note.global_index,
                                'error_reason': getattr(error_note, 'reason', '')
                            }
                            graded_data['major'].append(bar)

        return graded_data

    def _collect_from_match_results(self, note_matcher, time_filter=None, key_filter=None) -> Dict[str, List]:
        """
        ç›´æ¥ä»note_matcher.match_resultsä¸­æ”¶é›†æ•°æ®ï¼Œå¹¶æŒ‰è¯„çº§åˆ†ç±»

        Args:
            note_matcher: éŸ³ç¬¦åŒ¹é…å™¨å®ä¾‹
            time_filter: æ—¶é—´è¿‡æ»¤å™¨
            key_filter: æŒ‰é”®è¿‡æ»¤å™¨

        Returns:
            Dict[str, List]: æŒ‰è¯„çº§åˆ†ç±»çš„æ•°æ®å­—å…¸
        """
        # åˆå§‹åŒ–è¯„çº§åˆ†ç±»æ•°æ®ç»“æ„
        graded_data = {
            'correct': [],    # ä¼˜ç§€: è¯¯å·® â‰¤ 20ms
            'minor': [],      # è‰¯å¥½: 20ms < è¯¯å·® â‰¤ 30ms
            'moderate': [],   # ä¸€èˆ¬: 30ms < è¯¯å·® â‰¤ 50ms
            'large': [],      # è¾ƒå·®: 50ms < è¯¯å·® â‰¤ 1000ms
            'severe': [],     # ä¸¥é‡: è¯¯å·® > 1000ms
            'major': []       # å¤±è´¥: æ— åŒ¹é…
        }

        if not note_matcher or not hasattr(note_matcher, 'match_results'):
            logger.warning("âš ï¸ note_matcheræˆ–match_resultsä¸å­˜åœ¨")
            return graded_data

        # éå†æ‰€æœ‰åŒ¹é…ç»“æœ
        for result in note_matcher.match_results:
            # è·å–å¯¹åº”çš„éŸ³ç¬¦å¯¹è±¡
            try:
                record_note = note_matcher._record_data[result.record_index]
                replay_note = note_matcher._replay_data[result.replay_index]
            except (IndexError, AttributeError):
                logger.warning(f"âš ï¸ æ— æ³•è·å–éŸ³ç¬¦å¯¹è±¡: record_index={result.record_index}, replay_index={result.replay_index}")
                continue

            # æ£€æŸ¥æ˜¯å¦ç¬¦åˆè¿‡æ»¤æ¡ä»¶
            if not (self._should_include_note(record_note, time_filter, key_filter) and
                    self._should_include_note(replay_note, time_filter, key_filter)):
                continue

            # æ ¹æ®åŒ¹é…ç»“æœè¿›è¡Œè¯„çº§åˆ†ç±»
            if result.is_success:
                # æˆåŠŸåŒ¹é…ï¼šæ ¹æ®è¯¯å·®èŒƒå›´è¯„çº§
                if hasattr(result, 'offset_data') and result.offset_data:
                    error_abs = abs(result.offset_data.get('corrected_offset', 0))
                    error_ms = error_abs / 10.0  # è½¬æ¢ä¸ºms

                    if error_ms <= 20:
                        grade_key = 'correct'
                    elif error_ms <= 30:
                        grade_key = 'minor'
                    elif error_ms <= 50:
                        grade_key = 'moderate'
                    elif error_ms <= 1000:
                        grade_key = 'large'
                    else:
                        grade_key = 'severe'
                else:
                    grade_key = 'moderate'  # é»˜è®¤ä¸€èˆ¬è¯„çº§

                # æ·»åŠ å½•åˆ¶éŸ³ç¬¦çš„æ¡å½¢
                record_bars = self._extract_note_bars(record_note, 'record')
                for bar in record_bars:
                    bar['grade'] = grade_key
                    bar['error_ms'] = error_ms if 'error_ms' in locals() else 0
                    graded_data[grade_key].append(bar)

                # æ·»åŠ æ’­æ”¾éŸ³ç¬¦çš„æ¡å½¢
                replay_bars = self._extract_note_bars(replay_note, 'replay')
                for bar in replay_bars:
                    bar['grade'] = grade_key
                    bar['error_ms'] = error_ms if 'error_ms' in locals() else 0
                    graded_data[grade_key].append(bar)

            else:
                # åŒ¹é…å¤±è´¥ï¼šå½’ä¸ºmajorè¯„çº§
                # æ·»åŠ å½•åˆ¶éŸ³ç¬¦çš„æ¡å½¢ï¼ˆä¸¢é”¤æƒ…å†µï¼‰
                record_bars = self._extract_note_bars(record_note, 'record')
                for bar in record_bars:
                    bar['grade'] = 'major'
                    bar['error_ms'] = float('inf')
                    bar['match_status'] = 'failed'
                    graded_data['major'].append(bar)

                # æ·»åŠ æ’­æ”¾éŸ³ç¬¦çš„æ¡å½¢ï¼ˆå¤šé”¤æƒ…å†µï¼‰
                replay_bars = self._extract_note_bars(replay_note, 'replay')
                for bar in replay_bars:
                    bar['grade'] = 'major'
                    bar['error_ms'] = float('inf')
                    bar['match_status'] = 'failed'
                    graded_data['major'].append(bar)

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        total_events = sum(len(data) for data in graded_data.values())
        logger.info(f"ğŸ“Š åŸºäºåŒ¹é…ç­‰çº§çš„ç€‘å¸ƒå›¾æ•°æ®æ”¶é›†å®Œæˆ:")
        logger.info(f"   ä¼˜ç§€(correct): {len(graded_data['correct'])}ä¸ªäº‹ä»¶")
        logger.info(f"   è‰¯å¥½(minor): {len(graded_data['minor'])}ä¸ªäº‹ä»¶")
        logger.info(f"   ä¸€èˆ¬(moderate): {len(graded_data['moderate'])}ä¸ªäº‹ä»¶")
        logger.info(f"   è¾ƒå·®(large): {len(graded_data['large'])}ä¸ªäº‹ä»¶")
        logger.info(f"   ä¸¥é‡(severe): {len(graded_data['severe'])}ä¸ªäº‹ä»¶")
        logger.info(f"   å¤±è´¥(major): {len(graded_data['major'])}ä¸ªäº‹ä»¶")
        logger.info(f"   æ€»è®¡: {total_events}ä¸ªäº‹ä»¶")

        return graded_data

    def _should_include_note(self, note, time_filter=None, key_filter=None) -> bool:
        """
        æ£€æŸ¥éŸ³ç¬¦æ˜¯å¦åº”è¯¥è¢«åŒ…å«åœ¨ç€‘å¸ƒå›¾ä¸­

        Args:
            note: éŸ³ç¬¦å¯¹è±¡
            time_filter: æ—¶é—´è¿‡æ»¤å™¨
            key_filter: æŒ‰é”®è¿‡æ»¤å™¨

        Returns:
            bool: æ˜¯å¦åº”è¯¥åŒ…å«
        """
        # åº”ç”¨æŒ‰é”®è¿‡æ»¤
        if key_filter and hasattr(note, 'id'):
            if note.id not in key_filter:
                return False

        # åº”ç”¨æ—¶é—´è¿‡æ»¤
        if time_filter and hasattr(time_filter, 'get_time_range'):
            time_range = time_filter.get_time_range()
            if time_range:
                start_time_01ms, end_time_01ms = time_range
                try:
                    key_on = note.after_touch.index[0] + note.offset if len(note.after_touch) > 0 else note.offset
                    key_off = (note.after_touch.index[-1] + note.offset
                              if len(note.after_touch) > 0 else key_on)

                    if not (key_on >= start_time_01ms and key_off <= end_time_01ms):
                        return False
                except (IndexError, AttributeError):
                    return False

        return True



    def _extract_note_bars(self, note, label: str) -> List[Dict]:
        """
        ä»éŸ³ç¬¦ä¸­æå–baræ®µæ•°æ®

        Args:
            note: éŸ³ç¬¦å¯¹è±¡
            label: æ•°æ®æ ‡ç­¾ ('record' æˆ– 'replay')

        Returns:
            List[Dict]: baræ®µæ•°æ®åˆ—è¡¨
        """
        bars = []

        try:
            # è®¡ç®—key_onå’Œkey_offæ—¶é—´
            key_on = note.hammers.index[0] + note.offset if len(note.hammers) > 0 else note.offset
            key_off = (note.after_touch.index[-1] + note.offset
                      if len(note.after_touch) > 0 else key_on)

            key_id = note.id

            # ä¸ºæ¯ä¸ªé”¤å‡»åˆ›å»ºbaræ®µ
            for i in range(len(note.hammers)):
                t_hammer = note.hammers.index[i] + note.offset
                v_hammer = note.hammers.values[i]

                bar = {
                    't_on': t_hammer,
                    't_off': key_off,
                    'key_id': key_id,
                    'value': v_hammer,
                    'label': label,
                    'index': i
                }
                bars.append(bar)

        except (IndexError, AttributeError) as e:
            logger.warning(f"æå–éŸ³ç¬¦baræ®µå¤±è´¥: {e}")

        return bars


    def _create_waterfall_figure(self, graded_data: Dict[str, List]) -> go.Figure:
        """
        åˆ›å»ºåŸºäºè¯„çº§åˆ†ç±»çš„ç€‘å¸ƒå›¾Figure

        Args:
            graded_data: æŒ‰è¯„çº§åˆ†ç±»çš„æ•°æ®

        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        fig = go.Figure()

        # æ·»åŠ ä¸åŒè¯„çº§çš„æ•°æ®
        self._add_graded_data_traces(fig, graded_data)

        # é…ç½®å›¾è¡¨å¸ƒå±€
        self._configure_graded_waterfall_layout(fig, graded_data)

        return fig

    def _add_graded_data_traces(self, fig: go.Figure, graded_data: Dict[str, List]) -> None:
        """
        æ·»åŠ æŒ‰è¯„çº§åˆ†ç±»çš„æ•°æ®traces

        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            graded_data: æŒ‰è¯„çº§åˆ†ç±»çš„æ•°æ®
        """
        # å®šä¹‰è¯„çº§é¢œè‰²æ˜ å°„
        grade_colors = {
            'correct': 'rgba(0, 128, 0, 0.8)',      # ç»¿è‰² - ä¼˜ç§€
            'minor': 'rgba(0, 255, 0, 0.8)',        # æµ…ç»¿ - è‰¯å¥½
            'moderate': 'rgba(255, 255, 0, 0.8)',   # é»„è‰² - ä¸€èˆ¬
            'large': 'rgba(255, 165, 0, 0.8)',      # æ©™è‰² - è¾ƒå·®
            'severe': 'rgba(255, 0, 0, 0.8)',       # çº¢è‰² - ä¸¥é‡
            'major': 'rgba(128, 0, 128, 0.8)'       # ç´«è‰² - å¤±è´¥
        }

        # å®šä¹‰è¯„çº§æ˜¾ç¤ºåç§°
        grade_names = {
            'correct': 'ä¼˜ç§€åŒ¹é… (â‰¤20ms)',
            'minor': 'è‰¯å¥½åŒ¹é… (20-30ms)',
            'moderate': 'ä¸€èˆ¬åŒ¹é… (30-50ms)',
            'large': 'è¾ƒå·®åŒ¹é… (50ms-1s)',
            'severe': 'ä¸¥é‡åŒ¹é… (>1s)',
            'major': 'åŒ¹é…å¤±è´¥'
        }

        # ä¸ºæ¯ä¸ªè¯„çº§æ·»åŠ æ•°æ®
        for grade_key, grade_data in graded_data.items():
            if not grade_data:
                continue

            color = grade_colors.get(grade_key, 'rgba(128, 128, 128, 0.8)')
            name = grade_names.get(grade_key, f'è¯„çº§:{grade_key}')

            self._add_single_grade_traces(fig, grade_data, name, color, grade_key)

    def _add_single_grade_traces(self, fig: go.Figure, data: List[Dict], name: str, color: str, grade_key: str) -> None:
        """
        æ·»åŠ å•ä¸ªè¯„çº§çš„æ•°æ®traces

        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            data: è¯¥è¯„çº§çš„æ•°æ®åˆ—è¡¨
            name: traceåç§°
            color: é¢œè‰²
            grade_key: è¯„çº§é”®
        """
        for item in data:
            # è®¡ç®—å®é™…çš„key_idï¼ˆåŠ ä¸Šå°çš„åç§»ä»¥åŒºåˆ†å½•åˆ¶å’Œæ’­æ”¾ï¼‰
            base_key_id = item['key_id']
            if item.get('label') == 'replay':
                actual_key_id = base_key_id + 0.2  # æ’­æ”¾æ•°æ®ç¨å¾®åç§»
            else:
                actual_key_id = base_key_id

            # åˆ›å»ºhoveræ–‡æœ¬
            hover_text = self._create_graded_hover_text(item, grade_key)

            # æ·»åŠ Plotlyæ•£ç‚¹å›¾trace
            fig.add_trace(go.Scatter(
                x=[item['t_on']/10, item['t_off']/10],  # è½¬æ¢ä¸ºms
                y=[actual_key_id, actual_key_id],
                mode='lines',
                line=dict(color=color, width=3),
                name=name,
                showlegend=True,
                legendgroup=grade_key,
                hoverinfo='text',
                hovertext=hover_text,
                customdata=[[item['t_on']/10, item['t_off']/10, item['key_id'],
                            item.get('value', 0), grade_key, item.get('error_ms', 0)]]
            ))

    def _create_graded_hover_text(self, item: Dict, grade_key: str) -> str:
        """
        åˆ›å»ºåŸºäºè¯„çº§çš„hoveræ–‡æœ¬

        Args:
            item: æ•°æ®é¡¹
            grade_key: è¯„çº§é”®

        Returns:
            str: hoveræ–‡æœ¬
        """
        grade_names = {
            'correct': 'ä¼˜ç§€åŒ¹é…',
            'minor': 'è‰¯å¥½åŒ¹é…',
            'moderate': 'ä¸€èˆ¬åŒ¹é…',
            'large': 'è¾ƒå·®åŒ¹é…',
            'severe': 'ä¸¥é‡åŒ¹é…',
            'major': 'åŒ¹é…å¤±è´¥'
        }

        grade_name = grade_names.get(grade_key, f'è¯„çº§:{grade_key}')
        error_ms = item.get('error_ms', 0)

        if grade_key == 'major':
            data_type = item.get('data_type', '')
            if data_type == 'drop_hammer':
                error_info = "ä¸¢é”¤: å½•åˆ¶æ•°æ®æ— å¯¹åº”æ’­æ”¾"
            elif data_type == 'multi_hammer':
                error_info = "å¤šé”¤: æ’­æ”¾æ•°æ®æ— å¯¹åº”å½•åˆ¶"
            else:
                error_info = "åŒ¹é…å¤±è´¥"
        elif error_ms == float('inf'):
            error_info = "æ— è¯¯å·®æ•°æ®"
        else:
            error_info = f"è¯¯å·®: {error_ms:.2f}ms"

        # æ·»åŠ é¢å¤–ä¿¡æ¯
        extra_info = ""
        if item.get('data_type') in ['drop_hammer', 'multi_hammer']:
            extra_info = f'<br>åŸå› : {item.get("error_reason", "æœªçŸ¥")}'

        return (f'è¯„çº§: {grade_name}<br>'
                f'æŒ‰é”®ID: {item["key_id"]}<br>'
                f'åŠ›åº¦: {item.get("value", 0):.3f}<br>'
                f'{error_info}{extra_info}<br>'
                f'å¼€å§‹æ—¶é—´: {item["t_on"]/10:.1f}ms<br>'
                f'ç»“æŸæ—¶é—´: {item["t_off"]/10:.1f}ms<br>'
                f'æ•°æ®æ¥æº: {item.get("label", "unknown")}')

    def _configure_graded_waterfall_layout(self, fig: go.Figure, graded_data: Dict[str, List]) -> None:
        """
        é…ç½®åŸºäºè¯„çº§çš„ç€‘å¸ƒå›¾å¸ƒå±€

        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            graded_data: æŒ‰è¯„çº§åˆ†ç±»çš„æ•°æ®
        """
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_points = sum(len(data) for data in graded_data.values())

        # åˆ›å»ºæ ‡é¢˜
        title = f'é’¢ç´æŒ‰é”®åŒ¹é…è´¨é‡ç€‘å¸ƒå›¾ (å…±{total_points}ä¸ªäº‹ä»¶)'
        title += '<br><span style="font-size:10px; color:#666;">'

        grade_stats = []
        grade_names = {
            'correct': 'ä¼˜ç§€', 'minor': 'è‰¯å¥½', 'moderate': 'ä¸€èˆ¬',
            'large': 'è¾ƒå·®', 'severe': 'ä¸¥é‡', 'major': 'å¤±è´¥'
        }

        # ç»Ÿè®¡ä¸åŒç±»å‹çš„å¤±è´¥åŒ¹é…
        if graded_data.get('major'):
            drop_hammer_count = sum(1 for item in graded_data['major'] if item.get('data_type') == 'drop_hammer')
            multi_hammer_count = sum(1 for item in graded_data['major'] if item.get('data_type') == 'multi_hammer')
            other_failed_count = len(graded_data['major']) - drop_hammer_count - multi_hammer_count

            if drop_hammer_count > 0:
                grade_stats.append(f'ä¸¢é”¤: {drop_hammer_count}')
            if multi_hammer_count > 0:
                grade_stats.append(f'å¤šé”¤: {multi_hammer_count}')
            if other_failed_count > 0:
                grade_stats.append(f'å…¶ä»–å¤±è´¥: {other_failed_count}')
        else:
            for grade_key, count in graded_data.items():
                if count and grade_key != 'major':
                    grade_name = grade_names.get(grade_key, grade_key)
                    grade_stats.append(f'{grade_name}: {len(count)}')

        title += ' | '.join(grade_stats)
        title += '</span>'

        # è®¾ç½®å›¾è¡¨å¸ƒå±€
        fig.update_layout(
            title=title,
            xaxis_title='æ—¶é—´ (ms)',
            yaxis_title='æŒ‰é”®ID',
            yaxis=dict(tickmode='array', tickvals=list(range(1, 89)), range=[0.5, 89.5]),
            height=800,
            showlegend=True,
            template='plotly_white'
        )



    def _add_single_type_traces(self, fig: go.Figure, data: List[Dict],
                               name: str, color: str, y_offset: float) -> None:
        """
        æ·»åŠ å•ä¸€ç±»å‹æ•°æ®çš„traces

        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            data: æ•°æ®åˆ—è¡¨
            name: traceåç§°
            color: é¢œè‰²
            y_offset: Yè½´åç§»
        """
        if not data:
            return

        for item in data:
            # è®¡ç®—å®é™…çš„key_idï¼ˆåŠ ä¸Šåç§»ï¼‰
            actual_key_id = item['key_id'] + y_offset

            # åˆ›å»ºhoveræ–‡æœ¬
            hover_text = self._create_hover_text(item)

            fig.add_trace(go.Scatter(
                x=[item['t_on']/10, item['t_off']/10],  # è½¬æ¢ä¸ºms
                y=[actual_key_id, actual_key_id],
                mode='lines',
                line=dict(color=color, width=3),
                name=name,
                showlegend=True,  # å¯ç”¨å›¾ä¾‹
                legendgroup=name,  # æŒ‰ç±»å‹åˆ†ç»„
                hoverinfo='text',
                hovertext=hover_text,
                customdata=[[item['t_on']/10, item['t_off']/10, item['key_id'], item['value'], item.get('data_type', 'unknown'), item['index']]]
            ))

    def _create_hover_text(self, item: Dict) -> str:
        """
        åˆ›å»ºhoveræ–‡æœ¬

        Args:
            item: æ•°æ®é¡¹

        Returns:
            str: hoveræ–‡æœ¬
        """
        data_type_map = {
            'matched': 'é…å¯¹æŒ‰é”®',
            'drop_hammer': 'ä¸¢é”¤æŒ‰é”®',
            'multi_hammer': 'å¤šé”¤æŒ‰é”®',
            'unmatched_record': 'æœªåŒ¹é…å½•åˆ¶',
            'unmatched_replay': 'æœªåŒ¹é…æ’­æ”¾'
        }

        data_type = data_type_map.get(item.get('data_type', 'unknown'), 'æœªçŸ¥ç±»å‹')

        return (f'ç±»å‹: {data_type}<br>'
                f'æŒ‰é”®ID: {item["key_id"]}<br>'
                f'åŠ›åº¦: {item["value"]:.3f}<br>'
                f'å¼€å§‹æ—¶é—´: {item["t_on"]/10:.1f}ms<br>'
                f'ç»“æŸæ—¶é—´: {item["t_off"]/10:.1f}ms<br>'
                f'æ•°æ®æ¥æº: {item["label"]}')

    def _configure_waterfall_layout(self, fig: go.Figure, filtered_data: Dict[str, List]) -> None:
        """
        é…ç½®ç€‘å¸ƒå›¾å¸ƒå±€

        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            filtered_data: è¿‡æ»¤åçš„æ•°æ®
        """
        # è®¡ç®—æ•°æ®ç»Ÿè®¡
        total_points = sum(len(data) for data in filtered_data.values())

        # åˆ›å»ºæ ‡é¢˜
        title = f'é’¢ç´æŒ‰é”®äº‹ä»¶ç€‘å¸ƒå›¾ (å…±{total_points}ä¸ªäº‹ä»¶)'
        title += '<br><span style="font-size:10px; color:#666;">'
        title += f'é…å¯¹æŒ‰é”®: {len(filtered_data["matched"])} | '
        title += f'ä¸¢é”¤æŒ‰é”®: {len(filtered_data["drop_hammers"])} | '
        title += f'å¤šé”¤æŒ‰é”®: {len(filtered_data["multi_hammers"])}'
        title += '</span>'

        # è®¾ç½®å¸ƒå±€
        fig.update_layout(
            title=title,
            xaxis_title='æ—¶é—´ (ms)',
            yaxis_title='æŒ‰é”®ID',
            yaxis=dict(
                tickmode='array',
                tickvals=list(range(1, 89)),  # é’¢ç´æŒ‰é”®èŒƒå›´
                range=[0.5, 89.5]  # æ˜¾ç¤ºå®Œæ•´æŒ‰é”®èŒƒå›´
            ),
            height=800,
            showlegend=True,  # å¯ç”¨å›¾ä¾‹
            legend=dict(
                orientation='h',  # æ°´å¹³æ’åˆ—
                yanchor='bottom',
                y=1.02,  # å›¾ä¾‹ä½ç½®
                xanchor='center',
                x=0.5,
                bgcolor='rgba(255,255,255,0.8)',
                bordercolor='rgba(0,0,0,0.2)',
                borderwidth=1
            ),
            template='plotly_white',
            hovermode='closest'
        )

    def _create_error_figure(self, error_msg: str) -> go.Figure:
        """
        åˆ›å»ºé”™è¯¯å›¾è¡¨

        Args:
            error_msg: é”™è¯¯æ¶ˆæ¯

        Returns:
            go.Figure: é”™è¯¯å›¾è¡¨
        """
        fig = go.Figure()
        fig.add_annotation(
            text=error_msg,
            xref="paper", yref="paper",
            x=0.5, y=0.5, xanchor='center', yanchor='middle',
            showarrow=False, font_size=16
        )
        fig.update_layout(
            title="å›¾è¡¨ç”Ÿæˆå¤±è´¥",
            xaxis=dict(visible=False),
            yaxis=dict(visible=False),
            plot_bgcolor='white'
        )
        return fig
