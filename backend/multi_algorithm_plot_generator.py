#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¤šç®—æ³•å›¾è¡¨ç”Ÿæˆå™¨

è´Ÿè´£ç”Ÿæˆæ”¯æŒå¤šç®—æ³•å¯¹æ¯”çš„å›¾è¡¨ï¼Œä½¿ç”¨é¢å‘å¯¹è±¡è®¾è®¡ã€‚
"""
import math
import traceback
from typing import List, Optional, Any, Dict, Tuple
import plotly.graph_objects as go
import numpy as np
from backend.multi_algorithm_manager import AlgorithmDataset
from utils.logger import Logger
from utils.colors import ALGORITHM_COLOR_PALETTE

logger = Logger.get_logger()


class MultiAlgorithmPlotGenerator:
    """
    å¤šç®—æ³•å›¾è¡¨ç”Ÿæˆå™¨ç±»
    
    è´Ÿè´£ç”Ÿæˆæ”¯æŒå¤šç®—æ³•å¯¹æ¯”çš„å›¾è¡¨ï¼ŒåŒ…æ‹¬ï¼š
    - ç€‘å¸ƒå›¾ï¼ˆå¤šç®—æ³•å åŠ æ˜¾ç¤ºï¼‰
    - åç§»å¯¹é½åˆ†æå›¾ï¼ˆå¤šç®—æ³•å¹¶æ’æŸ±çŠ¶å›¾ï¼‰
    - å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆå¤šç®—æ³•å åŠ æ˜¾ç¤ºï¼‰
    """
    
    def __init__(self, data_filter=None):
        """
        åˆå§‹åŒ–å¤šç®—æ³•å›¾è¡¨ç”Ÿæˆå™¨
        
        Args:
            data_filter: æ•°æ®è¿‡æ»¤å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        """
        self.data_filter = data_filter
        
        # ä½¿ç”¨å…¨å±€é¢œè‰²æ–¹æ¡ˆ
        self.COLORS = ALGORITHM_COLOR_PALETTE
        
        logger.info("MultiAlgorithmPlotGeneratoråˆå§‹åŒ–å®Œæˆ")
    
    def generate_unified_waterfall_plot(
        self,
        backend,                        # åç«¯å®ä¾‹ï¼Œç”¨äºè·å–å…¨å±€å¹³å‡å»¶æ—¶
        analyzers: List[Any],           # åˆ†æå™¨åˆ—è¡¨ï¼ˆå•ç®—æ³•æ—¶1ä¸ªï¼Œå¤šç®—æ³•æ—¶å¤šä¸ªï¼‰
        algorithm_names: List[str],     # ç®—æ³•åç§°åˆ—è¡¨
        is_multi_algorithm: bool,       # æ˜¯å¦å¤šç®—æ³•æ¨¡å¼
        time_filter=None,
        key_filter=None
    ) -> Any:
        """
        ç”Ÿæˆç»Ÿä¸€çš„ç€‘å¸ƒå›¾ï¼ˆæ”¯æŒå•ç®—æ³•å’Œå¤šç®—æ³•æ¨¡å¼ï¼‰
        
        å•ç®—æ³•æ¨¡å¼ï¼šanalyzersåŒ…å«1ä¸ªåˆ†æå™¨
        å¤šç®—æ³•æ¨¡å¼ï¼šanalyzersåŒ…å«å¤šä¸ªåˆ†æå™¨
        
        Args:
            analyzers: åˆ†æå™¨åˆ—è¡¨
            algorithm_names: ç®—æ³•åç§°åˆ—è¡¨
            is_multi_algorithm: æ˜¯å¦å¤šç®—æ³•æ¨¡å¼
            time_filter: æ—¶é—´è¿‡æ»¤å™¨
            key_filter: æŒ‰é”®è¿‡æ»¤å™¨
            
        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        if not analyzers:
            logger.warning("æ²¡æœ‰åˆ†æå™¨ï¼Œæ— æ³•ç”Ÿæˆç€‘å¸ƒå›¾")
            return self._create_empty_plot("æ²¡æœ‰åˆ†æå™¨")

        try:
            mode_str = "å¤šç®—æ³•" if is_multi_algorithm else "å•ç®—æ³•"
            logger.info(f"å¼€å§‹ç”Ÿæˆç€‘å¸ƒå›¾ï¼Œæ¨¡å¼: {mode_str}ï¼Œå…± {len(analyzers)} ä¸ªåˆ†æå™¨")

            # ä¸ºå¤šç®—æ³•åˆ†é…y_offsetèŒƒå›´ï¼ˆç¡®ä¿æ˜ç¡®åŒºåˆ†ï¼‰
            if is_multi_algorithm:
                algorithm_y_range = 100  # æ¯ä¸ªç®—æ³•åˆ†é…çš„yè½´èŒƒå›´
            else:
                algorithm_y_range = 0  # å•ç®—æ³•ä¸éœ€è¦åç§»

            # è·å–å¹³å‡å»¶æ—¶æ•°æ®ï¼ˆå‚è€ƒ grade_detail_callbacks.py çš„é€»è¾‘ï¼‰
            avg_delay_ms = 0.0
            try:
                if is_multi_algorithm and algorithm_names and algorithm_names[0] != 'single':
                    # å¤šç®—æ³•æ¨¡å¼ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç®—æ³•çš„å¹³å‡å»¶æ—¶
                    active_algorithms = backend.get_active_algorithms() if hasattr(backend, 'get_active_algorithms') else []
                    target_algorithm = next((alg for alg in active_algorithms if alg.metadata.algorithm_name == algorithm_names[0]), None)
                    if target_algorithm and target_algorithm.analyzer and hasattr(target_algorithm.analyzer, 'get_global_average_delay'):
                        avg_delay_0_1ms = target_algorithm.analyzer.get_global_average_delay()
                        avg_delay_ms = avg_delay_0_1ms / 10.0
                else:
                    # å•ç®—æ³•æ¨¡å¼
                    avg_delay_0_1ms = backend.get_global_average_delay()
                    avg_delay_ms = avg_delay_0_1ms / 10.0
                logger.info(f"ä½¿ç”¨å¹³å‡å»¶æ—¶: {avg_delay_ms:.2f}ms")
            except Exception as e:
                logger.warning(f"è·å–å¹³å‡å»¶æ—¶å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼0.0ms")
            
            # æ”¶é›†æ‰€æœ‰æ•°æ®ç‚¹ç”¨äºå…¨å±€å½’ä¸€åŒ–
            all_values = []
            all_bars_by_algorithm = []
            
            # å¤„ç†æ¯ä¸ªåˆ†æå™¨
            for alg_idx, (analyzer, algorithm_name) in enumerate(zip(analyzers, algorithm_names)):
                if not analyzer:
                    logger.warning(f"åˆ†æå™¨ '{algorithm_name}' ä¸ºç©ºï¼Œè·³è¿‡")
                    continue
                
                logger.info(f"å¤„ç†åˆ†æå™¨ '{algorithm_name}': ç”ŸæˆåŒ…å«æ‰€æœ‰æ•°æ®çš„ç€‘å¸ƒå›¾")

                # è®¡ç®—å½“å‰ç®—æ³•çš„y_offset
                current_y_offset = alg_idx * algorithm_y_range if is_multi_algorithm else 0

                # æ”¶é›†å½“å‰åˆ†æå™¨çš„å®Œæ•´æ•°æ®ï¼šåŒ¹é…å¯¹ + ä¸¢é”¤ + å¤šé”¤
                algorithm_bars = self._collect_algorithm_comprehensive_data(
                    analyzer, current_y_offset, algorithm_name, alg_idx, avg_delay_ms
                )

                # æ³¨æ„ï¼šä¸¢é”¤å’Œå¤šé”¤æ•°æ®ä¸åº”è¯¥è¢«è¿‡æ»¤å™¨è¿‡æ»¤ï¼Œåº”è¯¥å§‹ç»ˆæ˜¾ç¤º
                # è¿‡æ»¤å™¨åªåº”è¯¥å½±å“åŒ¹é…å¯¹æ•°æ®çš„æ˜¾ç¤ºï¼Œä½†è¿™é‡Œæˆ‘ä»¬é€‰æ‹©æ˜¾ç¤ºæ‰€æœ‰æ•°æ®

                # æ”¶é›†åŠ›åº¦å€¼ç”¨äºå…¨å±€é¢œè‰²å½’ä¸€åŒ–
                for bar in algorithm_bars:
                    all_values.append(bar.get('velocity', 0.5))
                
                all_bars_by_algorithm.append({
                    'analyzer': analyzer,
                    'bars': algorithm_bars,
                    'algorithm_name': algorithm_name,
                    'y_offset': current_y_offset
                })
            
            if not all_bars_by_algorithm:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®ç‚¹ï¼Œæ— æ³•ç”Ÿæˆç€‘å¸ƒå›¾")
                return self._create_empty_plot("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®ç‚¹")
            
            # å…¨å±€å½’ä¸€åŒ–åŠ›åº¦å€¼ï¼ˆç”¨äºé¢œè‰²æ˜ å°„ï¼‰
            if all_values:
                vmin = min(all_values)
                vmax = max(all_values)
            else:
                vmin, vmax = 0, 1
            
            # ä½¿ç”¨colormap
            import matplotlib.pyplot as plt
            cmap = plt.colormaps['tab20b']
            norm = lambda v: (v - vmin) / (vmax - vmin) if vmax > vmin else 0.5
            
            # åˆ›å»ºå›¾è¡¨
            fig = go.Figure()
            
            # ä¸ºæ¯ä¸ªæ¡å½¢æ®µæ·»åŠ trace
            total_bars = 0
            drop_hammer_bars = 0
            multi_hammer_bars = 0
            matched_bars = 0
            
            for alg_data in all_bars_by_algorithm:
                bars = alg_data['bars']
                algorithm_name = alg_data['algorithm_name']
                
                logger.info(f"ç®—æ³• '{algorithm_name}': å‡†å¤‡ç»˜åˆ¶ {len(bars)} ä¸ªbars")
                
                for bar in bars:
                    total_bars += 1
                    data_type = bar.get('data_type', '')
                    if data_type == 'drop_hammer':
                        drop_hammer_bars += 1
                    elif data_type == 'multi_hammer':
                        multi_hammer_bars += 1
                    else:
                        matched_bars += 1
                    # è®¡ç®—é¢œè‰²
                    velocity = bar.get('velocity', 0.5)
                    color = 'rgba' + str(tuple(int(255*x) for x in cmap(norm(velocity))[:3]) + (0.9,))

                    # åˆ›å»ºtraceåç§°
                    data_type = bar.get('data_type', '')
                    if data_type == 'drop_hammer':
                        trace_name = f"{algorithm_name} - ä¸¢é”¤"
                    elif data_type == 'multi_hammer':
                        trace_name = f"{algorithm_name} - å¤šé”¤"
                    else:
                        trace_name = f"{algorithm_name} - {bar['label']}"
                    
                    # æ·»åŠ æ°´å¹³çº¿æ®µ
                    fig.add_trace(go.Scatter(
                        x=[bar['t_on']/10, bar['t_off']/10],
                        y=[bar['key_id'], bar['key_id']],
                        mode='lines',
                        line=dict(color=color, width=3),
                        name=trace_name,
                        showlegend=False,
                        legendgroup=algorithm_name,
                        hoverinfo='text' if bar.get('text') else 'skip',
                        text=bar.get('text', ''),
                        customdata=[[
                            bar['t_on']/10, 
                            bar['t_off']/10, 
                            int(bar.get('original_key_id', bar.get('key_id', 0))),
                            bar.get('raw_velocity', 0),
                            bar.get('label', 'unknown'),
                            bar.get('source_index', 0),
                            algorithm_name
                        ]]
                    ))
            
            # é…ç½®å›¾è¡¨å¸ƒå±€
            self._configure_unified_waterfall_layout(fig, all_bars_by_algorithm, is_multi_algorithm)

            logger.info(f"ç€‘å¸ƒå›¾ç”ŸæˆæˆåŠŸ: æ€»è®¡ {total_bars} ä¸ªbars (åŒ¹é…å¯¹: {matched_bars}, ä¸¢é”¤: {drop_hammer_bars}, å¤šé”¤: {multi_hammer_bars})")
            return fig

        except Exception as e:
            logger.error(f"ç”Ÿæˆç€‘å¸ƒå›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return self._create_empty_plot(f"ç”Ÿæˆç€‘å¸ƒå›¾å¤±è´¥: {str(e)}")

    def _collect_algorithm_comprehensive_data(self, analyzer, y_offset: float, algorithm_name: str, alg_idx: int, avg_delay_ms: float = 0.0) -> List[Dict]:
        """
        æ”¶é›†å•ä¸ªç®—æ³•çš„å®Œæ•´ç€‘å¸ƒå›¾æ•°æ®ï¼šåŒ¹é…å¯¹ + ä¸¢é”¤ + å¤šé”¤

        è¿™ä¸ªæ–¹æ³•ä½œä¸ºç»Ÿä¸€å…¥å£ï¼Œåè°ƒå„ä¸ªå­æ¨¡å—çš„æ•°æ®æ”¶é›†å·¥ä½œã€‚

        Args:
            analyzer: SPMIDAnalyzerå®ä¾‹
            y_offset: Yè½´åç§»é‡
            algorithm_name: ç®—æ³•åç§°
            alg_idx: ç®—æ³•ç´¢å¼•
            avg_delay_ms: å¹³å‡å»¶æ—¶ï¼ˆç”¨äºç›¸å¯¹å»¶æ—¶è®¡ç®—ï¼‰

        Returns:
            List[Dict]: è¯¥ç®—æ³•çš„æ‰€æœ‰ç€‘å¸ƒå›¾æ•°æ®
        """
        algorithm_bars = []

        logger.info(f"å¼€å§‹æ”¶é›†ç®—æ³• '{algorithm_name}' çš„ç€‘å¸ƒå›¾æ•°æ®")

        # 1. æ”¶é›†åŒ¹é…å¯¹æ•°æ®ï¼ˆæˆåŠŸå’Œå¤±è´¥çš„åŒ¹é…ï¼‰
        matched_bars = self._collect_matched_pair_data(analyzer, y_offset, algorithm_name, avg_delay_ms)
        algorithm_bars.extend(matched_bars)
        logger.info(f"åŒ¹é…å¯¹æ•°æ®: {len(matched_bars)} ä¸ªbars")

        # 2. æ”¶é›†ä¸¢é”¤æ•°æ®
        drop_hammer_bars = self._collect_drop_hammer_data(analyzer, y_offset, algorithm_name)
        algorithm_bars.extend(drop_hammer_bars)
        logger.info(f"ä¸¢é”¤æ•°æ®: {len(drop_hammer_bars)} ä¸ªbars")

        # 3. æ”¶é›†å¤šé”¤æ•°æ®
        multi_hammer_bars = self._collect_multi_hammer_data(analyzer, y_offset, algorithm_name)
        algorithm_bars.extend(multi_hammer_bars)
        logger.info(f"å¤šé”¤æ•°æ®: {len(multi_hammer_bars)} ä¸ªbars")

        total_bars = len(algorithm_bars)
        logger.info(f"ç®—æ³• '{algorithm_name}' æ•°æ®æ”¶é›†å®Œæˆ: æ€»è®¡ {total_bars} ä¸ªç€‘å¸ƒå›¾æ¡å½¢")

        return algorithm_bars

    def _collect_matched_pair_data(self, analyzer, y_offset: float, algorithm_name: str, avg_delay_ms: float) -> List[Dict]:
        """
        æ”¶é›†åŒ¹é…å¯¹æ•°æ®ï¼ˆæˆåŠŸåŒ¹é…å’Œå¤±è´¥åŒ¹é…ï¼‰

        Args:
            analyzer: SPMIDAnalyzerå®ä¾‹
            y_offset: Yè½´åç§»é‡
            algorithm_name: ç®—æ³•åç§°
            avg_delay_ms: å¹³å‡å»¶æ—¶

        Returns:
            List[Dict]: åŒ¹é…å¯¹çš„ç€‘å¸ƒå›¾æ•°æ®
        """
        bars = []

        if not hasattr(analyzer, 'note_matcher') or not analyzer.note_matcher:
            logger.info("æ²¡æœ‰note_matcherï¼Œè·³è¿‡åŒ¹é…å¯¹æ•°æ®æ”¶é›†")
            return bars

        note_matcher = analyzer.note_matcher
        if not hasattr(note_matcher, 'match_results'):
            logger.info("æ²¡æœ‰match_resultsï¼Œè·³è¿‡åŒ¹é…å¯¹æ•°æ®æ”¶é›†")
            return bars

        logger.info(f"å¼€å§‹æ”¶é›†åŒ¹é…å¯¹æ•°æ®ï¼Œå…± {len(note_matcher.match_results)} ä¸ªåŒ¹é…ç»“æœ")

        for result in note_matcher.match_results:
            try:
                # è·å–å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦
                record_note = note_matcher._record_data[result.record_index]
                replay_note = note_matcher._replay_data[result.replay_index] if result.replay_index is not None else None

                # è®¡ç®—å»¶æ—¶å’Œè¯„çº§
                grade_name, color_intensity, delay_ms, relative_delay_ms = self._calculate_match_grading(
                    result, record_note, replay_note, avg_delay_ms
                )

                record_match_index = getattr(result, 'record_index', 'N/A')
                replay_match_index = getattr(result, 'replay_index', 'N/A')

                # å¤„ç†å½•åˆ¶æ•°æ®
                if hasattr(record_note, 'after_touch') and record_note.after_touch is not None:
                    record_bars = self._extract_note_bars_for_multi(
                        record_note, 'record', y_offset, color_intensity,
                        algorithm_name, grade_name, record_match_index, delay_ms, relative_delay_ms
                    )
                    bars.extend(record_bars)

                    # å¤„ç†æ’­æ”¾æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if replay_note is not None and hasattr(replay_note, 'after_touch') and replay_note.after_touch is not None:
                        replay_bars = self._extract_note_bars_for_multi(
                            replay_note, 'replay', y_offset, color_intensity,
                            algorithm_name, grade_name, replay_match_index, delay_ms, relative_delay_ms
                        )

                        # åˆå¹¶hoverä¿¡æ¯
                        if record_bars and replay_bars:
                            self._merge_matched_hover_info(record_bars, replay_bars, avg_delay_ms)

                        bars.extend(replay_bars)

            except (IndexError, AttributeError, TypeError) as e:
                logger.warning(f"å¤„ç†åŒ¹é…ç»“æœå¤±è´¥: {e}")
                continue

        logger.info(f"åŒ¹é…å¯¹æ•°æ®æ”¶é›†å®Œæˆ: {len(bars)} ä¸ªbars")
        return bars

    def _collect_drop_hammer_data(self, analyzer, y_offset: float, algorithm_name: str) -> List[Dict]:
        """
        æ”¶é›†ä¸¢é”¤é”™è¯¯æ•°æ®

        Args:
            analyzer: SPMIDAnalyzerå®ä¾‹
            y_offset: Yè½´åç§»é‡
            algorithm_name: ç®—æ³•åç§°

        Returns:
            List[Dict]: ä¸¢é”¤çš„ç€‘å¸ƒå›¾æ•°æ®
        """
        bars = []
        drop_hammers = getattr(analyzer, 'drop_hammers', [])
        initial_valid_record_data = getattr(analyzer, 'initial_valid_record_data', [])

        if not drop_hammers:
            logger.info("æ²¡æœ‰ä¸¢é”¤æ•°æ®")
            return bars

        logger.info(f"å¼€å§‹æ”¶é›†ä¸¢é”¤æ•°æ®: {len(drop_hammers)} ä¸ª")

        for idx, error_note in enumerate(drop_hammers):
            try:
                # è·å–éŸ³ç¬¦ç´¢å¼•
                note_index = self._get_error_note_index(error_note)

                # éªŒè¯ç´¢å¼•å¹¶è·å–noteå¯¹è±¡
                if not self._is_valid_index(note_index, len(initial_valid_record_data)):
                    continue

                note = initial_valid_record_data[note_index] or self._create_default_note(error_note, note_index)

                # åªå¤„ç†æœ‰after_touchæ•°æ®çš„note
                if hasattr(note, 'after_touch') and note.after_touch is not None and hasattr(note.after_touch, 'index') and len(note.after_touch.index) > 0:
                    bars.extend(self._extract_note_bars_for_multi(
                        note, 'record', y_offset, 0.1, algorithm_name,
                        "å¤±è´¥", note_index, 0.0, 0.0, 'drop_hammer'
                    ))

                    # ä¸ºä¸¢é”¤æ•°æ®åˆ›å»ºæ‚¬åœä¿¡æ¯
                    for bar in bars[-1:]:  # åªå¤„ç†åˆšæ·»åŠ çš„bar
                        # ä¸¢é”¤æ•°æ®ï¼šå½•åˆ¶å­˜åœ¨ä½†æ’­æ”¾ç¼ºå¤±
                        bar['text'] = '<b>ä¸¢é”¤é”™è¯¯ (å½•åˆ¶æ•°æ®):</b><br>' + \
                                     f'ç±»å‹: record<br>' + \
                                     f'é”®ä½: {getattr(note, "id", "N/A")}<br>' + \
                                     f'é”¤é€Ÿ: {getattr(note, "hammers", ["N/A"])[0] if hasattr(note, "hammers") and note.hammers else "N/A"}<br>' + \
                                     f'ç­‰çº§: å¤±è´¥ (ä¸¢é”¤)<br>' + \
                                     f'ç´¢å¼•: {note_index}<br>' + \
                                     f'æŒ‰é”®æŒ‰ä¸‹: {bar["t_on"]/10:.2f}ms<br>' + \
                                     f'æŒ‰é”®é‡Šæ”¾: {bar["t_off"]/10:.2f}ms<br>' + \
                                     f'é”™è¯¯ç±»å‹: ä¸¢é”¤ (æ’­æ”¾æ•°æ®ç¼ºå¤±)<br>'

                    logger.info(f"ä¸¢é”¤ #{idx} å¤„ç†å®Œæˆ")
                else:
                    logger.warning(f"ä¸¢é”¤ #{idx} ç¼ºå°‘after_touchæ•°æ®ï¼Œè·³è¿‡")

            except Exception as e:
                logger.error(f"å¤„ç†ä¸¢é”¤ #{idx} å¤±è´¥: {e}")
                continue

        logger.info(f"ä¸¢é”¤æ•°æ®æ”¶é›†å®Œæˆ: {len(bars)} ä¸ªbars")
        return bars

    def _collect_multi_hammer_data(self, analyzer, y_offset: float, algorithm_name: str) -> List[Dict]:
        """
        æ”¶é›†å¤šé”¤é”™è¯¯æ•°æ®

        Args:
            analyzer: SPMIDAnalyzerå®ä¾‹
            y_offset: Yè½´åç§»é‡
            algorithm_name: ç®—æ³•åç§°

        Returns:
            List[Dict]: å¤šé”¤çš„ç€‘å¸ƒå›¾æ•°æ®
        """
        bars = []
        multi_hammers = getattr(analyzer, 'multi_hammers', [])
        initial_valid_replay_data = getattr(analyzer, 'initial_valid_replay_data', [])

        if not multi_hammers:
            logger.info("æ²¡æœ‰å¤šé”¤æ•°æ®")
            return bars

        logger.info(f"ğŸ”¨ å¼€å§‹æ”¶é›†å¤šé”¤æ•°æ®: {len(multi_hammers)} ä¸ª")

        for idx, error_note in enumerate(multi_hammers):
            try:
                # è·å–éŸ³ç¬¦ç´¢å¼•
                note_index = self._get_error_note_index(error_note)

                # éªŒè¯ç´¢å¼•å¹¶è·å–noteå¯¹è±¡
                if not self._is_valid_index(note_index, len(initial_valid_replay_data)):
                    continue

                note = initial_valid_replay_data[note_index] or self._create_default_note(error_note, note_index)

                # åªå¤„ç†æœ‰after_touchæ•°æ®çš„note
                if hasattr(note, 'after_touch') and note.after_touch is not None and hasattr(note.after_touch, 'index') and len(note.after_touch.index) > 0:
                    bars.extend(self._extract_note_bars_for_multi(
                        note, 'replay', y_offset, 0.1, algorithm_name,
                        "å¤±è´¥", note_index, 0.0, 0.0, 'multi_hammer'
                    ))

                    # ä¸ºå¤šé”¤æ•°æ®åˆ›å»ºæ‚¬åœä¿¡æ¯
                    for bar in bars[-1:]:  # åªå¤„ç†åˆšæ·»åŠ çš„bar
                        # å¤šé”¤æ•°æ®ï¼šæ’­æ”¾å­˜åœ¨ä½†å½•åˆ¶ç¼ºå¤±
                        bar['text'] = '<b>å¤šé”¤é”™è¯¯ (æ’­æ”¾æ•°æ®):</b><br>' + \
                                     f'ç±»å‹: replay<br>' + \
                                     f'é”®ä½: {getattr(note, "id", "N/A")}<br>' + \
                                     f'é”¤é€Ÿ: {getattr(note, "hammers", ["N/A"])[0] if hasattr(note, "hammers") and note.hammers else "N/A"}<br>' + \
                                     f'ç­‰çº§: å¤±è´¥ (å¤šé”¤)<br>' + \
                                     f'ç´¢å¼•: {note_index}<br>' + \
                                     f'æŒ‰é”®æŒ‰ä¸‹: {bar["t_on"]/10:.2f}ms<br>' + \
                                     f'æŒ‰é”®é‡Šæ”¾: {bar["t_off"]/10:.2f}ms<br>' + \
                                     f'é”™è¯¯ç±»å‹: å¤šé”¤ (å½•åˆ¶æ•°æ®ç¼ºå¤±)<br>'

                    logger.info(f"å¤šé”¤ #{idx} å¤„ç†å®Œæˆ")
                else:
                    logger.warning(f"å¤šé”¤ #{idx} ç¼ºå°‘after_touchæ•°æ®ï¼Œè·³è¿‡")

            except Exception as e:
                logger.error(f"å¤„ç†å¤šé”¤ #{idx} å¤±è´¥: {e}")
                continue

        logger.info(f"å¤šé”¤æ•°æ®æ”¶é›†å®Œæˆ: {len(bars)} ä¸ªbars")
        return bars

    def _calculate_match_grading(self, result, record_note, replay_note, avg_delay_ms: float):
        """
        è®¡ç®—åŒ¹é…ç»“æœçš„è¯„çº§å’Œå»¶æ—¶ä¿¡æ¯

        Returns:
            tuple: (grade_name, color_intensity, delay_ms, relative_delay_ms)
        """
        grade_name = "æœªçŸ¥"
        delay_ms = 0.0
        relative_delay_ms = 0.0

        if result.is_success and record_note and replay_note:
            # è®¡ç®—å»¶æ—¶
            record_keyon = self._calculate_note_keyon_time(record_note)
            replay_keyon = self._calculate_note_keyon_time(replay_note)
            delay_ms = (replay_keyon - record_keyon) / 10.0
            relative_delay_ms = delay_ms - avg_delay_ms

            # è¯„çº§
            if delay_ms <= 20:
                color_intensity, grade_name = 0.8, "ä¼˜ç§€"
            elif delay_ms <= 30:
                color_intensity, grade_name = 0.6, "è‰¯å¥½"
            elif delay_ms <= 50:
                color_intensity, grade_name = 0.4, "ä¸€èˆ¬"
            elif delay_ms <= 1000:
                color_intensity, grade_name = 0.3, "è¾ƒå·®"
            else:
                color_intensity, grade_name = 0.2, "ä¸¥é‡"
        else:
            color_intensity, grade_name = 0.1, "å¤±è´¥"
            relative_delay_ms = 0.0 - avg_delay_ms

        return grade_name, color_intensity, delay_ms, relative_delay_ms

    def _get_error_note_index(self, error_note) -> int:
        """
        ä»é”™è¯¯noteä¸­è·å–éŸ³ç¬¦ç´¢å¼•
        """
        note_index = error_note.global_index if hasattr(error_note, 'global_index') and error_note.global_index >= 0 else None
        if note_index is None and hasattr(error_note, 'infos') and error_note.infos is not None and len(error_note.infos) > 0:
            note_index = error_note.infos[0].index
        return note_index

    def _is_valid_index(self, index: int, data_length: int) -> bool:
        """
        éªŒè¯ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
        """
        if index is None or index < 0:
            return False
        if index >= data_length:
            logger.warning(f"ç´¢å¼•è¶…å‡ºèŒƒå›´: {index} >= {data_length}")
            return False
        return True

    def _create_default_note(self, error_note, index: int):
        """
        åˆ›å»ºé»˜è®¤çš„noteå¯¹è±¡ç”¨äºæ˜¾ç¤º
        """
        class DefaultNote:
            def __init__(self, key_id, index):
                self.id = key_id
                self.offset = 0
                # ä¸ºé»˜è®¤noteåˆ›å»ºåŸºæœ¬çš„after_touchæ•°æ®
                self.after_touch = type('AfterTouch', (), {
                    'index': [index * 10, (index + 1) * 10]  # ç®€å•çš„å¼€å§‹å’Œç»“æŸæ—¶é—´
                })()

        return DefaultNote(error_note.keyId if hasattr(error_note, 'keyId') else 60, index)

    def _merge_matched_hover_info(self, record_bars: List[Dict], replay_bars: List[Dict], avg_delay_ms: float) -> None:
        """
        å°†åŒ¹é…çš„replayä¿¡æ¯åˆå¹¶åˆ°record barsçš„hoveræ–‡æœ¬ä¸­ï¼Œå®ç°ç»Ÿä¸€çš„æ‚¬åœæ˜¾ç¤ºã€‚

        Args:
            record_bars: å½•åˆ¶æ•°æ®çš„æ¡å½¢åˆ—è¡¨
            replay_bars: æ’­æ”¾æ•°æ®çš„æ¡å½¢åˆ—è¡¨
            avg_delay_ms: å¹³å‡å»¶æ—¶ï¼ˆæ¯«ç§’ï¼‰
        """
        # åŒ¹é…é€»è¾‘ï¼šæŒ‰é”®ä½å¯¹åº”ï¼ˆç¡®ä¿recordå’Œreplayçš„ç›¸åŒé”®ä½æ•°æ®é…å¯¹ï¼‰
        for record_bar in record_bars:
            # æŸ¥æ‰¾å¯¹åº”çš„replay barï¼ˆé€šè¿‡original_key_idåŒ¹é…ï¼‰
            replay_info = None
            record_key_id = record_bar.get('original_key_id')

            for replay_bar in replay_bars:
                if replay_bar.get('original_key_id') == record_key_id:
                    replay_info = replay_bar
                    break

            if replay_info:
                logger.info(f"åˆå¹¶é”®ä½ {record_key_id}: å½•åˆ¶å’Œæ’­æ”¾æ•°æ®é…å¯¹æˆåŠŸ")

                # è·å–recordçš„åŸå§‹æ–‡æœ¬
                original_text = record_bar.get('text', '')
                logger.info(f"åŸå§‹recordæ–‡æœ¬é•¿åº¦: {len(original_text)}")

                # æå–replayç›¸å…³çš„å®Œæ•´ä¿¡æ¯
                replay_velocity = replay_info.get('raw_velocity', 'N/A')
                replay_key_press = replay_info.get('t_on', 0) / 10
                replay_key_release = replay_info.get('t_off', 0) / 10
                replay_grade = replay_info.get('grade_name', 'æœªçŸ¥')
                replay_match_index = replay_info.get('match_index', 'N/A')
                replay_delay_ms = replay_info.get('delay_ms', 0.0)
                replay_relative_delay_ms = replay_info.get('relative_delay_ms', 0.0)
                replay_first_hammer = replay_info.get('first_hammer_time', 'N/A')

                logger.info(f"ğŸµ æ’­æ”¾æ•°æ®: é”¤é€Ÿ={replay_velocity}, ç­‰çº§={replay_grade}, å»¶æ—¶={replay_delay_ms:.2f}ms")

                # åœ¨recordçš„hoveræ–‡æœ¬ä¸­æ·»åŠ å®Œæ•´çš„replayä¿¡æ¯éƒ¨åˆ†
                replay_section = '<br><b>æ’­æ”¾æ•°æ®:</b><br>' + \
                            f'ç±»å‹: replay<br>' + \
                            f'é”®ä½: {record_key_id}<br>' + \
                            f'é”¤é€Ÿ: {replay_velocity}<br>' + \
                            f'ç­‰çº§: {replay_grade}<br>' + \
                            f'ç´¢å¼•: {replay_match_index}<br>' + \
                            f'ç»å¯¹å»¶æ—¶: {replay_delay_ms:.2f}ms<br>' + \
                            f'ç›¸å¯¹å»¶æ—¶: {replay_relative_delay_ms:+.2f}ms<br>' + \
                            f'å¹³å‡å»¶æ—¶: {avg_delay_ms:.2f}ms<br>' + \
                            f'é¦–é”¤æ—¶é—´: {replay_first_hammer} ({replay_first_hammer/10:.2f}ms)<br>' + \
                            f'æŒ‰é”®æŒ‰ä¸‹: {replay_key_press:.2f}ms<br>' + \
                            f'æŒ‰é”®é‡Šæ”¾: {replay_key_release:.2f}ms<br>'

                merged_text = original_text + replay_section

                record_bar['text'] = merged_text
                logger.debug(f"åˆå¹¶å®Œæˆ - æœ€ç»ˆæ–‡æœ¬é•¿åº¦: {len(merged_text)}, åŒ…å«æ’­æ”¾æ•°æ®: {'æ’­æ”¾æ•°æ®:' in merged_text}")

                # ä¸ºreplay baråˆ›å»ºç‹¬ç«‹çš„æ‚¬åœä¿¡æ¯
                replay_text = '<b>æ’­æ”¾æ•°æ®:</b><br>' + \
                             f'ç±»å‹: replay<br>' + \
                             f'é”®ä½: {record_key_id}<br>' + \
                             f'é”¤é€Ÿ: {replay_velocity}<br>' + \
                             f'ç­‰çº§: {replay_grade}<br>' + \
                             f'ç´¢å¼•: {replay_match_index}<br>' + \
                             f'ç»å¯¹å»¶æ—¶: {replay_delay_ms:.2f}ms<br>' + \
                             f'ç›¸å¯¹å»¶æ—¶: {replay_relative_delay_ms:+.2f}ms<br>' + \
                             f'å¹³å‡å»¶æ—¶: {avg_delay_ms:.2f}ms<br>' + \
                             f'é¦–é”¤æ—¶é—´: {replay_first_hammer} ({replay_first_hammer/10:.2f}ms)<br>' + \
                             f'æŒ‰é”®æŒ‰ä¸‹: {replay_key_press:.2f}ms<br>' + \
                             f'æŒ‰é”®é‡Šæ”¾: {replay_key_release:.2f}ms<br>'
                replay_info['text'] = replay_text
            else:
                logger.warning(f"é”®ä½ {record_key_id}: æœªæ‰¾åˆ°å¯¹åº”çš„æ’­æ”¾æ•°æ®ï¼Œæ— æ³•åˆå¹¶hoverä¿¡æ¯")
                # ä¸ºæ²¡æœ‰åŒ¹é…æ’­æ”¾æ•°æ®çš„record baræ·»åŠ æç¤º
                original_text = record_bar.get('text', '')
                no_replay_section = '<br><b>æ’­æ”¾æ•°æ®:</b><br>æœªæ‰¾åˆ°åŒ¹é…çš„æ’­æ”¾æ•°æ®<br>'
                record_bar['text'] = original_text + no_replay_section

    def _calculate_note_keyon_time(self, note) -> float:
        """
        è®¡ç®—éŸ³ç¬¦çš„æŒ‰é”®å¼€å§‹æ—¶é—´

        Args:
            note: Noteå¯¹è±¡

        Returns:
            float: keyonæ—¶é—´ï¼ˆ0.1mså•ä½ï¼‰
        """
        try:
            if hasattr(note, 'after_touch') and note.after_touch is not None and hasattr(note.after_touch, 'index') and len(note.after_touch.index) > 0:
                return note.after_touch.index[0] + getattr(note, 'offset', 0)
            elif hasattr(note, 'hammers') and note.hammers is not None and hasattr(note.hammers, 'index') and len(note.hammers.index) > 0:
                # å¦‚æœæ²¡æœ‰after_touchï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªé”¤å­çš„æ—¶é—´ä½œä¸ºkeyon
                return note.hammers.index[0] + getattr(note, 'offset', 0)
            else:
                return 0.0
        except (IndexError, AttributeError, TypeError):
            return 0.0

    def _extract_note_bars_for_multi(self, note, label: str, y_offset: float, color_intensity: float, algorithm_name: str, grade_name: str = "æœªçŸ¥", match_index: str = "N/A", delay_ms: float = 0.0, relative_delay_ms: float = 0.0, data_type: str = None) -> List[Dict]:
        """
        ä¸ºå¤šç®—æ³•æ¨¡å¼æå–éŸ³ç¬¦æ¡å½¢æ•°æ®

        Args:
            note: Noteå¯¹è±¡
            label: 'record' æˆ– 'replay'
            y_offset: Yè½´åç§»é‡
            color_intensity: é¢œè‰²å¼ºåº¦ (0.0-1.0)
            algorithm_name: ç®—æ³•åç§°
            data_type: æ•°æ®ç±»å‹ ('drop_hammer', 'multi_hammer', None)

        Returns:
            List[Dict]: æ¡å½¢æ•°æ®åˆ—è¡¨
        """
        bars = []
        if not note:
            logger.warning(f"âš ï¸ _extract_note_bars_for_multi: noteä¸ºç©º, label={label}, data_type={data_type}")
            return bars
        
        if not hasattr(note, 'hammers'):
            logger.warning(f"âš ï¸ _extract_note_bars_for_multi: noteæ²¡æœ‰hammerså±æ€§, key_id={getattr(note, 'id', 'N/A')}, label={label}, data_type={data_type}")
            return bars
        
        if note.hammers is None:
            logger.warning(f"âš ï¸ _extract_note_bars_for_multi: note.hammersä¸ºNone, key_id={getattr(note, 'id', 'N/A')}, label={label}, data_type={data_type}")
            return bars

        # åŠ›åº¦å€¼å°†åœ¨æ¯ä¸ªé”¤å­çš„å¾ªç¯ä¸­å•ç‹¬å¤„ç†

        # ä¸ºæ¯ä¸ªnoteåˆ›å»ºä¸€ä¸ªåŸºäºafter_touchäº‹ä»¶çš„bar
        bars = []
        key_id = getattr(note, 'id', 1)

        # è®¡ç®—åŸºäºafter_touchçš„äº‹ä»¶æ—¶é—´
        try:
            if hasattr(note, 'after_touch') and note.after_touch is not None and len(note.after_touch) > 0 and hasattr(note.after_touch, 'index') and len(note.after_touch.index) > 0:
                # ä½¿ç”¨after_touchçš„å¼€å§‹å’Œç»“æŸæ—¶é—´
                key_on_time = note.after_touch.index[0] + getattr(note, 'offset', 0)
                key_off_time = note.after_touch.index[-1] + getattr(note, 'offset', 0)
                logger.info(f"ğŸ”§ ä½¿ç”¨after_touchåˆ›å»ºbar: key_id={key_id}, æ—¶é—´èŒƒå›´=[{key_on_time/10:.1f}, {key_off_time/10:.1f}]ms")
            else:
                logger.warning(f"âš ï¸ noteç¼ºå°‘after_touchæ•°æ®: key_id={key_id}")
                return bars

            # åº”ç”¨Yè½´åç§»
            actual_key_id = key_id + y_offset
            if label == 'replay':
                actual_key_id += 0.2  # æ’­æ”¾æ•°æ®ç¨å¾®åç§»

            # ä½¿ç”¨ç¬¬ä¸€ä¸ªé”¤å‡»çš„åŠ›åº¦ä½œä¸ºä»£è¡¨åŠ›åº¦
            hammer_velocity = "N/A"
            hammer_velocity_norm = 0.5
            if hasattr(note, 'hammers') and note.hammers is not None and hasattr(note.hammers, 'values') and len(note.hammers.values) > 0:
                hammer_velocity = note.hammers.values[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªé”¤å‡»çš„åŠ›åº¦
                try:
                    hammer_velocity_norm = float(hammer_velocity) / 127.0
                except (ValueError, TypeError):
                    hammer_velocity_norm = 0.5

            # è°ƒè¯•ï¼šæ£€æŸ¥åæ ‡å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
            logger.info(f"ğŸ“ ç»˜åˆ¶æ•°æ®ç‚¹: key_id={key_id}, y_offset={y_offset}, label={label}, actual_key_id={actual_key_id:.2f}, æ—¶é—´èŒƒå›´=[{key_on_time/10:.1f}, {key_off_time/10:.1f}]ms")

            # å°†match_indexè½¬æ¢ä¸ºæ•´æ•°ä½œä¸ºsource_index
            source_index = 0
            try:
                if isinstance(match_index, str) and match_index != "N/A":
                    source_index = int(match_index)
                elif isinstance(match_index, int):
                    source_index = match_index
            except (ValueError, TypeError):
                source_index = 0

            bar = {
                't_on': float(key_on_time),
                't_off': float(key_off_time),
                'key_id': actual_key_id,           # ç”¨äºç»˜å›¾çš„å®é™…é”®ä½IDï¼ˆåŒ…å«åç§»ï¼‰
                'original_key_id': key_id,         # åŸå§‹æ•´æ•°é”®ä½IDï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
                'velocity': hammer_velocity_norm,  # æ ‡å‡†åŒ–åŠ›åº¦ (0.0-1.0) ç”¨äºé¢œè‰²æ˜ å°„
                'raw_velocity': hammer_velocity,   # åŸå§‹åŠ›åº¦ ç”¨äºæ˜¾ç¤º
                'color_intensity': color_intensity,
                'algorithm_name': algorithm_name,
                'label': label,
                'data_type': data_type,
                'hammer_index': 0,                # å›ºå®šä¸º0ï¼Œå› ä¸ºåªæœ‰ä¸€ä¸ªbar
                'grade_name': grade_name,         # è¯„ä»·ç­‰çº§
                'match_index': match_index,       # åŒ¹é…ç³»ç»Ÿè¯„çº§æ—¶çš„ç´¢å¼•
                'source_index': source_index,     # éŸ³ç¬¦åœ¨åŸå§‹æ•°æ®æ•°ç»„ä¸­çš„ç´¢å¼•ï¼ˆç”¨äºç‚¹å‡»å¤„ç†ï¼‰
                'delay_ms': delay_ms,             # å»¶æ—¶ï¼ˆæ¯«ç§’ï¼‰
                'relative_delay_ms': relative_delay_ms,  # ç›¸å¯¹å»¶æ—¶ï¼ˆå»¶æ—¶ - å¹³å‡å»¶æ—¶ï¼‰
                'first_hammer_time': key_on_time  # ç¬¬ä¸€ä¸ªé”¤å­çš„é”¤å‡»æ—¶é—´
            }

            # ä¸ºbarç”Ÿæˆhoveræ–‡æœ¬
            bar_type_suffix = ""
            if data_type == "drop_hammer":
                bar_type_suffix = " (ä¸¢é”¤)"
            elif data_type == "multi_hammer":
                bar_type_suffix = " (å¤šé”¤)"

            # æ ¹æ®æ•°æ®ç±»å‹æ„å»ºä¸åŒçš„hoveræ–‡æœ¬
            if label == 'record':
                # å½•åˆ¶æ•°æ®ä¸æ˜¾ç¤ºå»¶æ—¶ä¿¡æ¯
                bar['text'] = (
                    f'ç®—æ³•: {algorithm_name}<br>'
                    f'ç±»å‹: {label}{bar_type_suffix}<br>'
                    f'é”®ä½: {key_id}<br>'
                    f'é”¤é€Ÿ: {hammer_velocity}<br>'
                    f'ç­‰çº§: {grade_name}<br>'
                    f'ç´¢å¼•: {match_index}<br>'
                    f'æŒ‰é”®æŒ‰ä¸‹: {key_on_time/10:.2f}ms<br>'
                    f'æŒ‰é”®é‡Šæ”¾: {key_off_time/10:.2f}ms<br>'
                )
            else:
                # æ’­æ”¾æ•°æ®æ˜¾ç¤ºå»¶æ—¶ä¿¡æ¯ï¼ˆä¼šåœ¨åˆå¹¶æ—¶æ·»åŠ å¹³å‡å»¶æ—¶ï¼‰
                bar['text'] = (
                    f'ç®—æ³•: {algorithm_name}<br>'
                    f'ç±»å‹: {label}{bar_type_suffix}<br>'
                    f'é”®ä½: {key_id}<br>'
                    f'é”¤é€Ÿ: {hammer_velocity}<br>'
                    f'ç­‰çº§: {grade_name}<br>'
                    f'ç´¢å¼•: {match_index}<br>'
                    f'ç»å¯¹å»¶æ—¶: {delay_ms:.2f}ms<br>'
                    f'ç›¸å¯¹å»¶æ—¶: {relative_delay_ms:+.2f}ms<br>'
                    f'æŒ‰é”®æŒ‰ä¸‹: {key_on_time/10:.2f}ms<br>'
                    f'æŒ‰é”®é‡Šæ”¾: {key_off_time/10:.2f}ms<br>'
                )

            bars.append(bar)
            logger.info(f"âœ… ä¸º {data_type} æˆåŠŸåˆ›å»ºäº† 1 ä¸ªbar (åŸºäºafter_touchäº‹ä»¶)")

        except (TypeError, ValueError, AttributeError) as e:
            logger.warning(f"ğŸš« åˆ›å»º {data_type} barå¤±è´¥: {e}")
            return bars

        return bars
    
    def _apply_key_filter(self, data: List, key_filter: set) -> List:
        """åº”ç”¨æŒ‰é”®è¿‡æ»¤"""
        if not key_filter:
            return data
        return [note for note in data if note.keyId in key_filter]
    
    def _hex_to_rgba(self, hex_color: str, alpha: float) -> str:
        """
        å°†åå…­è¿›åˆ¶é¢œè‰²è½¬æ¢ä¸ºrgbaæ ¼å¼
        
        Args:
            hex_color: åå…­è¿›åˆ¶é¢œè‰²ï¼ˆå¦‚ '#1f77b4'ï¼‰
            alpha: é€æ˜åº¦ï¼ˆ0-1ï¼‰
            
        Returns:
            str: rgbaé¢œè‰²å­—ç¬¦ä¸²ï¼ˆå¦‚ 'rgba(31, 119, 180, 0.8)'ï¼‰
        """
        hex_color = hex_color.lstrip('#')
        r = int(hex_color[0:2], 16)
        g = int(hex_color[2:4], 16)
        b = int(hex_color[4:6], 16)
        return f'rgba({r}, {g}, {b}, {alpha})'
    
    def generate_multi_algorithm_offset_alignment_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆå¤šç®—æ³•åç§»å¯¹é½åˆ†æå›¾ï¼ˆå¹¶æ’æŸ±çŠ¶å›¾ï¼Œä¸åŒé¢œè‰²ï¼‰
        
        è¿”å›5ä¸ªç‹¬ç«‹çš„å›¾è¡¨ï¼Œæ¯ä¸ªå›¾è¡¨æ˜¾ç¤ºä¸€ä¸ªæŒ‡æ ‡ï¼š
        - ä¸­ä½æ•°åç§»
        - å‡å€¼åç§»
        - æ ‡å‡†å·®
        - æ–¹å·®
        - ç›¸å¯¹å»¶æ—¶
        
        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: åŒ…å«å›¾è¡¨ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
            æ¯ä¸ªå­—å…¸åŒ…å«: {'title': str, 'figure': go.Figure}
        """
        if not algorithms:
            logger.debug("â„¹ï¸ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å¤šç®—æ³•åç§»å¯¹é½åˆ†æå›¾ç”Ÿæˆ")
            # è¿”å›åŒ…å«5ä¸ªç©ºå›¾è¡¨çš„åˆ—è¡¨
            empty_fig = self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            return [
                {'title': 'ä¸­ä½æ•°åç§»', 'figure': empty_fig},
                {'title': 'å‡å€¼åç§»', 'figure': empty_fig},
                {'title': 'æ ‡å‡†å·®', 'figure': empty_fig},
                {'title': 'æ–¹å·®', 'figure': empty_fig},
                {'title': 'ç›¸å¯¹å»¶æ—¶', 'figure': empty_fig}
            ]
        
        try:
            # è¿‡æ»¤å‡ºå°±ç»ªçš„ç®—æ³•
            ready_algorithms = [alg for alg in algorithms if alg.is_ready()]
            if not ready_algorithms:
                logger.warning("âš ï¸ æ²¡æœ‰å°±ç»ªçš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆå¤šç®—æ³•åç§»å¯¹é½åˆ†æå›¾")
                empty_fig = self._create_empty_plot("æ²¡æœ‰å°±ç»ªçš„ç®—æ³•")
                return [
                    {'title': 'ä¸­ä½æ•°åç§»', 'figure': empty_fig},
                    {'title': 'å‡å€¼åç§»', 'figure': empty_fig},
                    {'title': 'æ ‡å‡†å·®', 'figure': empty_fig},
                    {'title': 'æ–¹å·®', 'figure': empty_fig},
                    {'title': 'ç›¸å¯¹å»¶æ—¶', 'figure': empty_fig}
                ]
            
            logger.info(f"ğŸ“Š å¼€å§‹ç”Ÿæˆå¤šç®—æ³•åç§»å¯¹é½åˆ†æå›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            
            # ä¸ºæ¯ä¸ªç®—æ³•åˆ†é…é¢œè‰²ï¼ˆä½¿ç”¨å…¨å±€é¢œè‰²æ–¹æ¡ˆï¼‰
            colors = ALGORITHM_COLOR_PALETTE
            
            # æ”¶é›†æ‰€æœ‰ç®—æ³•çš„æ•°æ®
            all_algorithms_data = []
            
            for alg_idx, algorithm in enumerate(ready_algorithms):
                algorithm_name = algorithm.metadata.algorithm_name
                
                if not algorithm.analyzer:
                    logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' æ²¡æœ‰åˆ†æå™¨ï¼Œè·³è¿‡")
                    continue
                
                # è·å–ç²¾ç¡®åç§»å¯¹é½æ•°æ®ï¼ˆè¯¯å·® â‰¤ 50msï¼‰
                try:
                    # ä»analyzerè·å–ç²¾ç¡®åç§»æ•°æ®
                    offset_data = algorithm.analyzer.get_precision_offset_alignment_data()
                    
                    # æŒ‰æŒ‰é”®IDåˆ†ç»„å¹¶è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                    from collections import defaultdict
                    
                    # è®¡ç®—è¯¥ç®—æ³•çš„å¹³å‡å»¶æ—¶ï¼ˆç”¨äºè®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼‰
                    me_0_1ms = algorithm.analyzer.get_mean_error() if hasattr(algorithm.analyzer, 'get_mean_error') else 0.0
                    mean_delay = me_0_1ms / 10.0  # å¹³å‡å»¶æ—¶ï¼ˆmsï¼Œå¸¦ç¬¦å·ï¼‰
                    
                    # æŒ‰æŒ‰é”®IDåˆ†ç»„æœ‰æ•ˆåŒ¹é…çš„åç§»æ•°æ®ï¼ˆåªä½¿ç”¨keyon_offsetï¼‰
                    key_groups = defaultdict(list)
                    key_groups_relative = defaultdict(list)  # ç”¨äºå­˜å‚¨ç›¸å¯¹å»¶æ—¶
                    for item in offset_data:
                        key_id = item.get('key_id', 'N/A')
                        keyon_offset = item.get('keyon_offset', 0)  # åŸå§‹å»¶æ—¶ï¼ˆ0.1mså•ä½ï¼Œå¸¦ç¬¦å·ï¼‰
                        keyon_offset_abs = abs(keyon_offset)  # ç»å¯¹å€¼ç”¨äºå…¶ä»–ç»Ÿè®¡
                        keyon_offset_ms = keyon_offset / 10.0  # è½¬æ¢ä¸ºms
                        relative_delay = keyon_offset_ms - mean_delay  # ç›¸å¯¹å»¶æ—¶
                        key_groups[key_id].append(keyon_offset_abs)
                        key_groups_relative[key_id].append(relative_delay)
                    
                    # æå–æ•°æ®
                    algorithm_key_ids = []
                    algorithm_median = []
                    algorithm_mean = []
                    algorithm_std = []
                    algorithm_variance = []
                    algorithm_relative_mean = []  # ç›¸å¯¹å»¶æ—¶çš„å‡å€¼
                    
                    for key_id, offsets in key_groups.items():
                        if offsets:
                            try:
                                key_id_int = int(key_id)
                                algorithm_key_ids.append(key_id_int)
                                algorithm_median.append(np.median(offsets) / 10.0)  # è½¬æ¢ä¸ºms
                                algorithm_mean.append(np.mean(offsets) / 10.0)  # è½¬æ¢ä¸ºms
                                algorithm_std.append(np.std(offsets) / 10.0)  # è½¬æ¢ä¸ºms
                                algorithm_variance.append(np.var(offsets) / 100.0)  # è½¬æ¢ä¸ºmsÂ²
                                
                                # è®¡ç®—ç›¸å¯¹å»¶æ—¶çš„å‡å€¼
                                if key_id in key_groups_relative:
                                    relative_delays = key_groups_relative[key_id]
                                    algorithm_relative_mean.append(np.mean(relative_delays))
                                else:
                                    algorithm_relative_mean.append(0.0)
                            except (ValueError, TypeError):
                                continue
                    
                    if algorithm_key_ids:
                        all_algorithms_data.append({
                            'name': algorithm_name,
                            'display_name': algorithm.metadata.display_name,  # æ˜¾ç¤ºåç§°
                            'key_ids': algorithm_key_ids,
                            'median': algorithm_median,
                            'mean': algorithm_mean,
                            'std': algorithm_std,
                            'variance': algorithm_variance,
                            'relative_mean': algorithm_relative_mean,  # ç›¸å¯¹å»¶æ—¶çš„å‡å€¼
                            'color': colors[alg_idx % len(colors)],
                            'analyzer': algorithm.analyzer
                        })
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–ç®—æ³• '{algorithm_name}' çš„åç§»å¯¹é½æ•°æ®å¤±è´¥: {e}")
                    continue
            
            if not all_algorithms_data:
                logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„åç§»å¯¹é½æ•°æ®ï¼Œæ— æ³•ç”ŸæˆæŸ±çŠ¶å›¾")
                empty_fig = self._create_empty_plot("æ²¡æœ‰æœ‰æ•ˆçš„åç§»å¯¹é½æ•°æ®")
                return [
                    {'title': 'ä¸­ä½æ•°åç§»', 'figure': empty_fig},
                    {'title': 'å‡å€¼åç§»', 'figure': empty_fig},
                    {'title': 'æ ‡å‡†å·®', 'figure': empty_fig},
                    {'title': 'æ–¹å·®', 'figure': empty_fig},
                    {'title': 'ç›¸å¯¹å»¶æ—¶', 'figure': empty_fig}
                ]
            
            # å‡†å¤‡ç‹¬ç«‹çš„å›¾è¡¨åˆ—è¡¨
            figures_list = []
            
            # å®šä¹‰5ä¸ªæŒ‡æ ‡çš„é…ç½®
            metrics = [
                ('ä¸­ä½æ•°åç§»', 'median', 'ms', 'median'),
                ('å‡å€¼åç§»', 'mean', 'ms', 'mean'),
                ('æ ‡å‡†å·®', 'std', 'ms', 'std'),
                ('æ–¹å·®', 'variance', 'msÂ²', 'variance'),
                ('ç›¸å¯¹å»¶æ—¶', 'relative_mean', 'ms', 'relative')
            ]
            
            # è®¡ç®—xè½´ä½ç½®é€»è¾‘ï¼ˆgrouped bar chartï¼‰
            # è·å–æ‰€æœ‰é”®ä½çš„å¹¶é›†
            all_key_ids = set()
            for alg_data in all_algorithms_data:
                all_key_ids.update(alg_data['key_ids'])
            all_key_ids = sorted(list(all_key_ids))
            
            # ä¸ºæ¯ä¸ªç®—æ³•è®¡ç®—xè½´ä½ç½®
            num_algorithms = len(all_algorithms_data)
            bar_width = 0.8 / num_algorithms
            
            min_key_id = max(1, min(all_key_ids)) if all_key_ids else 1
            max_key_id = max(all_key_ids) if all_key_ids else 90
            
            for metric_name, data_key, unit, legend_group_suffix in metrics:
                fig = go.Figure()
                
                for alg_idx, alg_data in enumerate(all_algorithms_data):
                    algorithm_name = alg_data['name']
                    display_name = alg_data.get('display_name', algorithm_name)
                    color = alg_data['color']
                    
                    # å‡†å¤‡æ•°æ®
                    x_positions = []
                    y_values = []
                    
                    key_to_val = dict(zip(alg_data['key_ids'], alg_data[data_key]))
                    
                    for key_id in all_key_ids:
                        if key_id in alg_data['key_ids']:
                            x_positions.append(key_id + (alg_idx - num_algorithms / 2 + 0.5) * bar_width)
                            y_values.append(key_to_val[key_id])
                        # å¦‚æœæ²¡æœ‰æ•°æ®åˆ™ä¸æ·»åŠ 
                    
                    if not x_positions:
                        continue
                        
                    # æ·»åŠ æŸ±çŠ¶å›¾trace
                    fig.add_trace(go.Bar(
                        x=x_positions,
                        y=y_values,
                        name=display_name,
                        marker_color=color,
                        opacity=0.8,
                        width=bar_width,
                        text=[f'{val:.2f}' for val in y_values],
                        textposition='outside',
                        textfont=dict(size=8),
                        showlegend=True,
                        legend='legend',  # é»˜è®¤legend
                        legendgroup=algorithm_name, # æ‰€æœ‰å›¾è¡¨å…±ç”¨legendgroupï¼Œå®ç°è”åŠ¨æ˜¾ç¤º/éšè—
                        hovertemplate=f'ç®—æ³•: {display_name}<br>é”®ä½: %{{x:.0f}}<br>{metric_name}: %{{y:.2f}}{unit}<extra></extra>'
                    ))
                
                # è®¾ç½®å›¾è¡¨å¸ƒå±€
                fig.update_layout(
                    title=dict(text=metric_name, x=0.5, xanchor='center'),
                    xaxis_title='é”®ä½ID',
                    yaxis_title=f'{metric_name} ({unit})',
                    xaxis=dict(
                        tickmode='linear',
                        tick0=min_key_id,
                        dtick=1,
                        range=[min_key_id - 1, max_key_id + 1]
                    ),
                    yaxis=dict(
                        showgrid=True,
                        gridcolor='lightgray',
                        gridwidth=1
                    ),
                    template='simple_white',
                    showlegend=True,
                    legend=dict(
                        x=0.01, y=1.12, xanchor='left', yanchor='top',
                        bgcolor='rgba(255,255,255,0.8)', bordercolor='rgba(0,0,0,0.2)', borderwidth=1,
                        orientation='h', font=dict(size=11),
                        title_text=metric_name
                    ),
                    margin=dict(l=60, r=40, t=100, b=60),
                    height=500,  # æ¯ä¸ªå›¾è¡¨çš„ç‹¬ç«‹é«˜åº¦
                    paper_bgcolor='rgba(0,0,0,0)',
                    plot_bgcolor='rgba(0,0,0,0)',
                    font=dict(size=12)
                )
                
                figures_list.append({
                    'title': metric_name,
                    'figure': fig
                })
            
            logger.info(f"âœ… å¤šç®—æ³•åç§»å¯¹é½åˆ†æå›¾ç”ŸæˆæˆåŠŸï¼Œå…± {len(figures_list)} ä¸ªç‹¬ç«‹å›¾è¡¨")
            return figures_list
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¤šç®—æ³•åç§»å¯¹é½åˆ†æå›¾å¤±è´¥: {e}")
            
            logger.error(traceback.format_exc())
            empty_fig = self._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
            return [
                {'title': 'ç”Ÿæˆå¤±è´¥', 'figure': empty_fig}
            ]
    
    def export_multi_algorithm_delay_histogram_data_to_csv(self, algorithms: List[AlgorithmDataset], filename: str = None) -> Optional[List[str]]:
        """
        å°†å¤šç®—æ³•å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾çš„æ•°æ®å¯¼å‡ºä¸ºCSVæ–‡ä»¶ï¼ŒæŒ‰æ–‡ä»¶ååˆ†ç»„åˆ†åˆ«å­˜å‚¨

        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            filename: è‡ªå®šä¹‰æ–‡ä»¶åå‰ç¼€ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ

        Returns:
            List[str]: CSVæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœå¯¼å‡ºå¤±è´¥åˆ™è¿”å›None
        """
        try:
            import csv
            import os
            from datetime import datetime

            if not algorithms:
                logger.debug("â„¹ï¸ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å¯¼å‡º")
                return None

            # è¿‡æ»¤å‡ºå°±ç»ªçš„ç®—æ³•
            ready_algorithms = [alg for alg in algorithms if alg.is_ready()]
            if not ready_algorithms:
                logger.warning("âš ï¸ æ²¡æœ‰å°±ç»ªçš„ç®—æ³•ï¼Œæ— æ³•å¯¼å‡º")
                return None

            # æŒ‰æ–‡ä»¶ååˆ†ç»„æ”¶é›†æ•°æ®
            csv_data_by_filename = {}

            for algorithm in ready_algorithms:
                algorithm_name = algorithm.metadata.algorithm_name
                display_name = algorithm.metadata.display_name
                filename_display = algorithm.metadata.filename

                if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
                    logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' æ²¡æœ‰åˆ†æå™¨ï¼Œè·³è¿‡")
                    continue

                try:
                    # ä»analyzerè·å–ç²¾ç¡®åç§»æ•°æ®ï¼ˆè¯¯å·® â‰¤ 50msï¼‰
                    offset_data = algorithm.analyzer.get_precision_offset_alignment_data()

                    if not offset_data:
                        logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' æ²¡æœ‰åŒ¹é…æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    # è·å–matched_pairsä»¥ä¾¿æŸ¥æ‰¾æŒ‰é”®ID
                    matched_pairs = algorithm.analyzer.get_matched_pairs() if hasattr(algorithm.analyzer, 'get_matched_pairs') else []
                    record_note_dict = {r_idx: r_note for r_idx, _, r_note, _ in matched_pairs} if matched_pairs else {}
                    replay_note_dict = {p_idx: p_note for _, p_idx, _, p_note in matched_pairs} if matched_pairs else {}

                    # æ­¥éª¤1ï¼šæå–åŸå§‹å»¶æ—¶æ•°æ®ï¼ˆå¸¦ç¬¦å·çš„keyon_offsetï¼‰
                    absolute_delays_ms = [item.get('keyon_offset', 0.0) / 10.0 for item in offset_data]

                    if not absolute_delays_ms:
                        logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' æ²¡æœ‰æœ‰æ•ˆå»¶æ—¶æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    # æ­¥éª¤2ï¼šè®¡ç®—è¯¥ç®—æ³•çš„å¹³å‡å»¶æ—¶ï¼ˆç”¨äºè®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼‰
                    n = len(absolute_delays_ms)
                    mean_delay_ms = sum(absolute_delays_ms) / n

                    # åˆå§‹åŒ–è¯¥æ–‡ä»¶åçš„åˆ—è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                    if filename_display not in csv_data_by_filename:
                        csv_data_by_filename[filename_display] = []

                    # ä¸ºæ¯ä¸ªæ•°æ®ç‚¹åˆ›å»ºè®°å½•
                    for i, item in enumerate(offset_data):
                        absolute_delay = absolute_delays_ms[i]
                        relative_delay = absolute_delay - mean_delay_ms

                        # è·å–å½•åˆ¶å’Œæ’­æ”¾æŒ‰é”®ID
                        record_index = item.get('record_index', -1)
                        replay_index = item.get('replay_index', -1)
                        record_key_id = record_note_dict.get(record_index, None)
                        replay_key_id = replay_note_dict.get(replay_index, None)

                        record_key_id_value = record_key_id.id if record_key_id and hasattr(record_key_id, 'id') else item.get('key_id', 'N/A')
                        replay_key_id_value = replay_key_id.id if replay_key_id and hasattr(replay_key_id, 'id') else item.get('key_id', 'N/A')

                        csv_data_by_filename[filename_display].append({
                            'ç®—æ³•åç§°': algorithm_name,
                            'æ˜¾ç¤ºåç§°': display_name,
                            'å½•åˆ¶ç´¢å¼•': record_index,
                            'å›æ”¾ç´¢å¼•': replay_index,
                            'å½•åˆ¶æŒ‰é”®ID': record_key_id_value,
                            'å›æ”¾æŒ‰é”®ID': replay_key_id_value,
                            'å½•åˆ¶æŒ‰é”®æ—¶é—´(ms)': item.get('record_keyon', 0) / 10.0,
                            'å›æ”¾æŒ‰é”®æ—¶é—´(ms)': item.get('replay_keyon', 0) / 10.0,
                            'ç»å¯¹å»¶æ—¶(ms)': absolute_delay,
                            'ç®—æ³•å¹³å‡å»¶æ—¶(ms)': mean_delay_ms,
                            'ç›¸å¯¹å»¶æ—¶(ms)': relative_delay
                        })

                except Exception as e:
                    logger.warning(f"âš ï¸ å¤„ç†ç®—æ³• '{algorithm_name}' æ—¶å‡ºé”™: {e}")
                    continue

            if not csv_data_by_filename:
                logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œæ— æ³•å¯¼å‡º")
                return None

            # ç”Ÿæˆæ–‡ä»¶åå‰ç¼€
            if filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename_prefix = f"delay_histogram_data_{timestamp}"
            else:
                # å¦‚æœæä¾›äº†è‡ªå®šä¹‰æ–‡ä»¶åï¼Œå»æ‰æ‰©å±•åä½œä¸ºå‰ç¼€
                filename_prefix = filename.replace('.csv', '')

            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = "exports"
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)

            # å†™å…¥å¤šä¸ªCSVæ–‡ä»¶
            fieldnames = ['ç®—æ³•åç§°', 'æ˜¾ç¤ºåç§°', 'å½•åˆ¶ç´¢å¼•', 'å›æ”¾ç´¢å¼•',
                         'å½•åˆ¶æŒ‰é”®ID', 'å›æ”¾æŒ‰é”®ID',
                         'å½•åˆ¶æŒ‰é”®æ—¶é—´(ms)', 'å›æ”¾æŒ‰é”®æ—¶é—´(ms)',
                         'ç»å¯¹å»¶æ—¶(ms)', 'ç®—æ³•å¹³å‡å»¶æ—¶(ms)', 'ç›¸å¯¹å»¶æ—¶(ms)']

            exported_files = []
            total_records = 0

            for filename_key, csv_data in csv_data_by_filename.items():
                # ä¸ºæ¯ä¸ªæ–‡ä»¶åç”Ÿæˆå•ç‹¬çš„CSVæ–‡ä»¶
                safe_filename = "".join(c for c in filename_key if c.isalnum() or c in (' ', '-', '_')).rstrip()
                csv_filename = f"{filename_prefix}_{safe_filename}.csv"
                filepath = os.path.join(output_dir, csv_filename)

                with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(csv_data)

                exported_files.append(filepath)
                total_records += len(csv_data)
                logger.info(f"âœ… æ–‡ä»¶ '{filename_key}' çš„å»¶æ—¶åˆ†å¸ƒæ•°æ®å·²å¯¼å‡ºåˆ°: {filepath}")
                logger.info(f"ğŸ“Š å¯¼å‡º {len(csv_data)} æ¡è®°å½•")

            logger.info(f"âœ… å…±å¯¼å‡º {len(exported_files)} ä¸ªCSVæ–‡ä»¶ï¼Œæ€»è®¡ {total_records} æ¡è®°å½•")
            return exported_files

        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºå¤šç®—æ³•å»¶æ—¶åˆ†å¸ƒæ•°æ®å¤±è´¥: {e}")
            return None

    def export_multi_algorithm_pre_match_data_to_csv(self, algorithms: List[AlgorithmDataset], filename: str = None) -> Optional[List[str]]:
        """
        å¯¼å‡ºå¤šç®—æ³•åŒ¹é…å‰çš„æ•°æ®åˆ°CSVæ–‡ä»¶ï¼ˆæµ‹è¯•åŠŸèƒ½ï¼‰

        åœ¨æŒ‰é”®åŒ¹é…ä¹‹å‰è¿›è¡Œç¼–å·ï¼Œä¸ºæ¯ä¸ªç®—æ³•çš„å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦åˆ†åˆ«åˆ†é…ç´¢å¼•å¹¶å¯¼å‡ºCSVã€‚

        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            filename: è‡ªå®šä¹‰æ–‡ä»¶åå‰ç¼€ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ

        Returns:
            List[str]: CSVæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœå¯¼å‡ºå¤±è´¥åˆ™è¿”å›None
        """
        try:
            import csv
            import os
            from datetime import datetime

            if not algorithms:
                logger.debug("â„¹ï¸ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å¯¼å‡º")
                return None

            # è¿‡æ»¤å‡ºå°±ç»ªçš„ç®—æ³•
            ready_algorithms = [alg for alg in algorithms if alg.is_ready()]
            if not ready_algorithms:
                logger.warning("âš ï¸ æ²¡æœ‰å°±ç»ªçš„ç®—æ³•ï¼Œæ— æ³•å¯¼å‡º")
                return None

            # ç”Ÿæˆæ–‡ä»¶åå‰ç¼€
            if filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename_prefix = f"pre_match_data_{timestamp}"
            else:
                # å¦‚æœæä¾›äº†è‡ªå®šä¹‰æ–‡ä»¶åï¼Œå»æ‰æ‰©å±•åä½œä¸ºå‰ç¼€
                filename_prefix = filename.replace('.csv', '')

            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = "exports"
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)

            # å†™å…¥å¤šä¸ªCSVæ–‡ä»¶
            fieldnames = ['ç®—æ³•åç§°', 'æ˜¾ç¤ºåç§°', 'å½•åˆ¶ç´¢å¼•', 'å›æ”¾ç´¢å¼•',
                         'å½•åˆ¶æŒ‰é”®ID', 'å›æ”¾æŒ‰é”®ID',
                         'å½•åˆ¶æŒ‰é”®æ—¶é—´(ms)', 'å›æ”¾æŒ‰é”®æ—¶é—´(ms)']

            exported_files = []
            total_records = 0

            for algorithm in ready_algorithms:
                algorithm_name = algorithm.metadata.algorithm_name
                display_name = algorithm.metadata.display_name
                filename_display = algorithm.metadata.filename

                # è·å–åŒ¹é…å‰çš„æ•°æ®ï¼ˆç©ºæ•°æ®è¿‡æ»¤ä¹‹åï¼ŒæŒ‰é”®åŒ¹é…ä¹‹å‰ï¼‰
                initial_valid_record = algorithm.analyzer.get_initial_valid_record_data() if hasattr(algorithm.analyzer, 'get_initial_valid_record_data') else None
                initial_valid_replay = algorithm.analyzer.get_initial_valid_replay_data() if hasattr(algorithm.analyzer, 'get_initial_valid_replay_data') else None

                if not initial_valid_record or not initial_valid_replay:
                    logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' æ²¡æœ‰åŒ¹é…å‰çš„æ•°æ®ï¼Œè·³è¿‡")
                    continue

                # ä¸ºæ¯ä¸ªæ–‡ä»¶åç”Ÿæˆå•ç‹¬çš„CSVæ–‡ä»¶
                safe_filename = "".join(c for c in filename_display if c.isalnum() or c in (' ', '-', '_')).rstrip()
                csv_filename = f"{filename_prefix}_{safe_filename}.csv"
                filepath = os.path.join(output_dir, csv_filename)

                csv_data = []

                # è·å–å½•åˆ¶å’Œæ’­æ”¾æ•°æ®çš„æ•°é‡
                record_count = len(initial_valid_record)
                replay_count = len(initial_valid_replay)

                # ä½¿ç”¨è¾ƒå¤§çš„æ•°é‡ä½œä¸ºè¡Œæ•°
                max_count = max(record_count, replay_count)

                # å¹¶æ’ç¼–å·å½•åˆ¶å’Œæ’­æ”¾ç´¢å¼•
                for i in range(max_count):
                    # å½•åˆ¶æ•°æ®
                    if i < record_count:
                        record_note = initial_valid_record[i]
                        record_index = i  # å½•åˆ¶ç´¢å¼•
                        record_key_id = getattr(record_note, 'id', 'N/A')

                        # è·å–å½•åˆ¶éŸ³ç¬¦çš„æ—¶é—´ä¿¡æ¯
                        record_keyon_time = 0
                        if hasattr(record_note, 'after_touch') and record_note.after_touch is not None and not record_note.after_touch.empty:
                            record_keyon_time = record_note.after_touch.index[0] + record_note.offset
                        elif hasattr(record_note, 'hammers') and record_note.hammers is not None and not record_note.hammers.empty:
                            record_keyon_time = record_note.hammers.index[0] + record_note.offset
                    else:
                        record_index = -1  # æ²¡æœ‰å½•åˆ¶æ•°æ®
                        record_key_id = 'N/A'
                        record_keyon_time = 0

                    # æ’­æ”¾æ•°æ®
                    if i < replay_count:
                        replay_note = initial_valid_replay[i]
                        replay_index = i  # æ’­æ”¾ç´¢å¼•
                        replay_key_id = getattr(replay_note, 'id', 'N/A')

                        # è·å–æ’­æ”¾éŸ³ç¬¦çš„æ—¶é—´ä¿¡æ¯
                        replay_keyon_time = 0
                        if hasattr(replay_note, 'after_touch') and replay_note.after_touch is not None and not replay_note.after_touch.empty:
                            replay_keyon_time = replay_note.after_touch.index[0] + replay_note.offset
                        elif hasattr(replay_note, 'hammers') and replay_note.hammers is not None and not replay_note.hammers.empty:
                            replay_keyon_time = replay_note.hammers.index[0] + replay_note.offset
                    else:
                        replay_index = -1  # æ²¡æœ‰æ’­æ”¾æ•°æ®
                        replay_key_id = 'N/A'
                        replay_keyon_time = 0

                    csv_data.append({
                        'ç®—æ³•åç§°': algorithm_name,
                        'æ˜¾ç¤ºåç§°': display_name,
                        'å½•åˆ¶ç´¢å¼•': record_index,
                        'å›æ”¾ç´¢å¼•': replay_index,
                        'å½•åˆ¶æŒ‰é”®ID': record_key_id,
                        'å›æ”¾æŒ‰é”®ID': replay_key_id,
                        'å½•åˆ¶æŒ‰é”®æ—¶é—´(ms)': record_keyon_time / 10.0 if record_keyon_time else 0,
                        'å›æ”¾æŒ‰é”®æ—¶é—´(ms)': replay_keyon_time / 10.0 if replay_keyon_time else 0
                    })

                # å†™å…¥CSVæ–‡ä»¶
                with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(csv_data)

                exported_files.append(filepath)
                total_records += len(csv_data)
                logger.info(f"âœ… ç®—æ³• '{algorithm_name}' çš„åŒ¹é…å‰æ•°æ®å·²å¯¼å‡ºåˆ°: {filepath}")
                logger.info(f"ğŸ“Š å½•åˆ¶éŸ³ç¬¦: {len(initial_valid_record)} ä¸ª, æ’­æ”¾éŸ³ç¬¦: {len(initial_valid_replay)} ä¸ª")
                logger.info(f"ğŸ“Š å¯¼å‡ºè®°å½•æ•°: {len(csv_data)} æ¡")

            logger.info(f"âœ… å…±å¯¼å‡º {len(exported_files)} ä¸ªCSVæ–‡ä»¶ï¼Œæ€»è®¡ {total_records} æ¡è®°å½•")
            return exported_files

        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºå¤šç®—æ³•åŒ¹é…å‰æ•°æ®å¤±è´¥: {e}")
            return None

    def generate_multi_algorithm_delay_histogram_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆå åŠ æ˜¾ç¤ºï¼Œä¸åŒé¢œè‰²ï¼Œå›¾ä¾‹æ§åˆ¶ï¼‰

        ä¸ºæ¯ä¸ªç®—æ³•ç”Ÿæˆç›´æ–¹å›¾å’Œæ­£æ€æ‹Ÿåˆæ›²çº¿ï¼Œä½¿ç”¨ä¸åŒé¢œè‰²åŒºåˆ†ï¼Œå åŠ æ˜¾ç¤ºåœ¨åŒä¸€å›¾è¡¨ä¸­ã€‚

        æ•°æ®ç­›é€‰ï¼šåªä½¿ç”¨è¯¯å·®â‰¤50msçš„æŒ‰é”®æ•°æ®
        æ•°æ®å¤„ç†ï¼š
        - åªä½¿ç”¨è¯¯å·®â‰¤50msçš„æŒ‰é”®æ•°æ®
        - ç›¸å¯¹æ—¶å»¶ï¼ˆåŸå§‹æ—¶å»¶ - å¹³å‡æ—¶å»¶ï¼‰ç”¨äºåˆ†å¸ƒå›¾ï¼šæ¶ˆé™¤æ•´ä½“åç§»ï¼Œæ›´å…¬å¹³åœ°æ¯”è¾ƒç¨³å®šæ€§
        - å‡å€¼åç§»ï¼šæ˜¾ç¤ºåŸå§‹å»¶æ—¶çš„å¹³å‡å€¼ï¼Œåæ˜ ç®—æ³•æ•´ä½“å»¶æ—¶å€¾å‘
        - æ–¹å·®ï¼šåŸºäºåŸå§‹å»¶æ—¶è®¡ç®—ï¼Œåæ˜ ç»å¯¹ç¨³å®šæ€§
        - ç›¸å¯¹å»¶æ—¶åˆ†å¸ƒå›¾å‡å€¼æ¥è¿‘0ï¼Œæ ‡å‡†å·®åæ˜ ç›¸å¯¹ç¨³å®šæ€§
        - å»¶æ—¶æœ‰æ­£æœ‰è´Ÿï¼Œåæ˜ ç›¸å¯¹äºå¹³å‡æ°´å¹³çš„åå·®

        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨

        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        if not algorithms:
            logger.debug("â„¹ï¸ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å¤šç®—æ³•å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾ç”Ÿæˆ")
            return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
        
        try:
            # è¿‡æ»¤å‡ºå°±ç»ªçš„ç®—æ³•
            ready_algorithms = [alg for alg in algorithms if alg.is_ready()]
            if not ready_algorithms:
                logger.warning("âš ï¸ æ²¡æœ‰å°±ç»ªçš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆå¤šç®—æ³•å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾")
                return self._create_empty_plot("æ²¡æœ‰å°±ç»ªçš„ç®—æ³•")
            
            logger.info(f"ğŸ“Š å¼€å§‹ç”Ÿæˆå¤šç®—æ³•å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            
            # ä¸ºæ¯ä¸ªç®—æ³•åˆ†é…é¢œè‰²ï¼ˆä½¿ç”¨å…¨å±€é¢œè‰²æ–¹æ¡ˆï¼‰
            colors = ALGORITHM_COLOR_PALETTE
            
            
            
            fig = go.Figure()
            
            # æ”¶é›†æ‰€æœ‰ç®—æ³•çš„æ•°æ®
            all_delays = []  # ç”¨äºç¡®å®šå…¨å±€èŒƒå›´

            for alg_idx, algorithm in enumerate(ready_algorithms):
                algorithm_name = algorithm.metadata.algorithm_name
                display_name = algorithm.metadata.display_name
                filename = algorithm.metadata.filename

                # åˆ›å»ºæ›´å…·æè¿°æ€§çš„å›¾æ³¨åç§°ï¼šç®—æ³•å (æ–‡ä»¶å)
                descriptive_name = f"{display_name} ({filename})"

                if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
                    logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰åˆ†æå™¨æˆ–åŒ¹é…å™¨ï¼Œè·³è¿‡")
                    continue
                
                try:
                    # ä»analyzerè·å–ç²¾ç¡®åç§»æ•°æ®ï¼ˆè¯¯å·® â‰¤ 50msï¼‰
                    offset_data = algorithm.analyzer.get_precision_offset_alignment_data()

                    if not offset_data:
                        logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' æ²¡æœ‰ç²¾ç¡®åŒ¹é…æ•°æ®ï¼ˆâ‰¤50msï¼‰ï¼Œè·³è¿‡")
                        continue

                    # æå–ç²¾ç¡®åŒ¹é…çš„åŸå§‹å»¶æ—¶æ•°æ®ï¼ˆå¸¦ç¬¦å·çš„keyon_offsetï¼‰
                    absolute_delays_ms = [item.get('keyon_offset', 0.0) / 10.0 for item in offset_data]

                    if not absolute_delays_ms:
                        logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' ç­›é€‰åæ²¡æœ‰æœ‰æ•ˆå»¶æ—¶æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    # æ­¥éª¤3ï¼šè®¡ç®—è¯¥ç®—æ³•çš„å¹³å‡å»¶æ—¶ï¼ˆå‡å€¼åç§»ï¼‰
                    n = len(absolute_delays_ms)
                    mean_delay_ms = sum(absolute_delays_ms) / n

                    # æ­¥éª¤4ï¼šè®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼ˆæ¶ˆé™¤æ•´ä½“åç§»ï¼Œç”¨äºåˆ†å¸ƒå›¾ï¼‰
                    # ç›¸å¯¹å»¶æ—¶ = åŸå§‹å»¶æ—¶ - å¹³å‡å»¶æ—¶
                    # è¿™æ ·å‡å€¼æ¥è¿‘0ï¼Œæ›´é€‚åˆè¯„ä¼°ç›¸å¯¹ç¨³å®šæ€§
                    relative_delays_ms = [delay - mean_delay_ms for delay in absolute_delays_ms]

                    all_delays.extend(relative_delays_ms)

                    # æ­¥éª¤5ï¼šè®¡ç®—ç»Ÿè®¡é‡
                    # å‡å€¼åç§»ï¼šä½¿ç”¨åŸå§‹å»¶æ—¶çš„å¹³å‡å€¼ï¼Œåæ˜ ç®—æ³•æ•´ä½“çš„å»¶æ—¶å€¾å‘
                    mean_offset = mean_delay_ms

                    # æ–¹å·®ï¼šä½¿ç”¨åŸå§‹å»¶æ—¶çš„æ–¹å·®ï¼Œåæ˜ ç»å¯¹ç¨³å®šæ€§
                    if n > 1:
                        var_offset = sum((x - mean_delay_ms) ** 2 for x in absolute_delays_ms) / (n - 1)
                        std_offset = var_offset ** 0.5
                    else:
                        var_offset = 0.0
                        std_offset = 0.0

                    # ç›¸å¯¹å»¶æ—¶çš„ç»Ÿè®¡é‡ï¼ˆç”¨äºæ­£æ€æ‹Ÿåˆï¼‰
                    if n > 1:
                        var_relative = sum((x - 0) ** 2 for x in relative_delays_ms) / (n - 1)  # ç›¸å¯¹å‡å€¼=0
                        std_relative = var_relative ** 0.5
                    else:
                        std_relative = 0.0
                    
                    color = colors[alg_idx % len(colors)]
                    
                    # æ·»åŠ ç›´æ–¹å›¾
                    fig.add_trace(go.Histogram(
                        x=relative_delays_ms,
                        histnorm='probability density',
                        name=f'{descriptive_name} - å»¶æ—¶åˆ†å¸ƒ',
                        marker_color=color,
                        opacity=0.85,  # å¢åŠ ä¸é€æ˜åº¦ï¼Œä½¿é¢œè‰²æ›´æ˜æ˜¾
                        marker_line_color=color,  # æ·»åŠ è¾¹æ¡†é¢œè‰²ï¼Œä½¿ç”¨ç›¸åŒé¢œè‰²ä½†æ›´æ·±çš„è¾¹æ¡†
                        marker_line_width=0.5,
                        legendgroup=descriptive_name,
                        showlegend=True
                    ))
                    
                    # ç”Ÿæˆæ­£æ€æ‹Ÿåˆæ›²çº¿ï¼ˆåŸºäºç›¸å¯¹å»¶æ—¶ï¼Œå‡å€¼=0ï¼‰
                    if std_relative > 0:
                        min_x = min(relative_delays_ms)
                        max_x = max(relative_delays_ms)
                        span = max(1e-6, 3 * std_relative)
                        x_start = min(-span, min_x)  # ç›¸å¯¹å‡å€¼=0
                        x_end = max(span, max_x)

                        num_pts = 200
                        step = (x_end - x_start) / (num_pts - 1) if num_pts > 1 else 1.0
                        xs = [x_start + i * step for i in range(num_pts)]
                        ys = [(1.0 / (std_relative * (2 * math.pi) ** 0.5)) *
                              math.exp(-0.5 * ((x - 0) / std_relative) ** 2)  # å‡å€¼=0
                              for x in xs]

                        # æ·»åŠ æ­£æ€æ‹Ÿåˆæ›²çº¿
                        fig.add_trace(go.Scatter(
                            x=xs,
                            y=ys,
                            mode='lines',
                            name=f'{descriptive_name} - æ­£æ€æ‹Ÿåˆ (Î¼={mean_offset:.2f}ms, Ïƒ={std_offset:.2f}ms)',
                            line=dict(color=color, width=2),
                            legendgroup=descriptive_name,
                            showlegend=True
                        ))
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–ç®—æ³• '{algorithm_name}' çš„å»¶æ—¶æ•°æ®å¤±è´¥: {e}")
                    continue
            
            if not all_delays:
                logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„å»¶æ—¶æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆç›´æ–¹å›¾")
                return self._create_empty_plot("æ²¡æœ‰æœ‰æ•ˆçš„å»¶æ—¶æ•°æ®")
            
            # è®¾ç½®å¸ƒå±€ï¼ˆåˆ é™¤titleï¼Œå› ä¸ºUIåŒºåŸŸå·²æœ‰æ ‡é¢˜ï¼‰
            fig.update_layout(
                xaxis_title='ç›¸å¯¹å»¶æ—¶ (ms)',
                yaxis_title='æ¦‚ç‡å¯†åº¦',
                bargap=0.05,
                plot_bgcolor='white',
                paper_bgcolor='white',
                font=dict(size=12),
                height=500,
                clickmode='event+select',  # å¯ç”¨ç‚¹å‡»å’Œé€‰æ‹©äº‹ä»¶
                legend=dict(
                    orientation='h',
                    yanchor='bottom',
                    y=1.05,  # å›¾æ³¨æ›´é ä¸Šï¼Œç»™æ ‡é¢˜ç•™å‡ºç©ºé—´
                    xanchor='left',
                    x=0.0,  # ä»æœ€å·¦è¾¹å¼€å§‹ï¼Œé¿å…æŒ¤å‹å±…ä¸­æ ‡é¢˜
                    bgcolor='rgba(255, 255, 255, 0.9)',
                    bordercolor='gray',
                    borderwidth=1
                ),
                margin=dict(t=100, b=60, l=60, r=60)  # å¢åŠ é¡¶éƒ¨è¾¹è·ï¼Œç»™å›¾æ³¨å’Œæ ‡é¢˜æ›´å¤šç©ºé—´
            )
            
            logger.info(f"âœ… å¤šç®—æ³•å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾ç”ŸæˆæˆåŠŸï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            return fig
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¤šç®—æ³•å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾å¤±è´¥: {e}")
            
            logger.error(traceback.format_exc())
            return self._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    def generate_multi_algorithm_key_delay_scatter_plot(
        self,
        algorithms: List[AlgorithmDataset],
        only_common_keys: bool = False,
        selected_algorithm_names: List[str] = None
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸å»¶æ—¶æ•£ç‚¹å›¾ï¼ˆå åŠ æ˜¾ç¤ºï¼Œä¸åŒé¢œè‰²ï¼Œå›¾ä¾‹æ§åˆ¶ï¼‰

        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            only_common_keys: æ˜¯å¦åªæ˜¾ç¤ºå…¬å…±æŒ‰é”®
            selected_algorithm_names: æŒ‡å®šå‚ä¸å¯¹æ¯”çš„ç®—æ³•åç§°åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ‰€æœ‰æ¿€æ´»ç®—æ³•

        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        if not algorithms:
            logger.debug("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å¤šç®—æ³•æŒ‰é”®ä¸å»¶æ—¶æ•£ç‚¹å›¾ç”Ÿæˆ")
            return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
        
        try:
            # é¦–å…ˆæ ¹æ® selected_algorithm_names ç­›é€‰ç®—æ³•ï¼ˆå¦‚æœæŒ‡å®šäº†çš„è¯ï¼‰
            if selected_algorithm_names:
                filtered_algorithms = [alg for alg in algorithms if alg.metadata.algorithm_name in selected_algorithm_names]
                logger.info(f"æ ¹æ®ç”¨æˆ·é€‰æ‹©ç­›é€‰ç®—æ³•: {selected_algorithm_names} -> æ‰¾åˆ° {len(filtered_algorithms)} ä¸ªåŒ¹é…ç®—æ³•")
            else:
                filtered_algorithms = algorithms
                logger.info("æœªæŒ‡å®šç®—æ³•ç­›é€‰ï¼Œä½¿ç”¨æ‰€æœ‰ä¼ å…¥ç®—æ³•")

            # è¿‡æ»¤å‡ºæ¿€æ´»ä¸”å°±ç»ªçš„ç®—æ³•ï¼ˆç¡®ä¿åªæ˜¾ç¤ºç”¨æˆ·é€‰æ‹©çš„ç®—æ³•ï¼‰
            # è®°å½•ä¼ å…¥çš„ç®—æ³•çŠ¶æ€ï¼Œç”¨äºè°ƒè¯•
            for alg in filtered_algorithms:
                logger.debug(f"ç®—æ³• '{alg.metadata.algorithm_name}': is_active={alg.is_active}, is_ready={alg.is_ready()}")

            ready_algorithms = [alg for alg in filtered_algorithms if alg.is_active and alg.is_ready()]
            if not ready_algorithms:
                logger.warning("æ²¡æœ‰æ¿€æ´»ä¸”å°±ç»ªçš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸å»¶æ—¶æ•£ç‚¹å›¾")
                return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
            logger.info(f"å¼€å§‹ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸å»¶æ—¶æ•£ç‚¹å›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªæ¿€æ´»ç®—æ³•: {[alg.metadata.algorithm_name for alg in ready_algorithms]}")
            
            # å¦‚æœéœ€è¦åªæ˜¾ç¤ºå…¬å…±æŒ‰é”®ï¼Œå…ˆè®¡ç®—äº¤é›†
            common_keys = None
            if only_common_keys:
                key_sets = []
                for alg in ready_algorithms:
                    if alg.analyzer and alg.analyzer.note_matcher:
                        offset_data = alg.analyzer.note_matcher.get_precision_offset_alignment_data()
                        if offset_data:
                            keys = set(item.get('key_id') for item in offset_data if item.get('key_id') is not None)
                            key_sets.append(keys)
                
                if key_sets:
                    common_keys = set.intersection(*key_sets)
                    logger.info(f"åªæ˜¾ç¤ºå…¬å…±æŒ‰é”®: å…± {len(common_keys)} ä¸ª")
                else:
                    common_keys = set()
                    logger.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å…¬å…±æŒ‰é”®")
            
            # ä¸ºæ¯ä¸ªç®—æ³•åˆ†é…é¢œè‰²ï¼ˆä½¿ç”¨å…¨å±€é¢œè‰²æ–¹æ¡ˆï¼‰
            colors = ALGORITHM_COLOR_PALETTE
            
            fig = go.Figure()
            
            # æ”¶é›†æ‰€æœ‰æ¿€æ´»ç®—æ³•çš„æ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯
            algorithm_data_list = []
            
            for alg_idx, algorithm in enumerate(ready_algorithms):
                algorithm_name = algorithm.metadata.algorithm_name
                display_name = algorithm.metadata.display_name
                filename = algorithm.metadata.filename

                # åˆ›å»ºæ›´å…·æè¿°æ€§çš„å›¾æ³¨åç§°ï¼šç®—æ³•å (æ–‡ä»¶å)
                descriptive_name = f"{display_name} ({filename})"

                if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
                    logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰åˆ†æå™¨æˆ–åŒ¹é…å™¨ï¼Œè·³è¿‡")
                    continue

                try:
                    offset_data = algorithm.analyzer.get_precision_offset_alignment_data()

                    if not offset_data:
                        logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰ç²¾ç¡®åŒ¹é…æ•°æ®ï¼ˆâ‰¤50msï¼‰ï¼Œè·³è¿‡")
                        continue

                    # è·å–è¯¥ç®—æ³•çš„å¹³å‡å»¶æ—¶ï¼Œç”¨äºhovertemplateæ˜¾ç¤º
                    mean_error_0_1ms = algorithm.analyzer.get_mean_error()
                    algorithm_mean_delay_ms = mean_error_0_1ms / 10.0

                    # è·å–matched_pairsä»¥ä¾¿æŸ¥æ‰¾æ—¶é—´ä¿¡æ¯
                    matched_pairs = algorithm.analyzer.matched_pairs
                    record_note_dict = {r_idx: r_note for r_idx, _, r_note, _ in matched_pairs}
                    replay_note_dict = {p_idx: p_note for _, p_idx, _, p_note in matched_pairs}

                    # æå–æŒ‰é”®IDå’Œå»¶æ—¶æ•°æ®ï¼ˆå¸¦ç¬¦å·å€¼ï¼‰
                    key_ids = []
                    delays_ms = []  # å¸¦ç¬¦å·ï¼Œç”¨äºæ˜¾ç¤ºå’Œè®¡ç®—é˜ˆå€¼
                    customdata_list = []  # ç”¨äºå­˜å‚¨customdataï¼ŒåŒ…å«record_indexå’Œreplay_index
                    
                    for item in offset_data:
                        key_id = item.get('key_id')
                        keyon_offset = item.get('keyon_offset', 0)  # å•ä½ï¼š0.1ms
                        record_index = item.get('record_index')
                        replay_index = item.get('replay_index')
                        
                        if key_id is None or key_id == 'N/A':
                            continue
                            
                        # è¿‡æ»¤éå…¬å…±æŒ‰é”®
                        if only_common_keys and common_keys is not None:
                            if key_id not in common_keys:
                                continue
                        
                        try:
                            key_id_int = int(key_id)
                            delay_ms = keyon_offset / 10.0  # å¸¦ç¬¦å·ï¼Œä¿ç•™åŸå§‹å€¼

                            # è·å–å½•åˆ¶å’Œæ’­æ”¾æŒ‰é”®çš„æ—¶é—´ä¿¡æ¯
                            record_hammer_time_ms = 0.0
                            replay_hammer_time_ms = 0.0

                            # è·å–å½•åˆ¶éŸ³ç¬¦çš„é”¤å­æ—¶é—´
                            if record_index in record_note_dict:
                                record_note = record_note_dict[record_index]
                                if hasattr(record_note, 'hammers') and record_note.hammers is not None and not record_note.hammers.empty:
                                    record_hammer_time_ms = (record_note.hammers.index[0] + record_note.offset) / 10.0

                            # è·å–æ’­æ”¾éŸ³ç¬¦çš„é”¤å­æ—¶é—´
                            if replay_index in replay_note_dict:
                                replay_note = replay_note_dict[replay_index]
                                if hasattr(replay_note, 'hammers') and replay_note.hammers is not None and not replay_note.hammers.empty:
                                    replay_hammer_time_ms = (replay_note.hammers.index[0] + replay_note.offset) / 10.0

                            key_ids.append(key_id_int)
                            delays_ms.append(delay_ms)
                            # æ·»åŠ customdataï¼šåŒ…å«record_indexã€replay_indexã€ç®—æ³•åç§°ï¼Œç”¨äºç‚¹å‡»æ—¶æŸ¥æ‰¾åŒ¹é…å¯¹
                            customdata_list.append([record_index, replay_index, key_id_int, delay_ms, filename, record_hammer_time_ms, replay_hammer_time_ms])
                        except (ValueError, TypeError):
                            continue
                    
                    if not key_ids:
                        logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    color = colors[alg_idx % len(colors)]
                    
                    # ç›´æ¥ä½¿ç”¨æ•°æ®æ¦‚è§ˆé¡µé¢çš„æ•°æ®ï¼Œä¸é‡æ–°è®¡ç®—
                    # ä½¿ç”¨analyzerçš„æ–¹æ³•ï¼Œç¡®ä¿ä¸æ•°æ®æ¦‚è§ˆé¡µé¢å®Œå…¨ä¸€è‡´
                    me_0_1ms = algorithm.analyzer.get_mean_error()  # æ€»ä½“å‡å€¼ï¼ˆ0.1mså•ä½ï¼Œå¸¦ç¬¦å·ï¼‰
                    std_0_1ms = algorithm.analyzer.get_standard_deviation()  # æ€»ä½“æ ‡å‡†å·®ï¼ˆ0.1mså•ä½ï¼Œå¸¦ç¬¦å·ï¼‰
                    
                    # è½¬æ¢ä¸ºmså•ä½
                    mu = me_0_1ms / 10.0  # æ€»ä½“å‡å€¼ï¼ˆmsï¼Œå¸¦ç¬¦å·ï¼‰
                    sigma = std_0_1ms / 10.0  # æ€»ä½“æ ‡å‡†å·®ï¼ˆmsï¼Œå¸¦ç¬¦å·ï¼‰
                    
                    # è®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼šç»å¯¹å»¶æ—¶å‡å»å¹³å‡å»¶æ—¶
                    # ç›¸å¯¹å»¶æ—¶åæ˜ äº†æ¯ä¸ªåŒ¹é…å¯¹ç›¸å¯¹äºç®—æ³•å¹³å‡æ°´å¹³çš„"æå‰"æˆ–"å»¶è¿Ÿ"
                    delays_array = np.array(delays_ms)
                    relative_delays_array = delays_array - mu  # ç›¸å¯¹å»¶æ—¶
                    relative_delays_ms = relative_delays_array.tolist()

                    # è®¡ç®—ç›¸å¯¹å»¶æ—¶çš„ç»Ÿè®¡å€¼ï¼ˆç”¨äºé˜ˆå€¼ï¼‰
                    if len(relative_delays_ms) > 1:
                        relative_mu = np.mean(relative_delays_array)  # åº”è¯¥æ¥è¿‘0
                        relative_sigma = np.std(relative_delays_array, ddof=1)  # æ ·æœ¬æ ‡å‡†å·®
                        upper_threshold = relative_mu + 3 * relative_sigma
                        lower_threshold = relative_mu - 3 * relative_sigma
                    else:
                        relative_mu = 0.0
                        relative_sigma = 0.0
                        upper_threshold = 0.0
                        lower_threshold = 0.0

                    # å¯¹æ•°æ®æŒ‰ç…§æŒ‰é”®IDæ’åºï¼Œç¡®ä¿æ¨ªè½´æŒ‰é”®IDæœ‰åºé€’å¢
                    sorted_indices = sorted(range(len(key_ids)), key=lambda i: key_ids[i])
                    key_ids[:] = [key_ids[i] for i in sorted_indices]
                    delays_ms[:] = [delays_ms[i] for i in sorted_indices]
                    relative_delays_ms[:] = [relative_delays_ms[i] for i in sorted_indices]
                    customdata_list[:] = [customdata_list[i] for i in sorted_indices]

                    # ä¿å­˜ç®—æ³•æ•°æ®ï¼Œç”¨äºåç»­æ·»åŠ æ•£ç‚¹å›¾å’Œé˜ˆå€¼çº¿
                    algorithm_data_list.append({
                        'name': descriptive_name,  # ä½¿ç”¨æè¿°æ€§åç§°
                        'display_name': display_name,
                        'filename': filename,
                        'descriptive_name': descriptive_name,
                        'key_ids': key_ids,
                        'delays_ms': delays_ms,  # ç»å¯¹å»¶æ—¶ï¼Œç”¨äºcustomdata
                        'relative_delays_ms': relative_delays_ms,  # ç›¸å¯¹å»¶æ—¶ï¼Œç”¨äºç»˜å›¾
                        'customdata': customdata_list,  # ä¿å­˜customdata
                        'color': color,
                        'mu': mu,
                        'sigma': sigma,
                        'algorithm_mean_delay_ms': algorithm_mean_delay_ms,  # æ·»åŠ ç®—æ³•å¹³å‡å»¶æ—¶
                        'relative_mu': relative_mu,
                        'relative_sigma': relative_sigma,
                        'upper_threshold': upper_threshold,
                        'lower_threshold': lower_threshold
                    })
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–ç®—æ³• '{descriptive_name}' çš„æŒ‰é”®ä¸å»¶æ—¶æ•°æ®å¤±è´¥: {e}")
                    continue
            
            # æ·»åŠ æ•£ç‚¹å›¾æ•°æ®
            for alg_data in algorithm_data_list:
                # ä¸ºè¶…è¿‡é˜ˆå€¼çš„ç‚¹ä½¿ç”¨ä¸åŒé¢œè‰²å’Œå¤§å°ï¼ˆåŸºäºç›¸å¯¹å»¶æ—¶ï¼‰
                marker_colors = []
                marker_sizes = []
                for relative_delay in alg_data['relative_delays_ms']:
                    if relative_delay > alg_data['upper_threshold'] or relative_delay < alg_data['lower_threshold']:
                        # è¶…è¿‡é˜ˆå€¼çš„ç‚¹ä½¿ç”¨æ›´æ·±çš„é¢œè‰²ï¼Œæ›´å¤§å°ºå¯¸
                        marker_colors.append(alg_data['color'])
                        marker_sizes.append(12)
                    else:
                        marker_colors.append(alg_data['color'])
                        marker_sizes.append(8)

                # å°†æŒ‰é”®IDè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œåªæ˜¾ç¤ºIDæ•°å­—
                key_id_strings = [str(kid) for kid in alg_data['key_ids']]

                fig.add_trace(go.Scatter(
                    x=key_id_strings,
                    y=alg_data['relative_delays_ms'],  # ä½¿ç”¨ç›¸å¯¹å»¶æ—¶
                    mode='markers',
                    name=f"{alg_data['descriptive_name']} - åŒ¹é…å¯¹",
                    marker=dict(
                        size=marker_sizes,
                        color=marker_colors,
                        opacity=0.6,
                        line=dict(width=1, color=alg_data['color'])
                    ),
                    customdata=alg_data['customdata'],  # æ·»åŠ customdataï¼ŒåŒ…å«record_indexã€replay_indexå’Œç®—æ³•åç§°
                    legendgroup=alg_data['descriptive_name'],
                    showlegend=True,
                    hovertemplate=f"ç®—æ³•: {alg_data['descriptive_name']}<br>æŒ‰é”®: %{{customdata[2]}}<br>ç›¸å¯¹å»¶æ—¶: %{{y:.2f}}ms<br>ç»å¯¹å»¶æ—¶: %{{customdata[3]:.2f}}ms<br>å¹³å‡å»¶æ—¶: {alg_data['algorithm_mean_delay_ms']:.2f}ms<br>å½•åˆ¶é”¤å­æ—¶é—´: %{{customdata[5]:.2f}}ms<br>æ’­æ”¾é”¤å­æ—¶é—´: %{{customdata[6]:.2f}}ms<extra></extra>"
                ))
            
            # è·å–æ‰€æœ‰å”¯ä¸€çš„æŒ‰é”®IDï¼Œç”¨äºç¡®å®šé˜ˆå€¼çº¿çš„èŒƒå›´
            all_key_ids = set()
            for alg_data in algorithm_data_list:
                all_key_ids.update(alg_data['key_ids'])

            # å¯¹æŒ‰é”®IDæ’åºï¼Œåˆ›å»ºå®Œæ•´çš„æŒ‰é”®æ ‡ç­¾åˆ—è¡¨
            sorted_key_ids = sorted(all_key_ids)
            key_labels = [str(kid) for kid in sorted_key_ids]
            
            # ä¸ºæ¯ä¸ªæ¿€æ´»çš„ç®—æ³•æ·»åŠ é˜ˆå€¼çº¿ï¼ˆåªæ˜¾ç¤ºæ¿€æ´»ç®—æ³•çš„é˜ˆå€¼ï¼‰
            # ä½¿ç”¨go.Scatteråˆ›å»ºæ°´å¹³çº¿ï¼Œä½¿å…¶èƒ½å¤Ÿå“åº”å›¾ä¾‹ç‚¹å‡»
            for alg_data in algorithm_data_list:
                # æ·»åŠ ç›¸å¯¹å»¶æ—¶çš„å¹³å‡å€¼å‚è€ƒçº¿ï¼ˆ0çº¿ï¼Œå› ä¸ºç›¸å¯¹å»¶æ—¶çš„å¹³å‡å€¼æ˜¯0ï¼‰
                # ä½¿ç”¨Scatteråˆ›å»ºæ°´å¹³çº¿ï¼Œè®¾ç½®ç›¸åŒçš„legendgroupï¼Œä½¿å…¶ä¸æ•£ç‚¹å›¾ä¸€èµ·å“åº”å›¾ä¾‹ç‚¹å‡»
                fig.add_trace(go.Scatter(
                    x=key_labels,
                    y=[0] * len(key_labels),  # ç›¸å¯¹å»¶æ—¶çš„å¹³å‡å€¼æ˜¯0
                    mode='lines',
                    name=f"{alg_data['name']} - å¹³å‡å€¼",
                    line=dict(
                        color=alg_data['color'],
                        width=1.5,
                        dash='dot'
                    ),
                    legendgroup=alg_data['name'],  # ä¸æ•£ç‚¹å›¾ä½¿ç”¨ç›¸åŒçš„å›¾ä¾‹ç»„
                    showlegend=True,
                    hovertemplate=f"ç®—æ³•: {alg_data['name']}<br>ç›¸å¯¹å»¶æ—¶å¹³å‡å€¼ = 0ms<br>ç»å¯¹å»¶æ—¶å¹³å‡å€¼ = {alg_data['mu']:.2f}ms<extra></extra>"
                ))
                # æ³¨æ„ï¼šå·²ç§»é™¤æ ‡æ³¨ï¼Œä¿¡æ¯é€šè¿‡æ‚¬åœï¼ˆhoverï¼‰æ˜¾ç¤º

                # æ·»åŠ ç›¸å¯¹å»¶æ—¶çš„ä¸Šé˜ˆå€¼çº¿ï¼ˆç›¸å¯¹å‡å€¼ + 3å€ç›¸å¯¹æ ‡å‡†å·®ï¼‰
                fig.add_trace(go.Scatter(
                    x=key_labels,
                    y=[alg_data['upper_threshold']] * len(key_labels),
                    mode='lines',
                    name=f"{alg_data['name']} - ä¸Šé˜ˆå€¼",
                    line=dict(
                        color=alg_data['color'],
                        width=2,
                        dash='dash'
                    ),
                    legendgroup=alg_data['name'],  # ä¸æ•£ç‚¹å›¾ä½¿ç”¨ç›¸åŒçš„å›¾ä¾‹ç»„
                    showlegend=True,
                    hovertemplate=f"ç®—æ³•: {alg_data['name']}<br>ç›¸å¯¹å»¶æ—¶ä¸Šé˜ˆå€¼ = {alg_data['upper_threshold']:.2f}ms<extra></extra>"
                ))

                # æ·»åŠ ç›¸å¯¹å»¶æ—¶çš„ä¸‹é˜ˆå€¼çº¿ï¼ˆç›¸å¯¹å‡å€¼ - 3å€ç›¸å¯¹æ ‡å‡†å·®ï¼‰
                fig.add_trace(go.Scatter(
                    x=key_labels,
                    y=[alg_data['lower_threshold']] * len(key_labels),
                    mode='lines',
                    name=f"{alg_data['name']} - ä¸‹é˜ˆå€¼",
                    line=dict(
                        color=alg_data['color'],
                        width=2,
                        dash='dash'
                    ),
                    legendgroup=alg_data['name'],  # ä¸æ•£ç‚¹å›¾ä½¿ç”¨ç›¸åŒçš„å›¾ä¾‹ç»„
                    showlegend=True,
                    hovertemplate=f"ç®—æ³•: {alg_data['name']}<br>ç›¸å¯¹å»¶æ—¶ä¸‹é˜ˆå€¼ = {alg_data['lower_threshold']:.2f}ms<extra></extra>"
                ))
            
            # è®¾ç½®å¸ƒå±€
            fig.update_layout(
                # åˆ é™¤titleï¼Œå› ä¸ºUIåŒºåŸŸå·²æœ‰æ ‡é¢˜
                xaxis_title='æŒ‰é”®',
                yaxis_title='ç›¸å¯¹å»¶æ—¶ (ms)',
                xaxis=dict(
                    showgrid=True,
                    gridcolor='lightgray',
                    gridwidth=1,
                    type='category'  # è®¾ç½®ä¸ºç±»åˆ«è½´ï¼Œå› ä¸ºxè½´ç°åœ¨æ˜¯å­—ç¬¦ä¸²
                ),
                yaxis=dict(
                    showgrid=True,
                    gridcolor='lightgray',
                    gridwidth=1
                ),
                hovermode='closest',
                plot_bgcolor='white',
                paper_bgcolor='white',
                font=dict(size=12),
                height=800,
                showlegend=True,
                legend=dict(
                    orientation='h',
                    yanchor='bottom',
                    y=1.02,
                    xanchor='left',
                    x=0.0,
                    bgcolor='rgba(255, 255, 255, 0.9)',
                    bordercolor='gray',
                    borderwidth=1
                ),
                margin=dict(t=90, b=60, l=60, r=60)  # å¢åŠ é¡¶éƒ¨è¾¹è·ï¼Œä¸ºå›¾ä¾‹å’Œæ ‡æ³¨ç•™å‡ºç©ºé—´
            )
            
            logger.info(f"âœ… å¤šç®—æ³•æŒ‰é”®ä¸å»¶æ—¶æ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            return fig
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸å»¶æ—¶æ•£ç‚¹å›¾å¤±è´¥: {e}")
            
            logger.error(traceback.format_exc())
            return self._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    def generate_multi_algorithm_key_delay_zscore_scatter_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸å»¶æ—¶Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾
        
        Z-Scoreæ ‡å‡†åŒ–å…¬å¼ï¼šz = (x_i - Î¼) / Ïƒ
        - x_i: æ¯ä¸ªæ•°æ®ç‚¹çš„å»¶æ—¶å€¼
        - Î¼: è¯¥ç®—æ³•çš„æ€»ä½“å‡å€¼
        - Ïƒ: è¯¥ç®—æ³•çš„æ€»ä½“æ ‡å‡†å·®
        
        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            
        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        if not algorithms:
            logger.debug("â„¹ï¸ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç”Ÿæˆ")
            return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
        
        try:
            # è¿‡æ»¤å‡ºæ¿€æ´»ä¸”å°±ç»ªçš„ç®—æ³•
            ready_algorithms = [alg for alg in algorithms if alg.is_active and alg.is_ready()]
            if not ready_algorithms:
                logger.warning("æ²¡æœ‰æ¿€æ´»ä¸”å°±ç»ªçš„ç®—æ³•ï¼Œæ— æ³•ç”ŸæˆZ-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾")
                return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
            logger.info(f"å¼€å§‹ç”Ÿæˆå¤šç®—æ³•Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªæ¿€æ´»ç®—æ³•")
            
            # ä¸ºæ¯ä¸ªç®—æ³•åˆ†é…é¢œè‰²ï¼ˆä½¿ç”¨å…¨å±€é¢œè‰²æ–¹æ¡ˆï¼‰
            colors = ALGORITHM_COLOR_PALETTE
            
    
            fig = go.Figure()

            # ç”¨äºæ”¶é›†æ‰€æœ‰ç®—æ³•çš„xè½´èŒƒå›´
            all_x_min = None
            all_x_max = None

            # ç”¨äºæ”¶é›†æ‰€æœ‰æŒ‰é”®IDï¼Œç”¨äºåˆ›å»ºå®Œæ•´çš„æŒ‰é”®æ ‡ç­¾åˆ—è¡¨
            all_key_ids = set()
            
            # æ”¶é›†æ‰€æœ‰æ¿€æ´»ç®—æ³•çš„æ•°æ®
            for alg_idx, algorithm in enumerate(ready_algorithms):
                algorithm_name = algorithm.metadata.algorithm_name
                display_name = algorithm.metadata.display_name
                filename = algorithm.metadata.filename

                # åˆ›å»ºæ›´å…·æè¿°æ€§çš„å›¾æ³¨åç§°ï¼šç®—æ³•å (æ–‡ä»¶å)
                descriptive_name = f"{display_name} ({filename})"

                if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
                    logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰åˆ†æå™¨æˆ–åŒ¹é…å™¨ï¼Œè·³è¿‡")
                    continue
                
                try:
                    offset_data = algorithm.analyzer.get_precision_offset_alignment_data()

                    if not offset_data:
                        logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' æ²¡æœ‰ç²¾ç¡®åŒ¹é…æ•°æ®ï¼ˆâ‰¤50msï¼‰ï¼Œè·³è¿‡")
                        continue
                    
                    # è·å–matched_pairsä»¥ä¾¿æŸ¥æ‰¾æ—¶é—´ä¿¡æ¯
                    matched_pairs = algorithm.analyzer.matched_pairs
                    record_note_dict = {r_idx: r_note for r_idx, _, r_note, _ in matched_pairs}
                    replay_note_dict = {p_idx: p_note for _, p_idx, _, p_note in matched_pairs}

                    # æå–æŒ‰é”®IDå’Œå»¶æ—¶æ•°æ®
                    key_ids = []
                    delays_ms = []
                    customdata_list = []
                    
                    for item in offset_data:
                        key_id = item.get('key_id')
                        keyon_offset = item.get('keyon_offset', 0)  # å•ä½ï¼š0.1ms
                        record_index = item.get('record_index')
                        replay_index = item.get('replay_index')
                        
                        if key_id is None or key_id == 'N/A':
                            continue
                        
                        try:
                            key_id_int = int(key_id)
                            delay_ms = keyon_offset / 10.0  # è½¬æ¢ä¸ºms
                            
                            # è·å–å½•åˆ¶å’Œæ’­æ”¾æŒ‰é”®çš„æ—¶é—´ä¿¡æ¯
                            record_hammer_time_ms = 0.0
                            replay_hammer_time_ms = 0.0

                            # è·å–å½•åˆ¶éŸ³ç¬¦çš„é”¤å­æ—¶é—´
                            if record_index in record_note_dict:
                                record_note = record_note_dict[record_index]
                                if hasattr(record_note, 'hammers') and record_note.hammers is not None and not record_note.hammers.empty:
                                    record_hammer_time_ms = (record_note.hammers.index[0] + record_note.offset) / 10.0

                            # è·å–æ’­æ”¾éŸ³ç¬¦çš„é”¤å­æ—¶é—´
                            if replay_index in replay_note_dict:
                                replay_note = replay_note_dict[replay_index]
                                if hasattr(replay_note, 'hammers') and replay_note.hammers is not None and not replay_note.hammers.empty:
                                    replay_hammer_time_ms = (replay_note.hammers.index[0] + replay_note.offset) / 10.0

                            key_ids.append(key_id_int)
                            delays_ms.append(delay_ms)  # ä¿æŒç»å¯¹å»¶æ—¶ç”¨äºå…¶ä»–è®¡ç®—
                            # æ³¨æ„ï¼šcustomdata_list ä»ç„¶ä½¿ç”¨ç»å¯¹å»¶æ—¶ï¼Œå› ä¸ºhoveræ˜¾ç¤ºéœ€è¦åŒæ—¶æ˜¾ç¤ºç»å¯¹å’Œç›¸å¯¹å»¶æ—¶
                            customdata_list.append([
                                record_index,
                                replay_index,
                                key_id_int,
                                delay_ms,  # ç»å¯¹å»¶æ—¶
                                filename,  # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºå›¾æ³¨æ˜¾ç¤º
                                record_hammer_time_ms,
                                replay_hammer_time_ms
                            ])
                        except (ValueError, TypeError):
                            continue
                    
                    if not key_ids:
                        logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®ï¼Œè·³è¿‡")
                        continue
                    
                    # è·å–è¯¥ç®—æ³•çš„æ€»ä½“å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆç”¨äºZ-Scoreæ ‡å‡†åŒ–å’Œç›¸å¯¹å»¶æ—¶è®¡ç®—ï¼‰
                    me_0_1ms = algorithm.analyzer.get_mean_error()  # æ€»ä½“å‡å€¼ï¼ˆ0.1mså•ä½ï¼Œå¸¦ç¬¦å·ï¼‰
                    std_0_1ms = algorithm.analyzer.get_standard_deviation()  # æ€»ä½“æ ‡å‡†å·®ï¼ˆ0.1mså•ä½ï¼Œå¸¦ç¬¦å·ï¼‰

                    # è½¬æ¢ä¸ºmså•ä½
                    mu = me_0_1ms / 10.0  # æ€»ä½“å‡å€¼ï¼ˆmsï¼Œå¸¦ç¬¦å·ï¼‰
                    sigma = std_0_1ms / 10.0  # æ€»ä½“æ ‡å‡†å·®ï¼ˆmsï¼Œå¸¦ç¬¦å·ï¼‰

                    # è®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼šç»å¯¹å»¶æ—¶å‡å»å¹³å‡å»¶æ—¶
                    delays_array = np.array(delays_ms)
                    relative_delays_array = delays_array - mu  # ç›¸å¯¹å»¶æ—¶
                    relative_delays_ms = relative_delays_array.tolist()

                    # è®¡ç®—Z-Scoreï¼šz = (x_i - Î¼) / Ïƒ
                    if sigma > 0:
                        z_scores_array = (delays_array - mu) / sigma
                        # è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œç¡®ä¿Plotlyæ­£ç¡®å¤„ç†
                        z_scores = z_scores_array.tolist()
                        logger.info(f"ğŸ” ç®—æ³• '{algorithm_name}': Î¼={mu:.2f}ms, Ïƒ={sigma:.2f}ms, åŸå§‹å»¶æ—¶èŒƒå›´=[{delays_array.min():.2f}, {delays_array.max():.2f}]ms, ç›¸å¯¹å»¶æ—¶èŒƒå›´=[{relative_delays_array.min():.2f}, {relative_delays_array.max():.2f}]ms, Z-ScoreèŒƒå›´=[{z_scores_array.min():.2f}, {z_scores_array.max():.2f}]")
                    else:
                        z_scores = [0.0] * len(delays_ms)
                        logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' çš„æ ‡å‡†å·®ä¸º0ï¼Œæ— æ³•è¿›è¡ŒZ-Scoreæ ‡å‡†åŒ–")

                    # å¯¹æ•°æ®æŒ‰ç…§æŒ‰é”®IDæ’åºï¼Œç¡®ä¿æ¨ªè½´æŒ‰é”®IDæœ‰åºé€’å¢
                    sorted_indices = sorted(range(len(key_ids)), key=lambda i: key_ids[i])
                    key_ids[:] = [key_ids[i] for i in sorted_indices]
                    z_scores[:] = [z_scores[i] for i in sorted_indices]
                    customdata_list[:] = [customdata_list[i] for i in sorted_indices]

                    color = colors[alg_idx % len(colors)]

                    # æ·»åŠ æ•£ç‚¹å›¾ï¼ˆä½¿ç”¨Z-Scoreå€¼ä½œä¸ºyè½´ï¼‰
                    fig.add_trace(go.Scatter(
                        x=[str(kid) for kid in key_ids],  # å°†æŒ‰é”®IDè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
                        y=z_scores,  # ä½¿ç”¨Z-Scoreå€¼ï¼Œä¸æ˜¯åŸå§‹å»¶æ—¶å€¼
                        mode='markers',
                        name=f"{descriptive_name} - Z-Score",
                        marker=dict(
                            size=8,
                            color=color,
                            opacity=0.6,
                            line=dict(width=1, color=color)
                        ),
                        customdata=customdata_list,
                        legendgroup=descriptive_name,
                        showlegend=True,
                        hovertemplate=f"ç®—æ³•: {descriptive_name}<br>é”®ä½: %{{x}}<br>å»¶æ—¶: %{{customdata[3]:.2f}}ms<br>Z-Score: %{{y:.2f}}<br>å½•åˆ¶é”¤å­æ—¶é—´: %{{customdata[5]:.2f}}ms<br>æ’­æ”¾é”¤å­æ—¶é—´: %{{customdata[6]:.2f}}ms<extra></extra>"
                    ))
                    
                    # æ”¶é›†æ‰€æœ‰æŒ‰é”®IDï¼Œç”¨äºåç»­åˆ›å»ºå®Œæ•´çš„æŒ‰é”®æ ‡ç­¾åˆ—è¡¨
                    if key_ids:
                        all_key_ids.update(key_ids)
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–ç®—æ³• '{descriptive_name}' çš„Z-Scoreæ•°æ®å¤±è´¥: {e}")
                    continue
            
            # è·å–æ‰€æœ‰å”¯ä¸€çš„æŒ‰é”®IDï¼Œç”¨äºç¡®å®šé˜ˆå€¼çº¿çš„èŒƒå›´
            # å¯¹æŒ‰é”®IDæ’åºï¼Œåˆ›å»ºå®Œæ•´çš„æŒ‰é”®æ ‡ç­¾åˆ—è¡¨
            sorted_key_ids = sorted(all_key_ids)
            key_labels = [str(kid) for kid in sorted_key_ids]

            # ä¸ºæ¯ä¸ªç®—æ³•æ·»åŠ é˜ˆå€¼çº¿ï¼ˆä¸æŒ‰é”®ä¸å»¶æ—¶æ•£ç‚¹å›¾ä¸€æ ·çš„å¯¹æ¯”æ›²çº¿ï¼‰
            # è™½ç„¶Z-Scoreæ ‡å‡†åŒ–åæ‰€æœ‰ç®—æ³•çš„å‚è€ƒçº¿å€¼ç›¸åŒï¼Œä½†ä¸ºæ¯ä¸ªç®—æ³•æ·»åŠ ç‹¬ç«‹çš„çº¿ï¼Œ
            # ä½¿å…¶èƒ½å¤Ÿå“åº”å›¾ä¾‹ç‚¹å‡»ï¼Œä¸æ•£ç‚¹å›¾ä¸€èµ·æ˜¾ç¤º/éšè—
            for alg_idx, algorithm in enumerate(ready_algorithms):
                algorithm_name = algorithm.metadata.algorithm_name
                display_name = algorithm.metadata.display_name
                filename = algorithm.metadata.filename

                # åˆ›å»ºæ›´å…·æè¿°æ€§çš„å›¾æ³¨åç§°ï¼šç®—æ³•å (æ–‡ä»¶å)
                descriptive_name = f"{display_name} ({filename})"
                color = colors[alg_idx % len(colors)]

                # æ·»åŠ è¯¥ç®—æ³•çš„Z-Score = 0å‚è€ƒçº¿ï¼ˆå‡å€¼çº¿ï¼‰
                fig.add_trace(go.Scatter(
                    x=key_labels,
                    y=[0] * len(key_labels),
                    mode='lines',
                    name=f"{descriptive_name} - Z=0",
                    line=dict(
                        color=color,
                        width=1.5,
                        dash='dot'
                    ),
                    legendgroup=descriptive_name,  # ä¸æ•£ç‚¹å›¾ä½¿ç”¨ç›¸åŒçš„å›¾ä¾‹ç»„
                    showlegend=True,
                    hovertemplate=f"ç®—æ³•: {descriptive_name}<br>Z-Score = 0 (å‡å€¼çº¿)<extra></extra>"
                ))

                # æ·»åŠ è¯¥ç®—æ³•çš„Z-Score = +3é˜ˆå€¼çº¿ï¼ˆä¸Šé˜ˆå€¼ï¼‰
                fig.add_trace(go.Scatter(
                    x=key_labels,
                    y=[3] * len(key_labels),
                    mode='lines',
                    name=f"{descriptive_name} - Z=+3",
                    line=dict(
                        color=color,
                        width=2,
                        dash='dash'
                    ),
                    legendgroup=descriptive_name,  # ä¸æ•£ç‚¹å›¾ä½¿ç”¨ç›¸åŒçš„å›¾ä¾‹ç»„
                    showlegend=True,
                    hovertemplate=f"ç®—æ³•: {descriptive_name}<br>Z-Score = +3 (ä¸Šé˜ˆå€¼)<extra></extra>"
                ))

                # æ·»åŠ è¯¥ç®—æ³•çš„Z-Score = -3é˜ˆå€¼çº¿ï¼ˆä¸‹é˜ˆå€¼ï¼‰
                fig.add_trace(go.Scatter(
                    x=key_labels,
                    y=[-3] * len(key_labels),
                    mode='lines',
                    name=f"{descriptive_name} - Z=-3",
                    line=dict(
                        color=color,
                        width=2,
                        dash='dash'
                    ),
                    legendgroup=descriptive_name,  # ä¸æ•£ç‚¹å›¾ä½¿ç”¨ç›¸åŒçš„å›¾ä¾‹ç»„
                    showlegend=True,
                    hovertemplate=f"ç®—æ³•: {descriptive_name}<br>Z-Score = -3 (ä¸‹é˜ˆå€¼)<extra></extra>"
                ))
            
            # è®¾ç½®å¸ƒå±€
            fig.update_layout(
                # åˆ é™¤titleï¼Œå› ä¸ºUIåŒºåŸŸå·²æœ‰æ ‡é¢˜
                xaxis_title='æŒ‰é”®ID',
                yaxis_title='Z-Score (æ ‡å‡†åŒ–å»¶æ—¶)',
                xaxis=dict(
                    showgrid=True,
                    gridcolor='lightgray',
                    gridwidth=1,
                    type='category'  # è®¾ç½®ä¸ºç±»åˆ«è½´ï¼Œå› ä¸ºxè½´ç°åœ¨æ˜¯å­—ç¬¦ä¸²
                ),
                yaxis=dict(
                    showgrid=True,
                    gridcolor='lightgray',
                    gridwidth=1
                ),
                hovermode='closest',
                plot_bgcolor='white',
                paper_bgcolor='white',
                font=dict(size=12),
                height=800,
                showlegend=True,
                legend=dict(
                    orientation='h',
                    yanchor='bottom',
                    y=1.02,
                    xanchor='left',
                    x=0.0,
                    bgcolor='rgba(255, 255, 255, 0.9)',
                    bordercolor='gray',
                    borderwidth=1
                ),
                margin=dict(t=90, b=60, l=60, r=60)
            )
            
            logger.info(f"âœ… å¤šç®—æ³•Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            return fig
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¤šç®—æ³•Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾å¤±è´¥: {e}")
            
            logger.error(traceback.format_exc())
            return self._create_empty_plot(f"ç”ŸæˆZ-Scoreæ•£ç‚¹å›¾å¤±è´¥: {str(e)}")

    def generate_single_key_delay_comparison_plot(
        self,
        algorithms: List[AlgorithmDataset],
        target_key_id: int
    ) -> Any:
        """
        ç”Ÿæˆå•é”®å¤šæ›²å»¶æ—¶å¯¹æ¯”å›¾ï¼ˆæ•£ç‚¹å›¾+ç®±çº¿å›¾ï¼‰
        
        Args:
            algorithms: ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            target_key_id: ç›®æ ‡æŒ‰é”®ID
            
        Returns:
            Any: Plotlyå›¾è¡¨å¯¹è±¡
        """
        if not algorithms:
            return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
        if target_key_id is None:
            return self._create_empty_plot("è¯·é€‰æ‹©ä¸€ä¸ªæŒ‰é”®è¿›è¡Œåˆ†æ")
            
        try:
            
            fig = go.Figure()
            
            # é¢œè‰²åˆ—è¡¨
            colors = self.COLORS
            
            # è¿‡æ»¤å‡ºæ¿€æ´»ä¸”å°±ç»ªçš„ç®—æ³•
            ready_algorithms = [alg for alg in algorithms if alg.is_active and alg.is_ready()]
            if not ready_algorithms:
                return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»ä¸”å°±ç»ªçš„ç®—æ³•")
            
            # æ”¶é›†æ‰€æœ‰å»¶æ—¶æ•°æ®ï¼Œç”¨äºè‡ªåŠ¨è°ƒæ•´Yè½´
            all_delays = []
            has_data = False
            
            # éå†æ¯ä¸ªç®—æ³•
            for alg_idx, algorithm in enumerate(ready_algorithms):
                algorithm_name = algorithm.metadata.algorithm_name
                display_name = algorithm.metadata.display_name
                color = colors[alg_idx % len(colors)]
                
                # è·å–è¯¥ç®—æ³•çš„ç²¾ç¡®åç§»æ•°æ®ï¼ˆè¯¯å·® â‰¤ 50msï¼‰
                if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
                    continue

                offset_data = algorithm.analyzer.get_precision_offset_alignment_data()
                if not offset_data:
                    continue
                
                # æå–ç›®æ ‡æŒ‰é”®çš„å»¶æ—¶æ•°æ®
                key_delays = []
                customdata_list = []
                
                for item in offset_data:
                    key_id = item.get('key_id')
                    if key_id == target_key_id:
                        keyon_offset = item.get('keyon_offset', 0)
                        delay_ms = keyon_offset / 10.0  # ms
                        key_delays.append(delay_ms)
                        
                        # è®°å½•è¯¦ç»†ä¿¡æ¯ï¼Œç”¨äºæ‚¬åœ
                        record_index = item.get('record_index')
                        replay_index = item.get('replay_index')
                        # è‡ªå®šä¹‰æ•°æ®æ ¼å¼: [record_index, replay_index, delay_ms, algorithm_name]
                        # è¿™å¯¹äºäº¤äº’å¯èƒ½æœ‰ç”¨ï¼Œä½†åœ¨æ­¤å¤„ä¸»è¦ç”¨äºhover
                        customdata_list.append([record_index, replay_index, delay_ms, algorithm.metadata.filename])
                
                if not key_delays:
                    continue
                
                has_data = True    
                all_delays.extend(key_delays)
                
                # 1. æ·»åŠ ç®±çº¿å›¾ï¼ˆæ˜¾ç¤ºç»Ÿè®¡åˆ†å¸ƒï¼‰
                fig.add_trace(go.Box(
                    y=key_delays,
                    x=[display_name] * len(key_delays), # Xè½´ä¸ºç®—æ³•åç§°
                    name=display_name,
                    boxpoints='all',  # æ˜¾ç¤ºæ‰€æœ‰ç‚¹
                    jitter=0.5,       # ç‚¹çš„æŠ–åŠ¨èŒƒå›´
                    pointpos=-1.8,    # ç‚¹æ˜¾ç¤ºåœ¨ç®±çº¿å›¾å·¦ä¾§
                    marker=dict(
                        color=color,
                        size=6,
                        opacity=0.7
                    ),
                    line=dict(color=color),
                    fillcolor='rgba(255,255,255,0)',  # é€æ˜å¡«å……
                    showlegend=False,  # ç®±çº¿å›¾ä¸æ˜¾ç¤ºå›¾ä¾‹ï¼Œé¿å…é‡å¤
                    # æ›´æ–°äº¤äº’ä¿¡æ¯
                    customdata=customdata_list,
                    hovertemplate=f'ç®—æ³•: {display_name}<br>æŒ‰é”®: {target_key_id}<br>å»¶æ—¶: %{{y:.2f}}ms<extra></extra>'
                ))

            # æ›´æ–°å¸ƒå±€
            fig.update_layout(
                title=dict(
                    text=f"æŒ‰é”® {target_key_id} å»¶æ—¶åˆ†å¸ƒå¯¹æ¯” (å¤šæ›²ç›®/ç®—æ³•)",
                    x=0.5,
                    xanchor='center'
                ),
                xaxis=dict(
                    title="æ›²å­ / ç®—æ³•",
                    showgrid=False
                ),
                yaxis=dict(
                    title="ç›¸å¯¹å»¶æ—¶ (ms)",
                    showgrid=True,
                    gridcolor='lightgray',
                    zeroline=True,
                    zerolinecolor='gray'
                ),
                plot_bgcolor='white',
                paper_bgcolor='white',
                hovermode='closest',
                showlegend=False,  # ä¸éœ€è¦å›¾ä¾‹ï¼ŒXè½´æ ‡ç­¾å·²è¯´æ˜
                height=400,
                margin=dict(l=60, r=40, t=60, b=40)
            )
            
            if not has_data:
                return self._create_empty_plot(f"æŒ‰é”® {target_key_id} åœ¨é€‰å®šçš„ç®—æ³•ä¸­æ²¡æœ‰æ•°æ®")
                
            return fig
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå•é”®å¯¹æ¯”å›¾å¤±è´¥: {e}")
            
            logger.error(traceback.format_exc())
            return self._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")

    def generate_multi_algorithm_hammer_velocity_relative_delay_scatter_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•é”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ï¼ˆå åŠ æ˜¾ç¤ºï¼Œä¸åŒé¢œè‰²ï¼Œå›¾ä¾‹æ§åˆ¶ï¼‰

        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨

        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        if not algorithms:
            logger.debug("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å¤šç®—æ³•é”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ç”Ÿæˆ")
            return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")

        try:
            # è¿‡æ»¤å‡ºæ¿€æ´»ä¸”å°±ç»ªçš„ç®—æ³•
            ready_algorithms = [alg for alg in algorithms if alg.is_active and alg.is_ready()]
            if not ready_algorithms:
                logger.warning("æ²¡æœ‰æ¿€æ´»ä¸”å°±ç»ªçš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆé”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾")
                return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")

            logger.info(f"å¼€å§‹ç”Ÿæˆå¤šç®—æ³•é”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªæ¿€æ´»ç®—æ³•")

            # ä¸ºæ¯ä¸ªç®—æ³•åˆ†é…é¢œè‰²ï¼ˆä½¿ç”¨å…¨å±€é¢œè‰²æ–¹æ¡ˆï¼‰
            colors = ALGORITHM_COLOR_PALETTE
            
            fig = go.Figure()

            for alg_idx, algorithm in enumerate(ready_algorithms):
                algorithm_name = algorithm.metadata.algorithm_name
                display_name = algorithm.metadata.display_name
                filename = algorithm.metadata.filename

                # åˆ›å»ºæ›´å…·æè¿°æ€§çš„å›¾æ³¨åç§°ï¼šç®—æ³•å (æ–‡ä»¶å)
                descriptive_name = f"{display_name} ({filename})"

                if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
                    logger.warning(f"ç®—æ³• '{descriptive_name}' æ²¡æœ‰åˆ†æå™¨æˆ–åŒ¹é…å™¨ï¼Œè·³è¿‡")
                    continue

                try:
                    matched_pairs = algorithm.analyzer.get_matched_pairs()

                    if not matched_pairs:
                        logger.warning(f"ç®—æ³• '{descriptive_name}' æ²¡æœ‰åŒ¹é…æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    offset_data = algorithm.analyzer.get_precision_offset_alignment_data()

                    # æå–é”¤é€Ÿå’Œå»¶æ—¶æ•°æ®
                    hammer_velocities = []
                    delays_ms = []  # å»¶æ—¶ï¼ˆmså•ä½ï¼Œå¸¦ç¬¦å·ï¼‰
                    scatter_customdata = []  # å­˜å‚¨record_idxã€replay_idxå’Œalgorithm_nameï¼Œç”¨äºç‚¹å‡»äº‹ä»¶è¯†åˆ«

                    # åˆ›å»ºåŒ¹é…å¯¹ç´¢å¼•åˆ°åç§»æ•°æ®çš„æ˜ å°„
                    offset_map = {}
                    for item in offset_data:
                        record_idx = item.get('record_index')
                        replay_idx = item.get('replay_index')
                        if record_idx is not None and replay_idx is not None:
                            offset_map[(record_idx, replay_idx)] = item

                    for record_idx, replay_idx, record_note, replay_note in matched_pairs:
                        # è·å–æ’­æ”¾éŸ³ç¬¦çš„é”¤é€Ÿï¼ˆç¬¬ä¸€ä¸ªé”¤é€Ÿå€¼ï¼‰
                        if len(replay_note.hammers) > 0 and len(replay_note.hammers.values) > 0:
                            hammer_velocity = replay_note.hammers.values[0]
                        else:
                            continue

                        # ä»åç§»æ•°æ®ä¸­è·å–å»¶æ—¶
                        keyon_offset = None
                        if (record_idx, replay_idx) in offset_map:
                            keyon_offset = offset_map[(record_idx, replay_idx)].get('keyon_offset', 0)
                        else:
                            # å¦‚æœåç§»æ•°æ®ä¸­æ²¡æœ‰è¿™ä¸ªåŒ¹é…å¯¹ï¼Œè·³è¿‡å¤„ç†
                            continue

                        # å°†å»¶æ—¶ä»0.1msè½¬æ¢ä¸ºmsï¼ˆå¸¦ç¬¦å·ï¼‰
                        delay_ms = keyon_offset / 10.0

                        # è·³è¿‡é”¤é€Ÿä¸º0æˆ–è´Ÿæ•°çš„æ•°æ®ç‚¹ï¼ˆå¯¹æ•°æ— æ³•å¤„ç†ï¼‰
                        if hammer_velocity <= 0:
                            continue

                        # è·å–æŒ‰é”®ID
                        key_id = record_note.id if hasattr(record_note, 'id') else None

                        hammer_velocities.append(hammer_velocity)
                        delays_ms.append(delay_ms)
                        # å­˜å‚¨record_idxã€replay_idxã€algorithm_nameå’Œkey_idï¼Œç”¨äºç‚¹å‡»äº‹ä»¶è¯†åˆ«å’Œæ˜¾ç¤º
                        scatter_customdata.append([record_idx, replay_idx, display_name, key_id])

                    if not hammer_velocities:
                        logger.warning(f"ç®—æ³• '{algorithm_name}' æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    # è·å–è¯¥ç®—æ³•çš„æ€»ä½“å‡å€¼å’Œæ ‡å‡†å·®ï¼Œç”¨äºè®¡ç®—ç›¸å¯¹å»¶æ—¶å’Œé˜ˆå€¼
                    me_0_1ms = algorithm.analyzer.get_mean_error() if hasattr(algorithm.analyzer, 'get_mean_error') else 0.0
                    std_0_1ms = algorithm.analyzer.get_standard_deviation() if hasattr(algorithm.analyzer, 'get_standard_deviation') else 0.0

                    mu = me_0_1ms / 10.0  # æ€»ä½“å‡å€¼ï¼ˆmsï¼Œå¸¦ç¬¦å·ï¼‰
                    sigma = std_0_1ms / 10.0  # æ€»ä½“æ ‡å‡†å·®ï¼ˆmsï¼Œå¸¦ç¬¦å·ï¼‰

                    # è®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼šç»å¯¹å»¶æ—¶å‡å»å¹³å‡å»¶æ—¶
                    delays_array = np.array(delays_ms)
                    relative_delays = (delays_array - mu).tolist()

                    # è®¡ç®—ç›¸å¯¹å»¶æ—¶çš„ç»Ÿè®¡å€¼ï¼ˆç”¨äºé˜ˆå€¼ï¼‰
                    if len(relative_delays) > 1:
                        relative_mu = np.mean(relative_delays)  # åº”è¯¥æ¥è¿‘0
                        relative_sigma = np.std(relative_delays, ddof=1)  # æ ·æœ¬æ ‡å‡†å·®
                        upper_threshold = relative_mu + 3 * relative_sigma
                        lower_threshold = relative_mu - 3 * relative_sigma
                    else:
                        relative_mu = 0.0
                        relative_sigma = 0.0
                        upper_threshold = 0.0
                        lower_threshold = 0.0

                    # å°†é”¤é€Ÿè½¬æ¢ä¸ºå¯¹æ•°å½¢å¼ï¼ˆç±»ä¼¼åˆ†è´ï¼‰ï¼šlog10(velocity)
                    log_velocities = [math.log10(v) for v in hammer_velocities]

                    color = colors[alg_idx % len(colors)]

                    # æ·»åŠ æ•£ç‚¹å›¾æ•°æ®ï¼ˆxè½´ä½¿ç”¨å¯¹æ•°å½¢å¼çš„é”¤é€Ÿï¼Œyè½´ä½¿ç”¨ç›¸å¯¹å»¶æ—¶å€¼ï¼‰
                    # customdataæ ¼å¼: [delay_ms, original_velocity, record_idx, replay_idx, algorithm_name, key_id]
                    # ç¬¬ä¸€ä¸ªå…ƒç´ ç”¨äºhoveræ˜¾ç¤ºå»¶æ—¶ï¼Œç¬¬äºŒä¸ªå…ƒç´ ç”¨äºhoveræ˜¾ç¤ºåŸå§‹é”¤é€Ÿï¼Œåå››ä¸ªç”¨äºç‚¹å‡»äº‹ä»¶è¯†åˆ«å’Œæ˜¾ç¤º
                    combined_customdata = [[delay_ms, orig_vel, record_idx, replay_idx, alg_name, key_id]
                                          for delay_ms, orig_vel, (record_idx, replay_idx, alg_name, key_id)
                                          in zip(delays_ms, hammer_velocities, scatter_customdata)]

                    fig.add_trace(go.Scatter(
                        x=log_velocities,
                        y=relative_delays,  # ä½¿ç”¨ç›¸å¯¹å»¶æ—¶å€¼ï¼Œä¸æ˜¯Z-Scoreå€¼
                        mode='markers',
                        name=f"{descriptive_name} - ç›¸å¯¹å»¶æ—¶",
                        marker=dict(
                            size=8,
                            color=color,
                            opacity=0.6,
                            line=dict(width=1, color=color)
                        ),
                        legendgroup=descriptive_name,
                        showlegend=True,
                        hovertemplate=f"ç®—æ³•: {descriptive_name}<br>æŒ‰é”®: %{{customdata[5]}}<br>é”¤é€Ÿ: %{{customdata[1]:.0f}} (log: %{{x:.2f}})<br>ç›¸å¯¹å»¶æ—¶: %{{y:.2f}}ms<br>ç»å¯¹å»¶æ—¶: %{{customdata[0]:.2f}}ms<extra></extra>",
                        customdata=combined_customdata
                    ))

                    # æ·»åŠ ç›¸å¯¹å»¶æ—¶çš„å‚è€ƒçº¿å’Œå¹³è¡Œäºxè½´çš„é˜ˆå€¼çº¿
                    if len(log_velocities) > 0:
                        # è·å–xè½´èŒƒå›´ï¼ˆä½¿ç”¨æ‰€æœ‰ç®—æ³•çš„å¯¹æ•°èŒƒå›´ï¼‰
                        all_log_velocities = []
                        for alg in ready_algorithms:
                            try:
                                matched_pairs = alg.analyzer.note_matcher.get_matched_pairs()
                                for record_idx, replay_idx, record_note, replay_note in matched_pairs:
                                    if len(replay_note.hammers) > 0 and len(replay_note.hammers.values) > 0:
                                        vel = replay_note.hammers.values[0]
                                        if vel > 0:
                                            all_log_velocities.append(math.log10(vel))
                            except:
                                continue

                        # è®¡ç®—xè½´èŒƒå›´
                        x_min = min(all_log_velocities) if all_log_velocities else 0
                        x_max = max(all_log_velocities) if all_log_velocities else 2

                        # æ·»åŠ ç›¸å¯¹å»¶æ—¶çš„å¹³å‡å€¼å‚è€ƒçº¿ï¼ˆ0çº¿ï¼Œå› ä¸ºç›¸å¯¹å»¶æ—¶çš„å¹³å‡å€¼æ˜¯0ï¼‰
                        fig.add_trace(go.Scatter(
                            x=[x_min, x_max],
                            y=[relative_mu, relative_mu],  # ç›¸å¯¹å»¶æ—¶çš„å¹³å‡å€¼
                            mode='lines',
                            name=f'{descriptive_name} - å¹³å‡å€¼',
                            line=dict(
                                color=color,
                                width=1.5,
                                dash='dot'
                            ),
                            legendgroup=descriptive_name,
                            showlegend=True,
                            hovertemplate=f"ç®—æ³•: {descriptive_name}<br>ç›¸å¯¹å»¶æ—¶å¹³å‡å€¼ = {relative_mu:.2f}ms<extra></extra>"
                        ))

                        # æ·»åŠ ç›¸å¯¹å»¶æ—¶çš„ä¸Šé˜ˆå€¼çº¿ï¼ˆç›¸å¯¹å‡å€¼ + 3å€ç›¸å¯¹æ ‡å‡†å·®ï¼‰
                        fig.add_trace(go.Scatter(
                            x=[x_min, x_max],
                            y=[upper_threshold, upper_threshold],
                            mode='lines',
                            name=f'{descriptive_name} - ä¸Šé˜ˆå€¼',
                            line=dict(
                                color=color,
                                width=2,
                                dash='dash'
                            ),
                            legendgroup=descriptive_name,
                            showlegend=True,
                            hovertemplate=f"ç®—æ³•: {descriptive_name}<br>ç›¸å¯¹å»¶æ—¶ä¸Šé˜ˆå€¼ = {upper_threshold:.2f}ms<extra></extra>"
                        ))

                        # æ·»åŠ ç›¸å¯¹å»¶æ—¶çš„ä¸‹é˜ˆå€¼çº¿ï¼ˆç›¸å¯¹å‡å€¼ - 3å€ç›¸å¯¹æ ‡å‡†å·®ï¼‰
                        fig.add_trace(go.Scatter(
                            x=[x_min, x_max],
                            y=[lower_threshold, lower_threshold],
                            mode='lines',
                            name=f'{descriptive_name} - ä¸‹é˜ˆå€¼',
                            line=dict(
                                color=color,
                                width=2,
                                dash='dash'
                            ),
                            legendgroup=descriptive_name,
                            showlegend=True,
                            hovertemplate=f"ç®—æ³•: {descriptive_name}<br>ç›¸å¯¹å»¶æ—¶ä¸‹é˜ˆå€¼ = {lower_threshold:.2f}ms<extra></extra>"
                        ))


                except Exception as e:
                    logger.warning(f"è·å–ç®—æ³• '{descriptive_name}' çš„é”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•°æ®å¤±è´¥: {e}")
                    continue

            # è®¾ç½®å¸ƒå±€
            fig.update_layout(
                # åˆ é™¤titleï¼Œå› ä¸ºUIåŒºåŸŸå·²æœ‰æ ‡é¢˜
                xaxis_title='logâ‚â‚€(é”¤é€Ÿ)',
                yaxis_title='ç›¸å¯¹å»¶æ—¶ (ms)',
                xaxis=dict(
                    showgrid=True,
                    gridcolor='lightgray',
                    gridwidth=1
                ),
                yaxis=dict(
                    showgrid=True,
                    gridcolor='lightgray',
                    gridwidth=1
                ),
                hovermode='closest',
                plot_bgcolor='white',
                paper_bgcolor='white',
                font=dict(size=12),
                height=800,
                showlegend=True,
                legend=dict(
                    orientation='h',
                    yanchor='bottom',
                    y=1.02,
                    xanchor='left',
                    x=0.0,
                    bgcolor='rgba(255, 255, 255, 0.9)',
                    bordercolor='gray',
                    borderwidth=1
                ),
                margin=dict(t=90, b=60, l=60, r=60)
            )

            logger.info(f"å¤šç®—æ³•é”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            return fig

        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤šç®—æ³•é”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾å¤±è´¥: {e}")

            logger.error(traceback.format_exc())
            return self._create_empty_plot(f"ç”Ÿæˆé”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾å¤±è´¥: {str(e)}")

    def generate_multi_algorithm_hammer_velocity_delay_scatter_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ï¼ˆå åŠ æ˜¾ç¤ºï¼Œä¸åŒé¢œè‰²ï¼Œå›¾ä¾‹æ§åˆ¶ï¼‰
        
        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            
        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        if not algorithms:
            logger.debug("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å¤šç®—æ³•é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ç”Ÿæˆ")
            return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
        
        try:
            # è¿‡æ»¤å‡ºå°±ç»ªçš„ç®—æ³•
            ready_algorithms = [alg for alg in algorithms if alg.is_ready()]
            if not ready_algorithms:
                logger.warning("âš ï¸ æ²¡æœ‰å°±ç»ªçš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆå¤šç®—æ³•é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾")
                return self._create_empty_plot("æ²¡æœ‰å°±ç»ªçš„ç®—æ³•")
            
            logger.info(f"ğŸ“Š å¼€å§‹ç”Ÿæˆå¤šç®—æ³•é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            
            # ä¸ºæ¯ä¸ªç®—æ³•åˆ†é…é¢œè‰²ï¼ˆä½¿ç”¨å…¨å±€é¢œè‰²æ–¹æ¡ˆï¼‰
            colors = ALGORITHM_COLOR_PALETTE
            
            
            fig = go.Figure()

            for alg_idx, algorithm in enumerate(ready_algorithms):
                algorithm_name = algorithm.metadata.algorithm_name
                display_name = algorithm.metadata.display_name
                filename = algorithm.metadata.filename

                # åˆ›å»ºæ›´å…·æè¿°æ€§çš„å›¾æ³¨åç§°ï¼šç®—æ³•å (æ–‡ä»¶å)
                descriptive_name = f"{display_name} ({filename})"

                if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
                    logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰åˆ†æå™¨æˆ–åŒ¹é…å™¨ï¼Œè·³è¿‡")
                    continue

                try:
                    matched_pairs = algorithm.analyzer.get_matched_pairs()

                    if not matched_pairs:
                        logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰åŒ¹é…æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    offset_data = algorithm.analyzer.get_precision_offset_alignment_data()

                    # æå–é”¤é€Ÿå’Œå»¶æ—¶æ•°æ®ï¼Œå¹¶è®¡ç®—Z-Scoreï¼ˆä¸æŒ‰é”®ä¸å»¶æ—¶Z-Scoreæ•£ç‚¹å›¾ç›¸åŒï¼‰
                    hammer_velocities = []
                    delays_ms = []  # å»¶æ—¶ï¼ˆmså•ä½ï¼Œå¸¦ç¬¦å·ï¼Œç”¨äºè®¡ç®—Z-Scoreï¼‰
                    scatter_customdata = []  # å­˜å‚¨record_idxã€replay_idxå’Œalgorithm_nameï¼Œç”¨äºç‚¹å‡»äº‹ä»¶è¯†åˆ«
                    
                    # åˆ›å»ºåŒ¹é…å¯¹ç´¢å¼•åˆ°åç§»æ•°æ®çš„æ˜ å°„
                    offset_map = {}
                    for item in offset_data:
                        record_idx = item.get('record_index')
                        replay_idx = item.get('replay_index')
                        if record_idx is not None and replay_idx is not None:
                            offset_map[(record_idx, replay_idx)] = item
                    
                    for record_idx, replay_idx, record_note, replay_note in matched_pairs:
                        # è·å–æ’­æ”¾éŸ³ç¬¦çš„é”¤é€Ÿï¼ˆç¬¬ä¸€ä¸ªé”¤é€Ÿå€¼ï¼‰
                        if len(replay_note.hammers) > 0 and len(replay_note.hammers.values) > 0:
                            hammer_velocity = replay_note.hammers.values[0]
                        else:
                            continue
                        
                        # ä»åç§»æ•°æ®ä¸­è·å–å»¶æ—¶
                        keyon_offset = None
                        if (record_idx, replay_idx) in offset_map:
                            keyon_offset = offset_map[(record_idx, replay_idx)].get('keyon_offset', 0)
                        else:
                            # å¦‚æœåç§»æ•°æ®ä¸­æ²¡æœ‰è¿™ä¸ªåŒ¹é…å¯¹ï¼Œè·³è¿‡å¤„ç†
                            # è¿™æ˜¯ä¸ºäº†é¿å…ä½¿ç”¨ç§æœ‰API
                            continue
                        
                        # å°†å»¶æ—¶ä»0.1msè½¬æ¢ä¸ºmsï¼ˆå¸¦ç¬¦å·ï¼Œç”¨äºZ-Scoreè®¡ç®—ï¼‰
                        delay_ms = keyon_offset / 10.0
                        
                        # è·³è¿‡é”¤é€Ÿä¸º0æˆ–è´Ÿæ•°çš„æ•°æ®ç‚¹ï¼ˆå¯¹æ•°æ— æ³•å¤„ç†ï¼‰
                        if hammer_velocity <= 0:
                            continue
                        
                        # è·å–æŒ‰é”®ID
                        key_id = record_note.id if hasattr(record_note, 'id') else None
                        
                        hammer_velocities.append(hammer_velocity)
                        delays_ms.append(delay_ms)
                        # å­˜å‚¨record_idxã€replay_idxã€algorithm_nameå’Œkey_idï¼Œç”¨äºç‚¹å‡»äº‹ä»¶è¯†åˆ«å’Œæ˜¾ç¤º
                        scatter_customdata.append([record_idx, replay_idx, filename, key_id])
                    
                    if not hammer_velocities:
                        logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®ï¼Œè·³è¿‡")
                        continue
                    
                    # è®¡ç®—Z-Scoreï¼ˆä¸æŒ‰é”®ä¸å»¶æ—¶Z-Scoreæ•£ç‚¹å›¾ç›¸åŒçš„è®¡ç®—æ–¹å¼ï¼‰
                    me_0_1ms = algorithm.analyzer.get_mean_error() if hasattr(algorithm.analyzer, 'get_mean_error') else 0.0
                    std_0_1ms = algorithm.analyzer.get_standard_deviation() if hasattr(algorithm.analyzer, 'get_standard_deviation') else 0.0
                    
                    mu = me_0_1ms / 10.0  # æ€»ä½“å‡å€¼ï¼ˆmsï¼Œå¸¦ç¬¦å·ï¼‰
                    sigma = std_0_1ms / 10.0  # æ€»ä½“æ ‡å‡†å·®ï¼ˆmsï¼Œå¸¦ç¬¦å·ï¼‰
                    
                    # è®¡ç®—Z-Scoreï¼šz = (x_i - Î¼) / Ïƒ
                    delays_array = np.array(delays_ms)
                    if sigma > 0:
                        z_scores = ((delays_array - mu) / sigma).tolist()
                    else:
                        z_scores = [0.0] * len(delays_ms)
                    
                    # å°†é”¤é€Ÿè½¬æ¢ä¸ºå¯¹æ•°å½¢å¼ï¼ˆç±»ä¼¼åˆ†è´ï¼‰ï¼šlog10(velocity)
                    log_velocities = [math.log10(v) for v in hammer_velocities]
                    
                    color = colors[alg_idx % len(colors)]
                    
                    # æ·»åŠ æ•£ç‚¹å›¾æ•°æ®ï¼ˆxè½´ä½¿ç”¨å¯¹æ•°å½¢å¼çš„é”¤é€Ÿï¼Œyè½´ä½¿ç”¨Z-Scoreå€¼ï¼‰
                    # customdataæ ¼å¼: [delay_ms, original_velocity, record_idx, replay_idx, algorithm_name, key_id]
                    # ç¬¬ä¸€ä¸ªå…ƒç´ ç”¨äºhoveræ˜¾ç¤ºå»¶æ—¶ï¼Œç¬¬äºŒä¸ªå…ƒç´ ç”¨äºhoveræ˜¾ç¤ºåŸå§‹é”¤é€Ÿï¼Œåå››ä¸ªç”¨äºç‚¹å‡»äº‹ä»¶è¯†åˆ«å’Œæ˜¾ç¤º
                    combined_customdata = [[delay_ms, orig_vel, record_idx, replay_idx, alg_name, key_id] 
                                          for delay_ms, orig_vel, (record_idx, replay_idx, alg_name, key_id) 
                                          in zip(delays_ms, hammer_velocities, scatter_customdata)]
                    
                    fig.add_trace(go.Scatter(
                        x=log_velocities,
                        y=z_scores,
                        mode='markers',
                        name=f'{descriptive_name} - Z-Score',
                        marker=dict(
                            size=8,
                            color=color,
                            opacity=0.6,
                            line=dict(width=1, color=color)
                        ),
                        legendgroup=descriptive_name,
                        showlegend=True,
                        hovertemplate=f'ç®—æ³•: {descriptive_name}<br>æŒ‰é”®: %{{customdata[5]}}<br>é”¤é€Ÿ: %{{customdata[1]:.0f}} (log: %{{x:.2f}})<br>å»¶æ—¶: %{{customdata[0]:.2f}}ms<br>Z-Score: %{{y:.2f}}<extra></extra>',
                        customdata=combined_customdata
                    ))
                    
                    # æ·»åŠ Z-Scoreå‚è€ƒçº¿ï¼ˆä¸æŒ‰é”®ä¸å»¶æ—¶Z-Scoreæ•£ç‚¹å›¾ç›¸åŒï¼‰
                    if len(log_velocities) > 0:
                        # è·å–xè½´èŒƒå›´ï¼ˆä½¿ç”¨æ‰€æœ‰ç®—æ³•çš„å¯¹æ•°èŒƒå›´ï¼‰
                        all_log_velocities = []
                        for alg in ready_algorithms:
                            try:
                                matched_pairs = alg.analyzer.note_matcher.get_matched_pairs()
                                for record_idx, replay_idx, record_note, replay_note in matched_pairs:
                                    if len(replay_note.hammers) > 0 and len(replay_note.hammers.values) > 0:
                                        vel = replay_note.hammers.values[0]
                                        if vel > 0:
                                            all_log_velocities.append(math.log10(vel))
                            except:
                                continue
                        
                        # å¯¹æ•°å½¢å¼
                        x_min = min(all_log_velocities) if all_log_velocities else 0
                        x_max = max(all_log_velocities) if all_log_velocities else 2
                        
                        # æ·»åŠ Z=0çš„æ°´å¹³è™šçº¿ï¼ˆå‡å€¼çº¿ï¼‰
                        fig.add_trace(go.Scatter(
                            x=[x_min, x_max],
                            y=[0, 0],
                            mode='lines',
                            name=f'{descriptive_name} - Z=0',
                            line=dict(
                                color=color,
                                width=1.5,
                                dash='dot'
                            ),
                            legendgroup=descriptive_name,
                            showlegend=True,
                            hovertemplate=f'ç®—æ³•: {descriptive_name}<br>Z-Score = 0 (å‡å€¼çº¿)<extra></extra>'
                        ))

                        # æ·»åŠ Z=+3çš„æ°´å¹³è™šçº¿ï¼ˆä¸Šé˜ˆå€¼ï¼‰
                        fig.add_trace(go.Scatter(
                            x=[x_min, x_max],
                            y=[3, 3],
                            mode='lines',
                            name=f'{descriptive_name} - Z=+3',
                            line=dict(
                                color=color,
                                width=2,
                                dash='dash'
                            ),
                            legendgroup=descriptive_name,
                            showlegend=True,
                            hovertemplate=f'ç®—æ³•: {descriptive_name}<br>Z-Score = +3 (ä¸Šé˜ˆå€¼)<extra></extra>'
                        ))

                        # æ·»åŠ Z=-3çš„æ°´å¹³è™šçº¿ï¼ˆä¸‹é˜ˆå€¼ï¼‰
                        fig.add_trace(go.Scatter(
                            x=[x_min, x_max],
                            y=[-3, -3],
                            mode='lines',
                            name=f'{descriptive_name} - Z=-3',
                            line=dict(
                                color=color,
                                width=2,
                                dash='dash'
                            ),
                            legendgroup=descriptive_name,
                            showlegend=True,
                            hovertemplate=f'ç®—æ³•: {descriptive_name}<br>Z-Score = -3 (ä¸‹é˜ˆå€¼)<extra></extra>'
                        ))
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–ç®—æ³• '{algorithm_name}' çš„é”¤é€Ÿä¸å»¶æ—¶æ•°æ®å¤±è´¥: {e}")
                    continue
            
            # è®¾ç½®å¸ƒå±€
            
            fig.update_layout(
                # åˆ é™¤titleï¼Œå› ä¸ºUIåŒºåŸŸå·²æœ‰æ ‡é¢˜
                xaxis_title='é”¤é€Ÿï¼ˆlogâ‚â‚€ï¼‰',
                yaxis_title='Z-Scoreï¼ˆæ ‡å‡†åŒ–å»¶æ—¶ï¼‰',
                xaxis=dict(
                    showgrid=True,
                    gridcolor='lightgray',
                    gridwidth=1,
                    # ä½¿ç”¨çº¿æ€§åˆ»åº¦ï¼Œè®©Plotlyè‡ªåŠ¨å¤„ç†ï¼Œä½†è®¾ç½®åˆé€‚çš„èŒƒå›´
                    autorange=True,
                    # è®¾ç½®åˆ»åº¦æ ¼å¼
                    tickformat='.1f',  # æ˜¾ç¤º1ä½å°æ•°
                    dtick=0.2  # æ¯0.2ä¸ªå•ä½ä¸€ä¸ªåˆ»åº¦
                ),
                yaxis=dict(
                    showgrid=True,
                    gridcolor='lightgray',
                    gridwidth=1,
                    # é™åˆ¶Yè½´èŒƒå›´åˆ°åˆç†çš„Z-ScoreåŒºé—´ï¼Œé€šå¸¸Z-Scoreåœ¨-5åˆ°+5ä¹‹é—´
                    range=[-5, 5],
                    # è®¾ç½®åˆé€‚çš„åˆ»åº¦
                    dtick=1,  # æ¯ä¸ªæ•´æ•°ä¸€ä¸ªåˆ»åº¦
                    tickformat='.1f'
                ),
                hovermode='closest',
                plot_bgcolor='white',
                paper_bgcolor='white',
                font=dict(size=12),
                height=500,
                showlegend=True,
                legend=dict(
                    orientation='h',
                    yanchor='bottom',
                    y=1.02,
                    xanchor='left',
                    x=0.0,
                    bgcolor='rgba(255, 255, 255, 0.9)',
                    bordercolor='gray',
                    borderwidth=1
                ),
                margin=dict(t=70, b=60, l=60, r=60)
            )
            
            logger.info(f"âœ… å¤šç®—æ³•é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            return fig
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¤šç®—æ³•é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾å¤±è´¥: {e}")
            
            logger.error(traceback.format_exc())
            return self._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    def generate_multi_algorithm_key_hammer_velocity_scatter_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾ï¼ˆé¢œè‰²è¡¨ç¤ºå»¶æ—¶ï¼Œå åŠ æ˜¾ç¤ºï¼Œä¸åŒæ ‡è®°å½¢çŠ¶åŒºåˆ†ç®—æ³•ï¼‰
        
        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            
        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        if not algorithms:
            logger.debug("â„¹ï¸ æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å¤šç®—æ³•æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾ç”Ÿæˆ")
            return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
        
        try:
            # è¿‡æ»¤å‡ºå°±ç»ªçš„ç®—æ³•
            ready_algorithms = [alg for alg in algorithms if alg.is_ready()]
            if not ready_algorithms:
                logger.warning("âš ï¸ æ²¡æœ‰å°±ç»ªçš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾")
                return self._create_empty_plot("æ²¡æœ‰å°±ç»ªçš„ç®—æ³•")
            
            logger.info(f"ğŸ“Š å¼€å§‹ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            
            # ä¸ºæ¯ä¸ªç®—æ³•åˆ†é…ä¸åŒçš„æ ‡è®°å½¢çŠ¶å’Œé¢œè‰²æ–¹æ¡ˆ
            marker_symbols = ['circle', 'square', 'diamond', 'triangle-up', 'x', 'star', 'cross', 'pentagon']
            colorscales = ['Viridis', 'Plasma', 'Inferno', 'Magma', 'Cividis', 'Turbo', 'Blues', 'Reds']
            
            
            fig = go.Figure()
            
            # æ”¶é›†æ‰€æœ‰ç®—æ³•çš„å»¶æ—¶èŒƒå›´ï¼Œç”¨äºç»Ÿä¸€é¢œè‰²æ¡
            all_delays = []
            
            for alg_idx, algorithm in enumerate(ready_algorithms):
                algorithm_name = algorithm.metadata.algorithm_name
                display_name = algorithm.metadata.display_name
                filename = algorithm.metadata.filename

                # åˆ›å»ºæ›´å…·æè¿°æ€§çš„å›¾æ³¨åç§°ï¼šç®—æ³•å (æ–‡ä»¶å)
                descriptive_name = f"{display_name} ({filename})"

                if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
                    logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰åˆ†æå™¨æˆ–åŒ¹é…å™¨ï¼Œè·³è¿‡")
                    continue

                try:
                    matched_pairs = algorithm.analyzer.get_matched_pairs()

                    if not matched_pairs:
                        logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰åŒ¹é…æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    offset_data = algorithm.analyzer.get_precision_offset_alignment_data()
                    
                    # æå–æŒ‰é”®IDã€é”¤é€Ÿå’Œå»¶æ—¶æ•°æ®
                    key_ids = []
                    hammer_velocities = []
                    delays_ms = []
                    
                    # åˆ›å»ºåŒ¹é…å¯¹ç´¢å¼•åˆ°åç§»æ•°æ®çš„æ˜ å°„
                    offset_map = {}
                    for item in offset_data:
                        record_idx = item.get('record_index')
                        replay_idx = item.get('replay_index')
                        if record_idx is not None and replay_idx is not None:
                            offset_map[(record_idx, replay_idx)] = item
                    
                    for record_idx, replay_idx, record_note, replay_note in matched_pairs:
                        key_id = record_note.id
                        
                        if len(replay_note.hammers) > 0 and len(replay_note.hammers.values) > 0:
                            hammer_velocity = replay_note.hammers.values[0]
                        else:
                            continue
                        
                        keyon_offset = None
                        if (record_idx, replay_idx) in offset_map:
                            keyon_offset = offset_map[(record_idx, replay_idx)].get('keyon_offset', 0)
                        else:
                            # å¦‚æœåç§»æ•°æ®ä¸­æ²¡æœ‰è¿™ä¸ªåŒ¹é…å¯¹ï¼Œè·³è¿‡å¤„ç†
                            continue
                        
                        delay_ms = abs(keyon_offset) / 10.0
                        
                        try:
                            key_id_int = int(key_id)
                            key_ids.append(key_id_int)
                            hammer_velocities.append(hammer_velocity)
                            delays_ms.append(delay_ms)
                            all_delays.append(delay_ms)
                        except (ValueError, TypeError):
                            continue
                    
                    if not key_ids:
                        logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®ï¼Œè·³è¿‡")
                        continue
                    
                    marker_symbol = marker_symbols[alg_idx % len(marker_symbols)]
                    colorscale = colorscales[alg_idx % len(colorscales)]
                    
                    # æ·»åŠ æ•£ç‚¹å›¾æ•°æ®ï¼Œä½¿ç”¨ä¸åŒçš„æ ‡è®°å½¢çŠ¶å’Œé¢œè‰²æ–¹æ¡ˆåŒºåˆ†ç®—æ³•
                    fig.add_trace(go.Scatter(
                        x=key_ids,
                        y=hammer_velocities,
                        mode='markers',
                        name=f'{descriptive_name}',
                        marker=dict(
                            size=8,
                            color=delays_ms,
                            colorscale=colorscale,
                            colorbar=dict(
                                title=f'{descriptive_name}<br>å»¶æ—¶ (ms)',
                                thickness=15,
                                len=0.3,
                                x=1.02 + (alg_idx * 0.08),  # æ¯ä¸ªç®—æ³•çš„é¢œè‰²æ¡ä½ç½®ä¸åŒ
                                y=0.5 - (alg_idx * 0.3 / len(ready_algorithms))
                            ),
                            cmin=min(all_delays) if all_delays else 0,
                            cmax=max(all_delays) if all_delays else 100,
                            symbol=marker_symbol,
                            line=dict(width=1, color='rgba(0,0,0,0.3)')
                        ),
                        legendgroup=algorithm_name,
                        showlegend=True,
                        hovertemplate=f'ç®—æ³•: {algorithm_name}<br>é”®ä½: %{{x}}<br>é”¤é€Ÿ: %{{y}}<br>å»¶æ—¶: %{{marker.color:.2f}}ms<extra></extra>'
                    ))
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–ç®—æ³• '{algorithm_name}' çš„æŒ‰é”®ä¸é”¤é€Ÿæ•°æ®å¤±è´¥: {e}")
                    continue
            
            if not all_delays:
                logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨")
                return self._create_empty_plot("æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®")
            
            # è®¾ç½®å¸ƒå±€
            fig.update_layout(
                # åˆ é™¤titleï¼Œå› ä¸ºUIåŒºåŸŸå·²æœ‰æ ‡é¢˜
                xaxis_title='æŒ‰é”®ID',
                yaxis_title='é”¤é€Ÿ',
                xaxis=dict(
                    showgrid=True,
                    gridcolor='lightgray',
                    gridwidth=1,
                    dtick=10
                ),
                yaxis=dict(
                    showgrid=True,
                    gridcolor='lightgray',
                    gridwidth=1
                ),
                hovermode='closest',
                plot_bgcolor='white',
                paper_bgcolor='white',
                font=dict(size=12),
                height=500,
                showlegend=True,
                legend=dict(
                    orientation='h',
                    yanchor='bottom',
                    y=1.02,
                    xanchor='left',
                    x=0.0,
                    bgcolor='rgba(255, 255, 255, 0.9)',
                    bordercolor='gray',
                    borderwidth=1
                ),
                margin=dict(t=70, b=60, l=60, r=200)  # å¢åŠ å³ä¾§è¾¹è·ï¼Œä¸ºå¤šä¸ªé¢œè‰²æ¡ç•™å‡ºç©ºé—´
            )
            
            logger.info(f"âœ… å¤šç®—æ³•æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            return fig
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾å¤±è´¥: {e}")
            
            logger.error(traceback.format_exc())
            return self._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    def _create_empty_plot(self, message: str) -> go.Figure:
        """åˆ›å»ºç©ºå›¾è¡¨ï¼ˆç”¨äºé”™è¯¯æç¤ºï¼‰"""
        fig = go.Figure()
        fig.add_annotation(
            x=0.5,
            y=0.5,
            text=message,
            showarrow=False,
            font=dict(size=16, color='gray'),
            xref='paper',
            yref='paper'
        )
        fig.update_layout(
            xaxis=dict(showgrid=False, showticklabels=False),
            yaxis=dict(showgrid=False, showticklabels=False),
            height=400
        )
        return fig
    
    def _extract_song_identifier(self, filename: str) -> str:
        """
        ä»æ–‡ä»¶åä¸­æå–æ›²å­æ ‡è¯†ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦æ˜¯åŒä¸€é¦–æ›²å­ï¼‰
        
        Args:
            filename: åŸå§‹æ–‡ä»¶å
            
        Returns:
            str: æ›²å­æ ‡è¯†ï¼ˆå»æ‰è·¯å¾„å’Œæ‰©å±•åï¼‰
        """
        import os
        # å»æ‰è·¯å¾„ï¼Œåªä¿ç•™æ–‡ä»¶å
        basename = os.path.basename(filename)
        # å»æ‰æ‰©å±•å
        song_id = os.path.splitext(basename)[0]
        return song_id
    
    def _should_generate_time_series_plot(self, algorithms: List[AlgorithmDataset]) -> Tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ç”Ÿæˆå»¶æ—¶æ—¶é—´åºåˆ—å›¾

        æ¡ä»¶ï¼š
        1. è‡³å°‘æœ‰2ä¸ªç®—æ³•

        Args:
            algorithms: ç®—æ³•æ•°æ®é›†åˆ—è¡¨

        Returns:
            Tuple[bool, str]: (æ˜¯å¦åº”è¯¥ç”Ÿæˆ, åŸå› è¯´æ˜)
        """
        if not algorithms or len(algorithms) < 2:
            return False, "éœ€è¦è‡³å°‘2ä¸ªç®—æ³•æ‰èƒ½è¿›è¡Œå¯¹æ¯”"

        # åªè¦æœ‰è‡³å°‘2ä¸ªç®—æ³•å°±å¯ä»¥ç”Ÿæˆå›¾è¡¨ï¼Œä¸å†é™åˆ¶åŒç§ç®—æ³•çš„ä¸åŒæ›²å­
        return True, ""
    
    def _filter_ready_algorithms(self, algorithms: List[AlgorithmDataset]) -> List[AlgorithmDataset]:
        """
        è¿‡æ»¤å‡ºå°±ç»ªçš„ç®—æ³•

        Args:
            algorithms: åŸå§‹ç®—æ³•åˆ—è¡¨

        Returns:
            List[AlgorithmDataset]: å°±ç»ªçš„ç®—æ³•åˆ—è¡¨
        """
        return [alg for alg in algorithms if alg.is_ready()]

    def _prepare_algorithm_colors(self) -> List[str]:
        """
        å‡†å¤‡ç®—æ³•é¢œè‰²åˆ—è¡¨

        Returns:
            List[str]: é¢œè‰²åˆ—è¡¨
        """
        return ALGORITHM_COLOR_PALETTE

    def _process_single_algorithm_data(self, algorithm: AlgorithmDataset) -> Optional[Dict[str, Any]]:
        """
        å¤„ç†å•ä¸ªç®—æ³•çš„æ—¶é—´åºåˆ—æ•°æ®

        Args:
            algorithm: ç®—æ³•æ•°æ®é›†

        Returns:
            Optional[Dict[str, Any]]: å¤„ç†åçš„æ•°æ®ï¼ŒåŒ…å«æ—¶é—´ã€å»¶æ—¶ç­‰ä¿¡æ¯ï¼Œå¦‚æœå¤„ç†å¤±è´¥è¿”å›None
        """
        algorithm_name = algorithm.metadata.algorithm_name
        display_name = algorithm.metadata.display_name

        if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
            logger.warning(f"âš ï¸ ç®—æ³• '{display_name}' æ²¡æœ‰åˆ†æå™¨æˆ–åŒ¹é…å™¨ï¼Œè·³è¿‡")
            return None

        try:
            offset_data = algorithm.analyzer.note_matcher.get_precision_offset_alignment_data()

            if not offset_data:
                logger.warning(f"âš ï¸ ç®—æ³• '{display_name}' æ²¡æœ‰åŒ¹é…æ•°æ®ï¼Œè·³è¿‡")
                return None

            # æå–æ—¶é—´å’Œå»¶æ—¶æ•°æ®
            data_points = []

            for item in offset_data:
                record_keyon_raw = item.get('record_keyon')  # å•ä½ï¼š0.1ms
                keyon_offset_raw = item.get('keyon_offset')  # å•ä½ï¼š0.1ms
                key_id = item.get('key_id')
                record_index = item.get('record_index')
                replay_index = item.get('replay_index')

                # è¯¦ç»†è®°å½•åŸå§‹æ•°æ®ç”¨äºè°ƒè¯•
                logger.debug(f"[DEBUG] å¤„ç†è®°å½•: record_keyon_raw={record_keyon_raw} (type: {type(record_keyon_raw)}), keyon_offset_raw={keyon_offset_raw} (type: {type(keyon_offset_raw)})")

                # æ£€æŸ¥æ•°æ®ç±»å‹æœ‰æ•ˆæ€§ï¼ˆæ”¯æŒ numpy ç±»å‹ï¼‰
                record_keyon_is_valid = isinstance(record_keyon_raw, (int, float, np.integer, np.floating))
                keyon_offset_is_valid = isinstance(keyon_offset_raw, (int, float, np.integer, np.floating))

                logger.debug(f"[DEBUG] ç±»å‹æ£€æŸ¥: record_keyon_is_valid={record_keyon_is_valid}, keyon_offset_is_valid={keyon_offset_is_valid}")

                if not record_keyon_is_valid:
                    logger.debug(f"[DEBUG] è·³è¿‡è®°å½•: record_keyonæ— æ•ˆ ({record_keyon_raw}, type: {type(record_keyon_raw)})")
                    continue
                if not keyon_offset_is_valid:
                    logger.debug(f"[DEBUG] è·³è¿‡è®°å½•: keyon_offsetæ— æ•ˆ ({keyon_offset_raw}, type: {type(keyon_offset_raw)})")
                    continue

                # ä½¿ç”¨åŸå§‹æ•°æ®
                record_keyon = record_keyon_raw
                keyon_offset = keyon_offset_raw

                # è½¬æ¢ä¸ºmså•ä½
                time_ms = record_keyon / 10.0
                delay_ms = keyon_offset / 10.0

                data_points.append({
                    'time': time_ms,
                    'delay': delay_ms,
                    'key_id': key_id if key_id is not None else 'N/A',
                    'record_index': record_index,
                    'replay_index': replay_index
                })

            if not data_points:
                logger.warning(f"ç®—æ³• '{display_name}' æ²¡æœ‰æœ‰æ•ˆæ—¶é—´åºåˆ—æ•°æ®ï¼Œè·³è¿‡")
                return None

            # æŒ‰æ—¶é—´æ’åºï¼Œç¡®ä¿æŒ‰æ—¶é—´é¡ºåºæ˜¾ç¤º
            data_points.sort(key=lambda x: x['time'])

            # è®¡ç®—è¯¥ç®—æ³•çš„å¹³å‡å»¶æ—¶
            me_0_1ms = algorithm.analyzer.get_mean_error() if hasattr(algorithm.analyzer, 'get_mean_error') else 0.0
            mean_delay = me_0_1ms / 10.0  # å¹³å‡å»¶æ—¶ï¼ˆmsï¼Œå¸¦ç¬¦å·ï¼‰

            # è®¡ç®—ç›¸å¯¹å»¶æ—¶
            relative_delays_ms = []
            for point in data_points:
                delay_ms = point['delay']
                relative_delay = delay_ms - mean_delay
                relative_delays_ms.append(relative_delay)

            # æå–æ’åºåçš„æ•°æ®
            times_ms = [point['time'] for point in data_points]
            delays_ms = [point['delay'] for point in data_points]
            replay_times_ms = [point['time'] + point['delay'] for point in data_points]
            replay_times_offset_ms = [replay_time - mean_delay for replay_time in replay_times_ms]

            # customdata åŒ…å« [key_id, record_index, replay_index, algorithm_name, åŸå§‹å»¶æ—¶, å¹³å‡å»¶æ—¶, æ’­æ”¾æ—¶é—´, å½•åˆ¶æ—¶é—´]
            customdata_list = [[point['key_id'], point['record_index'], point['replay_index'],
                               algorithm_name, point['delay'], mean_delay, replay_time, point['time']]
                              for point, replay_time in zip(data_points, replay_times_ms)]

            return {
                'algorithm_name': algorithm_name,
                'display_name': display_name,
                'data_points': data_points,
                'times_ms': times_ms,
                'delays_ms': delays_ms,
                'relative_delays_ms': relative_delays_ms,
                'replay_times_ms': replay_times_ms,
                'replay_times_offset_ms': replay_times_offset_ms,
                'customdata_list': customdata_list,
                'mean_delay': mean_delay
            }

        except Exception as e:
            logger.warning(f"è·å–ç®—æ³• '{display_name}' çš„æ—¶é—´åºåˆ—æ•°æ®å¤±è´¥: {e}")
            return None

    def _create_relative_delay_traces(self, fig, algorithm_data: Dict[str, Any], color: str) -> None:
        """
        ä¸ºç›¸å¯¹å»¶æ—¶å›¾åˆ›å»ºtrace

        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            algorithm_data: ç®—æ³•æ•°æ®
            color: ç®—æ³•é¢œè‰²
        """
        algorithm_name = algorithm_data['algorithm_name']
        display_name = algorithm_data['display_name']
        replay_times_ms = algorithm_data['replay_times_ms']
        replay_times_offset_ms = algorithm_data['replay_times_offset_ms']
        relative_delays_ms = algorithm_data['relative_delays_ms']
        customdata_list = algorithm_data['customdata_list']
        mean_delay = algorithm_data['mean_delay']

        # æ·»åŠ åç§»åçš„æ’­æ”¾éŸ³è½¨æ•£ç‚¹å›¾ï¼ˆXè½´=åç§»åçš„æ’­æ”¾æ—¶é—´ï¼ŒYè½´=ç›¸å¯¹å»¶æ—¶ï¼‰
        fig.add_trace(go.Scatter(
            x=replay_times_offset_ms,  # Xè½´ä½¿ç”¨åç§»åçš„æ’­æ”¾æ—¶é—´ï¼ˆæ’­æ”¾æ—¶é—´ - å¹³å‡å»¶æ—¶ï¼‰
            y=relative_delays_ms,  # Yè½´ä½¿ç”¨ç›¸å¯¹å»¶æ—¶
            mode='markers+lines',  # æ˜¾ç¤ºæ•°æ®ç‚¹å¹¶æŒ‰æ—¶é—´é¡ºåºè¿æ¥
            name=f'{display_name} (åç§»åï¼Œå¹³å‡å»¶æ—¶: {mean_delay:.2f}ms)',
            marker=dict(
                size=5,
                color=color,
                line=dict(width=0.5, color=color)
            ),
            line=dict(color=color, width=1.5),
            legendgroup=f"{algorithm_name}_offset",
            showlegend=True,
            hovertemplate='<b>ç®—æ³•</b>: ' + display_name + ' (åç§»å)<br>' +
                         '<b>åç§»åæ’­æ”¾æ—¶é—´ï¼ˆXè½´ï¼‰</b>: %{x:.2f}ms<br>' +
                         '<b>ç›¸å¯¹å»¶æ—¶ï¼ˆYè½´ï¼‰</b>: %{y:.2f}ms<br>' +
                         '<b>å®é™…æ’­æ”¾æ—¶é—´</b>: %{customdata[6]:.2f}ms<br>' +
                         '<b>å½•åˆ¶æ—¶é—´</b>: %{customdata[7]:.2f}ms<br>' +
                         '<b>åŸå§‹å»¶æ—¶</b>: %{customdata[4]:.2f}ms<br>' +
                         '<b>å¹³å‡å»¶æ—¶</b>: %{customdata[5]:.2f}ms<br>' +
                         '<b>æŒ‰é”®ID</b>: %{customdata[0]}<br>' +
                         '<extra></extra>',
            customdata=customdata_list
        ))

    def _add_algorithm_reference_lines(self, fig, algorithm_data: Dict[str, Any], color: str) -> None:
        """
        ä¸ºç®—æ³•æ·»åŠ å‚è€ƒçº¿

        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            algorithm_data: ç®—æ³•æ•°æ®
            color: ç®—æ³•é¢œè‰²
        """
        algorithm_name = algorithm_data['algorithm_name']
        display_name = algorithm_data['display_name']
        delays_ms = algorithm_data['delays_ms']
        replay_times_offset_ms = algorithm_data['replay_times_offset_ms']
        algorithm = algorithm_data.get('algorithm_instance')

        if not delays_ms or len(delays_ms) == 0 or not algorithm or not algorithm.analyzer:
            return

        # è®¡ç®—æ ‡å‡†å·®
        std_0_1ms = algorithm.analyzer.get_standard_deviation() if hasattr(algorithm.analyzer, 'get_standard_deviation') else 0.0
        std_delay = std_0_1ms / 10.0

        # è·å–æ—¶é—´èŒƒå›´
        replay_time_offset_min = min(replay_times_offset_ms) if replay_times_offset_ms else 0
        replay_time_offset_max = max(replay_times_offset_ms) if replay_times_offset_ms else 1

        # æ·»åŠ é›¶çº¿å‚è€ƒçº¿
        fig.add_trace(go.Scatter(
            x=[replay_time_offset_min, replay_time_offset_max],
            y=[0, 0],
            mode='lines',
            name=f'{display_name} - é›¶çº¿',
            line=dict(dash='dash', color=color, width=1.5),
            hovertemplate=f'<b>{display_name} é›¶çº¿</b>: 0.00ms<extra></extra>',
            showlegend=False,
            legendgroup=algorithm_name
        ))

        # æ·»åŠ Â±3Ïƒå‚è€ƒçº¿
        if std_delay > 0:
            fig.add_trace(go.Scatter(
                x=[replay_time_offset_min, replay_time_offset_max],
                y=[3 * std_delay, 3 * std_delay],
                mode='lines',
                name=f'{display_name} - +3Ïƒ',
                line=dict(dash='dot', color=color, width=1),
                hovertemplate=f'<b>{display_name} +3Ïƒ</b>: {3 * std_delay:.2f}ms<extra></extra>',
                showlegend=False,
                legendgroup=algorithm_name
            ))
            fig.add_trace(go.Scatter(
                x=[replay_time_offset_min, replay_time_offset_max],
                y=[-3 * std_delay, -3 * std_delay],
                mode='lines',
                name=f'{display_name} - -3Ïƒ',
                line=dict(dash='dot', color=color, width=1),
                hovertemplate=f'<b>{display_name} -3Ïƒ</b>: {-3 * std_delay:.2f}ms<extra></extra>',
                showlegend=False,
                legendgroup=algorithm_name
            ))

    def _configure_multi_algorithm_axes(self, fig, all_relative_delays: List[float]) -> None:
        """
        é…ç½®å¤šç®—æ³•å›¾è¡¨çš„è½´

        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            all_relative_delays: æ‰€æœ‰ç›¸å¯¹å»¶æ—¶æ•°æ®
        """
        if not all_relative_delays:
            y_axis_min, y_axis_max, dtick = (-25, 25, 5)
        else:
            y_min = min(all_relative_delays)
            y_max = max(all_relative_delays)

            # è®¡ç®—æ•´ä½“æ ‡å‡†å·®
            delays_array = np.array(all_relative_delays)
            overall_std_dev = np.std(delays_array)

            # æ ¹æ®æ ‡å‡†å·®ç¡®å®šæ˜¾ç¤ºèŒƒå›´
            if overall_std_dev <= 3:  # å„ç®—æ³•æ•°æ®é«˜åº¦é›†ä¸­
                y_half_range = 12  # Â±12ms
                dtick = 3
            elif overall_std_dev <= 8:  # ä¸­ç­‰é›†ä¸­
                y_half_range = 20  # Â±20ms
                dtick = 4
            elif overall_std_dev <= 20:  # é€‚ä¸­ç¦»æ•£
                y_half_range = 35  # Â±35ms
                dtick = 7
            elif overall_std_dev <= 40:  # è¾ƒå¤§ç¦»æ•£
                y_half_range = 60  # Â±60ms
                dtick = 10
            else:  # è¶…å¤§ç¦»æ•£
                y_half_range = max(60, overall_std_dev * 1.5)  # è‡³å°‘Â±60msï¼Œæˆ–1.5å€æ ‡å‡†å·®
                dtick = 15

            # ä»¥0ä¸ºä¸­å¿ƒå¯¹ç§°æ˜¾ç¤ºï¼Œä½†ç¡®ä¿æ˜¾ç¤ºæ‰€æœ‰ç®—æ³•çš„æ•°æ®
            y_axis_min = min(y_min - 2, -y_half_range)
            y_axis_max = max(y_max + 2, y_half_range)

            # å¤šç®—æ³•æ¯”è¾ƒæ—¶ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„å¯¹æ¯”ç©ºé—´
            actual_range = y_axis_max - y_axis_min
            if actual_range < 20:
                y_axis_min = -10
                y_axis_max = 10
                dtick = 2

        # è®¾ç½®å¸ƒå±€
        fig.update_layout(
            xaxis_title='åç§»åæ’­æ”¾æ—¶é—´ (æ’­æ”¾æ—¶é—´ - å¹³å‡å»¶æ—¶) (ms)',
            yaxis_title='ç›¸å¯¹å»¶æ—¶ (ms)',
            plot_bgcolor='white',
            paper_bgcolor='white',
            font=dict(size=12),
            height=500,
            hovermode='closest',
            legend=dict(
                orientation='h',
                yanchor='bottom',
                y=1.05,
                xanchor='left',
                x=0.0,
                bgcolor='rgba(255, 255, 255, 0.9)',
                bordercolor='gray',
                borderwidth=1
            ),
            margin=dict(t=100, b=60, l=60, r=60)
        )

        # è®¾ç½®Yè½´
        fig.update_yaxes(
            range=[y_axis_min, y_axis_max],
            dtick=dtick,
            tickformat='.1f'
        )

    def _collect_all_relative_delay_data(self, ready_algorithms: List[AlgorithmDataset], colors: List[str], apply_time_offset: bool = False) -> List[Tuple[float, float, List, str, str]]:
        """
        æ”¶é›†æ‰€æœ‰ç®—æ³•çš„ç›¸å¯¹å»¶æ—¶æ•°æ®

        Args:
            ready_algorithms: å°±ç»ªçš„ç®—æ³•åˆ—è¡¨
            colors: é¢œè‰²åˆ—è¡¨
            apply_time_offset: æ˜¯å¦åº”ç”¨æ—¶é—´è½´åç§»ï¼ˆå‡å»å¹³å‡å»¶æ—¶ï¼‰

        Returns:
            List[Tuple[float, float, List, str, str]]: ç›¸å¯¹æ•°æ®åˆ—è¡¨ (time_ms, relative_delay_ms, customdata, descriptive_name, color)
        """
        all_relative_data = []

        for alg_idx, algorithm in enumerate(ready_algorithms):
            algorithm_name = algorithm.metadata.algorithm_name
            display_name = algorithm.metadata.display_name
            filename = algorithm.metadata.filename
            descriptive_name = f"{display_name} ({filename})"
            color = colors[alg_idx % len(colors)]

            if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
                continue

            try:
                offset_data = algorithm.analyzer.get_precision_offset_alignment_data()

                if not offset_data:
                    continue

                # è®¡ç®—è¯¥ç®—æ³•çš„å¹³å‡å»¶æ—¶ï¼ˆç”¨äºç›¸å¯¹å»¶æ—¶è®¡ç®—ï¼‰
                me_0_1ms = algorithm.analyzer.note_matcher.get_mean_error()
                mean_delay = me_0_1ms / 10.0  # å¹³å‡å»¶æ—¶ï¼ˆmsï¼‰

                # æå–æ’­æ”¾éŸ³è½¨æ•°æ®
                for item in offset_data:
                    record_keyon_raw = item.get('record_keyon')
                    replay_keyon_raw = item.get('replay_keyon')  # æ’­æ”¾æ—¶é—´
                    key_id = item.get('key_id')
                    record_index = item.get('record_index')
                    replay_index = item.get('replay_index')
                    record_velocity = item.get('record_velocity')
                    replay_velocity = item.get('replay_velocity')
                    velocity_diff = item.get('velocity_diff')
                    relative_delay = item.get('relative_delay', 0)

                    # ç±»å‹æ£€æŸ¥
                    record_keyon_is_valid = isinstance(record_keyon_raw, (int, float, np.integer, np.floating))
                    replay_keyon_is_valid = isinstance(replay_keyon_raw, (int, float, np.integer, np.floating))

                    if not record_keyon_is_valid or not replay_keyon_is_valid:
                        continue

                    # è½¬æ¢ä¸ºmså•ä½
                    time_ms = record_keyon_raw / 10.0  # Xè½´ï¼šå½•åˆ¶æ—¶é—´
                    replay_time_ms = replay_keyon_raw / 10.0  # æ’­æ”¾æ—¶é—´

                    # è®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼ˆç»å¯¹å»¶æ—¶ - å¹³å‡å»¶æ—¶ï¼‰
                    relative_delay_ms = (replay_time_ms - time_ms) - mean_delay

                    # å¦‚æœéœ€è¦æ—¶é—´è½´åç§»ï¼Œä½¿ç”¨åç§»åçš„æ’­æ”¾æ—¶é—´è½´
                    if apply_time_offset:
                        time_ms = replay_time_ms - mean_delay  # æ’­æ”¾æ—¶é—´ - å¹³å‡å»¶æ—¶
                        y_value = relative_delay_ms  # Yè½´ï¼šç›¸å¯¹å»¶æ—¶
                    else:
                        time_ms = replay_time_ms  # Xè½´ï¼šæ’­æ”¾æ—¶é—´
                        y_value = relative_delay_ms  # Yè½´ï¼šç›¸å¯¹å»¶æ—¶

                    # å­˜å‚¨åŸå§‹æ—¶é—´å€¼ï¼ˆåœ¨ä¿®æ”¹time_msä¹‹å‰ï¼‰
                    original_record_time = record_keyon_raw / 10.0
                    customdata = [key_id, record_index, replay_index, algorithm_name, replay_time_ms - original_record_time, relative_delay, mean_delay, record_velocity, replay_velocity, velocity_diff, replay_time_ms, original_record_time]

                    all_relative_data.append((time_ms, y_value, customdata, descriptive_name, color))

            except Exception as e:
                logger.warning(f"âš ï¸ å¤„ç†ç®—æ³• '{algorithm_name}' çš„ç›¸å¯¹å»¶æ—¶æ•°æ®å¤±è´¥: {e}")

        return all_relative_data

    def _create_raw_delay_plot_for_algorithms(self, all_raw_data: List[Tuple[float, float, List, str, str]]) -> Any:
        """
        ä¸ºå¤šç®—æ³•åˆ›å»ºåŸå§‹å»¶æ—¶å›¾è¡¨

        Args:
            all_raw_data: æ‰€æœ‰åŸå§‹å»¶æ—¶æ•°æ®

        Returns:
            Any: Plotlyå›¾è¡¨å¯¹è±¡
        """
        

        raw_delay_fig = go.Figure()

        # æŒ‰ç®—æ³•åˆ†ç»„æ•°æ®
        algorithm_data = {}
        for time_ms, delay_ms, customdata, descriptive_name, color in all_raw_data:
            if descriptive_name not in algorithm_data:
                algorithm_data[descriptive_name] = {
                    'times': [], 'delays': [], 'customdata': [], 'color': color
                }
            algorithm_data[descriptive_name]['times'].append(time_ms)
            algorithm_data[descriptive_name]['delays'].append(delay_ms)
            algorithm_data[descriptive_name]['customdata'].append(customdata)

        # æ·»åŠ æ¯ä¸ªç®—æ³•çš„trace
        for descriptive_name, data in algorithm_data.items():
            if data['times'] and data['delays']:
                # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
                sorted_indices = sorted(range(len(data['times'])), key=lambda i: data['times'][i])
                sorted_times = [data['times'][i] for i in sorted_indices]
                sorted_delays = [data['delays'][i] for i in sorted_indices]
                sorted_customdata = [data['customdata'][i] for i in sorted_indices]

                raw_delay_fig.add_trace(go.Scatter(
                    x=sorted_times,
                    y=sorted_delays,
                    mode='markers+lines',
                    name=f'{descriptive_name} (ç›¸å¯¹å»¶æ—¶)',
                    marker=dict(
                        size=4,
                        color=data['color'],
                        symbol='circle'  # å®å¿ƒåœ†ç‚¹
                    ),
                    line=dict(color=data['color'], width=1, dash='dot'),
                    hovertemplate='<b>ç®—æ³•</b>: ' + descriptive_name + '<br>' +
                                 '<b>æ’­æ”¾æ—¶é—´</b>: %{x:.2f}ms<br>' +
                                 '<b>å½•åˆ¶æ—¶é—´</b>: %{customdata[11]:.2f}ms<br>' +
                                 '<b>ç›¸å¯¹å»¶æ—¶</b>: %{y:.2f}ms<br>' +
                                 '<b>å¹³å‡å»¶æ—¶</b>: %{customdata[6]:.2f}ms<br>' +
                                 '<b>å½•åˆ¶é”¤é€Ÿ</b>: %{customdata[7]}<br>' +
                                 '<b>æ’­æ”¾é”¤é€Ÿ</b>: %{customdata[8]}<br>' +
                                 '<b>é”¤é€Ÿå·®å€¼</b>: %{customdata[9]}<br>' +
                                 '<b>æŒ‰é”®ID</b>: %{customdata[0]}<br>' +
                                 '<extra></extra>',
                    customdata=sorted_customdata
                ))

        # é…ç½®å¸ƒå±€
        raw_delay_fig.update_layout(
            xaxis_title='æ’­æ”¾æ—¶é—´ (ms)',
            yaxis_title='ç›¸å¯¹å»¶æ—¶ (ms)',
            showlegend=True,
            template='plotly_white',
            height=400,
            hovermode='closest',
            legend=dict(
                orientation='h',
                yanchor='bottom',
                y=1.02,
                xanchor='left',
                x=0.0,
                bgcolor='rgba(255, 255, 255, 0.9)',
                bordercolor='gray',
                borderwidth=1
            ),
            margin=dict(t=100, b=60, l=60, r=60)
        )

        return raw_delay_fig

    def _process_all_algorithms_data(self, ready_algorithms: List[AlgorithmDataset], colors: List[str]) -> Tuple[Any, List[Tuple[Dict[str, Any], str]]]:
        """
        å¤„ç†æ‰€æœ‰ç®—æ³•çš„æ•°æ®å¹¶åˆ›å»ºç›¸å¯¹å»¶æ—¶å›¾çš„traces

        Args:
            ready_algorithms: å°±ç»ªçš„ç®—æ³•åˆ—è¡¨
            colors: é¢œè‰²åˆ—è¡¨

        Returns:
            Tuple[Any, List[Tuple[Dict[str, Any], str]]]: (å›¾è¡¨å¯¹è±¡, ç®—æ³•ç»“æœåˆ—è¡¨)
        """
        
        fig = go.Figure()

        all_delays = []
        algorithm_results = []

        for alg_idx, algorithm in enumerate(ready_algorithms):
            logger.info(f"[DEBUG] å¤„ç†ç®—æ³• {alg_idx}: {algorithm.metadata.display_name}")
            algorithm_data = self._process_single_algorithm_data(algorithm)
            if algorithm_data is None:
                logger.warning(f"[DEBUG] ç®—æ³• {algorithm.metadata.display_name} è¿”å›Noneï¼Œè·³è¿‡")
                continue

            logger.info(f"[DEBUG] ç®—æ³• {algorithm.metadata.display_name} è¿”å›æ•°æ®: relative_delays_msé•¿åº¦={len(algorithm_data.get('relative_delays_ms', []))}")

            # æ·»åŠ ç®—æ³•å®ä¾‹å¼•ç”¨ï¼ˆç”¨äºåç»­å‚è€ƒçº¿è®¡ç®—ï¼‰
            algorithm_data['algorithm_instance'] = algorithm

            color = colors[alg_idx % len(colors)]

            # åˆ›å»ºç›¸å¯¹å»¶æ—¶å›¾çš„trace
            logger.info(f"[DEBUG] ä¸ºç®—æ³• {algorithm.metadata.display_name} åˆ›å»ºtraces")
            self._create_relative_delay_traces(fig, algorithm_data, color)

            # æ·»åŠ å‚è€ƒçº¿
            self._add_algorithm_reference_lines(fig, algorithm_data, color)

            # æ”¶é›†æ•°æ®ç”¨äºç»Ÿè®¡
            relative_delays = algorithm_data.get('relative_delays_ms', [])
            all_delays.extend(relative_delays)
            algorithm_results.append((algorithm_data, color))

            logger.info(f"[DEBUG] ç®—æ³• {algorithm.metadata.display_name} å¤„ç†å®Œæˆï¼Œæ·»åŠ äº† {len(relative_delays)} ä¸ªæ•°æ®ç‚¹")

        return fig, algorithm_results

    def _configure_multi_algorithm_plot_axes(self, fig: Any, algorithm_results: List[Tuple[Dict[str, Any], str]]) -> None:
        """
        é…ç½®å¤šç®—æ³•å›¾è¡¨çš„è½´

        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            algorithm_results: ç®—æ³•ç»“æœåˆ—è¡¨
        """
        # æ”¶é›†æ‰€æœ‰ç›¸å¯¹å»¶æ—¶æ•°æ®å¹¶é…ç½®è½´
        all_relative_delays = []
        for trace in fig.data:
            all_relative_delays.extend(trace.y)

        self._configure_multi_algorithm_axes(fig, all_relative_delays)

    def _create_multi_algorithm_relative_plot(self, ready_algorithms: List[AlgorithmDataset], colors: List[str], apply_time_offset: bool = False) -> Any:
        """
        åˆ›å»ºå¤šç®—æ³•ç›¸å¯¹å»¶æ—¶å›¾

        Args:
            ready_algorithms: å°±ç»ªçš„ç®—æ³•åˆ—è¡¨
            colors: é¢œè‰²åˆ—è¡¨
            apply_time_offset: æ˜¯å¦åº”ç”¨æ—¶é—´è½´åç§»

        Returns:
            Any: ç›¸å¯¹å»¶æ—¶å›¾è¡¨å¯¹è±¡
        """
        all_relative_data = self._collect_all_relative_delay_data(ready_algorithms, colors, apply_time_offset)
        return self._create_raw_delay_plot_for_algorithms(all_relative_data)

    def generate_multi_algorithm_delay_time_series_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•å»¶æ—¶æ—¶é—´åºåˆ—å›¾ï¼ˆä¸¤å¼ ç›¸å¯¹å»¶æ—¶å›¾ï¼šæ’­æ”¾æ—¶é—´è½´å¯¹æ¯”ï¼‰

        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨

        Returns:
            Dict[str, Any]: åŒ…å«ä¸Šæ–¹ç›¸å¯¹å»¶æ—¶å›¾å’Œä¸‹æ–¹ç›¸å¯¹å»¶æ—¶å›¾çš„å­—å…¸
        """
        if not algorithms:
            logger.debug("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•ï¼Œè·³è¿‡å¤šç®—æ³•å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç”Ÿæˆ")
            return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")

        try:
            # 1. è¿‡æ»¤å°±ç»ªçš„ç®—æ³•
            ready_algorithms = self._filter_ready_algorithms(algorithms)
            if not ready_algorithms:
                logger.warning("æ²¡æœ‰å°±ç»ªçš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆå¤šç®—æ³•å»¶æ—¶æ—¶é—´åºåˆ—å›¾")
                return self._create_empty_plot("æ²¡æœ‰å°±ç»ªçš„ç®—æ³•")

            # 2. æ£€æŸ¥æ˜¯å¦åº”è¯¥ç”Ÿæˆå›¾è¡¨
            should_generate, reason = self._should_generate_time_series_plot(ready_algorithms)
            if not should_generate:
                logger.info(f"è·³è¿‡å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç”Ÿæˆ: {reason}")
                return self._create_empty_plot(reason)

            logger.info(f"å¼€å§‹ç”Ÿæˆå¤šç®—æ³•å»¶æ—¶æ—¶é—´åºåˆ—å›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")

            # 3. å‡†å¤‡é¢œè‰²
            colors = self._prepare_algorithm_colors()

            # 4. å¤„ç†æ‰€æœ‰ç®—æ³•æ•°æ®å¹¶åˆ›å»ºç›¸å¯¹å»¶æ—¶å›¾
            fig, algorithm_results = self._process_all_algorithms_data(ready_algorithms, colors)

            # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…çš„æ•°æ®ç”¨äºç»˜å›¾
            has_data = any(len(trace.y) > 0 for trace in fig.data) if fig.data else False
            logger.info(f"[DEBUG] has_dataæ£€æŸ¥: fig.dataå­˜åœ¨={fig.data is not None}, tracesæ•°é‡={len(fig.data) if fig.data else 0}, has_data={has_data}")

            if not has_data:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ—¶é—´åºåˆ—æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨")
                # è®°å½•æ›´å¤šè°ƒè¯•ä¿¡æ¯
                for i, alg in enumerate(ready_algorithms):
                    logger.warning(f"  ç®—æ³• {i}: {alg.metadata.display_name}")
                return self._create_empty_plot("æ²¡æœ‰æœ‰æ•ˆçš„æ—¶é—´åºåˆ—æ•°æ®")

            # 5. é…ç½®ç›¸å¯¹å»¶æ—¶å›¾çš„å›¾æ³¨
            fig.update_layout(
                title='ç›¸å¯¹å»¶æ—¶æ—¶é—´åºåˆ—å›¾ï¼ˆæ’­æ”¾æ—¶é—´è½´ï¼‰',
                height=500,
                showlegend=True,
                legend=dict(
                    orientation='h',
                    yanchor='bottom',
                    y=1.02,
                    xanchor='left',
                    x=0.0,
                    bgcolor='rgba(255, 255, 255, 0.9)',
                    bordercolor='gray',
                    borderwidth=1,
                    title='ç®—æ³•å›¾ä¾‹'
                ),
                template='plotly_white',
                hovermode='closest'
            )

            # 6. åˆ›å»ºä¸Šæ–¹ç›¸å¯¹å»¶æ—¶å›¾ï¼ˆæ’­æ”¾æ—¶é—´è½´ï¼‰
            raw_delay_plot = self._create_multi_algorithm_relative_plot(ready_algorithms, colors, apply_time_offset=False)
            if raw_delay_plot:
                raw_delay_plot.update_layout(
                    title='ç›¸å¯¹å»¶æ—¶æ—¶é—´åºåˆ—å›¾ï¼ˆæ’­æ”¾æ—¶é—´è½´ï¼‰',
                    height=500,
                    showlegend=True,
                    legend=dict(
                        orientation='h',
                        yanchor='bottom',
                        y=1.02,
                        xanchor='left',
                        x=0.0,
                        bgcolor='rgba(255, 255, 255, 0.9)',
                        bordercolor='gray',
                        borderwidth=1,
                        title='ç®—æ³•å›¾ä¾‹'
                    ),
                    template='plotly_white',
                    hovermode='closest'
                )

            logger.info(f"å¤šç®—æ³•å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç”ŸæˆæˆåŠŸï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            return {
                'raw_delay_plot': raw_delay_plot,
                'relative_delay_plot': fig
            }

        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤šç®—æ³•å»¶æ—¶æ—¶é—´åºåˆ—å›¾å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            empty_plot = self._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {
                'raw_delay_plot': empty_plot,
                'relative_delay_plot': empty_plot
            }

    def _configure_unified_waterfall_layout(self, fig: go.Figure, all_bars_by_algorithm: List[Dict], is_multi_algorithm: bool) -> None:
        """
        é…ç½®ç»Ÿä¸€çš„ç€‘å¸ƒå›¾å¸ƒå±€ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€è½´æ ‡ç­¾ã€å›¾ä¾‹å’ŒåŠ¨æ€é«˜åº¦è°ƒæ•´ã€‚

        Args:
            fig: Plotlyå›¾å½¢å¯¹è±¡
            all_bars_by_algorithm: æŒ‰ç®—æ³•åˆ†ç»„çš„æ‰€æœ‰æ¡å½¢æ•°æ®
            is_multi_algorithm: æ˜¯å¦å¤šç®—æ³•æ¨¡å¼
        """
        # è®¡ç®—åŠ¨æ€é«˜åº¦
        if is_multi_algorithm:
            num_algorithms = len(all_bars_by_algorithm)
            # å¤šç®—æ³•æ¨¡å¼ï¼šæ¯ä¸ªç®—æ³•åˆ†é…æ›´å¤šé«˜åº¦
            base_height_per_algorithm = 600
            total_height = max(800, base_height_per_algorithm * num_algorithms)
        else:
            # å•ç®—æ³•æ¨¡å¼ï¼šå›ºå®šé«˜åº¦
            total_height = 800

        # è®¡ç®—yè½´èŒƒå›´ï¼ˆè€ƒè™‘å¤šç®—æ³•åç§»ï¼‰
        if is_multi_algorithm:
            num_algorithms = len(all_bars_by_algorithm)
            max_y_offset = (num_algorithms - 1) * 100  # æ¯ä¸ªç®—æ³•åç§»100
            y_min = 0.5
            y_max = 89.5 + max_y_offset + 1  # ç•™å‡ºä¸€äº›ä½™é‡

            # ä¸ºå¤šç®—æ³•åˆ›å»ºåˆé€‚çš„åˆ»åº¦
            tick_vals = []
            tick_texts = []
            for alg_idx in range(num_algorithms):
                base_offset = alg_idx * 100
                for key_id in range(21, 109, 12):  # æ¯12ä¸ªé”®æ˜¾ç¤ºä¸€ä¸ªåˆ»åº¦
                    tick_vals.append(key_id + base_offset)
                    if alg_idx == 0:
                        tick_texts.append(str(key_id))
                    else:
                        tick_texts.append(f"{key_id}({alg_idx+1})")

            y_axis_config = dict(
                tickmode='array',
                tickvals=tick_vals,
                ticktext=tick_texts,
                range=[y_min, y_max],
                autorange=False
            )
        else:
            # å•ç®—æ³•æ¨¡å¼ï¼šæ ‡å‡†é’¢ç´é”®èŒƒå›´
            y_axis_config = dict(
                tickmode='array',
                tickvals=list(range(1, 89)),
                range=[0.5, 89.5],
                autorange=False
            )

        # é…ç½®å¸ƒå±€
        fig.update_layout(
            title='ç€‘å¸ƒå›¾ - é’¢ç´æŒ‰é”®äº‹ä»¶æ—¶åºå¯è§†åŒ–',
            xaxis_title='æ—¶é—´ (ms)',
            yaxis_title='æŒ‰é”®ID' + (' (å¤šç®—æ³•åç§»)' if is_multi_algorithm else ''),
            yaxis=y_axis_config,
            height=total_height,
            showlegend=True,
            legend=dict(
                orientation='h',
                yanchor='bottom',
                y=1.02,
                xanchor='left',
                x=0.0,
                bgcolor='rgba(255, 255, 255, 0.9)',
                bordercolor='gray',
                borderwidth=1
            ),
            template='plotly_white',
            hovermode='closest',
            margin=dict(l=80, r=60, t=100, b=80)
        )
