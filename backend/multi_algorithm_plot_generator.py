#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¤šç®—æ³•å›¾è¡¨ç”Ÿæˆå™¨

è´Ÿè´£ç”Ÿæˆæ”¯æŒå¤šç®—æ³•å¯¹æ¯”çš„å›¾è¡¨ï¼Œä½¿ç”¨é¢å‘å¯¹è±¡è®¾è®¡ã€‚
"""
import math
import traceback
from typing import List, Optional, Any, Dict, Tuple
import plotly.graph_objects as go
import numpy as np
from backend.multi_algorithm_manager import AlgorithmDataset
from utils.logger import Logger
from utils.colors import ALGORITHM_COLOR_PALETTE

logger = Logger.get_logger()


class MultiAlgorithmPlotGenerator:
    """
    å¤šç®—æ³•å›¾è¡¨ç”Ÿæˆå™¨ç±»
    
    è´Ÿè´£ç”Ÿæˆæ”¯æŒå¤šç®—æ³•å¯¹æ¯”çš„å›¾è¡¨ï¼ŒåŒ…æ‹¬ï¼š
    - ç€‘å¸ƒå›¾ï¼ˆå¤šç®—æ³•å åŠ æ˜¾ç¤ºï¼‰
    - åç§»å¯¹é½åˆ†æå›¾ï¼ˆå¤šç®—æ³•å¹¶æ’æŸ±çŠ¶å›¾ï¼‰
    - å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆå¤šç®—æ³•å åŠ æ˜¾ç¤ºï¼‰
    """
    
    def __init__(self, key_filter=None):
        """
        åˆå§‹åŒ–å¤šç®—æ³•å›¾è¡¨ç”Ÿæˆå™¨
        
        Args:
            key_filter: æŒ‰é”®è¿‡æ»¤å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        """
        self.key_filter = key_filter
        
        # ä½¿ç”¨å…¨å±€é¢œè‰²æ–¹æ¡ˆ
        self.COLORS = ALGORITHM_COLOR_PALETTE
        
    
    def generate_unified_waterfall_plot(
        self,
        backend,                        # åç«¯å®ä¾‹ï¼Œç”¨äºè·å–å…¨å±€å¹³å‡å»¶æ—¶
        analyzers: List[Any],           # åˆ†æå™¨åˆ—è¡¨ï¼Œæ ¹æ®SPMIDæ–‡ä»¶æ•°é‡è‡ªåŠ¨å¤„ç†
        algorithm_names: List[str],     # ç®—æ³•åç§°åˆ—è¡¨
        time_filter=None,
        key_filter=None
    ) -> Any:
        """
        ç”Ÿæˆç»Ÿä¸€çš„ç€‘å¸ƒå›¾ï¼ˆè‡ªåŠ¨æ ¹æ®SPMIDæ–‡ä»¶æ•°é‡å¤„ç†ï¼‰
        
        æ ¹æ®analyzersçš„æ•°é‡è‡ªåŠ¨åˆ¤æ–­ï¼š
        - 1ä¸ªæ–‡ä»¶ï¼šä¸éœ€è¦yè½´åç§»
        - å¤šä¸ªæ–‡ä»¶ï¼šæ¯ä¸ªæ–‡ä»¶åˆ†é…ç‹¬ç«‹çš„yè½´èŒƒå›´
        
        Args:
            backend: åç«¯å®ä¾‹
            analyzers: åˆ†æå™¨åˆ—è¡¨
            algorithm_names: ç®—æ³•åç§°åˆ—è¡¨
            time_filter: æ—¶é—´è¿‡æ»¤å™¨
            key_filter: æŒ‰é”®è¿‡æ»¤å™¨
            
        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        if not analyzers:
            logger.warning("æ²¡æœ‰åˆ†æå™¨ï¼Œæ— æ³•ç”Ÿæˆç€‘å¸ƒå›¾")
            return self._create_empty_plot("æ²¡æœ‰åˆ†æå™¨")

        try:
            # è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦ä¸ºå¤šæ–‡ä»¶æ¨¡å¼
            is_multi_file = len(analyzers) > 1
            logger.info(f"å¼€å§‹ç”Ÿæˆç€‘å¸ƒå›¾ï¼Œå…± {len(analyzers)} ä¸ªSPMIDæ–‡ä»¶")

            # æ ¹æ®æ–‡ä»¶æ•°é‡å†³å®šæ˜¯å¦åˆ†é…y_offsetèŒƒå›´
            algorithm_y_range = 100 if is_multi_file else 0  # å¤šæ–‡ä»¶æ—¶æ¯ä¸ªåˆ†é…100çš„yè½´èŒƒå›´

            # è·å–å¹³å‡å»¶æ—¶æ•°æ®
            avg_delay_ms = self._get_average_delay(backend, is_multi_file, algorithm_names)
            
            # æ”¶é›†æ‰€æœ‰æ•°æ®ç‚¹ç”¨äºå…¨å±€å½’ä¸€åŒ–
            all_bars_by_algorithm = []

            # å¤„ç†æ¯ä¸ªåˆ†æå™¨
            for alg_idx, (analyzer, algorithm_name) in enumerate(zip(analyzers, algorithm_names)):
                if not analyzer:
                    logger.warning(f"åˆ†æå™¨ '{algorithm_name}' ä¸ºç©ºï¼Œè·³è¿‡")
                    continue

                # è®¡ç®—å½“å‰ç®—æ³•çš„y_offset
                current_y_offset = alg_idx * algorithm_y_range if is_multi_file else 0

                # æ”¶é›†å½“å‰åˆ†æå™¨çš„å®Œæ•´æ•°æ®ï¼šåŒ¹é…å¯¹ + ä¸¢é”¤ + å¤šé”¤
                algorithm_bars = self._collect_algorithm_comprehensive_data(
                    analyzer, current_y_offset, algorithm_name, alg_idx, avg_delay_ms
                )

                all_bars_by_algorithm.append({
                    'analyzer': analyzer,
                    'bars': algorithm_bars,
                    'algorithm_name': algorithm_name,
                    'y_offset': current_y_offset
                })

            if not all_bars_by_algorithm:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®ç‚¹ï¼Œæ— æ³•ç”Ÿæˆç€‘å¸ƒå›¾")
                return self._create_empty_plot("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®ç‚¹")

            # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„é”¤é€Ÿå€¼å¹¶è®¡ç®—å…¨å±€èŒƒå›´ï¼ˆç”¨äºé¢œè‰²å½’ä¸€åŒ–ï¼‰
            all_values = self._collect_velocity_values(all_bars_by_algorithm)
            vmin, vmax = self._calculate_velocity_range(all_values)

            # åˆ›å»ºå›¾è¡¨
            fig = go.Figure()
            
            # ä¸ºæ¯ä¸ªæ¡å½¢æ®µæ·»åŠ trace
            total_bars = 0
            drop_hammer_bars = 0
            multi_hammer_bars = 0
            matched_bars = 0
            
            for alg_data in all_bars_by_algorithm:
                bars = alg_data['bars']
                algorithm_name = alg_data['algorithm_name']

                logger.info(f"ç®—æ³• '{algorithm_name}': å‡†å¤‡ç»˜åˆ¶ {len(bars)} ä¸ªbars")

                for bar in bars:
                    total_bars += 1
                    data_type = bar.get('data_type', '')
                    if data_type == 'drop_hammer':
                        drop_hammer_bars += 1
                    elif data_type == 'multi_hammer':
                        multi_hammer_bars += 1
                    else:
                        matched_bars += 1

                    # æ·»åŠ barçš„trace
                    success = self._add_waterfall_bar_trace(fig, bar, algorithm_name, vmin, vmax)
                    if not success:
                        # æ•°æ®æ— æ•ˆè¢«è·³è¿‡ï¼Œç»Ÿè®¡éœ€è¦è°ƒæ•´
                        total_bars -= 1
                        if data_type == 'drop_hammer':
                            drop_hammer_bars -= 1
                        elif data_type == 'multi_hammer':
                            multi_hammer_bars -= 1
                        else:
                            matched_bars -= 1
            
            # é…ç½®å›¾è¡¨å¸ƒå±€
            self._configure_unified_waterfall_layout(fig, all_bars_by_algorithm, is_multi_file)

            logger.info(f"ç€‘å¸ƒå›¾ç”ŸæˆæˆåŠŸ: æ€»è®¡ {total_bars} ä¸ªbars (åŒ¹é…å¯¹: {matched_bars}, ä¸¢é”¤: {drop_hammer_bars}, å¤šé”¤: {multi_hammer_bars})")
            return fig

        except Exception as e:
            return self._handle_generation_error(e, "ç€‘å¸ƒå›¾")

    def _collect_algorithm_comprehensive_data(self, analyzer, y_offset: float, algorithm_name: str, alg_idx: int, avg_delay_ms: float = 0.0) -> List[Dict]:
        """
        æ”¶é›†å•ä¸ªç®—æ³•çš„å®Œæ•´ç€‘å¸ƒå›¾æ•°æ®ï¼šåŒ¹é…å¯¹ + ä¸¢é”¤ + å¤šé”¤

        è¿™ä¸ªæ–¹æ³•ä½œä¸ºç»Ÿä¸€å…¥å£ï¼Œåè°ƒå„ä¸ªå­æ¨¡å—çš„æ•°æ®æ”¶é›†å·¥ä½œã€‚

        Args:
            analyzer: SPMIDAnalyzerå®ä¾‹
            y_offset: Yè½´åç§»é‡
            algorithm_name: ç®—æ³•åç§°
            alg_idx: ç®—æ³•ç´¢å¼•
            avg_delay_ms: å¹³å‡å»¶æ—¶ï¼ˆç”¨äºç›¸å¯¹å»¶æ—¶è®¡ç®—ï¼‰

        Returns:
            List[Dict]: è¯¥ç®—æ³•çš„æ‰€æœ‰ç€‘å¸ƒå›¾æ•°æ®
        """
        algorithm_bars = []

        logger.info(f"å¼€å§‹æ”¶é›†ç®—æ³• '{algorithm_name}' çš„ç€‘å¸ƒå›¾æ•°æ®")

        # 1. æ”¶é›†åŒ¹é…å¯¹æ•°æ®ï¼ˆæˆåŠŸå’Œå¤±è´¥çš„åŒ¹é…ï¼‰
        matched_bars = self._collect_matched_pair_data(analyzer, y_offset, algorithm_name, avg_delay_ms)
        algorithm_bars.extend(matched_bars)

        # 2. æ”¶é›†ä¸¢é”¤æ•°æ®
        drop_hammer_bars = self._collect_drop_hammer_data(analyzer, y_offset, algorithm_name)
        algorithm_bars.extend(drop_hammer_bars)

        # 3. æ”¶é›†å¤šé”¤æ•°æ®
        multi_hammer_bars = self._collect_multi_hammer_data(analyzer, y_offset, algorithm_name)
        algorithm_bars.extend(multi_hammer_bars)

        return algorithm_bars

    def _collect_matched_pair_data(self, analyzer, y_offset: float, algorithm_name: str, avg_delay_ms: float) -> List[Dict]:
        """
        æ”¶é›†åŒ¹é…å¯¹æ•°æ®ï¼ˆæˆåŠŸåŒ¹é…å’Œå¤±è´¥åŒ¹é…ï¼‰

        Args:
            analyzer: SPMIDAnalyzerå®ä¾‹
            y_offset: Yè½´åç§»é‡
            algorithm_name: ç®—æ³•åç§°
            avg_delay_ms: å¹³å‡å»¶æ—¶

        Returns:
            List[Dict]: åŒ¹é…å¯¹çš„ç€‘å¸ƒå›¾æ•°æ®
        """
        bars = []

        if not hasattr(analyzer, 'note_matcher') or not analyzer.note_matcher:
            logger.info("æ²¡æœ‰note_matcherï¼Œè·³è¿‡åŒ¹é…å¯¹æ•°æ®æ”¶é›†")
            return bars

        note_matcher = analyzer.note_matcher
        if not hasattr(note_matcher, 'match_results'):
            logger.info("æ²¡æœ‰match_resultsï¼Œè·³è¿‡åŒ¹é…å¯¹æ•°æ®æ”¶é›†")
            return bars

        logger.info(f"å¼€å§‹æ”¶é›†åŒ¹é…å¯¹æ•°æ®ï¼Œå…± {len(note_matcher.match_results)} ä¸ªåŒ¹é…ç»“æœ")

        for result in note_matcher.match_results:
            try:
                # è·å–å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦
                record_note = note_matcher._record_data[result.record_index]
                replay_note = note_matcher._replay_data[result.replay_index] if result.replay_index is not None else None

                # è®¡ç®—å»¶æ—¶å’Œè¯„çº§
                grade_name, color_intensity, delay_ms, relative_delay_ms = self._calculate_match_grading(
                    result, record_note, replay_note, avg_delay_ms
                )

                record_match_index = getattr(result, 'record_index', 'N/A')
                replay_match_index = getattr(result, 'replay_index', 'N/A')

                # å¤„ç†å½•åˆ¶æ•°æ®
                if hasattr(record_note, 'after_touch') and record_note.after_touch is not None:
                    record_bars = self._extract_note_bars_for_multi(
                        record_note, 'record', y_offset, color_intensity,
                        algorithm_name, grade_name, record_match_index, delay_ms, relative_delay_ms
                    )
                    bars.extend(record_bars)

                    # å¤„ç†æ’­æ”¾æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if replay_note is not None and hasattr(replay_note, 'after_touch') and replay_note.after_touch is not None:
                        replay_bars = self._extract_note_bars_for_multi(
                            replay_note, 'replay', y_offset, color_intensity,
                            algorithm_name, grade_name, replay_match_index, delay_ms, relative_delay_ms
                        )

                        # åˆå¹¶hoverä¿¡æ¯
                        if record_bars and replay_bars:
                            self._merge_matched_hover_info(record_bars, replay_bars, avg_delay_ms)

                        bars.extend(replay_bars)

            except (IndexError, AttributeError, TypeError) as e:
                logger.warning(f"å¤„ç†åŒ¹é…ç»“æœå¤±è´¥: {e}")
                continue

        logger.info(f"åŒ¹é…å¯¹æ•°æ®æ”¶é›†å®Œæˆ: {len(bars)} ä¸ªbars")
        return bars

    def _collect_error_hammer_data(
        self, 
        analyzer, 
        y_offset: float, 
        algorithm_name: str,
        error_type: str,
        errors: List,
        data_source: List,
        data_type: str,
        error_label: str,
        error_description: str
    ) -> List[Dict]:
        """
        ç»Ÿä¸€çš„é”™è¯¯é”¤æ•°æ®æ”¶é›†æ–¹æ³•
        
        Args:
            analyzer: SPMIDAnalyzerå®ä¾‹
            y_offset: Yè½´åç§»é‡
            algorithm_name: ç®—æ³•åç§°
            error_type: é”™è¯¯ç±»å‹æ ‡è¯† ('drop_hammer' æˆ– 'multi_hammer')
            errors: é”™è¯¯åˆ—è¡¨
            data_source: æ•°æ®æºåˆ—è¡¨
            data_type: æ•°æ®ç±»å‹ ('record' æˆ– 'replay')
            error_label: é”™è¯¯æ ‡ç­¾ï¼ˆç”¨äºæ‚¬åœæ–‡æœ¬æ ‡é¢˜ï¼‰
            error_description: é”™è¯¯æè¿°ï¼ˆç”¨äºæ‚¬åœæ–‡æœ¬è¯¦æƒ…ï¼‰
            
        Returns:
            List[Dict]: é”™è¯¯é”¤çš„ç€‘å¸ƒå›¾æ•°æ®
        """
        bars = []
        
        if not errors:
            logger.info(f"æ²¡æœ‰{error_label}æ•°æ®")
            return bars
        
        logger.info(f"å¼€å§‹æ”¶é›†{error_label}æ•°æ®: {len(errors)} ä¸ª")
        
        for idx, error_note in enumerate(errors):
            try:
                # è·å–éŸ³ç¬¦ç´¢å¼•
                note_index = self._get_error_note_index(error_note)
                
                # éªŒè¯ç´¢å¼•å¹¶è·å–noteå¯¹è±¡
                if not self._is_valid_index(note_index, len(data_source)):
                    continue
                
                note = data_source[note_index]
                if note is None:
                    note = self._create_default_note(error_note, note_index)
                
                # åªå¤„ç†æœ‰after_touchæ•°æ®çš„note
                if hasattr(note, 'after_touch') and note.after_touch is not None and hasattr(note.after_touch, 'index') and len(note.after_touch.index) > 0:
                    bars.extend(self._extract_note_bars_for_multi(
                        note, data_type, y_offset, 0.1, algorithm_name,
                        "å¤±è´¥", note_index, 0.0, 0.0, error_type
                    ))
                    
                    # åˆ›å»ºæ‚¬åœä¿¡æ¯
                    for bar in bars[-1:]:  # åªå¤„ç†åˆšæ·»åŠ çš„bar
                        bar['text'] = f'<b>{error_label}:</b><br>' + \
                                     f'ç±»å‹: {data_type}<br>' + \
                                     f'é”®ä½: {getattr(note, "id", "N/A")}<br>' + \
                                     f'é”¤é€Ÿ: {self._extract_hammer_velocity(note)}<br>' + \
                                     f'ç­‰çº§: å¤±è´¥ ({error_label})<br>' + \
                                     f'ç´¢å¼•: {note_index}<br>' + \
                                     f'æŒ‰é”®æŒ‰ä¸‹: {bar["t_on"]/10:.2f}ms<br>' + \
                                     f'æŒ‰é”®é‡Šæ”¾: {bar["t_off"]/10:.2f}ms<br>' + \
                                     f'é”™è¯¯ç±»å‹: {error_description}<br>'
                    
                    logger.info(f"{error_label} #{idx} å¤„ç†å®Œæˆ")
                else:
                    logger.warning(f"{error_label} #{idx} ç¼ºå°‘after_touchæ•°æ®ï¼Œè·³è¿‡")
            
            except Exception as e:
                logger.error(f"å¤„ç†{error_label} #{idx} å¤±è´¥: {e}")
                continue
        
        logger.info(f"{error_label}æ•°æ®æ”¶é›†å®Œæˆ: {len(bars)} ä¸ªbars")
        return bars
    
    def _collect_drop_hammer_data(self, analyzer, y_offset: float, algorithm_name: str) -> List[Dict]:
        """
        æ”¶é›†ä¸¢é”¤é”™è¯¯æ•°æ®

        Args:
            analyzer: SPMIDAnalyzerå®ä¾‹
            y_offset: Yè½´åç§»é‡
            algorithm_name: ç®—æ³•åç§°

        Returns:
            List[Dict]: ä¸¢é”¤çš„ç€‘å¸ƒå›¾æ•°æ®
        """
        return self._collect_error_hammer_data(
            analyzer=analyzer,
            y_offset=y_offset,
            algorithm_name=algorithm_name,
            error_type='drop_hammer',
            errors=getattr(analyzer, 'drop_hammers', []),
            data_source=getattr(analyzer, 'initial_valid_record_data', []),
            data_type='record',
            error_label='ä¸¢é”¤é”™è¯¯ (å½•åˆ¶æ•°æ®)',
            error_description='ä¸¢é”¤ (æ’­æ”¾æ•°æ®ç¼ºå¤±)'
        )

    def _collect_multi_hammer_data(self, analyzer, y_offset: float, algorithm_name: str) -> List[Dict]:
        """
        æ”¶é›†å¤šé”¤é”™è¯¯æ•°æ®

        Args:
            analyzer: SPMIDAnalyzerå®ä¾‹
            y_offset: Yè½´åç§»é‡
            algorithm_name: ç®—æ³•åç§°

        Returns:
            List[Dict]: å¤šé”¤çš„ç€‘å¸ƒå›¾æ•°æ®
        """
        return self._collect_error_hammer_data(
            analyzer=analyzer,
            y_offset=y_offset,
            algorithm_name=algorithm_name,
            error_type='multi_hammer',
            errors=getattr(analyzer, 'multi_hammers', []),
            data_source=getattr(analyzer, 'initial_valid_replay_data', []),
            data_type='replay',
            error_label='å¤šé”¤é”™è¯¯ (æ’­æ”¾æ•°æ®)',
            error_description='å¤šé”¤ (å½•åˆ¶æ•°æ®ç¼ºå¤±)'
        )

    def _calculate_match_grading(self, result, record_note, replay_note, avg_delay_ms: float):
        """
        è®¡ç®—åŒ¹é…ç»“æœçš„è¯„çº§å’Œå»¶æ—¶ä¿¡æ¯

        Returns:
            tuple: (grade_name, color_intensity, delay_ms, relative_delay_ms)
        """
        grade_name = "æœªçŸ¥"
        delay_ms = 0.0
        relative_delay_ms = 0.0

        if result.is_success and record_note and replay_note:
            # è®¡ç®—å»¶æ—¶ï¼ˆç›´æ¥ä½¿ç”¨Note.key_on_msï¼Œå•ä½å·²æ˜¯msï¼‰
            if record_note.key_on_ms is not None and replay_note.key_on_ms is not None:
                delay_ms = replay_note.key_on_ms - record_note.key_on_ms
                relative_delay_ms = delay_ms - avg_delay_ms
            else:
                delay_ms = 0.0
                relative_delay_ms = 0.0

            # è¯„çº§
            if delay_ms <= 20:
                color_intensity, grade_name = 0.8, "ä¼˜ç§€"
            elif delay_ms <= 30:
                color_intensity, grade_name = 0.6, "è‰¯å¥½"
            elif delay_ms <= 50:
                color_intensity, grade_name = 0.4, "ä¸€èˆ¬"
            elif delay_ms <= 1000:
                color_intensity, grade_name = 0.3, "è¾ƒå·®"
            else:
                color_intensity, grade_name = 0.2, "ä¸¥é‡"
        else:
            color_intensity, grade_name = 0.1, "å¤±è´¥"
            relative_delay_ms = 0.0 - avg_delay_ms

        return grade_name, color_intensity, delay_ms, relative_delay_ms


    # TODO
    def _get_error_note_index(self, error_note) -> int:
        """
        ä»é”™è¯¯noteä¸­è·å–éŸ³ç¬¦ç´¢å¼•
        """
        note_index = error_note.global_index if hasattr(error_note, 'global_index') and error_note.global_index >= 0 else None
        # å¦‚æœglobal_indexä¸å¯ç”¨ï¼Œå°è¯•ä»notesè·å–ï¼ˆå‘åå…¼å®¹ï¼‰
        if note_index is None and hasattr(error_note, 'notes') and error_note.notes is not None and len(error_note.notes) > 0:
            # Noteå¯¹è±¡æ²¡æœ‰indexå±æ€§ï¼Œä½¿ç”¨global_index
            note_index = error_note.global_index
        return note_index

    def _is_valid_index(self, index: int, data_length: int) -> bool:
        """
        éªŒè¯ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
        """
        if index is None or index < 0:
            return False
        if index >= data_length:
            logger.warning(f"ç´¢å¼•è¶…å‡ºèŒƒå›´: {index} >= {data_length}")
            return False
        return True

    def _create_default_note(self, error_note, index: int):
        """
        åˆ›å»ºé»˜è®¤çš„noteå¯¹è±¡ç”¨äºæ˜¾ç¤º
        """
        class DefaultNote:
            def __init__(self, key_id, index):
                self.id = key_id
                self.offset = 0
                # ä¸ºé»˜è®¤noteåˆ›å»ºåŸºæœ¬çš„after_touchæ•°æ®
                self.after_touch = type('AfterTouch', (), {
                    'index': [index * 10, (index + 1) * 10]  # ç®€å•çš„å¼€å§‹å’Œç»“æŸæ—¶é—´
                })()

        return DefaultNote(error_note.keyId if hasattr(error_note, 'keyId') else 60, index)

    def _merge_matched_hover_info(self, record_bars: List[Dict], replay_bars: List[Dict], avg_delay_ms: float) -> None:
        """
        å°†åŒ¹é…çš„replayä¿¡æ¯åˆå¹¶åˆ°record barsçš„hoveræ–‡æœ¬ä¸­ï¼Œå®ç°ç»Ÿä¸€çš„æ‚¬åœæ˜¾ç¤ºã€‚

        Args:
            record_bars: å½•åˆ¶æ•°æ®çš„æ¡å½¢åˆ—è¡¨
            replay_bars: æ’­æ”¾æ•°æ®çš„æ¡å½¢åˆ—è¡¨
            avg_delay_ms: å¹³å‡å»¶æ—¶ï¼ˆæ¯«ç§’ï¼‰
        """
        # åŒ¹é…é€»è¾‘ï¼šæŒ‰é”®ä½å¯¹åº”ï¼ˆç¡®ä¿recordå’Œreplayçš„ç›¸åŒé”®ä½æ•°æ®é…å¯¹ï¼‰
        for record_bar in record_bars:
            # æŸ¥æ‰¾å¯¹åº”çš„replay barï¼ˆé€šè¿‡original_key_idåŒ¹é…ï¼‰
            replay_info = None
            record_key_id = record_bar.get('original_key_id')

            for replay_bar in replay_bars:
                if replay_bar.get('original_key_id') == record_key_id:
                    replay_info = replay_bar
                    break

            if replay_info:
                logger.info(f"åˆå¹¶é”®ä½ {record_key_id}: å½•åˆ¶å’Œæ’­æ”¾æ•°æ®é…å¯¹æˆåŠŸ")

                # è·å–recordçš„åŸå§‹æ–‡æœ¬
                original_text = record_bar.get('text', '')
                logger.info(f"åŸå§‹recordæ–‡æœ¬é•¿åº¦: {len(original_text)}")

                # æå–replayç›¸å…³çš„å®Œæ•´ä¿¡æ¯
                replay_velocity = replay_info.get('velocity', 'N/A')
                replay_key_press = replay_info.get('t_on', 0) / 10
                replay_key_release = replay_info.get('t_off', 0) / 10
                replay_grade = replay_info.get('grade_name', 'æœªçŸ¥')
                replay_match_index = replay_info.get('match_index', 'N/A')
                replay_delay_ms = replay_info.get('delay_ms', 0.0)
                replay_relative_delay_ms = replay_info.get('relative_delay_ms', 0.0)
                replay_first_hammer = replay_info.get('first_hammer_time', 'N/A')

                logger.info(f"ğŸµ æ’­æ”¾æ•°æ®: é”¤é€Ÿ={replay_velocity}, ç­‰çº§={replay_grade}, å»¶æ—¶={replay_delay_ms:.2f}ms")

                # åœ¨recordçš„hoveræ–‡æœ¬ä¸­æ·»åŠ å®Œæ•´çš„replayä¿¡æ¯éƒ¨åˆ†
                replay_section = '<br><b>æ’­æ”¾æ•°æ®:</b><br>' + \
                            f'ç±»å‹: replay<br>' + \
                            f'é”®ä½: {record_key_id}<br>' + \
                            f'é”¤é€Ÿ: {replay_velocity}<br>' + \
                            f'ç­‰çº§: {replay_grade}<br>' + \
                            f'ç´¢å¼•: {replay_match_index}<br>' + \
                            f'ç»å¯¹å»¶æ—¶: {replay_delay_ms:.2f}ms<br>' + \
                            f'ç›¸å¯¹å»¶æ—¶: {replay_relative_delay_ms:+.2f}ms<br>' + \
                            f'å¹³å‡å»¶æ—¶: {avg_delay_ms:.2f}ms<br>' + \
                            f'é¦–é”¤æ—¶é—´: {replay_first_hammer} ({replay_first_hammer/10:.2f}ms)<br>' + \
                            f'æŒ‰é”®æŒ‰ä¸‹: {replay_key_press:.2f}ms<br>' + \
                            f'æŒ‰é”®é‡Šæ”¾: {replay_key_release:.2f}ms<br>'

                merged_text = original_text + replay_section

                record_bar['text'] = merged_text
                # ä¸ºreplay baråˆ›å»ºç‹¬ç«‹çš„æ‚¬åœä¿¡æ¯
                replay_text = '<b>æ’­æ”¾æ•°æ®:</b><br>' + \
                             f'ç±»å‹: replay<br>' + \
                             f'é”®ä½: {record_key_id}<br>' + \
                             f'é”¤é€Ÿ: {replay_velocity}<br>' + \
                             f'ç­‰çº§: {replay_grade}<br>' + \
                             f'ç´¢å¼•: {replay_match_index}<br>' + \
                             f'ç»å¯¹å»¶æ—¶: {replay_delay_ms:.2f}ms<br>' + \
                             f'ç›¸å¯¹å»¶æ—¶: {replay_relative_delay_ms:+.2f}ms<br>' + \
                             f'å¹³å‡å»¶æ—¶: {avg_delay_ms:.2f}ms<br>' + \
                             f'é¦–é”¤æ—¶é—´: {replay_first_hammer} ({replay_first_hammer/10:.2f}ms)<br>' + \
                             f'æŒ‰é”®æŒ‰ä¸‹: {replay_key_press:.2f}ms<br>' + \
                             f'æŒ‰é”®é‡Šæ”¾: {replay_key_release:.2f}ms<br>'
                replay_info['text'] = replay_text
            else:
                logger.warning(f"é”®ä½ {record_key_id}: æœªæ‰¾åˆ°å¯¹åº”çš„æ’­æ”¾æ•°æ®ï¼Œæ— æ³•åˆå¹¶hoverä¿¡æ¯")
                # ä¸ºæ²¡æœ‰åŒ¹é…æ’­æ”¾æ•°æ®çš„record baræ·»åŠ æç¤º
                original_text = record_bar.get('text', '')
                no_replay_section = '<br><b>æ’­æ”¾æ•°æ®:</b><br>æœªæ‰¾åˆ°åŒ¹é…çš„æ’­æ”¾æ•°æ®<br>'
                record_bar['text'] = original_text + no_replay_section


    def _extract_note_bars_for_multi(self, note, label: str, y_offset: float, color_intensity: float, algorithm_name: str, grade_name: str = "æœªçŸ¥", match_index: str = "N/A", delay_ms: float = 0.0, relative_delay_ms: float = 0.0, data_type: str = None) -> List[Dict]:
        """
        ä¸ºå¤šç®—æ³•æ¨¡å¼æå–éŸ³ç¬¦æ¡å½¢æ•°æ®

        Args:
            note: Noteå¯¹è±¡
            label: 'record' æˆ– 'replay'
            y_offset: Yè½´åç§»é‡
            color_intensity: é¢œè‰²å¼ºåº¦ (0.0-1.0)
            algorithm_name: ç®—æ³•åç§°
            data_type: æ•°æ®ç±»å‹ ('drop_hammer', 'multi_hammer', None)

        Returns:
            List[Dict]: æ¡å½¢æ•°æ®åˆ—è¡¨
        """
        # éªŒè¯noteæ•°æ®
        if not self._validate_note_for_bar(note, label, data_type):
            return []
        
        key_id = getattr(note, 'id', 1)
        
        # ä»Noteå¯¹è±¡è·å–é¢„è®¡ç®—çš„æ—¶é—´å±æ€§
        if note.key_on_ms is None or note.key_off_ms is None:
            logger.warning(f"âš ï¸ noteç¼ºå°‘æ—¶é—´æ•°æ®: key_id={key_id}")
            return []
        
        # è½¬æ¢ä¸º0.1mså•ä½ï¼ˆbarå­—å…¸å­˜å‚¨çš„å•ä½ï¼‰
        key_on_time = note.key_on_ms * 10.0
        key_off_time = note.key_off_ms * 10.0
        
        try:
            # è®¡ç®—Yè½´ä½ç½®
            actual_key_id = self._calculate_y_position(key_id, y_offset, label)
            
            # æå–é”¤é€Ÿä¿¡æ¯
            hammer_velocity = self._extract_hammer_velocity(note)
            
            # è§£æmatch_index
            source_index = self._parse_match_index(match_index)
            
            # åˆ›å»ºbarå­—å…¸
            bar = self._create_bar_dict(
                key_on_time, key_off_time, actual_key_id, key_id,
                hammer_velocity, color_intensity,
                algorithm_name, label, data_type, grade_name, match_index,
                source_index, delay_ms, relative_delay_ms
            )
            
            # ç”Ÿæˆhoveræ–‡æœ¬
            bar['text'] = self._generate_hover_text(
                bar, label, data_type, algorithm_name, key_id,
                hammer_velocity, grade_name, match_index,
                delay_ms, relative_delay_ms, key_on_time, key_off_time
            )

            return [bar]
            
        except (TypeError, ValueError, AttributeError) as e:
            logger.warning(f"ğŸš« åˆ›å»º {data_type} barå¤±è´¥: {e}")
            return []
    
    def _validate_note_for_bar(self, note, label: str, data_type: str) -> bool:
        """éªŒè¯noteå¯¹è±¡æ˜¯å¦æœ‰æ•ˆ"""
        if not note:
            logger.warning(f"âš ï¸ noteä¸ºç©º, label={label}, data_type={data_type}")
            return False
        
        if not hasattr(note, 'hammers'):
            logger.warning(f"âš ï¸ noteæ²¡æœ‰hammerså±æ€§, key_id={getattr(note, 'id', 'N/A')}, label={label}, data_type={data_type}")
            return False
        
        if note.hammers is None:
            logger.warning(f"âš ï¸ note.hammersä¸ºNone, key_id={getattr(note, 'id', 'N/A')}, label={label}, data_type={data_type}")
            return False
        
        return True
    
    def _calculate_y_position(self, key_id: int, y_offset: float, label: str) -> float:
        """è®¡ç®—Yè½´ä½ç½®"""
        actual_key_id = key_id + y_offset
        if label == 'replay':
            actual_key_id += 0.2  # æ’­æ”¾æ•°æ®ç¨å¾®åç§»
        return actual_key_id
    
    def _extract_hammer_velocity(self, note) -> Any:
        """æå–é”¤é€Ÿä¿¡æ¯"""
        velocity = note.get_first_hammer_velocity()
        return velocity if velocity is not None else "N/A"

    def _normalize_velocity_value(self, velocity: float, vmin: float, vmax: float) -> float:
        """å°†é”¤é€Ÿå€¼å½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´ç”¨äºé¢œè‰²æ˜ å°„

        Args:
            velocity: é”¤é€Ÿå€¼
            vmin: é”¤é€Ÿæœ€å°å€¼
            vmax: é”¤é€Ÿæœ€å¤§å€¼

        Returns:
            float: å½’ä¸€åŒ–åçš„å€¼ (0.0-1.0)
        """
        if vmax > vmin:
            # æ­£å¸¸æƒ…å†µï¼šæ•°æ®æœ‰å˜åŒ–èŒƒå›´ï¼Œè¿›è¡Œmin-maxå½’ä¸€åŒ–
            return (velocity - vmin) / (vmax - vmin)
        elif vmax == vmin:
            # ç‰¹æ®Šæƒ…å†µï¼šæ‰€æœ‰é”¤é€Ÿå€¼éƒ½ç›¸åŒï¼Œæ‰€æœ‰ç‚¹ç”¨ç›¸åŒé¢œè‰²
            return 0.5  # ä¸­é—´è‰²è°ƒ
        else:
            # ç†è®ºä¸Šä¸ä¼šå‘ç”Ÿï¼Œä½†ä¿æŒå¥å£®æ€§
            return 0.5

    def _calculate_velocity_color(self, velocity: float, vmin: float, vmax: float) -> str:
        """æ ¹æ®é”¤é€Ÿå€¼è®¡ç®—é¢œè‰²

        Args:
            velocity: é”¤é€Ÿå€¼
            vmin: é”¤é€Ÿæœ€å°å€¼
            vmax: é”¤é€Ÿæœ€å¤§å€¼

        Returns:
            str: RGBAé¢œè‰²å­—ç¬¦ä¸²
        """
        import matplotlib.pyplot as plt
        cmap = plt.colormaps['YlOrRd']  # ä»æµ…é»„åˆ°æ·±çº¢ï¼Œè¶Šå¤§è¶Šæ·±

        # å½’ä¸€åŒ–å¹¶æ˜ å°„åˆ°é¢œè‰²
        normalized = self._normalize_velocity_value(velocity, vmin, vmax)
        color = 'rgba' + str(tuple(int(255*x) for x in cmap(normalized)[:3]) + (0.9,))
        return color

    def _create_bar_trace_name(self, algorithm_name: str, data_type: str, bar_label: str) -> str:
        """åˆ›å»ºbarçš„traceåç§°

        Args:
            algorithm_name: ç®—æ³•åç§°
            data_type: æ•°æ®ç±»å‹ ('drop_hammer', 'multi_hammer', æˆ–å…¶ä»–)
            bar_label: baræ ‡ç­¾

        Returns:
            str: traceåç§°
        """
        if data_type == 'drop_hammer':
            return f"{algorithm_name} - ä¸¢é”¤"
        elif data_type == 'multi_hammer':
            return f"{algorithm_name} - å¤šé”¤"
        else:
            return f"{algorithm_name} - {bar_label}"

    def _collect_velocity_values(self, all_bars_by_algorithm: List[Dict]) -> List[float]:
        """ä»æ‰€æœ‰ç®—æ³•çš„barsä¸­æ”¶é›†æœ‰æ•ˆçš„é”¤é€Ÿå€¼

        Args:
            all_bars_by_algorithm: æ‰€æœ‰ç®—æ³•çš„barsæ•°æ®åˆ—è¡¨

        Returns:
            List[float]: æœ‰æ•ˆçš„é”¤é€Ÿå€¼åˆ—è¡¨
        """
        all_values = []
        total_bars = 0
        valid_bars = 0
        na_bars = 0
        
        for alg_data in all_bars_by_algorithm:
            for bar in alg_data['bars']:
                total_bars += 1
                velocity = bar.get('velocity')
                if velocity != "N/A" and isinstance(velocity, (int, float)):
                    all_values.append(velocity)
                    valid_bars += 1
                else:
                    na_bars += 1
        
        logger.info(f"ğŸ¨ é”¤é€Ÿæ”¶é›†ç»Ÿè®¡: æ€»bars={total_bars}, æœ‰æ•ˆé”¤é€Ÿ={valid_bars}, æ— æ•ˆ/N/A={na_bars}")
        if all_values:
            logger.info(f"ğŸ¨ é”¤é€ŸèŒƒå›´: min={min(all_values)}, max={max(all_values)}, æ ·æœ¬æ•°={len(all_values)}")
        
        return all_values

    def _calculate_velocity_range(self, velocity_values: List[float]) -> Tuple[float, float]:
        """è®¡ç®—é”¤é€Ÿå€¼çš„å…¨å±€èŒƒå›´

        Args:
            velocity_values: é”¤é€Ÿå€¼åˆ—è¡¨

        Returns:
            Tuple[float, float]: (vmin, vmax)
        """
        if velocity_values:
            return min(velocity_values), max(velocity_values)
        else:
            return 0.0, 1.0

    def _add_waterfall_bar_trace(self, fig: go.Figure, bar: Dict, algorithm_name: str,
                                vmin: float, vmax: float) -> bool:
        """æ·»åŠ å•ä¸ªç€‘å¸ƒå›¾barçš„trace

        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            bar: baræ•°æ®å­—å…¸
            algorithm_name: ç®—æ³•åç§°
            vmin: é”¤é€Ÿæœ€å°å€¼
            vmax: é”¤é€Ÿæœ€å¤§å€¼

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ ï¼ˆFalseè¡¨ç¤ºæ•°æ®æ— æ•ˆè¢«è·³è¿‡ï¼‰
        """
        # è·å–é”¤é€Ÿæ•°æ®å¹¶è®¡ç®—é¢œè‰²
        velocity = bar.get('velocity')
        if velocity == "N/A" or not isinstance(velocity, (int, float)):
            # å¦‚æœæ²¡æœ‰é”¤é€Ÿæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤é¢œè‰²ï¼ˆç°è‰²ï¼‰
            color = 'rgba(128, 128, 128, 0.9)'
        else:
            # æœ‰é”¤é€Ÿæ•°æ®ï¼Œä½¿ç”¨åŸºäºé”¤é€Ÿçš„é¢œè‰²æ˜ å°„
            color = self._calculate_velocity_color(velocity, vmin, vmax)

        # åˆ›å»ºtraceåç§°
        data_type = bar.get('data_type', '')
        trace_name = self._create_bar_trace_name(algorithm_name, data_type, bar['label'])

        # æ·»åŠ æ°´å¹³çº¿æ®µ
        fig.add_trace(go.Scatter(
            x=[bar['t_on']/10, bar['t_off']/10],
            y=[bar['key_id'], bar['key_id']],
            mode='lines',
            line=dict(color=color, width=3),
            name=trace_name,
            showlegend=False,
            legendgroup=algorithm_name,
            hoverinfo='text' if bar.get('text') else 'skip',
            text=bar.get('text', ''),
            customdata=[[
                bar['t_on']/10,
                bar['t_off']/10,
                int(bar.get('original_key_id', bar.get('key_id', 0))),
                bar.get('velocity', 'N/A'),
                bar.get('label', 'unknown'),
                bar.get('source_index', 0),
                algorithm_name
            ]]
        ))
        return True

    def _handle_generation_error(self, error: Exception, plot_type: str, include_traceback: bool = True,
                                return_dict: bool = False, return_list: bool = False) -> Any:
        """é€šç”¨å›¾è¡¨ç”Ÿæˆé”™è¯¯å¤„ç†æ–¹æ³•

        Args:
            error: æ•è·çš„å¼‚å¸¸
            plot_type: å›¾è¡¨ç±»å‹æè¿°ï¼ˆç”¨äºé”™è¯¯æ¶ˆæ¯ï¼‰
            include_traceback: æ˜¯å¦åŒ…å«å®Œæ•´çš„å †æ ˆè·Ÿè¸ª
            return_dict: æ˜¯å¦è¿”å›å­—å…¸æ ¼å¼çš„é”™è¯¯ç»“æœï¼ˆç”¨äºè¿”å›å¤šä¸ªå›¾è¡¨çš„æ–¹æ³•ï¼‰
            return_list: æ˜¯å¦è¿”å›åˆ—è¡¨æ ¼å¼çš„é”™è¯¯ç»“æœï¼ˆç”¨äºè¿”å›å›¾è¡¨åˆ—è¡¨çš„æ–¹æ³•ï¼‰

        Returns:
            Any: ç©ºçš„å›¾è¡¨å¯¹è±¡ã€é”™è¯¯å­—å…¸æˆ–é”™è¯¯åˆ—è¡¨
        """
        logger.error(f"âŒ ç”Ÿæˆ{plot_type}å¤±è´¥: {error}")
        if include_traceback:
            logger.error(traceback.format_exc())

        empty_plot = self._create_empty_plot(f"ç”Ÿæˆå¤±è´¥: {str(error)}")

        if return_dict:
            return {
                'raw_delay_plot': empty_plot,
                'relative_delay_plot': empty_plot
            }
        elif return_list:
            return [{'title': 'ç”Ÿæˆå¤±è´¥', 'figure': empty_plot}]
        else:
            return empty_plot

    def _get_multi_file_average_delay(self, backend, algorithm_names: List[str]) -> float:
        """è·å–å¤šæ–‡ä»¶æ¨¡å¼çš„å¹³å‡å»¶æ—¶

        Args:
            backend: åç«¯å®ä¾‹
            algorithm_names: ç®—æ³•åç§°åˆ—è¡¨

        Returns:
            float: å¹³å‡å»¶æ—¶(ms)
        """
        if not algorithm_names or algorithm_names[0] == 'single':
            return 0.0

        try:
            # è·å–æ´»è·ƒç®—æ³•åˆ—è¡¨
            active_algorithms = backend.get_active_algorithms()
            
            if not active_algorithms:
                return 0.0

            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç®—æ³•
            target_algorithm_name = algorithm_names[0]
            target_algorithm = None
            for alg in active_algorithms:
                if (hasattr(alg, 'metadata') and
                    hasattr(alg.metadata, 'algorithm_name') and
                    alg.metadata.algorithm_name == target_algorithm_name):
                    target_algorithm = alg
                    break

            # è·å–è¯¥ç®—æ³•çš„å¹³å‡å»¶æ—¶
            if (target_algorithm and
                target_algorithm.analyzer and
                hasattr(target_algorithm.analyzer, 'get_global_average_delay')):

                avg_delay_0_1ms = target_algorithm.analyzer.get_global_average_delay()
                return avg_delay_0_1ms / 10.0

        except Exception as e:
            logger.warning(f"è·å–å¤šæ–‡ä»¶å¹³å‡å»¶æ—¶å¤±è´¥: {e}")

        return 0.0

    def _get_single_file_average_delay(self, backend) -> float:
        """è·å–å•æ–‡ä»¶æ¨¡å¼çš„å¹³å‡å»¶æ—¶

        Args:
            backend: åç«¯å®ä¾‹

        Returns:
            float: å¹³å‡å»¶æ—¶(ms)
        """
        try:
            avg_delay_0_1ms = backend.get_global_average_delay()
            return avg_delay_0_1ms / 10.0
        except Exception as e:
            logger.warning(f"è·å–å•æ–‡ä»¶å¹³å‡å»¶æ—¶å¤±è´¥: {e}")
            return 0.0

    def _get_average_delay(self, backend, is_multi_file: bool, algorithm_names: List[str]) -> float:
        """ç»Ÿä¸€è·å–å¹³å‡å»¶æ—¶ï¼ˆè‡ªåŠ¨é€‰æ‹©å•æ–‡ä»¶æˆ–å¤šæ–‡ä»¶æ¨¡å¼ï¼‰

        Args:
            backend: åç«¯å®ä¾‹
            is_multi_file: æ˜¯å¦ä¸ºå¤šæ–‡ä»¶æ¨¡å¼
            algorithm_names: ç®—æ³•åç§°åˆ—è¡¨

        Returns:
            float: å¹³å‡å»¶æ—¶(ms)
        """
        if is_multi_file:
            return self._get_multi_file_average_delay(backend, algorithm_names)
        else:
            return self._get_single_file_average_delay(backend)
    
    def _parse_match_index(self, match_index) -> int:
        """è§£æmatch_indexä¸ºsource_index"""
        source_index = 0
        try:
            if isinstance(match_index, str) and match_index != "N/A":
                source_index = int(match_index)
            elif isinstance(match_index, int):
                source_index = match_index
        except (ValueError, TypeError):
            source_index = 0
        return source_index
    
    def _create_bar_dict(self, key_on_time: float, key_off_time: float, actual_key_id: float,
                        key_id: int, hammer_velocity,
                        color_intensity: float, algorithm_name: str, label: str,
                        data_type: str, grade_name: str, match_index, source_index: int,
                        delay_ms: float, relative_delay_ms: float) -> Dict:
        """åˆ›å»ºbarå­—å…¸"""
        return {
            't_on': float(key_on_time),
            't_off': float(key_off_time),
            'key_id': actual_key_id,
            'original_key_id': key_id,
            'velocity': hammer_velocity,
            'color_intensity': color_intensity,
            'algorithm_name': algorithm_name,
            'label': label,
            'data_type': data_type,
            'hammer_index': 0,
            'grade_name': grade_name,
            'match_index': match_index,
            'source_index': source_index,
            'delay_ms': delay_ms,
            'relative_delay_ms': relative_delay_ms,
            'first_hammer_time': key_on_time
        }
    
    def _generate_hover_text(self, bar: Dict, label: str, data_type: str,
                            algorithm_name: str, key_id: int, hammer_velocity,
                            grade_name: str, match_index, delay_ms: float,
                            relative_delay_ms: float, key_on_time: float,
                            key_off_time: float) -> str:
        """ç”Ÿæˆhoveræ–‡æœ¬"""
        # ç”Ÿæˆæ•°æ®ç±»å‹åç¼€
        bar_type_suffix = ""
        if data_type == "drop_hammer":
            bar_type_suffix = " (ä¸¢é”¤)"
        elif data_type == "multi_hammer":
            bar_type_suffix = " (å¤šé”¤)"
        
        # æ ¹æ®labelæ„å»ºä¸åŒçš„hoveræ–‡æœ¬
        if label == 'record':
            return (
                f'ç®—æ³•: {algorithm_name}<br>'
                f'ç±»å‹: {label}{bar_type_suffix}<br>'
                f'é”®ä½: {key_id}<br>'
                f'é”¤é€Ÿ: {hammer_velocity}<br>'
                f'ç­‰çº§: {grade_name}<br>'
                f'ç´¢å¼•: {match_index}<br>'
                f'æŒ‰é”®æŒ‰ä¸‹: {key_on_time/10:.2f}ms<br>'
                f'æŒ‰é”®é‡Šæ”¾: {key_off_time/10:.2f}ms<br>'
            )
        else:
            return (
                f'ç®—æ³•: {algorithm_name}<br>'
                f'ç±»å‹: {label}{bar_type_suffix}<br>'
                f'é”®ä½: {key_id}<br>'
                f'é”¤é€Ÿ: {hammer_velocity}<br>'
                f'ç­‰çº§: {grade_name}<br>'
                f'ç´¢å¼•: {match_index}<br>'
                f'ç»å¯¹å»¶æ—¶: {delay_ms:.2f}ms<br>'
                f'ç›¸å¯¹å»¶æ—¶: {relative_delay_ms:+.2f}ms<br>'
                f'æŒ‰é”®æŒ‰ä¸‹: {key_on_time/10:.2f}ms<br>'
                f'æŒ‰é”®é‡Šæ”¾: {key_off_time/10:.2f}ms<br>'
            )
    
    def _apply_key_filter(self, data: List, key_filter: set) -> List:
        """åº”ç”¨æŒ‰é”®è¿‡æ»¤"""
        if not key_filter:
            return data
        return [note for note in data if note.keyId in key_filter]
    
    
    def generate_multi_algorithm_offset_alignment_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆå¤šç®—æ³•åç§»å¯¹é½åˆ†æå›¾ï¼ˆå¹¶æ’æŸ±çŠ¶å›¾ï¼Œä¸åŒé¢œè‰²ï¼‰
        
        è¿”å›5ä¸ªç‹¬ç«‹çš„å›¾è¡¨ï¼Œæ¯ä¸ªå›¾è¡¨æ˜¾ç¤ºä¸€ä¸ªæŒ‡æ ‡ï¼š
        - ä¸­ä½æ•°åç§»ã€å‡å€¼åç§»ã€æ ‡å‡†å·®ã€æ–¹å·®ã€ç›¸å¯¹å»¶æ—¶
        
        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: åŒ…å«å›¾è¡¨ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
        """
        # éªŒè¯è¾“å…¥
        if not algorithms:
            return self._create_empty_offset_figures("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
        
        try:
            # è¿‡æ»¤å°±ç»ªçš„ç®—æ³•
            ready_algorithms = [alg for alg in algorithms if alg.is_ready()]
            if not ready_algorithms:
                logger.warning("âš ï¸ æ²¡æœ‰å°±ç»ªçš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆå¤šç®—æ³•åç§»å¯¹é½åˆ†æå›¾")
                return self._create_empty_offset_figures("æ²¡æœ‰å°±ç»ªçš„ç®—æ³•")
            
            # æ”¶é›†æ‰€æœ‰ç®—æ³•çš„æ•°æ®
            all_algorithms_data = self._collect_all_algorithms_offset_data(ready_algorithms)
            
            if not all_algorithms_data:
                logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„åç§»å¯¹é½æ•°æ®ï¼Œæ— æ³•ç”ŸæˆæŸ±çŠ¶å›¾")
                return self._create_empty_offset_figures("æ²¡æœ‰æœ‰æ•ˆçš„åç§»å¯¹é½æ•°æ®")
            
            # ç”Ÿæˆå›¾è¡¨
            figures_list = self._generate_offset_metric_figures(all_algorithms_data)
            
            return figures_list
            
        except Exception as e:
            return self._handle_generation_error(e, "å¤šç®—æ³•åç§»å¯¹é½åˆ†æå›¾", return_list=True)
    
    def _create_empty_offset_figures(self, message: str) -> List[Dict[str, Any]]:
        """åˆ›å»ºç©ºçš„åç§»å¯¹é½å›¾è¡¨åˆ—è¡¨"""
        empty_fig = self._create_empty_plot(message)
        return [
            {'title': 'ä¸­ä½æ•°åç§»', 'figure': empty_fig},
            {'title': 'å‡å€¼åç§»', 'figure': empty_fig},
            {'title': 'æ ‡å‡†å·®', 'figure': empty_fig},
            {'title': 'æ–¹å·®', 'figure': empty_fig},
            {'title': 'ç›¸å¯¹å»¶æ—¶', 'figure': empty_fig}
        ]
    
    def _collect_all_algorithms_offset_data(self, ready_algorithms: List[AlgorithmDataset]) -> List[Dict]:
        """æ”¶é›†æ‰€æœ‰ç®—æ³•çš„åç§»å¯¹é½æ•°æ®"""
        all_algorithms_data = []
        colors = ALGORITHM_COLOR_PALETTE
        
        for alg_idx, algorithm in enumerate(ready_algorithms):
            algorithm_data = self._collect_single_algorithm_offset_data(
                algorithm, alg_idx, colors
            )
            if algorithm_data:
                all_algorithms_data.append(algorithm_data)
        
        return all_algorithms_data
    
    def _collect_single_algorithm_offset_data(self, algorithm: AlgorithmDataset, 
                                              alg_idx: int, colors: List[str]) -> Optional[Dict]:
        """æ”¶é›†å•ä¸ªç®—æ³•çš„åç§»å¯¹é½æ•°æ®"""
        algorithm_name = algorithm.metadata.algorithm_name
        
        if not algorithm.analyzer:
            logger.warning(f"âš ï¸ ç®—æ³• '{algorithm_name}' æ²¡æœ‰åˆ†æå™¨ï¼Œè·³è¿‡")
            return None
        
        try:
            # è·å–åç§»æ•°æ®
            offset_data = algorithm.analyzer.get_precision_offset_alignment_data()
            
            # è®¡ç®—å¹³å‡å»¶æ—¶
            mean_delay = self._calculate_mean_delay(algorithm.analyzer)
            
            # æŒ‰key_idåˆ†ç»„
            key_groups, key_groups_relative = self._group_offset_data_by_key(
                offset_data, mean_delay
            )
            
            # è®¡ç®—ç»Ÿè®¡æ•°æ®
            statistics = self._calculate_offset_statistics(key_groups, key_groups_relative)
            
            if not statistics['key_ids']:
                return None
            
            return {
                'name': algorithm_name,
                'display_name': algorithm.metadata.display_name,
                'color': colors[alg_idx % len(colors)],
                'analyzer': algorithm.analyzer,
                **statistics
            }
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–ç®—æ³• '{algorithm_name}' çš„åç§»å¯¹é½æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _calculate_mean_delay(self, analyzer) -> float:
        """è®¡ç®—ç®—æ³•çš„å¹³å‡å»¶æ—¶"""
        me_0_1ms = analyzer.get_mean_error() if hasattr(analyzer, 'get_mean_error') else 0.0
        return me_0_1ms / 10.0  # è½¬æ¢ä¸ºms
    
    def _group_offset_data_by_key(self, offset_data: List[Dict], 
                                   mean_delay: float) -> Tuple[Dict, Dict]:
        """æŒ‰key_idåˆ†ç»„åç§»æ•°æ®"""
        from collections import defaultdict
        
        key_groups = defaultdict(list)
        key_groups_relative = defaultdict(list)
        
        for item in offset_data:
            key_id = item.get('key_id', 'N/A')
            keyon_offset = item.get('keyon_offset', 0)
            keyon_offset_abs = abs(keyon_offset)
            keyon_offset_ms = keyon_offset / 10.0
            relative_delay = keyon_offset_ms - mean_delay
            
            key_groups[key_id].append(keyon_offset_abs)
            key_groups_relative[key_id].append(relative_delay)
        
        return key_groups, key_groups_relative
    
    def _calculate_offset_statistics(self, key_groups: Dict, 
                                     key_groups_relative: Dict) -> Dict:
        """è®¡ç®—åç§»ç»Ÿè®¡æ•°æ®"""
        key_ids = []
        median = []
        mean = []
        std = []
        variance = []
        relative_mean = []
        
        for key_id, offsets in key_groups.items():
            if not offsets:
                continue
            
            try:
                key_id_int = int(key_id)
                key_ids.append(key_id_int)
                median.append(np.median(offsets) / 10.0)
                mean.append(np.mean(offsets) / 10.0)
                std.append(np.std(offsets) / 10.0)
                variance.append(np.var(offsets) / 100.0)
                
                # è®¡ç®—ç›¸å¯¹å»¶æ—¶çš„å‡å€¼
                if key_id in key_groups_relative:
                    relative_mean.append(np.mean(key_groups_relative[key_id]))
                else:
                    relative_mean.append(0.0)
            except (ValueError, TypeError):
                continue
        
        return {
            'key_ids': key_ids,
            'median': median,
            'mean': mean,
            'std': std,
            'variance': variance,
            'relative_mean': relative_mean
        }
    
    def _generate_offset_metric_figures(self, all_algorithms_data: List[Dict]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ‰€æœ‰æŒ‡æ ‡çš„å›¾è¡¨"""
        # å®šä¹‰æŒ‡æ ‡é…ç½®
        metrics = [
            ('ä¸­ä½æ•°åç§»', 'median', 'ms'),
            ('å‡å€¼åç§»', 'mean', 'ms'),
            ('æ ‡å‡†å·®', 'std', 'ms'),
            ('æ–¹å·®', 'variance', 'msÂ²'),
            ('ç›¸å¯¹å»¶æ—¶', 'relative_mean', 'ms')
        ]
        
        # è®¡ç®—å…¨å±€å‚æ•°
        all_key_ids = self._get_all_key_ids(all_algorithms_data)
        num_algorithms = len(all_algorithms_data)
        bar_width = 0.8 / num_algorithms
        min_key_id = max(1, min(all_key_ids)) if all_key_ids else 1
        max_key_id = max(all_key_ids) if all_key_ids else 90
        
        # ä¸ºæ¯ä¸ªæŒ‡æ ‡ç”Ÿæˆå›¾è¡¨
        figures_list = []
        for metric_name, data_key, unit in metrics:
            fig = self._create_single_offset_metric_figure(
                metric_name, data_key, unit, all_algorithms_data,
                all_key_ids, num_algorithms, bar_width, min_key_id, max_key_id
            )
            figures_list.append({'title': metric_name, 'figure': fig})
        
        return figures_list
    
    def _get_all_key_ids(self, all_algorithms_data: List[Dict]) -> List[int]:
        """è·å–æ‰€æœ‰é”®ä½IDçš„å¹¶é›†"""
        all_key_ids = set()
        for alg_data in all_algorithms_data:
            all_key_ids.update(alg_data['key_ids'])
        return sorted(list(all_key_ids))
    
    def _create_single_offset_metric_figure(self, metric_name: str, data_key: str, 
                                            unit: str, all_algorithms_data: List[Dict],
                                            all_key_ids: List[int], num_algorithms: int,
                                            bar_width: float, min_key_id: int, 
                                            max_key_id: int) -> go.Figure:
        """åˆ›å»ºå•ä¸ªæŒ‡æ ‡çš„å›¾è¡¨"""
        fig = go.Figure()
        
        # ä¸ºæ¯ä¸ªç®—æ³•æ·»åŠ trace
        for alg_idx, alg_data in enumerate(all_algorithms_data):
            self._add_algorithm_trace_to_figure(
                fig, alg_data, alg_idx, data_key, metric_name, unit,
                all_key_ids, num_algorithms, bar_width
            )
        
        # é…ç½®å¸ƒå±€
        self._configure_offset_figure_layout(
            fig, metric_name, unit, min_key_id, max_key_id
        )
        
        return fig
    
    def _add_algorithm_trace_to_figure(self, fig: go.Figure, alg_data: Dict, 
                                       alg_idx: int, data_key: str, metric_name: str,
                                       unit: str, all_key_ids: List[int], 
                                       num_algorithms: int, bar_width: float):
        """æ·»åŠ ç®—æ³•çš„traceåˆ°å›¾è¡¨"""
        algorithm_name = alg_data['name']
        display_name = alg_data.get('display_name', algorithm_name)
        color = alg_data['color']
        
        # å‡†å¤‡æ•°æ®
        x_positions = []
        y_values = []
        key_to_val = dict(zip(alg_data['key_ids'], alg_data[data_key]))
        
        for key_id in all_key_ids:
            if key_id in alg_data['key_ids']:
                x_pos = key_id + (alg_idx - num_algorithms / 2 + 0.5) * bar_width
                x_positions.append(x_pos)
                y_values.append(key_to_val[key_id])
        
        if not x_positions:
            return
        
        # æ·»åŠ æŸ±çŠ¶å›¾trace
        fig.add_trace(go.Bar(
            x=x_positions,
            y=y_values,
            name=display_name,
            marker_color=color,
            opacity=0.8,
            width=bar_width,
            text=[f'{val:.2f}' for val in y_values],
            textposition='outside',
            textfont=dict(size=8),
            showlegend=True,
            legendgroup=algorithm_name,
            hovertemplate=f'ç®—æ³•: {display_name}<br>é”®ä½: %{{x:.0f}}<br>{metric_name}: %{{y:.2f}}{unit}<extra></extra>'
        ))
    
    def _configure_offset_figure_layout(self, fig: go.Figure, metric_name: str, 
                                        unit: str, min_key_id: int, max_key_id: int):
        """é…ç½®åç§»å›¾è¡¨çš„å¸ƒå±€"""
        fig.update_layout(
            title=dict(text=metric_name, x=0.5, xanchor='center'),
            xaxis_title='é”®ä½ID',
            yaxis_title=f'{metric_name} ({unit})',
            xaxis=dict(
                tickmode='linear',
                tick0=min_key_id,
                dtick=1,
                range=[min_key_id - 1, max_key_id + 1]
            ),
            yaxis=dict(
                showgrid=True,
                gridcolor='lightgray',
                gridwidth=1
            ),
            template='simple_white',
            showlegend=True,
            legend=dict(
                x=0.01, y=1.12, xanchor='left', yanchor='top',
                bgcolor='rgba(255,255,255,0.8)',
                bordercolor='rgba(0,0,0,0.2)',
                borderwidth=1,
                orientation='h',
                font=dict(size=11),
                title_text=metric_name
            ),
            margin=dict(l=60, r=40, t=100, b=60),
            height=500,
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            font=dict(size=12)
        )

    def generate_multi_algorithm_delay_histogram_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆå åŠ æ˜¾ç¤ºï¼Œä¸åŒé¢œè‰²ï¼Œå›¾ä¾‹æ§åˆ¶ï¼‰

        ä¸ºæ¯ä¸ªç®—æ³•ç”Ÿæˆç›´æ–¹å›¾å’Œæ­£æ€æ‹Ÿåˆæ›²çº¿ï¼Œä½¿ç”¨ä¸åŒé¢œè‰²åŒºåˆ†ï¼Œå åŠ æ˜¾ç¤ºåœ¨åŒä¸€å›¾è¡¨ä¸­ã€‚
        æ•°æ®ç­›é€‰ï¼šåªä½¿ç”¨è¯¯å·®â‰¤50msçš„æŒ‰é”®æ•°æ®

        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨

        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        # éªŒè¯å¹¶å‡†å¤‡ç®—æ³•
        ready_algorithms = self._validate_and_prepare_algorithms(algorithms)
        if not ready_algorithms:
            return self._create_empty_plot("æ²¡æœ‰å°±ç»ªçš„ç®—æ³•")
        
        try:
            fig = go.Figure()
            all_delays = []
            
            # ä¸ºæ¯ä¸ªç®—æ³•æ”¶é›†æ•°æ®å¹¶æ·»åŠ traces
            for alg_idx, algorithm in enumerate(ready_algorithms):
                delay_data = self._collect_algorithm_delay_data(algorithm, alg_idx)
                if not delay_data:
                    continue
                
                all_delays.extend(delay_data['relative_delays'])
                
                # æ·»åŠ ç›´æ–¹å›¾å’Œæ­£æ€æ‹Ÿåˆæ›²çº¿
                self._add_histogram_traces(fig, delay_data)
            
            if not all_delays:
                logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„å»¶æ—¶æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆç›´æ–¹å›¾")
                return self._create_empty_plot("æ²¡æœ‰æœ‰æ•ˆçš„å»¶æ—¶æ•°æ®")
            
            # é…ç½®å¸ƒå±€
            self._configure_histogram_layout(fig)
            return fig
            
        except Exception as e:
            return self._handle_generation_error(e, "å¤šç®—æ³•å»¶æ—¶åˆ†å¸ƒç›´æ–¹å›¾")
    
    def _collect_algorithm_delay_data(self, algorithm: AlgorithmDataset, alg_idx: int) -> Optional[Dict]:
        """æ”¶é›†å•ä¸ªç®—æ³•çš„å»¶æ—¶æ•°æ®"""
        # æå–å…ƒæ•°æ®
        metadata = self._extract_algorithm_metadata(algorithm)
        descriptive_name = metadata['descriptive_name']
        
        # éªŒè¯åˆ†æå™¨
        if not self._validate_analyzer(algorithm, descriptive_name):
            return None
        
        try:
            # è·å–åç§»æ•°æ®
            offset_data = self._get_offset_data(algorithm)
            if not offset_data:
                logger.warning(f"âš ï¸ ç®—æ³• '{metadata['algorithm_name']}' æ²¡æœ‰ç²¾ç¡®åŒ¹é…æ•°æ®ï¼ˆâ‰¤50msï¼‰ï¼Œè·³è¿‡")
                return None
            
            # æå–ç»å¯¹å»¶æ—¶
            absolute_delays_ms = [item.get('keyon_offset', 0.0) / 10.0 for item in offset_data]
            if not absolute_delays_ms:
                logger.warning(f"âš ï¸ ç®—æ³• '{metadata['algorithm_name']}' ç­›é€‰åæ²¡æœ‰æœ‰æ•ˆå»¶æ—¶æ•°æ®ï¼Œè·³è¿‡")
                return None
            
            # è®¡ç®—å¹³å‡å»¶æ—¶
            mean_delay_ms = self._calculate_mean_delay(algorithm.analyzer)
            
            # è®¡ç®—ç›¸å¯¹å»¶æ—¶å’Œç»Ÿè®¡é‡
            relative_delays_ms = [delay - mean_delay_ms for delay in absolute_delays_ms]
            statistics = self._calculate_delay_statistics(
                absolute_delays_ms, relative_delays_ms, mean_delay_ms
            )
            
            return {
                'descriptive_name': descriptive_name,
                'relative_delays': relative_delays_ms,
                'statistics': statistics,
                'color': self._get_algorithm_color(alg_idx)
            }
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–ç®—æ³• '{metadata['algorithm_name']}' çš„å»¶æ—¶æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _calculate_delay_statistics(self, absolute_delays: List[float], 
                                    relative_delays: List[float], 
                                    mean_delay: float) -> Dict[str, float]:
        """è®¡ç®—å»¶æ—¶ç»Ÿè®¡é‡"""
        n = len(absolute_delays)
        
        # ç»å¯¹å»¶æ—¶ç»Ÿè®¡ï¼ˆåæ˜ æ•´ä½“ç¨³å®šæ€§ï¼‰
        if n > 1:
            var_offset = sum((x - mean_delay) ** 2 for x in absolute_delays) / (n - 1)
            std_offset = var_offset ** 0.5
        else:
            std_offset = 0.0
        
        # ç›¸å¯¹å»¶æ—¶ç»Ÿè®¡ï¼ˆç”¨äºæ­£æ€æ‹Ÿåˆï¼‰
        if n > 1:
            var_relative = sum(x ** 2 for x in relative_delays) / (n - 1)
            std_relative = var_relative ** 0.5
        else:
            std_relative = 0.0
        
        return {
            'mean_offset': mean_delay,
            'std_offset': std_offset,
            'std_relative': std_relative
        }
    
    def _add_histogram_traces(self, fig: go.Figure, delay_data: Dict):
        """æ·»åŠ ç›´æ–¹å›¾å’Œæ­£æ€æ‹Ÿåˆæ›²çº¿traces"""
        descriptive_name = delay_data['descriptive_name']
        relative_delays = delay_data['relative_delays']
        stats = delay_data['statistics']
        color = delay_data['color']
        
        # æ·»åŠ ç›´æ–¹å›¾
        fig.add_trace(go.Histogram(
            x=relative_delays,
            histnorm='probability density',
            name=f'{descriptive_name} - å»¶æ—¶åˆ†å¸ƒ',
            marker_color=color,
            opacity=0.85,
            marker_line_color=color,
            marker_line_width=0.5,
            legendgroup=descriptive_name,
            showlegend=True
        ))
        
        # æ·»åŠ æ­£æ€æ‹Ÿåˆæ›²çº¿
        if stats['std_relative'] > 0:
            xs, ys = self._generate_normal_curve(
                relative_delays, stats['std_relative']
            )
            fig.add_trace(go.Scatter(
                x=xs,
                y=ys,
                mode='lines',
                name=f'{descriptive_name} - æ­£æ€æ‹Ÿåˆ (Î¼={stats["mean_offset"]:.2f}ms, Ïƒ={stats["std_offset"]:.2f}ms)',
                line=dict(color=color, width=2),
                legendgroup=descriptive_name,
                showlegend=True
            ))
    
    def _generate_normal_curve(self, relative_delays: List[float], 
                               std_relative: float) -> Tuple[List[float], List[float]]:
        """ç”Ÿæˆæ­£æ€åˆ†å¸ƒæ‹Ÿåˆæ›²çº¿çš„åæ ‡"""
        min_x = min(relative_delays)
        max_x = max(relative_delays)
        span = max(1e-6, 3 * std_relative)
        x_start = min(-span, min_x)
        x_end = max(span, max_x)
        
        num_pts = 200
        step = (x_end - x_start) / (num_pts - 1) if num_pts > 1 else 1.0
        xs = [x_start + i * step for i in range(num_pts)]
        ys = [(1.0 / (std_relative * (2 * math.pi) ** 0.5)) *
              math.exp(-0.5 * (x / std_relative) ** 2) for x in xs]
        
        return xs, ys
    
    def _configure_histogram_layout(self, fig: go.Figure):
        """é…ç½®ç›´æ–¹å›¾å¸ƒå±€"""
        fig.update_layout(
            xaxis_title='ç›¸å¯¹å»¶æ—¶ (ms)',
            yaxis_title='æ¦‚ç‡å¯†åº¦',
            bargap=0.05,
            plot_bgcolor='white',
            paper_bgcolor='white',
            font=dict(size=12),
            height=500,
            clickmode='event+select',
            legend=dict(
                orientation='h',
                yanchor='bottom',
                y=1.05,
                xanchor='left',
                x=0.0,
                bgcolor='rgba(255, 255, 255, 0.9)',
                bordercolor='gray',
                borderwidth=1
            ),
            margin=dict(t=100, b=60, l=60, r=60)
        )
    
    def generate_multi_algorithm_key_delay_scatter_plot(
        self,
        algorithms: List[AlgorithmDataset],
        only_common_keys: bool = False,
        selected_algorithm_names: List[str] = None
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸å»¶æ—¶æ•£ç‚¹å›¾ï¼ˆå åŠ æ˜¾ç¤ºï¼Œä¸åŒé¢œè‰²ï¼Œå›¾ä¾‹æ§åˆ¶ï¼‰

        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            only_common_keys: æ˜¯å¦åªæ˜¾ç¤ºå…¬å…±æŒ‰é”®
            selected_algorithm_names: æŒ‡å®šå‚ä¸å¯¹æ¯”çš„ç®—æ³•åç§°åˆ—è¡¨

        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        try:
            # ç­›é€‰å’Œå‡†å¤‡ç®—æ³•
            filtered_algorithms = self._filter_algorithms_by_names(
                algorithms, selected_algorithm_names
            )
            ready_algorithms = self._validate_and_prepare_algorithms(filtered_algorithms)
            if not ready_algorithms:
                return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
            logger.info(f"å¼€å§‹ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸å»¶æ—¶æ•£ç‚¹å›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªæ¿€æ´»ç®—æ³•")
            
            # è®¡ç®—å…¬å…±æŒ‰é”®ï¼ˆå¦‚æœéœ€è¦ï¼‰
            common_keys = self._calculate_common_keys(ready_algorithms) if only_common_keys else None
            
            fig = go.Figure()
            
            # æ”¶é›†æ‰€æœ‰ç®—æ³•æ•°æ®
            algorithm_data_list = []
            for alg_idx, algorithm in enumerate(ready_algorithms):
                alg_data = self._collect_scatter_algorithm_data(algorithm, alg_idx, common_keys)
                if alg_data:
                    algorithm_data_list.append(alg_data)
            
            if not algorithm_data_list:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„ç®—æ³•æ•°æ®")
                return self._create_empty_plot("æ²¡æœ‰æœ‰æ•ˆçš„ç®—æ³•æ•°æ®")
            
            # æ·»åŠ æ•£ç‚¹å›¾å’Œé˜ˆå€¼çº¿
            self._add_scatter_plot_traces(fig, algorithm_data_list)
            self._add_scatter_threshold_lines(fig, algorithm_data_list)
            
            # é…ç½®å¸ƒå±€
            self._configure_scatter_plot_layout(fig)
            
            return fig
            
        except Exception as e:
            return self._handle_generation_error(e, "å¤šç®—æ³•æŒ‰é”®ä¸å»¶æ—¶æ•£ç‚¹å›¾")
    
    def generate_multi_algorithm_key_delay_zscore_scatter_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸å»¶æ—¶Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾
        
        Z-Scoreæ ‡å‡†åŒ–å…¬å¼ï¼šz = (x_i - Î¼) / Ïƒ
        - x_i: æ¯ä¸ªæ•°æ®ç‚¹çš„å»¶æ—¶å€¼
        - Î¼: è¯¥ç®—æ³•çš„æ€»ä½“å‡å€¼
        - Ïƒ: è¯¥ç®—æ³•çš„æ€»ä½“æ ‡å‡†å·®
        
        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            
        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        if not algorithms:
            return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
        
        try:
            # éªŒè¯å’Œå‡†å¤‡ç®—æ³•åˆ—è¡¨
            ready_algorithms = self._validate_and_prepare_algorithms(algorithms)
            if not ready_algorithms:
                return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
            fig = go.Figure()
            all_key_ids = set()
            
            # æ”¶é›†æ‰€æœ‰æ¿€æ´»ç®—æ³•çš„æ•°æ®
            for alg_idx, algorithm in enumerate(ready_algorithms):
                metadata = self._extract_algorithm_metadata(algorithm)
                descriptive_name = metadata['descriptive_name']
                
                if not self._validate_analyzer(algorithm, descriptive_name):
                    continue
                
                try:
                    # æå–æ•£ç‚¹å›¾æ•°æ®
                    scatter_data = self._extract_scatter_delay_data(algorithm, metadata)
                    if not scatter_data:
                        continue
                    
                    key_ids, delays_ms, customdata_list = scatter_data
                    
                    # è®¡ç®—Z-Scoreå€¼
                    z_scores, mu, sigma = self._calculate_zscore_values(delays_ms, algorithm)
                    
                    # æ’åºæ•°æ®
                    key_ids, z_scores, customdata_list = self._sort_scatter_data(
                        key_ids, z_scores, customdata_list
                    )
                    
                    # æ·»åŠ æ•£ç‚¹å›¾traces
                    color = self._get_algorithm_color(alg_idx)
                    self._add_zscore_scatter_traces(
                        fig, key_ids, z_scores, customdata_list, descriptive_name, color
                    )
                    
                    # æ”¶é›†æŒ‰é”®ID
                    all_key_ids.update(key_ids)
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–ç®—æ³• '{descriptive_name}' çš„Z-Scoreæ•°æ®å¤±è´¥: {e}")
                    continue
            
            # æ·»åŠ é˜ˆå€¼çº¿ï¼ˆZ=0, Â±3ï¼‰
            sorted_key_ids = sorted(all_key_ids)
            key_labels = [str(kid) for kid in sorted_key_ids]
            self._add_zscore_threshold_lines(fig, key_labels, ready_algorithms)
            
            # é…ç½®å¸ƒå±€
            self._configure_zscore_layout(fig)
            
            return fig
            
        except Exception as e:
            return self._handle_generation_error(e, "å¤šç®—æ³•Z-Scoreæ ‡å‡†åŒ–æ•£ç‚¹å›¾")

    def generate_single_key_delay_comparison_plot(
        self,
        algorithms: List[AlgorithmDataset],
        target_key_id: int
    ) -> Any:
        """
        ç”Ÿæˆå•é”®å¤šæ›²å»¶æ—¶å¯¹æ¯”å›¾ï¼ˆæ•£ç‚¹å›¾+ç®±çº¿å›¾ï¼‰
        
        Args:
            algorithms: ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            target_key_id: ç›®æ ‡æŒ‰é”®ID
            
        Returns:
            Any: Plotlyå›¾è¡¨å¯¹è±¡
        """
        if not algorithms:
            return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
        if target_key_id is None:
            return self._create_empty_plot("è¯·é€‰æ‹©ä¸€ä¸ªæŒ‰é”®è¿›è¡Œåˆ†æ")
            
        try:
            # éªŒè¯å’Œå‡†å¤‡ç®—æ³•åˆ—è¡¨
            ready_algorithms = self._validate_and_prepare_algorithms(algorithms)
            if not ready_algorithms:
                return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»ä¸”å°±ç»ªçš„ç®—æ³•")
            
            fig = go.Figure()
            has_data = False
            
            # éå†æ¯ä¸ªç®—æ³•
            for alg_idx, algorithm in enumerate(ready_algorithms):
                metadata = self._extract_algorithm_metadata(algorithm)
                display_name = metadata['display_name']
                filename = metadata['filename']
                descriptive_name = metadata['descriptive_name']
                
                # éªŒè¯åˆ†æå™¨
                if not self._validate_analyzer(algorithm, descriptive_name):
                    continue
                
                # è·å–åç§»æ•°æ®
                offset_data = self._get_offset_data(algorithm)
                if not offset_data:
                    continue
                
                # æå–ç›®æ ‡æŒ‰é”®çš„å»¶æ—¶æ•°æ®
                key_delays, customdata_list = self._extract_single_key_delays(
                    offset_data, target_key_id, filename
                )
                
                if not key_delays:
                    continue
                
                has_data = True
                
                # æ·»åŠ ç®±çº¿å›¾
                color = self._get_algorithm_color(alg_idx)
                self._add_box_trace(
                    fig, key_delays, display_name, target_key_id, customdata_list, color
                )
            
            if not has_data:
                return self._create_empty_plot(f"æŒ‰é”® {target_key_id} åœ¨é€‰å®šçš„ç®—æ³•ä¸­æ²¡æœ‰æ•°æ®")
            
            # é…ç½®å¸ƒå±€
            self._configure_single_key_layout(fig, target_key_id)
            
            return fig
            
        except Exception as e:
            return self._handle_generation_error(e, "å•é”®å¯¹æ¯”å›¾")

    def generate_multi_algorithm_hammer_velocity_relative_delay_scatter_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•é”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ï¼ˆå åŠ æ˜¾ç¤ºï¼Œä¸åŒé¢œè‰²ï¼Œå›¾ä¾‹æ§åˆ¶ï¼‰

        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨

        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        try:
            # éªŒè¯å’Œå‡†å¤‡ç®—æ³•åˆ—è¡¨
            ready_algorithms = self._validate_and_prepare_algorithms(algorithms)
            if not ready_algorithms:
                return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")

            logger.info(f"å¼€å§‹ç”Ÿæˆå¤šç®—æ³•é”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªæ¿€æ´»ç®—æ³•")
            
            fig = go.Figure()
            
            # è®¡ç®—xè½´èŒƒå›´
            x_min, x_max = self._calculate_log_velocity_range(ready_algorithms)

            for alg_idx, algorithm in enumerate(ready_algorithms):
                metadata = self._extract_algorithm_metadata(algorithm)
                algorithm_name = metadata['algorithm_name']
                descriptive_name = metadata['descriptive_name']
                display_name = metadata['display_name']

                # éªŒè¯åˆ†æå™¨
                if not self._validate_analyzer(algorithm, descriptive_name):
                    continue

                try:
                    # è·å–åŒ¹é…å¯¹
                    matched_pairs = self._get_matched_pairs(algorithm)
                    if not matched_pairs:
                        logger.warning(f"ç®—æ³• '{descriptive_name}' æ²¡æœ‰åŒ¹é…æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    # è·å–åç§»æ•°æ®å¹¶åˆ›å»ºæ˜ å°„
                    offset_data = self._get_offset_data(algorithm)
                    offset_map = self._create_offset_map(offset_data)

                    # æå–é”¤é€Ÿå’Œå»¶æ—¶æ•°æ®ï¼ˆä½¿ç”¨algorithm_nameä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼‰
                    hammer_velocities, delays_ms, scatter_customdata = \
                        self._extract_hammer_velocity_delay_data(matched_pairs, offset_map, algorithm_name)

                    if not hammer_velocities:
                        logger.warning(f"ç®—æ³• '{descriptive_name}' æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    # è®¡ç®—ç›¸å¯¹å»¶æ—¶ç»Ÿè®¡
                    relative_delays, statistics = \
                        self._calculate_relative_delay_statistics(delays_ms, algorithm)

                    # å°†é”¤é€Ÿè½¬æ¢ä¸ºå¯¹æ•°å½¢å¼
                    log_velocities = [math.log10(v) for v in hammer_velocities]

                    # è·å–ç®—æ³•é¢œè‰²
                    color = self._get_algorithm_color(alg_idx)

                    # æ·»åŠ æ•£ç‚¹å›¾trace
                    self._add_hammer_velocity_scatter_trace(
                        fig, log_velocities, relative_delays, delays_ms,
                        hammer_velocities, scatter_customdata, descriptive_name, color
                    )

                    # æ·»åŠ é˜ˆå€¼çº¿
                    if len(log_velocities) > 0:
                        self._add_relative_delay_threshold_lines(
                            fig, x_min, x_max, statistics, descriptive_name, color
                        )

                except Exception as e:
                    logger.warning(f"è·å–ç®—æ³• '{descriptive_name}' çš„é”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•°æ®å¤±è´¥: {e}")
                    continue

            # é…ç½®å¸ƒå±€
            self._configure_hammer_velocity_layout(fig)

            logger.info(f"å¤šç®—æ³•é”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            return fig

        except Exception as e:
            return self._handle_generation_error(e, "å¤šç®—æ³•é”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶æ•£ç‚¹å›¾")

    def generate_multi_algorithm_hammer_velocity_delay_scatter_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ï¼ˆå åŠ æ˜¾ç¤ºï¼Œä¸åŒé¢œè‰²ï¼Œå›¾ä¾‹æ§åˆ¶ï¼‰
        
        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            
        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        try:
            # éªŒè¯å’Œå‡†å¤‡ç®—æ³•åˆ—è¡¨
            ready_algorithms = self._validate_and_prepare_algorithms(algorithms)
            if not ready_algorithms:
                return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
            logger.info(f"ğŸ“Š å¼€å§‹ç”Ÿæˆå¤šç®—æ³•é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            
            fig = go.Figure()
            
            # è®¡ç®—xè½´èŒƒå›´
            x_min, x_max = self._calculate_log_velocity_range(ready_algorithms)

            for alg_idx, algorithm in enumerate(ready_algorithms):
                metadata = self._extract_algorithm_metadata(algorithm)
                algorithm_name = metadata['algorithm_name']
                descriptive_name = metadata['descriptive_name']
                display_name = metadata['display_name']

                # éªŒè¯åˆ†æå™¨
                if not self._validate_analyzer(algorithm, descriptive_name):
                    continue

                try:
                    # è·å–åŒ¹é…å¯¹
                    matched_pairs = self._get_matched_pairs(algorithm)
                    if not matched_pairs:
                        logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰åŒ¹é…æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    # è·å–åç§»æ•°æ®å¹¶åˆ›å»ºæ˜ å°„
                    offset_data = self._get_offset_data(algorithm)
                    offset_map = self._create_offset_map(offset_data)

                    # æå–é”¤é€Ÿå’Œå»¶æ—¶æ•°æ®ï¼ˆä½¿ç”¨algorithm_nameä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼‰
                    hammer_velocities, delays_ms, scatter_customdata = \
                        self._extract_hammer_velocity_delay_data(matched_pairs, offset_map, algorithm_name)

                    if not hammer_velocities:
                        logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    # è®¡ç®—Z-Score
                    z_scores, mu, sigma = self._calculate_zscore_values(delays_ms, algorithm)

                    # å°†é”¤é€Ÿè½¬æ¢ä¸ºå¯¹æ•°å½¢å¼
                    log_velocities = [math.log10(v) for v in hammer_velocities]

                    # è·å–ç®—æ³•é¢œè‰²
                    color = self._get_algorithm_color(alg_idx)

                    # æ·»åŠ æ•£ç‚¹å›¾trace
                    self._add_hammer_velocity_zscore_scatter_trace(
                        fig, log_velocities, z_scores, delays_ms,
                        hammer_velocities, scatter_customdata, descriptive_name, color
                    )

                    # æ·»åŠ Z-Scoreé˜ˆå€¼çº¿
                    if len(log_velocities) > 0:
                        self._add_zscore_threshold_lines_for_velocity(
                            fig, x_min, x_max, descriptive_name, color
                        )

                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–ç®—æ³• '{descriptive_name}' çš„é”¤é€Ÿä¸å»¶æ—¶æ•°æ®å¤±è´¥: {e}")
                    continue

            # é…ç½®å¸ƒå±€
            self._configure_hammer_velocity_zscore_layout(fig)

            logger.info(f"âœ… å¤šç®—æ³•é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            return fig
            
        except Exception as e:
            return self._handle_generation_error(e, "å¤šç®—æ³•é”¤é€Ÿä¸å»¶æ—¶æ•£ç‚¹å›¾")
    
    def generate_multi_algorithm_key_hammer_velocity_scatter_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾ï¼ˆé¢œè‰²è¡¨ç¤ºå»¶æ—¶ï¼Œå åŠ æ˜¾ç¤ºï¼Œä¸åŒæ ‡è®°å½¢çŠ¶åŒºåˆ†ç®—æ³•ï¼‰
        
        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            
        Returns:
            go.Figure: Plotlyå›¾è¡¨å¯¹è±¡
        """
        try:
            # éªŒè¯å’Œå‡†å¤‡ç®—æ³•åˆ—è¡¨
            ready_algorithms = self._validate_and_prepare_algorithms(algorithms)
            if not ready_algorithms:
                return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")
            
            logger.info(f"ğŸ“Š å¼€å§‹ç”Ÿæˆå¤šç®—æ³•æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            
            fig = go.Figure()
            all_delays = []
            
            for alg_idx, algorithm in enumerate(ready_algorithms):
                metadata = self._extract_algorithm_metadata(algorithm)
                algorithm_name = metadata['algorithm_name']
                descriptive_name = metadata['descriptive_name']

                # éªŒè¯åˆ†æå™¨
                if not self._validate_analyzer(algorithm, descriptive_name):
                    continue

                try:
                    # è·å–åŒ¹é…å¯¹
                    matched_pairs = self._get_matched_pairs(algorithm)
                    if not matched_pairs:
                        logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰åŒ¹é…æ•°æ®ï¼Œè·³è¿‡")
                        continue

                    # è·å–åç§»æ•°æ®å¹¶åˆ›å»ºæ˜ å°„
                    offset_data = self._get_offset_data(algorithm)
                    offset_map = self._create_offset_map(offset_data)
                    
                    # æå–æŒ‰é”®IDã€é”¤é€Ÿå’Œå»¶æ—¶æ•°æ®
                    key_ids, hammer_velocities, delays_ms = \
                        self._extract_key_hammer_velocity_data(matched_pairs, offset_map)
                    
                    if not key_ids:
                        logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®ï¼Œè·³è¿‡")
                        continue
                    
                    # æ·»åŠ åˆ°æ€»å»¶æ—¶åˆ—è¡¨
                    all_delays.extend(delays_ms)
                    
                    # æ·»åŠ æ•£ç‚¹å›¾trace
                    self._add_key_hammer_velocity_scatter_trace(
                        fig, key_ids, hammer_velocities, delays_ms,
                        descriptive_name, algorithm_name, alg_idx,
                        len(ready_algorithms), all_delays
                    )
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–ç®—æ³• '{descriptive_name}' çš„æŒ‰é”®ä¸é”¤é€Ÿæ•°æ®å¤±è´¥: {e}")
                    continue
            
            if not all_delays:
                logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨")
                return self._create_empty_plot("æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®")
            
            # é…ç½®å¸ƒå±€
            self._configure_key_hammer_velocity_layout(fig)
            
            logger.info(f"âœ… å¤šç®—æ³•æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾ç”ŸæˆæˆåŠŸï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")
            return fig
            
        except Exception as e:
            return self._handle_generation_error(e, "å¤šç®—æ³•æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾")
    
    def _create_empty_plot(self, message: str) -> go.Figure:
        """åˆ›å»ºç©ºå›¾è¡¨ï¼ˆç”¨äºé”™è¯¯æç¤ºï¼‰"""
        fig = go.Figure()
        fig.add_annotation(
            x=0.5,
            y=0.5,
            text=message,
            showarrow=False,
            font=dict(size=16, color='gray'),
            xref='paper',
            yref='paper'
        )
        fig.update_layout(
            xaxis=dict(showgrid=False, showticklabels=False),
            yaxis=dict(showgrid=False, showticklabels=False),
            height=400
        )
        return fig
    
    # ==================== é€šç”¨è¾…åŠ©æ–¹æ³• ====================
    
    def _validate_and_prepare_algorithms(self, algorithms: List[AlgorithmDataset]) -> Optional[List[AlgorithmDataset]]:
        """
        éªŒè¯å’Œå‡†å¤‡ç®—æ³•åˆ—è¡¨
        
        Args:
            algorithms: ç®—æ³•æ•°æ®é›†åˆ—è¡¨
            
        Returns:
            Optional[List[AlgorithmDataset]]: å°±ç»ªçš„ç®—æ³•åˆ—è¡¨ï¼Œå¦‚æœéªŒè¯å¤±è´¥è¿”å›None
        """
        if not algorithms:
            logger.warning("æ²¡æœ‰ä¼ å…¥ä»»ä½•ç®—æ³•")
            return None
        
        ready_algorithms = [alg for alg in algorithms if alg.is_active and alg.is_ready()]
        
        if not ready_algorithms:
            logger.warning("æ²¡æœ‰æ¿€æ´»ä¸”å°±ç»ªçš„ç®—æ³•")
            return None
        
        logger.info(f"éªŒè¯é€šè¿‡: å…± {len(ready_algorithms)} ä¸ªå°±ç»ªç®—æ³•")
        return ready_algorithms
    
    def _extract_algorithm_metadata(self, algorithm: AlgorithmDataset) -> Dict[str, str]:
        """
        æå–ç®—æ³•å…ƒæ•°æ®
        
        Args:
            algorithm: ç®—æ³•æ•°æ®é›†
            
        Returns:
            Dict[str, str]: åŒ…å« algorithm_name, display_name, filename, descriptive_name çš„å­—å…¸
        """
        return {
            'algorithm_name': algorithm.metadata.algorithm_name,
            'display_name': algorithm.metadata.display_name,
            'filename': algorithm.metadata.filename,
            'descriptive_name': f"{algorithm.metadata.display_name} ({algorithm.metadata.filename})"
        }
    
    def _validate_analyzer(self, algorithm: AlgorithmDataset, descriptive_name: str) -> bool:
        """
        éªŒè¯ç®—æ³•çš„åˆ†æå™¨æ˜¯å¦å¯ç”¨
        
        Args:
            algorithm: ç®—æ³•æ•°æ®é›†
            descriptive_name: ç®—æ³•çš„æè¿°æ€§åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            
        Returns:
            bool: åˆ†æå™¨å¯ç”¨è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
            logger.warning(f"âš ï¸ ç®—æ³• '{descriptive_name}' æ²¡æœ‰åˆ†æå™¨æˆ–åŒ¹é…å™¨ï¼Œè·³è¿‡")
            return False
        return True
    
    def _get_algorithm_color(self, algorithm_index: int) -> str:
        """
        è·å–ç®—æ³•å¯¹åº”çš„é¢œè‰²
        
        Args:
            algorithm_index: ç®—æ³•ç´¢å¼•
            
        Returns:
            str: é¢œè‰²ä»£ç 
        """
        return self.COLORS[algorithm_index % len(self.COLORS)]
    
    # ==================== æ•°æ®è·å–å’Œè½¬æ¢æ–¹æ³•ï¼ˆæ¶ˆé™¤é‡å¤ä»£ç ï¼‰ ====================
    
    def _get_offset_data(self, algorithm: AlgorithmDataset):
        """
        è·å–ç®—æ³•çš„ç²¾ç¡®åç§»å¯¹é½æ•°æ®
        
        Args:
            algorithm: ç®—æ³•æ•°æ®é›†
            
        Returns:
            åç§»å¯¹é½æ•°æ®åˆ—è¡¨ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›ç©ºåˆ—è¡¨
        """
        try:
            if algorithm.analyzer:
                return algorithm.analyzer.get_precision_offset_alignment_data() or []
        except Exception as e:
            logger.warning(f"è·å–åç§»æ•°æ®å¤±è´¥: {e}")
        return []
    
    def _get_matched_pairs(self, algorithm: AlgorithmDataset):
        """
        è·å–ç®—æ³•çš„åŒ¹é…å¯¹æ•°æ®
        
        Args:
            algorithm: ç®—æ³•æ•°æ®é›†
            
        Returns:
            åŒ¹é…å¯¹åˆ—è¡¨ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›ç©ºåˆ—è¡¨
        """
        try:
            if algorithm.analyzer:
                return algorithm.analyzer.matched_pairs or []
        except Exception as e:
            logger.warning(f"è·å–åŒ¹é…å¯¹å¤±è´¥: {e}")
        return []
    
    def _create_note_dicts(self, matched_pairs):
        """
        ä»åŒ¹é…å¯¹åˆ›å»ºéŸ³ç¬¦å­—å…¸
        
        Args:
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨ [(record_idx, replay_idx, record_note, replay_note), ...]
            
        Returns:
            Tuple[Dict, Dict]: (record_note_dict, replay_note_dict)
        """
        record_note_dict = {r_idx: r_note for r_idx, _, r_note, _ in matched_pairs}
        replay_note_dict = {p_idx: p_note for _, p_idx, _, p_note in matched_pairs}
        return record_note_dict, replay_note_dict
    
    def _create_offset_map(self, offset_data):
        """
        åˆ›å»ºåç§»æ•°æ®ç´¢å¼•æ˜ å°„
        
        Args:
            offset_data: åç§»å¯¹é½æ•°æ®åˆ—è¡¨
            
        Returns:
            Dict: ä»¥ (record_index, replay_index) ä¸ºé”®çš„åç§»æ•°æ®å­—å…¸
        """
        offset_map = {}
        for item in offset_data:
            record_idx = item.get('record_index')
            replay_idx = item.get('replay_index')
            if record_idx is not None and replay_idx is not None:
                offset_map[(record_idx, replay_idx)] = item
        return offset_map
    
    def _convert_offset_to_ms(self, keyon_offset) -> float:
        """
        å°†åç§»é‡ä» 0.1ms å•ä½è½¬æ¢ä¸º ms
        
        Args:
            keyon_offset: åç§»é‡ï¼ˆ0.1ms å•ä½ï¼‰
            
        Returns:
            float: åç§»é‡ï¼ˆms å•ä½ï¼‰
        """
        return keyon_offset / 10.0
    
    def _filter_algorithms_by_names(self, algorithms: List[AlgorithmDataset], 
                                    selected_names: List[str] = None) -> List[AlgorithmDataset]:
        """æ ¹æ®åç§°ç­›é€‰ç®—æ³•"""
        if selected_names:
            filtered = [alg for alg in algorithms 
                       if alg.metadata.algorithm_name in selected_names]
            logger.info(f"æ ¹æ®ç”¨æˆ·é€‰æ‹©ç­›é€‰ç®—æ³•: {selected_names} -> æ‰¾åˆ° {len(filtered)} ä¸ªåŒ¹é…ç®—æ³•")
            return filtered
        else:
            logger.info("æœªæŒ‡å®šç®—æ³•ç­›é€‰ï¼Œä½¿ç”¨æ‰€æœ‰ä¼ å…¥ç®—æ³•")
            return algorithms
    
    def _calculate_common_keys(self, algorithms: List[AlgorithmDataset]) -> Optional[set]:
        """è®¡ç®—æ‰€æœ‰ç®—æ³•çš„å…¬å…±æŒ‰é”®"""
        key_sets = []
        for alg in algorithms:
            if alg.analyzer and alg.analyzer.note_matcher:
                offset_data = alg.analyzer.note_matcher.get_precision_offset_alignment_data()
                if offset_data:
                    keys = set(item.get('key_id') for item in offset_data 
                              if item.get('key_id') is not None)
                    key_sets.append(keys)
        
        if key_sets:
            common_keys = set.intersection(*key_sets)
            logger.info(f"åªæ˜¾ç¤ºå…¬å…±æŒ‰é”®: å…± {len(common_keys)} ä¸ª")
            return common_keys
        else:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å…¬å…±æŒ‰é”®")
            return set()
    
    def _collect_scatter_algorithm_data(self, algorithm: AlgorithmDataset, alg_idx: int,
                                       common_keys: Optional[set]) -> Optional[Dict]:
        """æ”¶é›†å•ä¸ªç®—æ³•çš„æ•£ç‚¹å›¾æ•°æ®"""
        metadata = self._extract_algorithm_metadata(algorithm)
        if not self._validate_analyzer(algorithm, metadata['descriptive_name']):
            return None
        
        try:
            # è·å–åŸºç¡€æ•°æ®
            offset_data = self._get_offset_data(algorithm)
            if not offset_data:
                logger.warning(f"âš ï¸ ç®—æ³• '{metadata['descriptive_name']}' æ²¡æœ‰ç²¾ç¡®åŒ¹é…æ•°æ®ï¼Œè·³è¿‡")
                return None
            
            # è·å–å¹³å‡å»¶æ—¶
            algorithm_mean_delay_ms = self._calculate_mean_delay(algorithm.analyzer)
            
            # è·å–åŒ¹é…å¯¹
            matched_pairs = self._get_matched_pairs(algorithm)
            record_note_dict, replay_note_dict = self._create_note_dicts(matched_pairs)
            
            # æå–å»¶æ—¶æ•°æ®ï¼ˆä¼ é€’algorithm_nameä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼‰
            delay_data = self._extract_scatter_delay_data(
                offset_data, record_note_dict, replay_note_dict, 
                common_keys, metadata['algorithm_name']
            )
            
            if not delay_data['key_ids']:
                logger.warning(f"âš ï¸ ç®—æ³• '{metadata['descriptive_name']}' æ²¡æœ‰æœ‰æ•ˆçš„æ•£ç‚¹å›¾æ•°æ®ï¼Œè·³è¿‡")
                return None
            
            # è®¡ç®—ç»Ÿè®¡é‡å’Œç›¸å¯¹å»¶æ—¶
            stats = self._calculate_scatter_statistics(
                delay_data['delays_ms'], algorithm.analyzer
            )
            
            # åˆå¹¶æ•°æ®ï¼ˆå…ˆåˆå¹¶å†æ’åºï¼Œå› ä¸ºæ’åºéœ€è¦relative_delays_msï¼‰
            result_data = {
                **metadata,
                **delay_data,
                **stats,
                'color': self._get_algorithm_color(alg_idx),
                'algorithm_mean_delay_ms': algorithm_mean_delay_ms
            }
            
            # æ’åºæ•°æ®
            self._sort_scatter_data(result_data)
            
            return result_data
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–ç®—æ³• '{metadata['descriptive_name']}' çš„æŒ‰é”®ä¸å»¶æ—¶æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _extract_scatter_delay_data(self, offset_data: List[Dict], 
                                    record_note_dict: Dict, replay_note_dict: Dict,
                                    common_keys: Optional[set], algorithm_name: str) -> Dict:
        """æå–æ•£ç‚¹å›¾çš„å»¶æ—¶æ•°æ®"""
        key_ids = []
        delays_ms = []
        customdata_list = []
        
        for item in offset_data:
            key_id = item.get('key_id')
            if key_id is None or key_id == 'N/A':
                continue
            
            # è¿‡æ»¤éå…¬å…±æŒ‰é”®
            if common_keys is not None and key_id not in common_keys:
                continue
            
            try:
                key_id_int = int(key_id)
                keyon_offset = item.get('keyon_offset', 0)
                delay_ms = self._convert_offset_to_ms(keyon_offset)
                
                # è·å–é”¤å­æ—¶é—´
                record_index = item.get('record_index')
                replay_index = item.get('replay_index')
                record_hammer_time = self._get_hammer_time(record_note_dict, record_index)
                replay_hammer_time = self._get_hammer_time(replay_note_dict, replay_index)
                
                key_ids.append(key_id_int)
                delays_ms.append(delay_ms)
                customdata_list.append([
                    record_index, replay_index, key_id_int, delay_ms, 
                    algorithm_name, record_hammer_time, replay_hammer_time
                ])
            except (ValueError, TypeError):
                continue
        
        return {
            'key_ids': key_ids,
            'delays_ms': delays_ms,
            'customdata': customdata_list
        }
    
    def _get_hammer_time(self, note_dict: Dict, index: int) -> float:
        """è·å–éŸ³ç¬¦çš„é”¤å­æ—¶é—´"""
        if index in note_dict:
            note = note_dict[index]
            if (hasattr(note, 'hammers') and note.hammers is not None and 
                not note.hammers.empty):
                return (note.hammers.index[0] + note.offset) / 10.0
        return 0.0
    
    def _calculate_scatter_statistics(self, delays_ms: List[float], analyzer) -> Dict:
        """è®¡ç®—æ•£ç‚¹å›¾ç»Ÿè®¡é‡"""
        # è·å–æ€»ä½“ç»Ÿè®¡ï¼ˆå¤ç”¨analyzeræ–¹æ³•ï¼‰
        me_0_1ms = analyzer.get_mean_error()
        std_0_1ms = analyzer.get_standard_deviation()
        mu = me_0_1ms / 10.0
        sigma = std_0_1ms / 10.0
        
        # è®¡ç®—ç›¸å¯¹å»¶æ—¶
        delays_array = np.array(delays_ms)
        relative_delays_array = delays_array - mu
        relative_delays_ms = relative_delays_array.tolist()
        
        # è®¡ç®—ç›¸å¯¹å»¶æ—¶çš„é˜ˆå€¼
        if len(relative_delays_ms) > 1:
            relative_mu = np.mean(relative_delays_array)
            relative_sigma = np.std(relative_delays_array, ddof=1)
            upper_threshold = relative_mu + 3 * relative_sigma
            lower_threshold = relative_mu - 3 * relative_sigma
        else:
            relative_mu = 0.0
            relative_sigma = 0.0
            upper_threshold = 0.0
            lower_threshold = 0.0
        
        return {
            'mu': mu,
            'sigma': sigma,
            'relative_delays_ms': relative_delays_ms,
            'relative_mu': relative_mu,
            'relative_sigma': relative_sigma,
            'upper_threshold': upper_threshold,
            'lower_threshold': lower_threshold
        }
    
    def _sort_scatter_data(self, data: Dict):
        """æŒ‰é”®IDæ’åºæ•£ç‚¹å›¾æ•°æ®"""
        sorted_indices = sorted(range(len(data['key_ids'])), 
                               key=lambda i: data['key_ids'][i])
        data['key_ids'][:] = [data['key_ids'][i] for i in sorted_indices]
        data['delays_ms'][:] = [data['delays_ms'][i] for i in sorted_indices]
        data['relative_delays_ms'][:] = [data['relative_delays_ms'][i] for i in sorted_indices]
        data['customdata'][:] = [data['customdata'][i] for i in sorted_indices]
    
    def _add_scatter_plot_traces(self, fig: go.Figure, algorithm_data_list: List[Dict]):
        """æ·»åŠ æ•£ç‚¹å›¾traces"""
        for alg_data in algorithm_data_list:
            # è®¡ç®—markeræ ·å¼
            marker_colors = []
            marker_sizes = []
            for relative_delay in alg_data['relative_delays_ms']:
                if (relative_delay > alg_data['upper_threshold'] or 
                    relative_delay < alg_data['lower_threshold']):
                    marker_colors.append(alg_data['color'])
                    marker_sizes.append(12)
                else:
                    marker_colors.append(alg_data['color'])
                    marker_sizes.append(8)
            
            key_id_strings = [str(kid) for kid in alg_data['key_ids']]
            
            fig.add_trace(go.Scatter(
                x=key_id_strings,
                y=alg_data['relative_delays_ms'],
                mode='markers',
                name=f"{alg_data['descriptive_name']} - åŒ¹é…å¯¹",
                marker=dict(
                    size=marker_sizes,
                    color=marker_colors,
                    opacity=0.6,
                    line=dict(width=1, color=alg_data['color'])
                ),
                customdata=alg_data['customdata'],
                legendgroup=alg_data['descriptive_name'],
                showlegend=True,
                hovertemplate=f"ç®—æ³•: {alg_data['descriptive_name']}<br>æŒ‰é”®: %{{customdata[2]}}<br>ç›¸å¯¹å»¶æ—¶: %{{y:.2f}}ms<br>ç»å¯¹å»¶æ—¶: %{{customdata[3]:.2f}}ms<br>å¹³å‡å»¶æ—¶: {alg_data['algorithm_mean_delay_ms']:.2f}ms<br>å½•åˆ¶é”¤å­æ—¶é—´: %{{customdata[5]:.2f}}ms<br>æ’­æ”¾é”¤å­æ—¶é—´: %{{customdata[6]:.2f}}ms<extra></extra>"
            ))
    
    def _add_scatter_threshold_lines(self, fig: go.Figure, algorithm_data_list: List[Dict]):
        """æ·»åŠ æ•£ç‚¹å›¾é˜ˆå€¼çº¿"""
        # è·å–æ‰€æœ‰æŒ‰é”®ID
        all_key_ids = set()
        for alg_data in algorithm_data_list:
            all_key_ids.update(alg_data['key_ids'])
        key_labels = [str(kid) for kid in sorted(all_key_ids)]
        
        for alg_data in algorithm_data_list:
            descriptive_name = alg_data['descriptive_name']
            color = alg_data['color']
            
            # å¹³å‡å€¼çº¿ï¼ˆ0çº¿ï¼‰
            fig.add_trace(go.Scatter(
                x=key_labels,
                y=[0] * len(key_labels),
                mode='lines',
                name=f"{descriptive_name} - å¹³å‡å€¼",
                line=dict(color=color, width=1.5, dash='dot'),
                legendgroup=descriptive_name,
                showlegend=True,
                hovertemplate=f"ç®—æ³•: {descriptive_name}<br>ç›¸å¯¹å»¶æ—¶å¹³å‡å€¼ = 0ms<br>ç»å¯¹å»¶æ—¶å¹³å‡å€¼ = {alg_data['mu']:.2f}ms<extra></extra>"
            ))
            
            # ä¸Šé˜ˆå€¼çº¿
            fig.add_trace(go.Scatter(
                x=key_labels,
                y=[alg_data['upper_threshold']] * len(key_labels),
                mode='lines',
                name=f"{descriptive_name} - ä¸Šé˜ˆå€¼",
                line=dict(color=color, width=2, dash='dash'),
                legendgroup=descriptive_name,
                showlegend=True,
                hovertemplate=f"ç®—æ³•: {descriptive_name}<br>ç›¸å¯¹å»¶æ—¶ä¸Šé˜ˆå€¼ = {alg_data['upper_threshold']:.2f}ms<extra></extra>"
            ))
            
            # ä¸‹é˜ˆå€¼çº¿
            fig.add_trace(go.Scatter(
                x=key_labels,
                y=[alg_data['lower_threshold']] * len(key_labels),
                mode='lines',
                name=f"{descriptive_name} - ä¸‹é˜ˆå€¼",
                line=dict(color=color, width=2, dash='dash'),
                legendgroup=descriptive_name,
                showlegend=True,
                hovertemplate=f"ç®—æ³•: {descriptive_name}<br>ç›¸å¯¹å»¶æ—¶ä¸‹é˜ˆå€¼ = {alg_data['lower_threshold']:.2f}ms<extra></extra>"
            ))
    
    def _configure_scatter_plot_layout(self, fig: go.Figure):
        """é…ç½®æ•£ç‚¹å›¾å¸ƒå±€"""
        fig.update_layout(
            xaxis_title='æŒ‰é”®',
            yaxis_title='ç›¸å¯¹å»¶æ—¶ (ms)',
            xaxis=dict(
                showgrid=True,
                gridcolor='lightgray',
                gridwidth=1,
                type='category'
            ),
            yaxis=dict(
                showgrid=True,
                gridcolor='lightgray',
                gridwidth=1
            ),
            hovermode='closest',
            plot_bgcolor='white',
            paper_bgcolor='white',
            font=dict(size=12),
            height=800,
            showlegend=True,
            legend=dict(
                orientation='h',
                yanchor='bottom',
                y=1.02,
                xanchor='left',
                x=0.0,
                bgcolor='rgba(255, 255, 255, 0.9)',
                bordercolor='gray',
                borderwidth=1
            ),
            margin=dict(t=90, b=60, l=60, r=60)
        )
    
    def _calculate_zscore_values(self, delays_ms: List[float], algorithm) -> Tuple[List[float], float, float]:
        """
        è®¡ç®—Z-Scoreå€¼
        
        Args:
            delays_ms: ç»å¯¹å»¶æ—¶åˆ—è¡¨ï¼ˆæ¯«ç§’ï¼‰
            algorithm: ç®—æ³•æ•°æ®é›†å¯¹è±¡
            
        Returns:
            Tuple[List[float], float, float]: (Z-Scoreåˆ—è¡¨, å‡å€¼, æ ‡å‡†å·®)
        """
        # è·å–æ€»ä½“å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆ0.1mså•ä½ï¼‰
        me_0_1ms = algorithm.analyzer.get_mean_error()
        std_0_1ms = algorithm.analyzer.get_standard_deviation()
        
        # è½¬æ¢ä¸ºmså•ä½
        mu = me_0_1ms / 10.0
        sigma = std_0_1ms / 10.0
        
        # è®¡ç®—Z-Scoreï¼šz = (x_i - Î¼) / Ïƒ
        if sigma > 0:
            delays_array = np.array(delays_ms)
            z_scores_array = (delays_array - mu) / sigma
            z_scores = z_scores_array.tolist()
            
            logger.info(f"ğŸ” Z-Scoreè®¡ç®—: Î¼={mu:.2f}ms, Ïƒ={sigma:.2f}ms, "
                       f"åŸå§‹å»¶æ—¶èŒƒå›´=[{delays_array.min():.2f}, {delays_array.max():.2f}]ms, "
                       f"Z-ScoreèŒƒå›´=[{z_scores_array.min():.2f}, {z_scores_array.max():.2f}]")
        else:
            z_scores = [0.0] * len(delays_ms)
            logger.warning(f"âš ï¸ æ ‡å‡†å·®ä¸º0ï¼Œæ— æ³•è¿›è¡ŒZ-Scoreæ ‡å‡†åŒ–")
        
        return z_scores, mu, sigma
    
    def _add_zscore_scatter_traces(self, fig: go.Figure, key_ids: List[int], z_scores: List[float],
                                   customdata_list: List, descriptive_name: str, color: str):
        """æ·»åŠ Z-Scoreæ•£ç‚¹å›¾traces"""
        fig.add_trace(go.Scatter(
            x=[str(kid) for kid in key_ids],
            y=z_scores,
            mode='markers',
            name=f"{descriptive_name} - Z-Score",
            marker=dict(
                size=8,
                color=color,
                opacity=0.6,
                line=dict(width=1, color=color)
            ),
            customdata=customdata_list,
            legendgroup=descriptive_name,
            showlegend=True,
            hovertemplate=f"ç®—æ³•: {descriptive_name}<br>é”®ä½: %{{x}}<br>"
                         f"å»¶æ—¶: %{{customdata[3]:.2f}}ms<br>Z-Score: %{{y:.2f}}<br>"
                         f"å½•åˆ¶é”¤å­æ—¶é—´: %{{customdata[5]:.2f}}ms<br>"
                         f"æ’­æ”¾é”¤å­æ—¶é—´: %{{customdata[6]:.2f}}ms<extra></extra>"
        ))
    
    def _add_zscore_threshold_lines(self, fig: go.Figure, key_labels: List[str],
                                    ready_algorithms: List, thresholds: List[float] = [0, 3, -3]):
        """
        æ·»åŠ Z-Scoreé˜ˆå€¼çº¿
        
        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            key_labels: æŒ‰é”®æ ‡ç­¾åˆ—è¡¨
            ready_algorithms: å‡†å¤‡å¥½çš„ç®—æ³•åˆ—è¡¨
            thresholds: é˜ˆå€¼åˆ—è¡¨ï¼Œé»˜è®¤[0, 3, -3]
        """
        threshold_names = {0: 'Z=0 (å‡å€¼çº¿)', 3: 'Z=+3 (ä¸Šé˜ˆå€¼)', -3: 'Z=-3 (ä¸‹é˜ˆå€¼)'}
        threshold_styles = {0: 'dot', 3: 'dash', -3: 'dash'}
        threshold_widths = {0: 1.5, 3: 2, -3: 2}
        
        for alg_idx, algorithm in enumerate(ready_algorithms):
            metadata = self._extract_algorithm_metadata(algorithm)
            descriptive_name = metadata['descriptive_name']
            color = self._get_algorithm_color(alg_idx)
            
            for threshold in thresholds:
                fig.add_trace(go.Scatter(
                    x=key_labels,
                    y=[threshold] * len(key_labels),
                    mode='lines',
                    name=f"{descriptive_name} - {threshold_names[threshold].split()[0]}",
                    line=dict(
                        color=color,
                        width=threshold_widths[threshold],
                        dash=threshold_styles[threshold]
                    ),
                    legendgroup=descriptive_name,
                    showlegend=True,
                    hovertemplate=f"ç®—æ³•: {descriptive_name}<br>{threshold_names[threshold]}<extra></extra>"
                ))
    
    def _configure_zscore_layout(self, fig: go.Figure):
        """é…ç½®Z-Scoreæ•£ç‚¹å›¾å¸ƒå±€"""
        fig.update_layout(
            xaxis_title='æŒ‰é”®ID',
            yaxis_title='Z-Score (æ ‡å‡†åŒ–å»¶æ—¶)',
            xaxis=dict(
                showgrid=True,
                gridcolor='lightgray',
                gridwidth=1,
                type='category'
            ),
            yaxis=dict(
                showgrid=True,
                gridcolor='lightgray',
                gridwidth=1
            ),
            hovermode='closest',
            plot_bgcolor='white',
            paper_bgcolor='white',
            font=dict(size=12),
            height=800,
            showlegend=True,
            legend=dict(
                orientation='h',
                yanchor='bottom',
                y=1.02,
                xanchor='left',
                x=0.0,
                bgcolor='rgba(255, 255, 255, 0.9)',
                bordercolor='gray',
                borderwidth=1
            ),
            margin=dict(t=90, b=60, l=60, r=60)
        )
    
    def _extract_single_key_delays(self, offset_data: List[Dict], target_key_id: int, 
                                   filename: str) -> Tuple[List[float], List]:
        """
        æå–å•ä¸ªæŒ‰é”®çš„å»¶æ—¶æ•°æ®
        
        Args:
            offset_data: åç§»æ•°æ®åˆ—è¡¨
            target_key_id: ç›®æ ‡æŒ‰é”®ID
            filename: æ–‡ä»¶åï¼ˆç”¨äºcustomdataï¼‰
            
        Returns:
            Tuple[List[float], List]: (å»¶æ—¶åˆ—è¡¨, customdataåˆ—è¡¨)
        """
        key_delays = []
        customdata_list = []
        
        for item in offset_data:
            key_id = item.get('key_id')
            if key_id == target_key_id:
                keyon_offset = item.get('keyon_offset', 0)
                delay_ms = keyon_offset / 10.0  # è½¬æ¢ä¸ºms
                key_delays.append(delay_ms)
                
                # è®°å½•è¯¦ç»†ä¿¡æ¯ï¼Œç”¨äºæ‚¬åœ
                record_index = item.get('record_index')
                replay_index = item.get('replay_index')
                customdata_list.append([record_index, replay_index, delay_ms, filename])
        
        return key_delays, customdata_list
    
    def _add_box_trace(self, fig: go.Figure, key_delays: List[float], display_name: str,
                      target_key_id: int, customdata_list: List, color: str):
        """
        æ·»åŠ ç®±çº¿å›¾trace
        
        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            key_delays: å»¶æ—¶åˆ—è¡¨
            display_name: ç®—æ³•æ˜¾ç¤ºåç§°
            target_key_id: ç›®æ ‡æŒ‰é”®ID
            customdata_list: è‡ªå®šä¹‰æ•°æ®åˆ—è¡¨
            color: é¢œè‰²
        """
        fig.add_trace(go.Box(
            y=key_delays,
            x=[display_name] * len(key_delays),  # Xè½´ä¸ºç®—æ³•åç§°
            name=display_name,
            boxpoints='all',  # æ˜¾ç¤ºæ‰€æœ‰ç‚¹
            jitter=0.5,       # ç‚¹çš„æŠ–åŠ¨èŒƒå›´
            pointpos=-1.8,    # ç‚¹æ˜¾ç¤ºåœ¨ç®±çº¿å›¾å·¦ä¾§
            marker=dict(
                color=color,
                size=6,
                opacity=0.7
            ),
            line=dict(color=color),
            fillcolor='rgba(255,255,255,0)',  # é€æ˜å¡«å……
            showlegend=False,  # ç®±çº¿å›¾ä¸æ˜¾ç¤ºå›¾ä¾‹ï¼Œé¿å…é‡å¤
            customdata=customdata_list,
            hovertemplate=f'ç®—æ³•: {display_name}<br>æŒ‰é”®: {target_key_id}<br>å»¶æ—¶: %{{y:.2f}}ms<extra></extra>'
        ))
    
    def _configure_single_key_layout(self, fig: go.Figure, target_key_id: int):
        """
        é…ç½®å•é”®å¯¹æ¯”å›¾å¸ƒå±€
        
        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            target_key_id: ç›®æ ‡æŒ‰é”®ID
        """
        fig.update_layout(
            title=dict(
                text=f"æŒ‰é”® {target_key_id} å»¶æ—¶åˆ†å¸ƒå¯¹æ¯” (å¤šæ›²ç›®/ç®—æ³•)",
                x=0.5,
                xanchor='center'
            ),
            xaxis=dict(
                title="æ›²å­ / ç®—æ³•",
                showgrid=False
            ),
            yaxis=dict(
                title="ç›¸å¯¹å»¶æ—¶ (ms)",
                showgrid=True,
                gridcolor='lightgray',
                zeroline=True,
                zerolinecolor='gray'
            ),
            plot_bgcolor='white',
            paper_bgcolor='white',
            hovermode='closest',
            showlegend=False,  # ä¸éœ€è¦å›¾ä¾‹ï¼ŒXè½´æ ‡ç­¾å·²è¯´æ˜
            height=400,
            margin=dict(l=60, r=40, t=60, b=40)
        )
    
    def _extract_hammer_velocity_delay_data(self, matched_pairs: List[Tuple], 
                                           offset_map: Dict, algorithm_name: str) -> Tuple[List, List, List]:
        """
        æå–é”¤é€Ÿå’Œå»¶æ—¶æ•°æ®
        
        Args:
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨
            offset_map: åç§»æ•°æ®æ˜ å°„
            algorithm_name: ç®—æ³•å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆç®—æ³•å_æ–‡ä»¶åï¼‰
            
        Returns:
            Tuple[List, List, List]: (é”¤é€Ÿåˆ—è¡¨, å»¶æ—¶åˆ—è¡¨(ms), customdataåˆ—è¡¨)
        """
        hammer_velocities = []
        delays_ms = []
        scatter_customdata = []
        
        for record_idx, replay_idx, record_note, replay_note in matched_pairs:
            # è·å–æ’­æ”¾éŸ³ç¬¦çš„é”¤é€Ÿï¼ˆç¬¬ä¸€ä¸ªé”¤é€Ÿå€¼ï¼‰
            if len(replay_note.hammers) > 0 and len(replay_note.hammers.values) > 0:
                hammer_velocity = replay_note.hammers.values[0]
            else:
                continue
            
            # è·³è¿‡é”¤é€Ÿä¸º0æˆ–è´Ÿæ•°çš„æ•°æ®ç‚¹ï¼ˆå¯¹æ•°æ— æ³•å¤„ç†ï¼‰
            if hammer_velocity <= 0:
                continue
            
            # ä»åç§»æ•°æ®ä¸­è·å–å»¶æ—¶
            if (record_idx, replay_idx) not in offset_map:
                continue
            
            keyon_offset = offset_map[(record_idx, replay_idx)].get('keyon_offset', 0)
            delay_ms = self._convert_offset_to_ms(keyon_offset)
            
            # è·å–æŒ‰é”®ID
            key_id = record_note.id if hasattr(record_note, 'id') else None
            
            hammer_velocities.append(hammer_velocity)
            delays_ms.append(delay_ms)
            # ä½¿ç”¨algorithm_nameï¼ˆå®Œæ•´çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼‰è€Œä¸æ˜¯display_name
            scatter_customdata.append([record_idx, replay_idx, algorithm_name, key_id])
        
        return hammer_velocities, delays_ms, scatter_customdata
    
    def _calculate_relative_delay_statistics(self, delays_ms: List[float], 
                                            algorithm) -> Tuple[List[float], Dict]:
        """
        è®¡ç®—ç›¸å¯¹å»¶æ—¶ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            delays_ms: ç»å¯¹å»¶æ—¶åˆ—è¡¨(ms)
            algorithm: ç®—æ³•æ•°æ®é›†
            
        Returns:
            Tuple[List[float], Dict]: (ç›¸å¯¹å»¶æ—¶åˆ—è¡¨, ç»Ÿè®¡ä¿¡æ¯å­—å…¸)
        """
        # è·å–è¯¥ç®—æ³•çš„æ€»ä½“å‡å€¼å’Œæ ‡å‡†å·®
        me_0_1ms = algorithm.analyzer.get_mean_error() if hasattr(algorithm.analyzer, 'get_mean_error') else 0.0
        std_0_1ms = algorithm.analyzer.get_standard_deviation() if hasattr(algorithm.analyzer, 'get_standard_deviation') else 0.0
        
        mu = me_0_1ms / 10.0  # æ€»ä½“å‡å€¼ï¼ˆmsï¼‰
        sigma = std_0_1ms / 10.0  # æ€»ä½“æ ‡å‡†å·®ï¼ˆmsï¼‰
        
        # è®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼šç»å¯¹å»¶æ—¶å‡å»å¹³å‡å»¶æ—¶
        delays_array = np.array(delays_ms)
        relative_delays = (delays_array - mu).tolist()
        
        # è®¡ç®—ç›¸å¯¹å»¶æ—¶çš„ç»Ÿè®¡å€¼ï¼ˆç”¨äºé˜ˆå€¼ï¼‰
        if len(relative_delays) > 1:
            relative_mu = np.mean(relative_delays)  # åº”è¯¥æ¥è¿‘0
            relative_sigma = np.std(relative_delays, ddof=1)  # æ ·æœ¬æ ‡å‡†å·®
            upper_threshold = relative_mu + 3 * relative_sigma
            lower_threshold = relative_mu - 3 * relative_sigma
        else:
            relative_mu = 0.0
            relative_sigma = 0.0
            upper_threshold = 0.0
            lower_threshold = 0.0
        
        statistics = {
            'mu': mu,
            'sigma': sigma,
            'relative_mu': relative_mu,
            'relative_sigma': relative_sigma,
            'upper_threshold': upper_threshold,
            'lower_threshold': lower_threshold
        }
        
        return relative_delays, statistics
    
    def _add_hammer_velocity_scatter_trace(self, fig: go.Figure, log_velocities: List[float],
                                          relative_delays: List[float], delays_ms: List[float],
                                          hammer_velocities: List[float], scatter_customdata: List,
                                          descriptive_name: str, color: str):
        """
        æ·»åŠ é”¤é€Ÿæ•£ç‚¹å›¾trace
        
        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            log_velocities: å¯¹æ•°é”¤é€Ÿåˆ—è¡¨
            relative_delays: ç›¸å¯¹å»¶æ—¶åˆ—è¡¨
            delays_ms: ç»å¯¹å»¶æ—¶åˆ—è¡¨
            hammer_velocities: é”¤é€Ÿåˆ—è¡¨
            scatter_customdata: è‡ªå®šä¹‰æ•°æ®åˆ—è¡¨
            descriptive_name: ç®—æ³•æè¿°åç§°
            color: é¢œè‰²
        """
        # ç»„åˆcustomdata: [delay_ms, original_velocity, record_idx, replay_idx, algorithm_name, key_id]
        combined_customdata = [[delay_ms, orig_vel, record_idx, replay_idx, alg_name, key_id]
                              for delay_ms, orig_vel, (record_idx, replay_idx, alg_name, key_id)
                              in zip(delays_ms, hammer_velocities, scatter_customdata)]
        
        fig.add_trace(go.Scatter(
            x=log_velocities,
            y=relative_delays,
            mode='markers',
            name=f"{descriptive_name} - ç›¸å¯¹å»¶æ—¶",
            marker=dict(
                size=8,
                color=color,
                opacity=0.6,
                line=dict(width=1, color=color)
            ),
            legendgroup=descriptive_name,
            showlegend=True,
            hovertemplate=f"ç®—æ³•: {descriptive_name}<br>æŒ‰é”®: %{{customdata[5]}}<br>"
                         f"é”¤é€Ÿ: %{{customdata[1]:.0f}} (log: %{{x:.2f}})<br>"
                         f"ç›¸å¯¹å»¶æ—¶: %{{y:.2f}}ms<br>ç»å¯¹å»¶æ—¶: %{{customdata[0]:.2f}}ms<extra></extra>",
            customdata=combined_customdata
        ))
    
    def _calculate_log_velocity_range(self, ready_algorithms: List) -> Tuple[float, float]:
        """
        è®¡ç®—æ‰€æœ‰ç®—æ³•çš„å¯¹æ•°é”¤é€ŸèŒƒå›´
        
        Args:
            ready_algorithms: å‡†å¤‡å¥½çš„ç®—æ³•åˆ—è¡¨
            
        Returns:
            Tuple[float, float]: (x_min, x_max)
        """
        all_log_velocities = []
        
        for alg in ready_algorithms:
            try:
                matched_pairs = alg.analyzer.note_matcher.get_matched_pairs()
                for record_idx, replay_idx, record_note, replay_note in matched_pairs:
                    if len(replay_note.hammers) > 0 and len(replay_note.hammers.values) > 0:
                        vel = replay_note.hammers.values[0]
                        if vel > 0:
                            all_log_velocities.append(math.log10(vel))
            except:
                continue
        
        x_min = min(all_log_velocities) if all_log_velocities else 0
        x_max = max(all_log_velocities) if all_log_velocities else 2
        
        return x_min, x_max
    
    def _add_relative_delay_threshold_lines(self, fig: go.Figure, x_min: float, x_max: float,
                                           statistics: Dict, descriptive_name: str, color: str):
        """
        æ·»åŠ ç›¸å¯¹å»¶æ—¶é˜ˆå€¼çº¿
        
        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            x_min: Xè½´æœ€å°å€¼
            x_max: Xè½´æœ€å¤§å€¼
            statistics: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
            descriptive_name: ç®—æ³•æè¿°åç§°
            color: é¢œè‰²
        """
        relative_mu = statistics['relative_mu']
        upper_threshold = statistics['upper_threshold']
        lower_threshold = statistics['lower_threshold']
        
        # æ·»åŠ å¹³å‡å€¼å‚è€ƒçº¿ï¼ˆ0çº¿ï¼‰
        fig.add_trace(go.Scatter(
            x=[x_min, x_max],
            y=[relative_mu, relative_mu],
            mode='lines',
            name=f'{descriptive_name} - å¹³å‡å€¼',
            line=dict(color=color, width=1.5, dash='dot'),
            legendgroup=descriptive_name,
            showlegend=True,
            hovertemplate=f"ç®—æ³•: {descriptive_name}<br>ç›¸å¯¹å»¶æ—¶å¹³å‡å€¼ = {relative_mu:.2f}ms<extra></extra>"
        ))
        
        # æ·»åŠ ä¸Šé˜ˆå€¼çº¿
        fig.add_trace(go.Scatter(
            x=[x_min, x_max],
            y=[upper_threshold, upper_threshold],
            mode='lines',
            name=f'{descriptive_name} - ä¸Šé˜ˆå€¼',
            line=dict(color=color, width=2, dash='dash'),
            legendgroup=descriptive_name,
            showlegend=True,
            hovertemplate=f"ç®—æ³•: {descriptive_name}<br>ç›¸å¯¹å»¶æ—¶ä¸Šé˜ˆå€¼ = {upper_threshold:.2f}ms<extra></extra>"
        ))
        
        # æ·»åŠ ä¸‹é˜ˆå€¼çº¿
        fig.add_trace(go.Scatter(
            x=[x_min, x_max],
            y=[lower_threshold, lower_threshold],
            mode='lines',
            name=f'{descriptive_name} - ä¸‹é˜ˆå€¼',
            line=dict(color=color, width=2, dash='dash'),
            legendgroup=descriptive_name,
            showlegend=True,
            hovertemplate=f"ç®—æ³•: {descriptive_name}<br>ç›¸å¯¹å»¶æ—¶ä¸‹é˜ˆå€¼ = {lower_threshold:.2f}ms<extra></extra>"
        ))
    
    def _configure_hammer_velocity_layout(self, fig: go.Figure):
        """é…ç½®é”¤é€Ÿä¸ç›¸å¯¹å»¶æ—¶å›¾å¸ƒå±€"""
        fig.update_layout(
            xaxis_title='logâ‚â‚€(é”¤é€Ÿ)',
            yaxis_title='ç›¸å¯¹å»¶æ—¶ (ms)',
            xaxis=dict(
                showgrid=True,
                gridcolor='lightgray',
                gridwidth=1
            ),
            yaxis=dict(
                showgrid=True,
                gridcolor='lightgray',
                gridwidth=1
            ),
            hovermode='closest',
            plot_bgcolor='white',
            paper_bgcolor='white',
            font=dict(size=12),
            height=800,
            showlegend=True,
            legend=dict(
                orientation='h',
                yanchor='bottom',
                y=1.02,
                xanchor='left',
                x=0.0,
                bgcolor='rgba(255, 255, 255, 0.9)',
                bordercolor='gray',
                borderwidth=1
            ),
            margin=dict(t=90, b=60, l=60, r=60)
        )
    
    def _add_hammer_velocity_zscore_scatter_trace(self, fig: go.Figure, log_velocities: List[float],
                                                  z_scores: List[float], delays_ms: List[float],
                                                  hammer_velocities: List[float], scatter_customdata: List,
                                                  descriptive_name: str, color: str):
        """
        æ·»åŠ é”¤é€ŸZ-Scoreæ•£ç‚¹å›¾trace
        
        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            log_velocities: å¯¹æ•°é”¤é€Ÿåˆ—è¡¨
            z_scores: Z-Scoreåˆ—è¡¨
            delays_ms: ç»å¯¹å»¶æ—¶åˆ—è¡¨
            hammer_velocities: é”¤é€Ÿåˆ—è¡¨
            scatter_customdata: è‡ªå®šä¹‰æ•°æ®åˆ—è¡¨
            descriptive_name: ç®—æ³•æè¿°åç§°
            color: é¢œè‰²
        """
        # ç»„åˆcustomdata: [delay_ms, original_velocity, record_idx, replay_idx, algorithm_name, key_id]
        combined_customdata = [[delay_ms, orig_vel, record_idx, replay_idx, alg_name, key_id]
                              for delay_ms, orig_vel, (record_idx, replay_idx, alg_name, key_id)
                              in zip(delays_ms, hammer_velocities, scatter_customdata)]
        
        fig.add_trace(go.Scatter(
            x=log_velocities,
            y=z_scores,
            mode='markers',
            name=f'{descriptive_name} - Z-Score',
            marker=dict(
                size=8,
                color=color,
                opacity=0.6,
                line=dict(width=1, color=color)
            ),
            legendgroup=descriptive_name,
            showlegend=True,
            hovertemplate=f'ç®—æ³•: {descriptive_name}<br>æŒ‰é”®: %{{customdata[5]}}<br>'
                         f'é”¤é€Ÿ: %{{customdata[1]:.0f}} (log: %{{x:.2f}})<br>'
                         f'å»¶æ—¶: %{{customdata[0]:.2f}}ms<br>Z-Score: %{{y:.2f}}<extra></extra>',
            customdata=combined_customdata
        ))
    
    def _add_zscore_threshold_lines_for_velocity(self, fig: go.Figure, x_min: float, x_max: float,
                                                 descriptive_name: str, color: str):
        """
        ä¸ºé”¤é€Ÿå›¾æ·»åŠ Z-Scoreé˜ˆå€¼çº¿
        
        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            x_min: Xè½´æœ€å°å€¼
            x_max: Xè½´æœ€å¤§å€¼
            descriptive_name: ç®—æ³•æè¿°åç§°
            color: é¢œè‰²
        """
        # æ·»åŠ Z=0çš„æ°´å¹³è™šçº¿ï¼ˆå‡å€¼çº¿ï¼‰
        fig.add_trace(go.Scatter(
            x=[x_min, x_max],
            y=[0, 0],
            mode='lines',
            name=f'{descriptive_name} - Z=0',
            line=dict(color=color, width=1.5, dash='dot'),
            legendgroup=descriptive_name,
            showlegend=True,
            hovertemplate=f'ç®—æ³•: {descriptive_name}<br>Z-Score = 0 (å‡å€¼çº¿)<extra></extra>'
        ))
        
        # æ·»åŠ Z=+3çš„æ°´å¹³è™šçº¿ï¼ˆä¸Šé˜ˆå€¼ï¼‰
        fig.add_trace(go.Scatter(
            x=[x_min, x_max],
            y=[3, 3],
            mode='lines',
            name=f'{descriptive_name} - Z=+3',
            line=dict(color=color, width=2, dash='dash'),
            legendgroup=descriptive_name,
            showlegend=True,
            hovertemplate=f'ç®—æ³•: {descriptive_name}<br>Z-Score = +3 (ä¸Šé˜ˆå€¼)<extra></extra>'
        ))
        
        # æ·»åŠ Z=-3çš„æ°´å¹³è™šçº¿ï¼ˆä¸‹é˜ˆå€¼ï¼‰
        fig.add_trace(go.Scatter(
            x=[x_min, x_max],
            y=[-3, -3],
            mode='lines',
            name=f'{descriptive_name} - Z=-3',
            line=dict(color=color, width=2, dash='dash'),
            legendgroup=descriptive_name,
            showlegend=True,
            hovertemplate=f'ç®—æ³•: {descriptive_name}<br>Z-Score = -3 (ä¸‹é˜ˆå€¼)<extra></extra>'
        ))
    
    def _configure_hammer_velocity_zscore_layout(self, fig: go.Figure):
        """é…ç½®é”¤é€ŸZ-Scoreå›¾å¸ƒå±€"""
        fig.update_layout(
            xaxis_title='é”¤é€Ÿï¼ˆlogâ‚â‚€ï¼‰',
            yaxis_title='Z-Scoreï¼ˆæ ‡å‡†åŒ–å»¶æ—¶ï¼‰',
            xaxis=dict(
                showgrid=True,
                gridcolor='lightgray',
                gridwidth=1,
                autorange=True,
                tickformat='.1f',
                dtick=0.2
            ),
            yaxis=dict(
                showgrid=True,
                gridcolor='lightgray',
                gridwidth=1,
                range=[-5, 5],
                dtick=1,
                tickformat='.1f'
            ),
            hovermode='closest',
            plot_bgcolor='white',
            paper_bgcolor='white',
            font=dict(size=12),
            height=500,
            showlegend=True,
            legend=dict(
                orientation='h',
                yanchor='bottom',
                y=1.02,
                xanchor='left',
                x=0.0,
                bgcolor='rgba(255, 255, 255, 0.9)',
                bordercolor='gray',
                borderwidth=1
            ),
            margin=dict(t=70, b=60, l=60, r=60)
        )
    
    def _extract_key_hammer_velocity_data(self, matched_pairs: List[Tuple], 
                                          offset_map: Dict) -> Tuple[List[int], List[float], List[float]]:
        """
        æå–æŒ‰é”®IDã€é”¤é€Ÿå’Œå»¶æ—¶æ•°æ®
        
        Args:
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨
            offset_map: åç§»æ•°æ®æ˜ å°„
            
        Returns:
            Tuple[List[int], List[float], List[float]]: (æŒ‰é”®IDåˆ—è¡¨, é”¤é€Ÿåˆ—è¡¨, å»¶æ—¶åˆ—è¡¨)
        """
        key_ids = []
        hammer_velocities = []
        delays_ms = []
        
        for record_idx, replay_idx, record_note, replay_note in matched_pairs:
            key_id = record_note.id
            
            # è·å–é”¤é€Ÿ
            if len(replay_note.hammers) > 0 and len(replay_note.hammers.values) > 0:
                hammer_velocity = replay_note.hammers.values[0]
            else:
                continue
            
            # è·å–å»¶æ—¶
            if (record_idx, replay_idx) not in offset_map:
                continue
            
            keyon_offset = offset_map[(record_idx, replay_idx)].get('keyon_offset', 0)
            delay_ms = abs(keyon_offset) / 10.0
            
            try:
                key_id_int = int(key_id)
                key_ids.append(key_id_int)
                hammer_velocities.append(hammer_velocity)
                delays_ms.append(delay_ms)
            except (ValueError, TypeError):
                continue
        
        return key_ids, hammer_velocities, delays_ms
    
    def _add_key_hammer_velocity_scatter_trace(self, fig: go.Figure, key_ids: List[int],
                                               hammer_velocities: List[float], delays_ms: List[float],
                                               descriptive_name: str, algorithm_name: str,
                                               alg_idx: int, num_algorithms: int, all_delays: List[float]):
        """
        æ·»åŠ æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾trace
        
        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            key_ids: æŒ‰é”®IDåˆ—è¡¨
            hammer_velocities: é”¤é€Ÿåˆ—è¡¨
            delays_ms: å»¶æ—¶åˆ—è¡¨
            descriptive_name: ç®—æ³•æè¿°åç§°
            algorithm_name: ç®—æ³•åç§°
            alg_idx: ç®—æ³•ç´¢å¼•
            num_algorithms: ç®—æ³•æ€»æ•°
            all_delays: æ‰€æœ‰å»¶æ—¶åˆ—è¡¨ï¼ˆç”¨äºé¢œè‰²èŒƒå›´ï¼‰
        """
        marker_symbols = ['circle', 'square', 'diamond', 'triangle-up', 'x', 'star', 'cross', 'pentagon']
        colorscales = ['Viridis', 'Plasma', 'Inferno', 'Magma', 'Cividis', 'Turbo', 'Blues', 'Reds']
        
        marker_symbol = marker_symbols[alg_idx % len(marker_symbols)]
        colorscale = colorscales[alg_idx % len(colorscales)]
        
        fig.add_trace(go.Scatter(
            x=key_ids,
            y=hammer_velocities,
            mode='markers',
            name=f'{descriptive_name}',
            marker=dict(
                size=8,
                color=delays_ms,
                colorscale=colorscale,
                colorbar=dict(
                    title=f'{descriptive_name}<br>å»¶æ—¶ (ms)',
                    thickness=15,
                    len=0.3,
                    x=1.02 + (alg_idx * 0.08),
                    y=0.5 - (alg_idx * 0.3 / num_algorithms)
                ),
                cmin=min(all_delays) if all_delays else 0,
                cmax=max(all_delays) if all_delays else 100,
                symbol=marker_symbol,
                line=dict(width=1, color='rgba(0,0,0,0.3)')
            ),
            legendgroup=algorithm_name,
            showlegend=True,
            hovertemplate=f'ç®—æ³•: {algorithm_name}<br>é”®ä½: %{{x}}<br>é”¤é€Ÿ: %{{y}}<br>å»¶æ—¶: %{{marker.color:.2f}}ms<extra></extra>'
        ))
    
    def _configure_key_hammer_velocity_layout(self, fig: go.Figure):
        """é…ç½®æŒ‰é”®ä¸é”¤é€Ÿæ•£ç‚¹å›¾å¸ƒå±€"""
        fig.update_layout(
            xaxis_title='æŒ‰é”®ID',
            yaxis_title='é”¤é€Ÿ',
            xaxis=dict(
                showgrid=True,
                gridcolor='lightgray',
                gridwidth=1,
                dtick=10
            ),
            yaxis=dict(
                showgrid=True,
                gridcolor='lightgray',
                gridwidth=1
            ),
            hovermode='closest',
            plot_bgcolor='white',
            paper_bgcolor='white',
            font=dict(size=12),
            height=500,
            showlegend=True,
            legend=dict(
                orientation='h',
                yanchor='bottom',
                y=1.02,
                xanchor='left',
                x=0.0,
                bgcolor='rgba(255, 255, 255, 0.9)',
                bordercolor='gray',
                borderwidth=1
            ),
            margin=dict(t=70, b=60, l=60, r=200)
        )
    
    
    def _should_generate_time_series_plot(self, algorithms: List[AlgorithmDataset]) -> Tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ç”Ÿæˆå»¶æ—¶æ—¶é—´åºåˆ—å›¾

        æ¡ä»¶ï¼š
        1. è‡³å°‘æœ‰2ä¸ªç®—æ³•

        Args:
            algorithms: ç®—æ³•æ•°æ®é›†åˆ—è¡¨

        Returns:
            Tuple[bool, str]: (æ˜¯å¦åº”è¯¥ç”Ÿæˆ, åŸå› è¯´æ˜)
        """
        if not algorithms or len(algorithms) < 2:
            return False, "éœ€è¦è‡³å°‘2ä¸ªç®—æ³•æ‰èƒ½è¿›è¡Œå¯¹æ¯”"

        # åªè¦æœ‰è‡³å°‘2ä¸ªç®—æ³•å°±å¯ä»¥ç”Ÿæˆå›¾è¡¨ï¼Œä¸å†é™åˆ¶åŒç§ç®—æ³•çš„ä¸åŒæ›²å­
        return True, ""
    
    def _filter_ready_algorithms(self, algorithms: List[AlgorithmDataset]) -> List[AlgorithmDataset]:
        """
        è¿‡æ»¤å‡ºå°±ç»ªçš„ç®—æ³•

        Args:
            algorithms: åŸå§‹ç®—æ³•åˆ—è¡¨

        Returns:
            List[AlgorithmDataset]: å°±ç»ªçš„ç®—æ³•åˆ—è¡¨
        """
        return [alg for alg in algorithms if alg.is_ready()]

    def _prepare_algorithm_colors(self) -> List[str]:
        """
        å‡†å¤‡ç®—æ³•é¢œè‰²åˆ—è¡¨

        Returns:
            List[str]: é¢œè‰²åˆ—è¡¨
        """
        return ALGORITHM_COLOR_PALETTE

    def _process_single_algorithm_data(self, algorithm: AlgorithmDataset) -> Optional[Dict[str, Any]]:
        """
        å¤„ç†å•ä¸ªç®—æ³•çš„æ—¶é—´åºåˆ—æ•°æ®

        Args:
            algorithm: ç®—æ³•æ•°æ®é›†

        Returns:
            Optional[Dict[str, Any]]: å¤„ç†åçš„æ•°æ®ï¼ŒåŒ…å«æ—¶é—´ã€å»¶æ—¶ç­‰ä¿¡æ¯ï¼Œå¦‚æœå¤„ç†å¤±è´¥è¿”å›None
        """
        algorithm_name = algorithm.metadata.algorithm_name
        display_name = algorithm.metadata.display_name

        if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
            logger.warning(f"âš ï¸ ç®—æ³• '{display_name}' æ²¡æœ‰åˆ†æå™¨æˆ–åŒ¹é…å™¨ï¼Œè·³è¿‡")
            return None

        try:
            offset_data = algorithm.analyzer.note_matcher.get_precision_offset_alignment_data()

            if not offset_data:
                logger.warning(f"âš ï¸ ç®—æ³• '{display_name}' æ²¡æœ‰åŒ¹é…æ•°æ®ï¼Œè·³è¿‡")
                return None

            # æå–æ—¶é—´å’Œå»¶æ—¶æ•°æ®
            data_points = []

            for item in offset_data:
                record_keyon_raw = item.get('record_keyon')  # å•ä½ï¼š0.1ms
                keyon_offset_raw = item.get('keyon_offset')  # å•ä½ï¼š0.1ms
                key_id = item.get('key_id')
                record_index = item.get('record_index')
                replay_index = item.get('replay_index')

                # æ£€æŸ¥æ•°æ®ç±»å‹æœ‰æ•ˆæ€§ï¼ˆæ”¯æŒ numpy ç±»å‹ï¼‰
                record_keyon_is_valid = isinstance(record_keyon_raw, (int, float, np.integer, np.floating))
                keyon_offset_is_valid = isinstance(keyon_offset_raw, (int, float, np.integer, np.floating))


                if not record_keyon_is_valid:
                    continue
                if not keyon_offset_is_valid:
                    continue

                # ä½¿ç”¨åŸå§‹æ•°æ®
                record_keyon = record_keyon_raw
                keyon_offset = keyon_offset_raw

                # è½¬æ¢ä¸ºmså•ä½
                time_ms = record_keyon / 10.0
                delay_ms = keyon_offset / 10.0

                data_points.append({
                    'time': time_ms,
                    'delay': delay_ms,
                    'key_id': key_id if key_id is not None else 'N/A',
                    'record_index': record_index,
                    'replay_index': replay_index
                })

            if not data_points:
                logger.warning(f"ç®—æ³• '{display_name}' æ²¡æœ‰æœ‰æ•ˆæ—¶é—´åºåˆ—æ•°æ®ï¼Œè·³è¿‡")
                return None

            # æŒ‰æ—¶é—´æ’åºï¼Œç¡®ä¿æŒ‰æ—¶é—´é¡ºåºæ˜¾ç¤º
            data_points.sort(key=lambda x: x['time'])

            # è®¡ç®—è¯¥ç®—æ³•çš„å¹³å‡å»¶æ—¶
            me_0_1ms = algorithm.analyzer.get_mean_error() if hasattr(algorithm.analyzer, 'get_mean_error') else 0.0
            mean_delay = me_0_1ms / 10.0  # å¹³å‡å»¶æ—¶ï¼ˆmsï¼Œå¸¦ç¬¦å·ï¼‰

            # è®¡ç®—ç›¸å¯¹å»¶æ—¶
            relative_delays_ms = []
            for point in data_points:
                delay_ms = point['delay']
                relative_delay = delay_ms - mean_delay
                relative_delays_ms.append(relative_delay)

            # æå–æ’åºåçš„æ•°æ®
            times_ms = [point['time'] for point in data_points]
            delays_ms = [point['delay'] for point in data_points]
            replay_times_ms = [point['time'] + point['delay'] for point in data_points]
            replay_times_offset_ms = [replay_time - mean_delay for replay_time in replay_times_ms]

            # customdata åŒ…å« [key_id, record_index, replay_index, algorithm_name, åŸå§‹å»¶æ—¶, å¹³å‡å»¶æ—¶, æ’­æ”¾æ—¶é—´, å½•åˆ¶æ—¶é—´]
            customdata_list = [[point['key_id'], point['record_index'], point['replay_index'],
                               algorithm_name, point['delay'], mean_delay, replay_time, point['time']]
                              for point, replay_time in zip(data_points, replay_times_ms)]

            return {
                'algorithm_name': algorithm_name,
                'display_name': display_name,
                'data_points': data_points,
                'times_ms': times_ms,
                'delays_ms': delays_ms,
                'relative_delays_ms': relative_delays_ms,
                'replay_times_ms': replay_times_ms,
                'replay_times_offset_ms': replay_times_offset_ms,
                'customdata_list': customdata_list,
                'mean_delay': mean_delay
            }

        except Exception as e:
            logger.warning(f"è·å–ç®—æ³• '{display_name}' çš„æ—¶é—´åºåˆ—æ•°æ®å¤±è´¥: {e}")
            return None

    def _create_relative_delay_traces(self, fig, algorithm_data: Dict[str, Any], color: str) -> None:
        """
        ä¸ºç›¸å¯¹å»¶æ—¶å›¾åˆ›å»ºtrace

        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            algorithm_data: ç®—æ³•æ•°æ®
            color: ç®—æ³•é¢œè‰²
        """
        algorithm_name = algorithm_data['algorithm_name']
        display_name = algorithm_data['display_name']
        replay_times_ms = algorithm_data['replay_times_ms']
        replay_times_offset_ms = algorithm_data['replay_times_offset_ms']
        relative_delays_ms = algorithm_data['relative_delays_ms']
        customdata_list = algorithm_data['customdata_list']
        mean_delay = algorithm_data['mean_delay']

        # æ·»åŠ åç§»åçš„æ’­æ”¾éŸ³è½¨æ•£ç‚¹å›¾ï¼ˆXè½´=åç§»åçš„æ’­æ”¾æ—¶é—´ï¼ŒYè½´=ç›¸å¯¹å»¶æ—¶ï¼‰
        fig.add_trace(go.Scatter(
            x=replay_times_offset_ms,  # Xè½´ä½¿ç”¨åç§»åçš„æ’­æ”¾æ—¶é—´ï¼ˆæ’­æ”¾æ—¶é—´ - å¹³å‡å»¶æ—¶ï¼‰
            y=relative_delays_ms,  # Yè½´ä½¿ç”¨ç›¸å¯¹å»¶æ—¶
            mode='markers+lines',  # æ˜¾ç¤ºæ•°æ®ç‚¹å¹¶æŒ‰æ—¶é—´é¡ºåºè¿æ¥
            name=f'{display_name} (åç§»åï¼Œå¹³å‡å»¶æ—¶: {mean_delay:.2f}ms)',
            marker=dict(
                size=5,
                color=color,
                line=dict(width=0.5, color=color)
            ),
            line=dict(color=color, width=1.5),
            legendgroup=f"{algorithm_name}_offset",
            showlegend=True,
            hovertemplate='<b>ç®—æ³•</b>: ' + display_name + ' (åç§»å)<br>' +
                         '<b>åç§»åæ’­æ”¾æ—¶é—´ï¼ˆXè½´ï¼‰</b>: %{x:.2f}ms<br>' +
                         '<b>ç›¸å¯¹å»¶æ—¶ï¼ˆYè½´ï¼‰</b>: %{y:.2f}ms<br>' +
                         '<b>å®é™…æ’­æ”¾æ—¶é—´</b>: %{customdata[6]:.2f}ms<br>' +
                         '<b>å½•åˆ¶æ—¶é—´</b>: %{customdata[7]:.2f}ms<br>' +
                         '<b>åŸå§‹å»¶æ—¶</b>: %{customdata[4]:.2f}ms<br>' +
                         '<b>å¹³å‡å»¶æ—¶</b>: %{customdata[5]:.2f}ms<br>' +
                         '<b>æŒ‰é”®ID</b>: %{customdata[0]}<br>' +
                         '<extra></extra>',
            customdata=customdata_list
        ))

    def _add_algorithm_reference_lines(self, fig, algorithm_data: Dict[str, Any], color: str) -> None:
        """
        ä¸ºç®—æ³•æ·»åŠ å‚è€ƒçº¿

        Args:
            fig: Plotlyå›¾è¡¨å¯¹è±¡
            algorithm_data: ç®—æ³•æ•°æ®
            color: ç®—æ³•é¢œè‰²
        """
        algorithm_name = algorithm_data['algorithm_name']
        display_name = algorithm_data['display_name']
        delays_ms = algorithm_data['delays_ms']
        replay_times_offset_ms = algorithm_data['replay_times_offset_ms']
        algorithm = algorithm_data.get('algorithm_instance')

        if not delays_ms or len(delays_ms) == 0 or not algorithm or not algorithm.analyzer:
            return

        # è®¡ç®—æ ‡å‡†å·®
        std_0_1ms = algorithm.analyzer.get_standard_deviation() if hasattr(algorithm.analyzer, 'get_standard_deviation') else 0.0
        std_delay = std_0_1ms / 10.0

        # è·å–æ—¶é—´èŒƒå›´
        replay_time_offset_min = min(replay_times_offset_ms) if replay_times_offset_ms else 0
        replay_time_offset_max = max(replay_times_offset_ms) if replay_times_offset_ms else 1

        # æ·»åŠ é›¶çº¿å‚è€ƒçº¿
        fig.add_trace(go.Scatter(
            x=[replay_time_offset_min, replay_time_offset_max],
            y=[0, 0],
            mode='lines',
            name=f'{display_name} - é›¶çº¿',
            line=dict(dash='dash', color=color, width=1.5),
            hovertemplate=f'<b>{display_name} é›¶çº¿</b>: 0.00ms<extra></extra>',
            showlegend=False,
            legendgroup=algorithm_name
        ))

        # æ·»åŠ Â±3Ïƒå‚è€ƒçº¿
        if std_delay > 0:
            fig.add_trace(go.Scatter(
                x=[replay_time_offset_min, replay_time_offset_max],
                y=[3 * std_delay, 3 * std_delay],
                mode='lines',
                name=f'{display_name} - +3Ïƒ',
                line=dict(dash='dot', color=color, width=1),
                hovertemplate=f'<b>{display_name} +3Ïƒ</b>: {3 * std_delay:.2f}ms<extra></extra>',
                showlegend=False,
                legendgroup=algorithm_name
            ))
            fig.add_trace(go.Scatter(
                x=[replay_time_offset_min, replay_time_offset_max],
                y=[-3 * std_delay, -3 * std_delay],
                mode='lines',
                name=f'{display_name} - -3Ïƒ',
                line=dict(dash='dot', color=color, width=1),
                hovertemplate=f'<b>{display_name} -3Ïƒ</b>: {-3 * std_delay:.2f}ms<extra></extra>',
                showlegend=False,
                legendgroup=algorithm_name
            ))

    def _collect_all_relative_delay_data(self, ready_algorithms: List[AlgorithmDataset], colors: List[str], apply_time_offset: bool = False) -> List[Tuple[float, float, List, str, str]]:
        """
        æ”¶é›†æ‰€æœ‰ç®—æ³•çš„ç›¸å¯¹å»¶æ—¶æ•°æ®

        Args:
            ready_algorithms: å°±ç»ªçš„ç®—æ³•åˆ—è¡¨
            colors: é¢œè‰²åˆ—è¡¨
            apply_time_offset: æ˜¯å¦åº”ç”¨æ—¶é—´è½´åç§»ï¼ˆå‡å»å¹³å‡å»¶æ—¶ï¼‰

        Returns:
            List[Tuple[float, float, List, str, str]]: ç›¸å¯¹æ•°æ®åˆ—è¡¨ (time_ms, relative_delay_ms, customdata, descriptive_name, color)
        """
        all_relative_data = []

        for alg_idx, algorithm in enumerate(ready_algorithms):
            algorithm_name = algorithm.metadata.algorithm_name
            display_name = algorithm.metadata.display_name
            filename = algorithm.metadata.filename
            descriptive_name = f"{display_name} ({filename})"
            color = colors[alg_idx % len(colors)]

            if not algorithm.analyzer or not algorithm.analyzer.note_matcher:
                continue

            try:
                offset_data = algorithm.analyzer.get_precision_offset_alignment_data()

                if not offset_data:
                    continue

                # è®¡ç®—è¯¥ç®—æ³•çš„å¹³å‡å»¶æ—¶ï¼ˆç”¨äºç›¸å¯¹å»¶æ—¶è®¡ç®—ï¼‰
                me_0_1ms = algorithm.analyzer.note_matcher.get_mean_error()
                mean_delay = me_0_1ms / 10.0  # å¹³å‡å»¶æ—¶ï¼ˆmsï¼‰

                # æå–æ’­æ”¾éŸ³è½¨æ•°æ®
                for item in offset_data:
                    record_keyon_raw = item.get('record_keyon')
                    replay_keyon_raw = item.get('replay_keyon')  # æ’­æ”¾æ—¶é—´
                    key_id = item.get('key_id')
                    record_index = item.get('record_index')
                    replay_index = item.get('replay_index')
                    record_velocity = item.get('record_velocity')
                    replay_velocity = item.get('replay_velocity')
                    velocity_diff = item.get('velocity_diff')
                    relative_delay = item.get('relative_delay', 0)

                    # ç±»å‹æ£€æŸ¥
                    record_keyon_is_valid = isinstance(record_keyon_raw, (int, float, np.integer, np.floating))
                    replay_keyon_is_valid = isinstance(replay_keyon_raw, (int, float, np.integer, np.floating))

                    if not record_keyon_is_valid or not replay_keyon_is_valid:
                        continue

                    # è½¬æ¢ä¸ºmså•ä½
                    time_ms = record_keyon_raw / 10.0  # Xè½´ï¼šå½•åˆ¶æ—¶é—´
                    replay_time_ms = replay_keyon_raw / 10.0  # æ’­æ”¾æ—¶é—´

                    # è®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼ˆç»å¯¹å»¶æ—¶ - å¹³å‡å»¶æ—¶ï¼‰
                    relative_delay_ms = (replay_time_ms - time_ms) - mean_delay

                    # å¦‚æœéœ€è¦æ—¶é—´è½´åç§»ï¼Œä½¿ç”¨åç§»åçš„æ’­æ”¾æ—¶é—´è½´
                    if apply_time_offset:
                        time_ms = replay_time_ms - mean_delay  # æ’­æ”¾æ—¶é—´ - å¹³å‡å»¶æ—¶
                        y_value = relative_delay_ms  # Yè½´ï¼šç›¸å¯¹å»¶æ—¶
                    else:
                        time_ms = replay_time_ms  # Xè½´ï¼šæ’­æ”¾æ—¶é—´
                        y_value = relative_delay_ms  # Yè½´ï¼šç›¸å¯¹å»¶æ—¶

                    # å­˜å‚¨åŸå§‹æ—¶é—´å€¼ï¼ˆåœ¨ä¿®æ”¹time_msä¹‹å‰ï¼‰
                    original_record_time = record_keyon_raw / 10.0
                    customdata = [key_id, record_index, replay_index, algorithm_name, replay_time_ms - original_record_time, relative_delay, mean_delay, record_velocity, replay_velocity, velocity_diff, replay_time_ms, original_record_time]

                    all_relative_data.append((time_ms, y_value, customdata, descriptive_name, color))

            except Exception as e:
                logger.warning(f"âš ï¸ å¤„ç†ç®—æ³• '{algorithm_name}' çš„ç›¸å¯¹å»¶æ—¶æ•°æ®å¤±è´¥: {e}")

        return all_relative_data

    def _create_raw_delay_plot_for_algorithms(self, all_raw_data: List[Tuple[float, float, List, str, str]]) -> Any:
        """
        ä¸ºå¤šç®—æ³•åˆ›å»ºåŸå§‹å»¶æ—¶å›¾è¡¨

        Args:
            all_raw_data: æ‰€æœ‰åŸå§‹å»¶æ—¶æ•°æ®

        Returns:
            Any: Plotlyå›¾è¡¨å¯¹è±¡
        """
        

        raw_delay_fig = go.Figure()

        # æŒ‰ç®—æ³•åˆ†ç»„æ•°æ®
        algorithm_data = {}
        for time_ms, delay_ms, customdata, descriptive_name, color in all_raw_data:
            if descriptive_name not in algorithm_data:
                algorithm_data[descriptive_name] = {
                    'times': [], 'delays': [], 'customdata': [], 'color': color
                }
            algorithm_data[descriptive_name]['times'].append(time_ms)
            algorithm_data[descriptive_name]['delays'].append(delay_ms)
            algorithm_data[descriptive_name]['customdata'].append(customdata)

        # æ·»åŠ æ¯ä¸ªç®—æ³•çš„trace
        for descriptive_name, data in algorithm_data.items():
            if data['times'] and data['delays']:
                # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
                sorted_indices = sorted(range(len(data['times'])), key=lambda i: data['times'][i])
                sorted_times = [data['times'][i] for i in sorted_indices]
                sorted_delays = [data['delays'][i] for i in sorted_indices]
                sorted_customdata = [data['customdata'][i] for i in sorted_indices]

                raw_delay_fig.add_trace(go.Scatter(
                    x=sorted_times,
                    y=sorted_delays,
                    mode='markers+lines',
                    name=f'{descriptive_name} (ç›¸å¯¹å»¶æ—¶)',
                    marker=dict(
                        size=4,
                        color=data['color'],
                        symbol='circle'  # å®å¿ƒåœ†ç‚¹
                    ),
                    line=dict(color=data['color'], width=1, dash='dot'),
                    hovertemplate='<b>ç®—æ³•</b>: ' + descriptive_name + '<br>' +
                                 '<b>æ’­æ”¾æ—¶é—´</b>: %{x:.2f}ms<br>' +
                                 '<b>å½•åˆ¶æ—¶é—´</b>: %{customdata[11]:.2f}ms<br>' +
                                 '<b>ç›¸å¯¹å»¶æ—¶</b>: %{y:.2f}ms<br>' +
                                 '<b>å¹³å‡å»¶æ—¶</b>: %{customdata[6]:.2f}ms<br>' +
                                 '<b>å½•åˆ¶é”¤é€Ÿ</b>: %{customdata[7]}<br>' +
                                 '<b>æ’­æ”¾é”¤é€Ÿ</b>: %{customdata[8]}<br>' +
                                 '<b>é”¤é€Ÿå·®å€¼</b>: %{customdata[9]}<br>' +
                                 '<b>æŒ‰é”®ID</b>: %{customdata[0]}<br>' +
                                 '<extra></extra>',
                    customdata=sorted_customdata
                ))

        # é…ç½®å¸ƒå±€
        raw_delay_fig.update_layout(
            xaxis_title='æ’­æ”¾æ—¶é—´ (ms)',
            yaxis_title='ç›¸å¯¹å»¶æ—¶ (ms)',
            showlegend=True,
            template='plotly_white',
            height=400,
            hovermode='closest',
            legend=dict(
                orientation='h',
                yanchor='bottom',
                y=1.02,
                xanchor='left',
                x=0.0,
                bgcolor='rgba(255, 255, 255, 0.9)',
                bordercolor='gray',
                borderwidth=1
            ),
            margin=dict(t=100, b=60, l=60, r=60)
        )

        return raw_delay_fig

    def _process_all_algorithms_data(self, ready_algorithms: List[AlgorithmDataset], colors: List[str]) -> Tuple[Any, List[Tuple[Dict[str, Any], str]]]:
        """
        å¤„ç†æ‰€æœ‰ç®—æ³•çš„æ•°æ®å¹¶åˆ›å»ºç›¸å¯¹å»¶æ—¶å›¾çš„traces

        Args:
            ready_algorithms: å°±ç»ªçš„ç®—æ³•åˆ—è¡¨
            colors: é¢œè‰²åˆ—è¡¨

        Returns:
            Tuple[Any, List[Tuple[Dict[str, Any], str]]]: (å›¾è¡¨å¯¹è±¡, ç®—æ³•ç»“æœåˆ—è¡¨)
        """
        
        fig = go.Figure()

        all_delays = []
        algorithm_results = []

        for alg_idx, algorithm in enumerate(ready_algorithms):
            logger.info(f"[DEBUG] å¤„ç†ç®—æ³• {alg_idx}: {algorithm.metadata.display_name}")
            algorithm_data = self._process_single_algorithm_data(algorithm)
            if algorithm_data is None:
                logger.warning(f"[DEBUG] ç®—æ³• {algorithm.metadata.display_name} è¿”å›Noneï¼Œè·³è¿‡")
                continue

            logger.info(f"[DEBUG] ç®—æ³• {algorithm.metadata.display_name} è¿”å›æ•°æ®: relative_delays_msé•¿åº¦={len(algorithm_data.get('relative_delays_ms', []))}")

            # æ·»åŠ ç®—æ³•å®ä¾‹å¼•ç”¨ï¼ˆç”¨äºåç»­å‚è€ƒçº¿è®¡ç®—ï¼‰
            algorithm_data['algorithm_instance'] = algorithm

            color = colors[alg_idx % len(colors)]

            # åˆ›å»ºç›¸å¯¹å»¶æ—¶å›¾çš„trace
            logger.info(f"[DEBUG] ä¸ºç®—æ³• {algorithm.metadata.display_name} åˆ›å»ºtraces")
            self._create_relative_delay_traces(fig, algorithm_data, color)

            # æ·»åŠ å‚è€ƒçº¿
            self._add_algorithm_reference_lines(fig, algorithm_data, color)

            # æ”¶é›†æ•°æ®ç”¨äºç»Ÿè®¡
            relative_delays = algorithm_data.get('relative_delays_ms', [])
            all_delays.extend(relative_delays)
            algorithm_results.append((algorithm_data, color))

            logger.info(f"[DEBUG] ç®—æ³• {algorithm.metadata.display_name} å¤„ç†å®Œæˆï¼Œæ·»åŠ äº† {len(relative_delays)} ä¸ªæ•°æ®ç‚¹")

        return fig, algorithm_results

    def _create_multi_algorithm_relative_plot(self, ready_algorithms: List[AlgorithmDataset], colors: List[str], apply_time_offset: bool = False) -> Any:
        """
        åˆ›å»ºå¤šç®—æ³•ç›¸å¯¹å»¶æ—¶å›¾

        Args:
            ready_algorithms: å°±ç»ªçš„ç®—æ³•åˆ—è¡¨
            colors: é¢œè‰²åˆ—è¡¨
            apply_time_offset: æ˜¯å¦åº”ç”¨æ—¶é—´è½´åç§»

        Returns:
            Any: ç›¸å¯¹å»¶æ—¶å›¾è¡¨å¯¹è±¡
        """
        all_relative_data = self._collect_all_relative_delay_data(ready_algorithms, colors, apply_time_offset)
        return self._create_raw_delay_plot_for_algorithms(all_relative_data)

    def generate_multi_algorithm_delay_time_series_plot(
        self,
        algorithms: List[AlgorithmDataset]
    ) -> Any:
        """
        ç”Ÿæˆå¤šç®—æ³•å»¶æ—¶æ—¶é—´åºåˆ—å›¾ï¼ˆä¸¤å¼ ç›¸å¯¹å»¶æ—¶å›¾ï¼šæ’­æ”¾æ—¶é—´è½´å¯¹æ¯”ï¼‰

        Args:
            algorithms: æ¿€æ´»çš„ç®—æ³•æ•°æ®é›†åˆ—è¡¨

        Returns:
            Dict[str, Any]: åŒ…å«ä¸Šæ–¹ç›¸å¯¹å»¶æ—¶å›¾å’Œä¸‹æ–¹ç›¸å¯¹å»¶æ—¶å›¾çš„å­—å…¸
        """
        if not algorithms:
            return self._create_empty_plot("æ²¡æœ‰æ¿€æ´»çš„ç®—æ³•")

        try:
            # 1. è¿‡æ»¤å°±ç»ªçš„ç®—æ³•
            ready_algorithms = self._filter_ready_algorithms(algorithms)
            if not ready_algorithms:
                logger.warning("æ²¡æœ‰å°±ç»ªçš„ç®—æ³•ï¼Œæ— æ³•ç”Ÿæˆå¤šç®—æ³•å»¶æ—¶æ—¶é—´åºåˆ—å›¾")
                return self._create_empty_plot("æ²¡æœ‰å°±ç»ªçš„ç®—æ³•")

            # 2. æ£€æŸ¥æ˜¯å¦åº”è¯¥ç”Ÿæˆå›¾è¡¨
            should_generate, reason = self._should_generate_time_series_plot(ready_algorithms)
            if not should_generate:
                logger.info(f"è·³è¿‡å»¶æ—¶æ—¶é—´åºåˆ—å›¾ç”Ÿæˆ: {reason}")
                return self._create_empty_plot(reason)

            logger.info(f"å¼€å§‹ç”Ÿæˆå¤šç®—æ³•å»¶æ—¶æ—¶é—´åºåˆ—å›¾ï¼Œå…± {len(ready_algorithms)} ä¸ªç®—æ³•")

            # 3. å‡†å¤‡é¢œè‰²
            colors = self._prepare_algorithm_colors()

            # 4. å¤„ç†æ‰€æœ‰ç®—æ³•æ•°æ®å¹¶åˆ›å»ºç›¸å¯¹å»¶æ—¶å›¾
            fig, algorithm_results = self._process_all_algorithms_data(ready_algorithms, colors)

            # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…çš„æ•°æ®ç”¨äºç»˜å›¾
            has_data = any(len(trace.y) > 0 for trace in fig.data) if fig.data else False
            logger.info(f"[DEBUG] has_dataæ£€æŸ¥: fig.dataå­˜åœ¨={fig.data is not None}, tracesæ•°é‡={len(fig.data) if fig.data else 0}, has_data={has_data}")

            if not has_data:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ—¶é—´åºåˆ—æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨")
                # è®°å½•æ›´å¤šè°ƒè¯•ä¿¡æ¯
                for i, alg in enumerate(ready_algorithms):
                    logger.warning(f"  ç®—æ³• {i}: {alg.metadata.display_name}")
                return self._create_empty_plot("æ²¡æœ‰æœ‰æ•ˆçš„æ—¶é—´åºåˆ—æ•°æ®")

            # 5. é…ç½®ç›¸å¯¹å»¶æ—¶å›¾çš„å›¾æ³¨
            fig.update_layout(
                title='ç›¸å¯¹å»¶æ—¶æ—¶é—´åºåˆ—å›¾ï¼ˆæ’­æ”¾æ—¶é—´è½´ï¼‰',
                height=500,
                showlegend=True,
                legend=dict(
                    orientation='h',
                    yanchor='bottom',
                    y=1.02,
                    xanchor='left',
                    x=0.0,
                    bgcolor='rgba(255, 255, 255, 0.9)',
                    bordercolor='gray',
                    borderwidth=1,
                    title='ç®—æ³•å›¾ä¾‹'
                ),
                template='plotly_white',
                hovermode='closest'
            )

            # 6. åˆ›å»ºä¸Šæ–¹ç›¸å¯¹å»¶æ—¶å›¾ï¼ˆæ’­æ”¾æ—¶é—´è½´ï¼‰
            raw_delay_plot = self._create_multi_algorithm_relative_plot(ready_algorithms, colors, apply_time_offset=False)
            if raw_delay_plot:
                raw_delay_plot.update_layout(
                    title='ç›¸å¯¹å»¶æ—¶æ—¶é—´åºåˆ—å›¾ï¼ˆæ’­æ”¾æ—¶é—´è½´ï¼‰',
                    height=500,
                    showlegend=True,
                    legend=dict(
                        orientation='h',
                        yanchor='bottom',
                        y=1.02,
                        xanchor='left',
                        x=0.0,
                        bgcolor='rgba(255, 255, 255, 0.9)',
                        bordercolor='gray',
                        borderwidth=1,
                        title='ç®—æ³•å›¾ä¾‹'
                    ),
                    template='plotly_white',
                    hovermode='closest'
                )

            return {
                'raw_delay_plot': raw_delay_plot,
                'relative_delay_plot': fig
            }

        except Exception as e:
            return self._handle_generation_error(e, "å¤šç®—æ³•å»¶æ—¶æ—¶é—´åºåˆ—å›¾", return_dict=True)

    def _configure_unified_waterfall_layout(self, fig: go.Figure, all_bars_by_algorithm: List[Dict], is_multi_file: bool) -> None:
        """
        é…ç½®ç»Ÿä¸€çš„ç€‘å¸ƒå›¾å¸ƒå±€ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€è½´æ ‡ç­¾ã€å›¾ä¾‹å’ŒåŠ¨æ€é«˜åº¦è°ƒæ•´ã€‚

        Args:
            fig: Plotlyå›¾å½¢å¯¹è±¡
            all_bars_by_algorithm: æŒ‰ç®—æ³•åˆ†ç»„çš„æ‰€æœ‰æ¡å½¢æ•°æ®
            is_multi_file: æ˜¯å¦å¤šæ–‡ä»¶æ¨¡å¼
        """
        # è®¡ç®—åŠ¨æ€é«˜åº¦
        if is_multi_file:
            num_files = len(all_bars_by_algorithm)
            # å¤šæ–‡ä»¶æ¨¡å¼ï¼šæ¯ä¸ªæ–‡ä»¶åˆ†é…æ›´å¤šé«˜åº¦
            base_height_per_file = 600
            total_height = max(800, base_height_per_file * num_files)
        else:
            # å•æ–‡ä»¶æ¨¡å¼ï¼šå›ºå®šé«˜åº¦
            total_height = 800

        # è®¡ç®—yè½´èŒƒå›´ï¼ˆè€ƒè™‘å¤šæ–‡ä»¶åç§»ï¼‰
        if is_multi_file:
            num_files = len(all_bars_by_algorithm)
            max_y_offset = (num_files - 1) * 100  # æ¯ä¸ªæ–‡ä»¶åç§»100
            y_min = 0.5
            y_max = 89.5 + max_y_offset + 1  # ç•™å‡ºä¸€äº›ä½™é‡

            # ä¸ºå¤šæ–‡ä»¶åˆ›å»ºåˆé€‚çš„åˆ»åº¦
            tick_vals = []
            tick_texts = []
            for file_idx in range(num_files):
                base_offset = file_idx * 100
                for key_id in range(21, 109, 12):  # æ¯12ä¸ªé”®æ˜¾ç¤ºä¸€ä¸ªåˆ»åº¦
                    tick_vals.append(key_id + base_offset)
                    if file_idx == 0:
                        tick_texts.append(str(key_id))
                    else:
                        tick_texts.append(f"{key_id}({file_idx+1})")

            y_axis_config = dict(
                tickmode='array',
                tickvals=tick_vals,
                ticktext=tick_texts,
                range=[y_min, y_max],
                autorange=False
            )
        else:
            # å•æ–‡ä»¶æ¨¡å¼ï¼šæ ‡å‡†é’¢ç´é”®èŒƒå›´
            y_axis_config = dict(
                tickmode='array',
                tickvals=list(range(1, 89)),
                range=[0.5, 89.5],
                autorange=False
            )

        # é…ç½®å¸ƒå±€
        fig.update_layout(
            title='ç€‘å¸ƒå›¾ - é’¢ç´æŒ‰é”®äº‹ä»¶æ—¶åºå¯è§†åŒ–',
            xaxis_title='æ—¶é—´ (ms)',
            yaxis_title='æŒ‰é”®ID' + (' (å¤šæ–‡ä»¶åç§»)' if is_multi_file else ''),
            yaxis=y_axis_config,
            height=total_height,
            showlegend=True,
            legend=dict(
                orientation='h',
                yanchor='bottom',
                y=1.02,
                xanchor='left',
                x=0.0,
                bgcolor='rgba(255, 255, 255, 0.9)',
                bordercolor='gray',
                borderwidth=1
            ),
            template='plotly_white',
            hovermode='closest',
            margin=dict(l=80, r=60, t=100, b=80)
        )
