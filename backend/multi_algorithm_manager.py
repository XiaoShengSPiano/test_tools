#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¤šç®—æ³•å¯¹æ¯”ç®¡ç†å™¨

è´Ÿè´£ç®¡ç†å¤šä¸ªç®—æ³•çš„æ•°æ®é›†ï¼Œæ”¯æŒç®—æ³•å¯¹æ¯”åˆ†æã€‚
ä½¿ç”¨é¢å‘å¯¹è±¡è®¾è®¡ï¼Œæ”¯æŒå¹¶å‘å¤„ç†ã€‚
"""

from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
from enum import Enum
import asyncio
from concurrent.futures import ThreadPoolExecutor
import hashlib
import json
import time
from utils.logger import Logger
from utils.colors import ALGORITHM_COLOR_PALETTE
from spmid.spmid_analyzer import SPMIDAnalyzer
from spmid.spmid_reader import Note

logger = Logger.get_logger()


class AlgorithmStatus(Enum):
    """ç®—æ³•çŠ¶æ€æšä¸¾"""
    PENDING = "pending"  # ç­‰å¾…åŠ è½½
    LOADING = "loading"  # æ­£åœ¨åŠ è½½
    READY = "ready"  # å·²å°±ç»ª
    ERROR = "error"  # åŠ è½½å¤±è´¥


@dataclass
class AlgorithmMetadata:
    """ç®—æ³•å…ƒæ•°æ®"""
    algorithm_name: str  # ç®—æ³•åç§°ï¼ˆå†…éƒ¨å”¯ä¸€æ ‡è¯†ï¼šç®—æ³•å_æ–‡ä»¶åï¼ˆæ— æ‰©å±•åï¼‰ï¼‰
    display_name: str  # æ˜¾ç¤ºåç§°ï¼ˆç”¨æˆ·è¾“å…¥çš„åŸå§‹ç®—æ³•åç§°ï¼‰
    filename: str  # åŸå§‹æ–‡ä»¶å
    upload_time: float  # ä¸Šä¼ æ—¶é—´æˆ³
    status: AlgorithmStatus = AlgorithmStatus.PENDING
    error_message: Optional[str] = None


class AlgorithmDataset:
    """
    å•ä¸ªç®—æ³•çš„æ•°æ®é›†ç±»
    
    å°è£…å•ä¸ªç®—æ³•çš„æ‰€æœ‰æ•°æ®ã€åˆ†æç»“æœå’Œç»Ÿè®¡ä¿¡æ¯ã€‚
    æ¯ä¸ªç®—æ³•å®ä¾‹ç‹¬ç«‹ç®¡ç†è‡ªå·±çš„åˆ†æå™¨ã€‚
    """
    
    def __init__(self, algorithm_name: str, display_name: str, filename: str, color_index: int = 0):
        """
        åˆå§‹åŒ–ç®—æ³•æ•°æ®é›†
        
        Args:
            algorithm_name: ç®—æ³•åç§°ï¼ˆå†…éƒ¨å”¯ä¸€æ ‡è¯†ï¼šç®—æ³•å_æ–‡ä»¶åï¼ˆæ— æ‰©å±•åï¼‰ï¼‰
            display_name: æ˜¾ç¤ºåç§°ï¼ˆç”¨æˆ·è¾“å…¥çš„åŸå§‹ç®—æ³•åç§°ï¼‰
            filename: åŸå§‹æ–‡ä»¶å
            color_index: é¢œè‰²ç´¢å¼•ï¼ˆç”¨äºåˆ†é…å›¾è¡¨é¢œè‰²ï¼‰
        """
        self.metadata = AlgorithmMetadata(
            algorithm_name=algorithm_name,
            display_name=display_name,
            filename=filename,
            upload_time=0.0
        )
        
        # åˆ†æå™¨å®ä¾‹
        self.analyzer: Optional[SPMIDAnalyzer] = None
        
        # æ˜¾ç¤ºæ§åˆ¶
        self.color = ALGORITHM_COLOR_PALETTE[color_index % len(ALGORITHM_COLOR_PALETTE)]
        self.is_active: bool = True  # æ˜¯å¦åœ¨å¯¹æ¯”ä¸­æ˜¾ç¤º
        
        # åŸå§‹æ•°æ®ï¼ˆç”¨äºé‡æ–°åˆ†æï¼‰
        self.record_data: Optional[List[Note]] = None
        self.replay_data: Optional[List[Note]] = None
        
        logger.info(f"âœ… AlgorithmDatasetåˆå§‹åŒ–: {algorithm_name} (æ–‡ä»¶: {filename})")
    
    def load_data(self, record_data: List[Note], replay_data: List[Note], filter_collector=None) -> bool:
        """
        åŠ è½½å¹¶åˆ†ææ•°æ®
        
        Args:
            record_data: å½•åˆ¶æ•°æ®
            replay_data: æ’­æ”¾æ•°æ®
            filter_collector: å¯é€‰çš„è¿‡æ»¤ä¿¡æ¯æ”¶é›†å™¨ï¼ˆåŒ…å«åŠ è½½é˜¶æ®µçš„è¿‡æ»¤ä¿¡æ¯ï¼‰
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            perf_load_start = time.time()
            self.metadata.status = AlgorithmStatus.LOADING
            logger.info(f"                ğŸ“Š [Dataset] å¼€å§‹åŠ è½½æ•°æ®...")

            # ============ ä¿å­˜åŸå§‹æ•°æ® ============
            perf_save_start = time.time()
            self.record_data = record_data
            self.replay_data = replay_data
            perf_save_end = time.time()
            logger.info(f"                â±ï¸  [æ€§èƒ½] Dataset-ä¿å­˜æ•°æ®: {(perf_save_end - perf_save_start)*1000:.2f}ms")

            # ============ åˆ›å»ºåˆ†æå™¨å¹¶æ‰§è¡Œåˆ†æ ============
            perf_analyze_start = time.time()
            logger.info(f"                ğŸ”¬ å¼€å§‹æ‰§è¡ŒSPMIDAnalyzeråˆ†æ...")
            self.analyzer = SPMIDAnalyzer()
            self.analyzer.analyze(record_data, replay_data, filter_collector)
            perf_analyze_end = time.time()
            analyze_time_ms = (perf_analyze_end - perf_analyze_start) * 1000
            logger.info(f"                â±ï¸  [æ€§èƒ½] Dataset-SPMIDAnalyzeråˆ†æ: {analyze_time_ms:.2f}ms")

            self.metadata.status = AlgorithmStatus.READY
            
            perf_load_end = time.time()
            total_time_ms = (perf_load_end - perf_load_start) * 1000
            logger.info(f"                ğŸ [Dataset] æ•°æ®åŠ è½½å®Œæˆï¼Œæ€»è€—æ—¶: {total_time_ms:.2f}ms")
            return True
            
        except Exception as e:
            self.metadata.status = AlgorithmStatus.ERROR
            self.metadata.error_message = str(e)
            logger.error(f"                âŒ ç®—æ³• {self.metadata.algorithm_name} æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not self.analyzer:
            return {}
        
        return {
            'algorithm_name': self.metadata.algorithm_name,  # å†…éƒ¨å”¯ä¸€æ ‡è¯†
            'display_name': self.metadata.display_name,  # æ˜¾ç¤ºåç§°
            'filename': self.metadata.filename,
            'offset_statistics': self.analyzer.get_offset_statistics() if self.analyzer.note_matcher else {},
            'global_average_delay': self.analyzer.get_global_average_delay() if self.analyzer.note_matcher else 0.0,
            'mean_error': self.analyzer.get_mean_error() if self.analyzer.note_matcher else 0.0,
            'matched_pairs_count': len(self.analyzer.matched_pairs) if hasattr(self.analyzer, 'matched_pairs') else 0,
        }
    
    def get_offset_alignment_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–åç§»å¯¹é½æ•°æ®
        
        Returns:
            List[Dict[str, Any]]: åç§»å¯¹é½æ•°æ®åˆ—è¡¨
        """
        if not self.analyzer or not self.analyzer.note_matcher:
            return []
        
        return self.analyzer.note_matcher.get_offset_alignment_data()
    
    def get_key_statistics_table_data(self) -> List[Dict[str, Union[int, float, str]]]:
        """
        è·å–æŒ‰é”®ç»Ÿè®¡è¡¨æ ¼æ•°æ®
        
        Returns:
            List[Dict[str, Any]]: æŒ‰é”®ç»Ÿè®¡æ•°æ®åˆ—è¡¨ï¼Œæ¯è¡ŒåŒ…å«ä¸€ä¸ªæŒ‰é”®çš„ç»Ÿè®¡ä¿¡æ¯
        """
        if not self.analyzer or not self.analyzer.note_matcher:
            return []
        
        # è·å–åŸºç¡€ç»Ÿè®¡æ•°æ®
        data = self.analyzer.note_matcher.get_key_statistics_for_bar_chart()
        
        # ä¸ºæ¯è¡Œæ·»åŠ ç®—æ³•åç§°ï¼ˆæ ¼å¼ï¼šç®—æ³•å_æ–‡ä»¶åï¼‰
        algorithm_display = f"{self.metadata.display_name}_{self.metadata.filename}"
        for row in data:
            row['algorithm_name'] = algorithm_display
        
        return data
    
    def is_ready(self) -> bool:
        """æ£€æŸ¥ç®—æ³•æ˜¯å¦å·²å°±ç»ª"""
        return self.metadata.status == AlgorithmStatus.READY and self.analyzer is not None



class MultiAlgorithmManager:
    """
    å¤šç®—æ³•å¯¹æ¯”ç®¡ç†å™¨ç±»
    
    è´Ÿè´£ç®¡ç†å¤šä¸ªç®—æ³•æ•°æ®é›†ï¼Œæ”¯æŒï¼š
    - æ·»åŠ /åˆ é™¤ç®—æ³•
    - å¹¶å‘åŠ è½½å¤šä¸ªç®—æ³•
    - ç®—æ³•çŠ¶æ€ç®¡ç†
    - ç®—æ³•æ˜¾ç¤ºæ§åˆ¶
    """
    
    def __init__(self, max_algorithms: Optional[int] = None):
        """
        åˆå§‹åŒ–å¤šç®—æ³•ç®¡ç†å™¨
        
        Args:
            max_algorithms: æœ€å¤§ç®—æ³•æ•°é‡ï¼ˆNoneè¡¨ç¤ºæ— é™åˆ¶ï¼‰
        """
        self.algorithms: Dict[str, AlgorithmDataset] = {}  # algorithm_name -> AlgorithmDataset
        self.max_algorithms = max_algorithms
        # çº¿ç¨‹æ± ç”¨äºå¹¶å‘å¤„ç†ï¼Œå¦‚æœæ— é™åˆ¶åˆ™ä½¿ç”¨é»˜è®¤å€¼10
        executor_workers = max_algorithms if max_algorithms is not None else 10
        self.executor = ThreadPoolExecutor(max_workers=executor_workers)
        
        limit_text = "æ— é™åˆ¶" if max_algorithms is None else str(max_algorithms)
        logger.info(f"MultiAlgorithmManageråˆå§‹åŒ–å®Œæˆ (æœ€å¤§ç®—æ³•æ•°: {limit_text})")
    
    def get_algorithm_count(self) -> int:
        """è·å–å½“å‰ç®—æ³•æ•°é‡"""
        return len(self.algorithms)
    
    def can_add_algorithm(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ·»åŠ æ–°ç®—æ³•"""
        if self.max_algorithms is None:
            return True  # æ— é™åˆ¶
        return self.get_algorithm_count() < self.max_algorithms
    
    def validate_algorithm_name(self, algorithm_name: str) -> Tuple[bool, str]:
        """
        éªŒè¯ç®—æ³•åç§°æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            algorithm_name: ç®—æ³•åç§°
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        if not algorithm_name or not algorithm_name.strip():
            return False, "ç®—æ³•åç§°ä¸èƒ½ä¸ºç©º"
        
        algorithm_name = algorithm_name.strip()
        
        if algorithm_name in self.algorithms:
            return False, f"ç®—æ³•åç§° '{algorithm_name}' å·²å­˜åœ¨"
        
        return True, ""
    
    def _generate_unique_algorithm_name(self, algorithm_name: str, filename: str) -> str:
        """
        ç”Ÿæˆå”¯ä¸€çš„ç®—æ³•åç§°ï¼ˆç®—æ³•å_æ–‡ä»¶åï¼ˆæ— æ‰©å±•åï¼‰ï¼‰
        
        Args:
            algorithm_name: ç”¨æˆ·è¾“å…¥çš„ç®—æ³•åç§°
            filename: æ–‡ä»¶å
            
        Returns:
            str: å”¯ä¸€çš„ç®—æ³•åç§°
        """
        import os
        # å»æ‰è·¯å¾„å’Œæ‰©å±•åï¼Œåªä¿ç•™æ–‡ä»¶åï¼ˆæ— æ‰©å±•åï¼‰
        basename = os.path.basename(filename)
        filename_without_ext = os.path.splitext(basename)[0]
        # ç”Ÿæˆç»„åˆåç§°ï¼šç®—æ³•å_æ–‡ä»¶å
        unique_name = f"{algorithm_name}_{filename_without_ext}"
        return unique_name
    
    async def add_algorithm_async(self, algorithm_name: str, filename: str,
                                  record_data: List[Note], replay_data: List[Note],
                                  filter_collector=None) -> Tuple[bool, str]:
        """
        å¼‚æ­¥æ·»åŠ ç®—æ³•ï¼ˆæ”¯æŒå¹¶å‘å¤„ç†ï¼‰
        
        ä½¿ç”¨ ThreadPoolExecutor è¿›è¡Œå¹¶å‘å¤„ç†ï¼Œå› ä¸ºæ•°æ®åˆ†ææ˜¯ CPU å¯†é›†å‹ä»»åŠ¡ã€‚
        è‡ªåŠ¨é€šè¿‡"ç®—æ³•å_æ–‡ä»¶åï¼ˆæ— æ‰©å±•åï¼‰"ç”Ÿæˆå”¯ä¸€æ ‡è¯†ï¼ŒåŒºåˆ†åŒç§ç®—æ³•çš„ä¸åŒæ›²å­ã€‚
        
        Args:
            algorithm_name: ç®—æ³•åç§°ï¼ˆç”¨æˆ·è¾“å…¥çš„åŸå§‹åç§°ï¼‰
            filename: æ–‡ä»¶å
            record_data: å½•åˆ¶æ•°æ®
            replay_data: æ’­æ”¾æ•°æ®
            filter_collector: å¯é€‰çš„è¿‡æ»¤ä¿¡æ¯æ”¶é›†å™¨ï¼ˆåŒ…å«åŠ è½½é˜¶æ®µçš„è¿‡æ»¤ä¿¡æ¯ï¼‰
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, å”¯ä¸€ç®—æ³•åæˆ–é”™è¯¯ä¿¡æ¯)
                - æˆåŠŸæ—¶è¿”å›: (True, unique_algorithm_name)
                - å¤±è´¥æ—¶è¿”å›: (False, error_message)
        """
        perf_manager_start = time.time()
        logger.info(f"            ğŸ”§ [Manager] å¼€å§‹æ·»åŠ ç®—æ³•...")
        
        # ============ ç”Ÿæˆå”¯ä¸€ç®—æ³•å ============
        perf_name_start = time.time()
        unique_algorithm_name = self._generate_unique_algorithm_name(algorithm_name, filename)
        perf_name_end = time.time()
        logger.info(f"            â±ï¸  [æ€§èƒ½] Manager-ç”Ÿæˆå”¯ä¸€å: {(perf_name_end - perf_name_start)*1000:.2f}ms")
        
        # ============ éªŒè¯ç®—æ³•å ============
        is_valid, error_msg = self.validate_algorithm_name(unique_algorithm_name)
        if not is_valid:
            return False, error_msg
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§æ•°é‡
        if not self.can_add_algorithm():
            limit_text = str(self.max_algorithms) if self.max_algorithms is not None else "æ— é™åˆ¶"
            return False, f"å·²è¾¾åˆ°æœ€å¤§ç®—æ³•æ•°é‡é™åˆ¶ ({limit_text})"
        
        # ============ åˆ›å»ºç®—æ³•æ•°æ®é›† ============
        perf_create_start = time.time()
        color_index = len(self.algorithms)
        algorithm = AlgorithmDataset(unique_algorithm_name, algorithm_name, filename, color_index)
        perf_create_end = time.time()
        logger.info(f"            â±ï¸  [æ€§èƒ½] Manager-åˆ›å»ºæ•°æ®é›†: {(perf_create_end - perf_create_start)*1000:.2f}ms")
        
        # ============ æ‰§è¡Œæ•°æ®åˆ†æï¼ˆçº¿ç¨‹æ± ï¼‰ ============
        perf_analysis_start = time.time()
        logger.info(f"            ğŸ”„ æ‰§è¡Œæ•°æ®åˆ†æï¼ˆçº¿ç¨‹æ± ï¼‰...")
        
        loop = asyncio.get_event_loop()
        success = await loop.run_in_executor(
            self.executor,
            algorithm.load_data,
            record_data,
            replay_data,
            filter_collector
        )
        
        perf_analysis_end = time.time()
        analysis_time_ms = (perf_analysis_end - perf_analysis_start) * 1000
        logger.info(f"            â±ï¸  [æ€§èƒ½] Manager-æ•°æ®åˆ†æ: {analysis_time_ms:.2f}ms")
        
        if success:
            self.algorithms[unique_algorithm_name] = algorithm
            
            perf_manager_end = time.time()
            total_time_ms = (perf_manager_end - perf_manager_start) * 1000
            logger.info(f"            ğŸ [Manager] ç®—æ³•æ·»åŠ å®Œæˆï¼Œæ€»è€—æ—¶: {total_time_ms:.2f}ms")
            logger.info(f"            âœ… ç®—æ³• '{algorithm_name}' (æ–‡ä»¶: {filename}) æ·»åŠ æˆåŠŸï¼Œå”¯ä¸€æ ‡è¯†: {unique_algorithm_name}")
            return True, unique_algorithm_name  # è¿”å›å”¯ä¸€æ ‡è¯†ç¬¦
        else:
            error_msg = algorithm.metadata.error_message or "æœªçŸ¥é”™è¯¯"
            logger.error(f"            âŒ ç®—æ³• '{algorithm_name}' (æ–‡ä»¶: {filename}) æ·»åŠ å¤±è´¥: {error_msg}")
            return False, error_msg
    
    def remove_algorithm(self, algorithm_name: str) -> bool:
        """
        ç§»é™¤ç®—æ³•
        
        Args:
            algorithm_name: ç®—æ³•åç§°
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if algorithm_name not in self.algorithms:
            return False
        
        del self.algorithms[algorithm_name]
        logger.info(f"ç®—æ³• '{algorithm_name}' å·²ç§»é™¤")
        return True
    
    def get_algorithm(self, algorithm_name: str) -> Optional[AlgorithmDataset]:
        """è·å–æŒ‡å®šç®—æ³•"""
        return self.algorithms.get(algorithm_name)
    
    def get_all_algorithms(self) -> List[AlgorithmDataset]:
        """è·å–æ‰€æœ‰ç®—æ³•åˆ—è¡¨"""
        return list(self.algorithms.values())
    
    def get_active_algorithms(self) -> List[AlgorithmDataset]:
        """è·å–æ¿€æ´»çš„ç®—æ³•åˆ—è¡¨ï¼ˆç”¨äºå¯¹æ¯”æ˜¾ç¤ºï¼‰"""
        return [alg for alg in self.algorithms.values() if alg.is_active and alg.is_ready()]
    
    def toggle_algorithm(self, algorithm_name: str) -> bool:
        """
        åˆ‡æ¢ç®—æ³•çš„æ˜¾ç¤º/éšè—çŠ¶æ€
        
        Args:
            algorithm_name: ç®—æ³•åç§°
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        if algorithm_name not in self.algorithms:
            return False
        
        algorithm = self.algorithms[algorithm_name]
        algorithm.is_active = not algorithm.is_active
        logger.info(f"ç®—æ³• '{algorithm_name}' æ˜¾ç¤ºçŠ¶æ€: {'æ˜¾ç¤º' if algorithm.is_active else 'éšè—'}")
        return True
    
    def clear_all(self) -> None:
        """æ¸…ç©ºæ‰€æœ‰ç®—æ³•"""
        self.algorithms.clear()
        logger.info("æ‰€æœ‰ç®—æ³•å·²æ¸…ç©º")
    
    def get_comparison_statistics(self) -> Dict[str, Any]:
        """
        è·å–æ‰€æœ‰ç®—æ³•çš„å¯¹æ¯”ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: å¯¹æ¯”ç»Ÿè®¡ä¿¡æ¯
        """
        active_algorithms = self.get_active_algorithms()
        
        if not active_algorithms:
            return {}
        
        comparison_data = {}
        for algorithm in active_algorithms:
            comparison_data[algorithm.metadata.algorithm_name] = algorithm.get_statistics()
        
        return comparison_data

