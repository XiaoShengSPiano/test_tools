#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SPMIDéŸ³ç¬¦åŒ¹é…å™¨

è´Ÿè´£SPMIDæ•°æ®çš„æŒ‰é”®åŒ¹é…ï¼ŒåŒ…æ‹¬ï¼š
- éŸ³ç¬¦åŒ¹é…ç®—æ³•
- åŒ¹é…å¯¹ç”Ÿæˆ
- åŒ¹é…ç»“æœç®¡ç†

åŒ¹é…é€»è¾‘æ¶æ„ï¼š
==========================================

ã€æ ¸å¿ƒç­–ç•¥ã€‘
- è´ªå¿ƒåŒ¹é…ï¼šæ¯ä¸ªå½•åˆ¶éŸ³ç¬¦åªåŒ¹é…ä¸€ä¸ªæœ€ä½³çš„æ’­æ”¾éŸ³ç¬¦
- ä¸‰é˜¶æ®µæœç´¢ï¼šç²¾ç¡®æœç´¢(â‰¤50ms) â†’ è¾ƒå·®æœç´¢(50ms-100ms) â†’ ä¸¥é‡æœç´¢(100ms-200ms)
- å…­ç­‰çº§é˜ˆå€¼ï¼šæŒ‰è¯¯å·®èŒƒå›´ç²¾ç¡®åˆ†ç±» (20ms, 30ms, 50ms, 100ms, 200ms)

ã€åŒ¹é…æµç¨‹ã€‘
1. find_all_matched_pairs() - ä¸»å…¥å£
   â”œâ”€â”€ åˆå§‹åŒ–åŒ¹é…çŠ¶æ€
   â”œâ”€â”€ å¯¹æ¯ä¸ªå½•åˆ¶éŸ³ç¬¦è°ƒç”¨ _find_match_for_single_note()
   â””â”€â”€ ç»Ÿè®¡åŒ¹é…ç»“æœ

2. _find_match_for_single_note() - å•éŸ³ç¬¦åŒ¹é…
   â”œâ”€â”€ æå–éŸ³ç¬¦ä¿¡æ¯ (_extract_note_info)
   â”œâ”€â”€ ç”Ÿæˆå€™é€‰åˆ—è¡¨ (_generate_candidates_for_note)
   â”œâ”€â”€ é€‰æ‹©æœ€ä½³å€™é€‰ (_select_best_candidate)
   â””â”€â”€ å¤„ç†åŒ¹é…ç»“æœ (ç²¾ç¡®åŒ¹é…/è¿‘ä¼¼åŒ¹é…/å¤±è´¥)

3. _generate_candidates_for_note() - å€™é€‰ç”Ÿæˆ
   â”œâ”€â”€ ç¬¬ä¸€é˜¶æ®µï¼šé˜ˆå€¼å†…å€™é€‰ (_generate_sorted_candidates_within_threshold)
   â”œâ”€â”€ ç¬¬äºŒé˜¶æ®µï¼šå¦‚æ— å€™é€‰åˆ™æ‰©å±•åˆ°å…¨å±€ (_generate_all_candidates_sorted)
   â””â”€â”€ ç¬¬ä¸‰é˜¶æ®µï¼šåº”ç”¨æ‰©å±•é˜ˆå€¼è¿‡æ»¤ (â‰¤200ms)



"""

import pandas as pd
import numpy as np
from .spmid_reader import Note
from .delay_metrics import DelayMetrics
from typing import List, Tuple, Dict, Union, Optional, Any
from utils.logger import Logger
from enum import Enum
from collections import defaultdict
import heapq
import statistics

logger = Logger.get_logger()

from utils.constants import GRADE_THRESHOLDS, get_grade_by_delay

# åŒ¹é…é˜ˆå€¼å¸¸é‡ (0.1mså•ä½) - ç»Ÿä¸€ä» utils.constants è·å–
EXCELLENT_THRESHOLD = GRADE_THRESHOLDS['excellent'] * 10.0
GOOD_THRESHOLD = GRADE_THRESHOLDS['good'] * 10.0
FAIR_THRESHOLD = GRADE_THRESHOLDS['fair'] * 10.0
POOR_THRESHOLD = GRADE_THRESHOLDS['poor'] * 10.0
SEVERE_THRESHOLD = GRADE_THRESHOLDS['severe'] * 10.0
# å¤±è´¥åŒ¹é…ï¼š> SEVERE_THRESHOLD (200ms)

# å¤šé”¤æ£€æµ‹é˜ˆå€¼ (ms) - æ’­æ”¾æå‰å½•åˆ¶çš„é˜ˆå€¼
# å¦‚æœæ’­æ”¾keyon < å½•åˆ¶keyon - ADVANCE_THRESHOLDï¼Œè®¤ä¸ºæ˜¯å¯ç–‘çš„å¤šé”¤
ADVANCE_THRESHOLD = 200.0  # 200ms

# Lookaheadçª—å£é…ç½® - å‰ç»æ£€æŸ¥ä¼˜åŒ–
# æŸ¥çœ‹å †é¡¶å‰Nä¸ªå€™é€‰ï¼Œé€‰æ‹©ç»¼åˆå¾—åˆ†æœ€ä¼˜çš„
LOOKAHEAD_WINDOW_SIZE = 3  # çª—å£å¤§å°ï¼šæŸ¥çœ‹å‰3ä¸ªå€™é€‰
# æ’­æ”¾æå‰å½•åˆ¶æ—¶çš„æƒ©ç½šç³»æ•°
# score = error + (advance_time * BIAS_PENALTY_FACTOR)
BIAS_PENALTY_FACTOR = 2.0  # æå‰æƒ©ç½šç³»æ•°ï¼š2å€

# å…¼å®¹æ€§å¸¸é‡ (å‘åå…¼å®¹)
PRECISION_THRESHOLD = FAIR_THRESHOLD      # 50ms - ç²¾ç¡®åŒ¹é…ä¸Šé™
APPROXIMATE_THRESHOLD = POOR_THRESHOLD    # 100ms - è¾ƒå·®åŒ¹é…ä¸Šé™

# åŒ¹é…ç±»å‹æšä¸¾ - æŒ‰è¯¯å·®ç­‰çº§ç»†åˆ†
class MatchType(Enum):
    """åŒ¹é…ç»“æœç±»å‹ - æŒ‰è¯¯å·®ç­‰çº§åˆ†ç±»"""
    EXCELLENT = "excellent"      # ä¼˜ç§€åŒ¹é… (è¯¯å·® â‰¤ 20ms)
    GOOD = "good"               # è‰¯å¥½åŒ¹é… (20ms < è¯¯å·® â‰¤ 30ms)
    FAIR = "fair"               # ä¸€èˆ¬åŒ¹é… (30ms < è¯¯å·® â‰¤ 50ms)
    POOR = "poor"               # è¾ƒå·®åŒ¹é… (50ms < è¯¯å·® â‰¤ 100ms)
    SEVERE = "severe"           # ä¸¥é‡åŒ¹é… (100ms < è¯¯å·® â‰¤ 200ms)
    FAILED = "failed"           # å¤±è´¥åŒ¹é… (è¯¯å·® > 200ms æˆ–æ— å€™é€‰)

# åŒ¹é…ç»“æœç±»
class MatchResult:
    """åŒ¹é…ç»“æœå°è£…ç±»"""
    def __init__(self, match_type: MatchType, record_index: int,
                 replay_index: Optional[int] = None, error_ms: float = 0.0,
                 pair: Optional[Tuple[Note, Note]] = None, reason: str = ""):
        self.match_type = match_type
        self.record_index = record_index
        self.replay_index = replay_index
        self.error_ms = error_ms  # è¯¯å·®(æ¯«ç§’)
        self.pair = pair  # åŒ¹é…å¯¹ (record_note, replay_note)
        self.reason = reason  # å¤±è´¥åŸå› 

    @property
    def is_success(self) -> bool:
        """æ˜¯å¦åŒ¹é…æˆåŠŸ"""
        return self.match_type != MatchType.FAILED

# å€™é€‰ä¿¡æ¯ç±»
class Candidate:
    """å€™é€‰åŒ¹é…ä¿¡æ¯"""
    def __init__(self, total_error: float, note: Note):
        self.total_error = total_error
        self.note = note

    @property
    def error_ms(self) -> float:
        """è¯¯å·®è½¬æ¢ä¸ºæ¯«ç§’"""
        return self.total_error / 10.0

    def add_match_result(self, match_result: MatchResult, corrected_offset_ms: float):
        """æ·»åŠ åŒ¹é…ç»“æœ"""
        if match_result.is_success:
            self.matched_count += 1
            self.offsets_ms.append(corrected_offset_ms)

            # ç»Ÿè®¡åŒ¹é…è´¨é‡
            if match_result.match_type == MatchType.EXCELLENT:
                self.excellent_count += 1
            elif match_result.match_type == MatchType.GOOD:
                self.good_count += 1
            elif match_result.match_type == MatchType.FAIR:
                self.fair_count += 1
            elif match_result.match_type == MatchType.POOR:
                self.poor_count += 1
            elif match_result.match_type == MatchType.SEVERE:
                self.severe_count += 1
        else:
            self.failed_count += 1

    def calculate_statistics(self):
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        if self.offsets_ms:
            self.median_offset = statistics.median(self.offsets_ms)
            self.mean_offset = statistics.mean(self.offsets_ms)
            self.min_offset = min(self.offsets_ms)
            self.max_offset = max(self.offsets_ms)
            self.range_offset = self.max_offset - self.min_offset

            if len(self.offsets_ms) > 1:
                self.std_offset = statistics.stdev(self.offsets_ms)
                self.variance_offset = statistics.variance(self.offsets_ms)
            else:
                self.std_offset = 0.0
                self.variance_offset = 0.0

    def __str__(self):
        return f"æŒ‰é”®{self.key_id}: å½•åˆ¶{self.total_record_notes}, æ’­æ”¾{self.total_replay_notes}, åŒ¹é…{self.matched_count}, å¤±è´¥{self.failed_count}, å‡å€¼{self.mean_offset:.2f}ms"

# åŒ¹é…ç»Ÿè®¡ç±»
class MatchStatistics:
    """åŒ¹é…ç»Ÿè®¡ä¿¡æ¯ - å…­ç­‰çº§ç³»ç»Ÿ"""

    def __init__(self):
        # å…­ç­‰çº§åŒ¹é…ç»Ÿè®¡ (ä½¿ç”¨ç»Ÿä¸€ key)
        self.excellent_matches = 0    # ä¼˜ç§€åŒ¹é… (â‰¤20ms)
        self.good_matches = 0         # è‰¯å¥½åŒ¹é… (20-30ms)
        self.fair_matches = 0         # ä¸€èˆ¬åŒ¹é… (30-50ms)
        self.poor_matches = 0         # è¾ƒå·®åŒ¹é… (50-100ms)
        self.severe_matches = 0       # ä¸¥é‡è¯¯å·® (100-200ms)
        self.failed_matches = 0       # å¤±è´¥åŒ¹é… (>200msæˆ–æ— å€™é€‰)

    def __str__(self):
        return f"ä¼˜ç§€:{self.excellent_matches}, è‰¯å¥½:{self.good_matches}, ä¸€èˆ¬:{self.fair_matches}, è¾ƒå·®:{self.poor_matches}, ä¸¥é‡:{self.severe_matches}, å¤±è´¥:{self.failed_matches}"

class NoteMatcher:
    """SPMIDéŸ³ç¬¦åŒ¹é…å™¨ç±»"""
    
    def __init__(self):
        """
        åˆå§‹åŒ–éŸ³ç¬¦åŒ¹é…å™¨
        """
        # åŒ¹é…ç»“æœåˆ†ç±»å­˜å‚¨
        # ç²¾ç¡®åŒ¹é…å¯¹ï¼š(record_note, replay_note, match_type, keyon_error_ms)
        self.matched_pairs: List[Tuple[Note, Note, MatchType, float]] = []
        self.drop_hammers: List[Note] = []                   # ä¸¢é”¤éŸ³ç¬¦
        self.multi_hammers: List[Note] = []                  # å¤šé”¤éŸ³ç¬¦
        self.abnormal_matches: List[Tuple[Note, Note]] = []  # å¼‚å¸¸åŒ¹é…å¯¹ (record_note, replay_note)
        self.duration_diff_pairs: List[Tuple[Note, Note, float]] = []  # æŒç»­æ—¶é—´å·®å¼‚å¯¹ (rec_note, rep_note, ratio)

        # åŒ¹é…ç»Ÿè®¡
        self.match_statistics = MatchStatistics()

        # å»¶æ—¶æŒ‡æ ‡è®¡ç®—å™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self._delay_metrics: Optional[DelayMetrics] = None
    
    
    def find_all_matched_pairs(self, record_data: List[Note], replay_data: List[Note]) -> List[Tuple[Note, Note]]:
        """
        æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…å¯¹ï¼šåŸºäºæœ€å°å †çš„keyonä¼˜å…ˆåŒ¹é…ï¼ˆæ”¯æŒåŒå‘æ‹†åˆ†ï¼‰
        
        æ ¸å¿ƒç‰¹æ€§ï¼š
        1. æŒ‰keyonæ—¶é—´é¡ºåºå¤„ç†ï¼ˆæœ€å°å †ï¼‰
        2. è´ªå¿ƒç­–ç•¥ï¼škeyonæœ€å°ï¼ˆåœ¨é˜ˆå€¼å†…ï¼‰
        3. æ”¯æŒåŒå‘æ‹†åˆ†ï¼ˆå½•åˆ¶/æ’­æ”¾éƒ½å¯æ‹†åˆ†ï¼‰
        4. ä¿ç•™6ç­‰çº§è´¨é‡è¯„åˆ¤
        5. åŠ¨æ€é‡æ–°åŒ¹é…
        
        åŒ¹é…æµç¨‹ï¼š
        1. æŒ‰key_idåˆ†ç»„
        2. å¯¹æ¯ä¸ªæŒ‰é”®æ„å»ºæœ€å°å †ï¼ˆæŒ‰keyonæ’åºï¼‰
        3. æŒ‰keyoné¡ºåºåŒ¹é…ï¼Œæ£€æµ‹æŒç»­æ—¶é—´å·®å¼‚å¹¶æ‹†åˆ†
        4. æ‹†åˆ†åçš„æ•°æ®é‡æ–°åŠ å…¥å †
        
        
        Args:
            record_data: å½•åˆ¶æ•°æ®
            replay_data: æ’­æ”¾æ•°æ®

        Returns:
            List[Tuple[Note, Note]]: ç²¾ç¡®åŒ¹é…å¯¹åˆ—è¡¨ (record_note, replay_note)
        """
        # æŒ‰key_idåˆ†ç»„
        record_by_key = self._group_notes_by_key(record_data)
        replay_by_key = self._group_notes_by_key(replay_data)

        # å¯¹æ¯ä¸ªæŒ‰é”®è¿›è¡ŒåŒ¹é…
        all_matched_pairs = []
        for key_id in sorted(record_by_key.keys()):
            key_record_notes = record_by_key[key_id]
            key_replay_notes = replay_by_key.get(key_id, [])

            key_matched_pairs = self._match_single_key_with_heap(
                key_id, key_record_notes, key_replay_notes
            )
            all_matched_pairs.extend(key_matched_pairs)

        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        logger.info(f"ğŸ“Š åŒ¹é…å®Œæˆç»Ÿè®¡:")
        logger.info(f"   âœ… æ­£å¸¸åŒ¹é…å¯¹ (matched_pairs): {len(self.matched_pairs)}")
        logger.debug(f"   [DEBUG] all_matched_pairsé•¿åº¦: {len(all_matched_pairs)}")
        logger.info(f"   âš ï¸ å¼‚å¸¸åŒ¹é…å¯¹ (abnormal_matches): {len(self.abnormal_matches)}")
        logger.info(f"   âš ï¸ ä¸¢é”¤ (drop_hammers): {len(self.drop_hammers)}")
        logger.info(f"   âš ï¸ å¤šé”¤ (multi_hammers): {len(self.multi_hammers)}")
        logger.info(f"   è¯„çº§ç»Ÿè®¡:")
        logger.info(f"      - excellent (â‰¤20ms): {self.match_statistics.excellent_matches}")
        logger.info(f"      - good (20-30ms): {self.match_statistics.good_matches}")
        logger.info(f"      - fair (30-50ms): {self.match_statistics.fair_matches}")
        logger.info(f"      - poor (50-100ms): {self.match_statistics.poor_matches}")
        logger.info(f"      - severe (100-200ms): {self.match_statistics.severe_matches}")
        
        return all_matched_pairs
    
    def _match_single_key_with_heap(self, key_id: int,
                                     record_notes: List[Note],
                                     replay_notes: List[Note]) -> List[Tuple[Note, Note]]:
        """
        ä½¿ç”¨æœ€å°å †å¯¹å•ä¸ªæŒ‰é”®è¿›è¡ŒåŒ¹é…ï¼ˆæ”¯æŒæ‹†åˆ†ï¼‰

        Args:
            key_id: æŒ‰é”®ID
            record_notes: è¯¥æŒ‰é”®çš„å½•åˆ¶éŸ³ç¬¦åˆ—è¡¨
            replay_notes: è¯¥æŒ‰é”®çš„æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨

        Returns:
            List[Tuple[Note, Note]]: è¯¥æŒ‰é”®çš„åŒ¹é…å¯¹åˆ—è¡¨ (record_note, replay_note)
        """
        
        # æ„å»ºæœ€å°å †
        record_heap, replay_heap = self._build_matching_heaps(key_id, record_notes, replay_notes)
        
        # åˆå§‹åŒ–çŠ¶æ€
        matched_pairs = []
        used_replay_uuids = set()  # å·²ä½¿ç”¨çš„æ’­æ”¾éŸ³ç¬¦UUID
        skipped_replay_uuids = set()  # è·³è¿‡çš„æ’­æ”¾éŸ³ç¬¦UUIDï¼ˆå¯ç–‘çš„å¤šé”¤ï¼‰
        
        
        # ä¸»å¾ªç¯ï¼šå¤„ç†æ‰€æœ‰å½•åˆ¶æ•°æ®
        match_count, failed_count = self._process_record_notes(
            key_id, record_heap, replay_heap, used_replay_uuids,
            skipped_replay_uuids, matched_pairs
        )
        
        logger.debug(f"æŒ‰é”®{key_id}åŒ¹é…å®Œæˆ: æˆåŠŸ{match_count}ä¸ª, å¤±è´¥{failed_count}ä¸ª")
        
        return matched_pairs
    
    def _build_matching_heaps(self, key_id: int,
                               record_notes: List[Note],
                               replay_notes: List[Note]) -> Tuple[List, List]:
        """
        æ„å»ºå½•åˆ¶å’Œæ’­æ”¾çš„æœ€å°å †
        
        Args:
            key_id: æŒ‰é”®ID
            record_notes: å½•åˆ¶éŸ³ç¬¦åˆ—è¡¨
            replay_notes: æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨
            
        Returns:
            Tuple[List, List]: (record_heap, replay_heap)
        """
        # å †å…ƒç´ æ ¼å¼: (key_on_ms, uuid, note_object, split_seq)
        # key_on_ms: ç”¨äºå †æ’åº
        # uuid: å”¯ä¸€è¯†åˆ«å·ï¼Œé˜²æ­¢åŒæ—¶é—´ç‚¹æ—¶æ¯”è¾ƒNoteå¯¹è±¡ï¼ˆä¼šå¯¼è‡´Pandas Seriesæ¯”è¾ƒé”™è¯¯ï¼‰
        # split_seq: None=åŸå§‹æ•°æ®, 0/1/2...=æ‹†åˆ†åºå·

        # å½•åˆ¶å †
        record_heap = []
        for note in record_notes:
            heapq.heappush(record_heap, (note.key_on_ms, note.uuid, note, None))

        # æ’­æ”¾å †
        replay_heap = []
        for note in replay_notes:
            heapq.heappush(replay_heap, (note.key_on_ms, note.uuid, note, None))

        
        return record_heap, replay_heap
    
    def _process_record_notes(self, key_id: int, record_heap: List, replay_heap: List,
                                used_replay_uuids: set, skipped_replay_uuids: set,
                                matched_pairs: List) -> Tuple[int, int]:
        """
        å¤„ç†æ‰€æœ‰å½•åˆ¶æ•°æ®çš„ä¸»å¾ªç¯

        Args:
            key_id: æŒ‰é”®ID
            record_heap: å½•åˆ¶å †
            replay_heap: æ’­æ”¾å †
            used_replay_uuids: å·²ä½¿ç”¨çš„æ’­æ”¾éŸ³ç¬¦UUIDé›†åˆ
            skipped_replay_uuids: è·³è¿‡çš„æ’­æ”¾éŸ³ç¬¦UUIDé›†åˆï¼ˆå¯ç–‘çš„å¤šé”¤ï¼‰
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨ï¼ˆè¾“å‡ºï¼‰

        Returns:
            Tuple[int, int]: (æˆåŠŸåŒ¹é…æ•°, å¤±è´¥åŒ¹é…æ•°)
        """
        match_count = 0
        failed_count = 0
        
        while record_heap:
            # å–å‡ºå½•åˆ¶æ•°æ®
            rec_keyon, rec_uuid, rec_note, rec_split_seq = heapq.heappop(record_heap)
            
            logger.debug(f"    å¤„ç†å½•åˆ¶Note: UUID={rec_note.uuid[:8]}..., key_on={rec_note.key_on_ms:.2f}ms, split_seq={rec_split_seq}")
            
            # æ¸…ç†å·²ä½¿ç”¨çš„æ’­æ”¾æ•°æ®
            self._clean_used_replay_notes(replay_heap, used_replay_uuids)
            
            # æŸ¥æ‰¾æ’­æ”¾å€™é€‰ï¼ˆæ”¯æŒè·³è¿‡å¯ç–‘çš„å¤šé”¤ï¼‰
            replay_candidate = self._find_replay_candidate(
                replay_heap, rec_note, skipped_replay_uuids
            )
            
            if replay_candidate is None:
                # æ— å¯ç”¨å€™é€‰ â†’ å¤±è´¥
                failed_count += 1
                continue
            
            rep_note, keyon_error_ms = replay_candidate
            
            # æ£€æŸ¥è¯¯å·®é˜ˆå€¼
            if not self._check_error_threshold(keyon_error_ms):
                # è¶…å‡ºé˜ˆå€¼ â†’ å¤±è´¥
                failed_count += 1
                continue
            
            # åˆ›å»ºæˆåŠŸåŒ¹é…ï¼ˆæ”¯æŒæ‹†åˆ†ï¼Œåœ¨popæ’­æ”¾æ•°æ®ä¹‹å‰æ£€æŸ¥æ˜¯å¦éœ€è¦æ‹†åˆ†ï¼‰
            success, split_type = self._create_successful_match(
                rec_note, rep_note,
                keyon_error_ms, matched_pairs, used_replay_uuids,
                record_heap, replay_heap
            )
            
            if success:
                # åŒ¹é…æˆåŠŸï¼šæ¶ˆè´¹æ’­æ”¾æ•°æ®
                heapq.heappop(replay_heap)
                match_count += 1
                logger.debug(f"    âœ“ åŒ¹é…æˆåŠŸ (match_count={match_count})")
            else:
                logger.debug(f"    âœ— åŒ¹é…å¤±è´¥")
        
        return match_count, failed_count
    
    def _clean_used_replay_notes(self, replay_heap: List, used_replay_uuids: set):
        """æ¸…ç†æ’­æ”¾å †é¡¶çš„å·²ä½¿ç”¨æ•°æ®ï¼ˆæƒ°æ€§åˆ é™¤ï¼‰"""
        while replay_heap:
            _, _, rep_note, _ = replay_heap[0]  # å †å…ƒç´ : (key_on_ms, uuid, note, split_seq)

            if rep_note.uuid in used_replay_uuids:
                heapq.heappop(replay_heap)
                continue
            else:
                break
    
    def _find_replay_candidate(self, replay_heap: List, rec_note: Note,
                                skipped_replay_uuids: set) -> Optional[Tuple[Note, float]]:
        """
        ä½¿ç”¨Lookaheadçª—å£æŸ¥æ‰¾æœ€ä½³æ’­æ”¾å€™é€‰
        
        ç­–ç•¥ï¼š
        1. å…ˆè·³è¿‡æå‰è¶…è¿‡200msçš„å€™é€‰ï¼ˆADVANCE_THRESHOLDæ£€æµ‹ï¼‰
        2. Peekå‰Nä¸ªå€™é€‰è¿›è¡Œç»¼åˆè¯„åˆ†
        3. é€‰æ‹©å¾—åˆ†æœ€ä½çš„å€™é€‰
        4. è·³è¿‡å‰é¢çš„æ¬¡ä¼˜å€™é€‰
        
        Args:
            replay_heap: æ’­æ”¾å † (key_on_ms, note, split_seq)
            rec_note: å½•åˆ¶Noteå¯¹è±¡
            skipped_replay_uuids: è·³è¿‡çš„æ’­æ”¾éŸ³ç¬¦UUIDé›†åˆï¼ˆè¾“å‡ºï¼‰
            
        Returns:
            Optional[Tuple[Note, float]]: (rep_note, error_ms) æˆ– None
        """
        if not replay_heap:
            logger.debug(f"      âœ— æ— å¯ç”¨æ’­æ”¾æ•°æ® â†’ å¤±è´¥")
            return None
        
        rec_keyon = rec_note.key_on_ms
        
        # ã€ç¬¬ä¸€é“é˜²çº¿ã€‘å¾ªç¯è·³è¿‡"æå‰è¿‡å¤š"çš„æ’­æ”¾æ•°æ®ï¼ˆ>200msï¼Œæç«¯æƒ…å†µï¼‰+ é”¤é€Ÿå¼‚å¸¸æ£€æµ‹
        while replay_heap:
            _, _, rep_note, _ = replay_heap[0]
            rep_keyon = rep_note.key_on_ms
            
            # æ£€æŸ¥æ¡ä»¶1ï¼šæ’­æ”¾æ˜¯å¦"æå‰"è¿‡å¤šï¼Ÿ
            if rep_keyon < rec_keyon - ADVANCE_THRESHOLD:
                # æ’­æ”¾æ˜æ˜¾æå‰å½•åˆ¶ï¼Œå¯èƒ½æ˜¯å¤šé”¤
                heapq.heappop(replay_heap)
                skipped_replay_uuids.add(rep_note.uuid)
                continue

            # æ£€æŸ¥æ¡ä»¶2ï¼šé”¤é€Ÿå¼‚å¸¸æ£€æµ‹ï¼ˆå½•åˆ¶æ— é”¤é€Ÿä½†æ’­æ”¾æœ‰é”¤é€Ÿ = å¤šé”¤ï¼‰
            if self._is_multi_hammer_by_velocity(rec_note, rep_note):
                # å½•åˆ¶æ•°æ®æ— é”¤é€Ÿï¼Œæ’­æ”¾æ•°æ®æœ‰é”¤é€Ÿï¼Œåˆ¤å®šä¸ºå¤šé”¤
                heapq.heappop(replay_heap)
                skipped_replay_uuids.add(rep_note.uuid)
                continue
            
            # ä¸¤ä¸ªæ¡ä»¶éƒ½ä¸æ»¡è¶³ï¼Œè·³å‡ºå¾ªç¯
            break
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¯ç”¨å€™é€‰
        if not replay_heap:
            logger.debug(f"      âœ— è·³è¿‡å¤šé”¤åæ— å¯ç”¨æ’­æ”¾æ•°æ® â†’ å¤±è´¥")
            return None
        
        # ã€ç¬¬äºŒé“é˜²çº¿ã€‘Lookaheadçª—å£è¯„åˆ†ï¼Œé€‰æ‹©æœ€ä½³å€™é€‰
        best_candidate = self._select_best_candidate_with_lookahead(
            replay_heap, rec_keyon, skipped_replay_uuids
        )
        
        if best_candidate is None:
            logger.debug(f"      âœ— Lookaheadè¯„åˆ†åæ— å¯æ¥å—å€™é€‰ â†’ å¤±è´¥")
            return None
        
        return best_candidate
    
    def _select_best_candidate_with_lookahead(self, replay_heap: List, rec_keyon: float,
                                               skipped_replay_uuids: set) -> Optional[Tuple[Note, float]]:
        """
        ä½¿ç”¨Lookaheadçª—å£è¯„åˆ†å¹¶é€‰æ‹©æœ€ä½³å€™é€‰
        
        Args:
            replay_heap: æ’­æ”¾å † (key_on_ms, note, split_seq)
            rec_keyon: å½•åˆ¶keyonæ—¶é—´ï¼ˆmsï¼‰
            skipped_replay_uuids: è·³è¿‡çš„æ’­æ”¾éŸ³ç¬¦UUIDé›†åˆï¼ˆè¾“å‡ºï¼‰
            
        Returns:
            Optional[Tuple[Note, float]]: (rep_note, error_ms) æˆ– None
        """
        # 1. Peekå‰Nä¸ªå€™é€‰
        window_size = min(LOOKAHEAD_WINDOW_SIZE, len(replay_heap))
        candidates = []
        
        for i in range(window_size):
            rep_keyon, rep_uuid, rep_note, rep_split_seq = replay_heap[i]
            candidates.append({
                'heap_index': i,
                'keyon': rep_keyon,
                'note': rep_note
            })
        
        # 2. å¯¹å€™é€‰è¿›è¡Œè¯„åˆ†
        scored_candidates = []
        for candidate in candidates:
            score_result = self._calculate_candidate_score(candidate, rec_keyon)
            scored_candidates.append(score_result)
        
        # 3. é€‰æ‹©å¾—åˆ†æœ€ä½çš„
        scored_candidates.sort(key=lambda x: x['score'])
        best = scored_candidates[0]
        best_index = best['candidate']['heap_index']
        
        # 4. è·³è¿‡å‰é¢çš„æ¬¡ä¼˜å€™é€‰
        if best_index > 0:
            for i in range(best_index):
                _, _, rep_note, _ = heapq.heappop(replay_heap)
                skipped_replay_uuids.add(rep_note.uuid)

        # 5. è¿”å›æœ€ä½³å€™é€‰ï¼ˆç°åœ¨åœ¨å †é¡¶ï¼‰
        _, _, rep_note, _ = replay_heap[0]
        keyon_error_ms = best['error']

        return (rep_note, keyon_error_ms)
    
    def _is_multi_hammer_by_velocity(self, rec_note: Note, rep_note: Note) -> bool:
        """
        é€šè¿‡é”¤é€Ÿæ£€æµ‹æ˜¯å¦ä¸ºå¤šé”¤
        
        åˆ¤å®šæ¡ä»¶ï¼šå½•åˆ¶æ— é”¤é€Ÿæˆ–é”¤é€Ÿ=0ï¼Œä½†æ’­æ”¾æœ‰é”¤é€Ÿ>0
        """
        rec_hammer = rec_note.get_first_hammer_velocity()
        rep_hammer = rep_note.get_first_hammer_velocity()
        
        rec_no_hammer = (rec_hammer is None or rec_hammer == 0)
        rep_has_hammer = (rep_hammer is not None and rep_hammer > 0)
        
        return rec_no_hammer and rep_has_hammer

    def _calculate_candidate_score(self, candidate: dict, rec_keyon: float) -> dict:
        """
        è®¡ç®—å€™é€‰çš„ç»¼åˆå¾—åˆ†
        
        è¯„åˆ†å…¬å¼ï¼šscore = error + bias_penalty
        - error: ç»å¯¹è¯¯å·®
        - bias_penalty: åå‘æƒ©ç½šï¼ˆæå‰æ—¶åŠ å€æƒ©ç½šï¼‰
        
        Args:
            candidate: å€™é€‰ä¿¡æ¯å­—å…¸
            rec_keyon: å½•åˆ¶keyonæ—¶é—´ï¼ˆmsï¼‰
            
        Returns:
            dict: è¯„åˆ†ç»“æœ
        """
        replay_keyon = candidate['keyon']
        
        # 1. åŸºç¡€è¯¯å·®
        error = abs(replay_keyon - rec_keyon)
        
        # 2. è®¡ç®—åå‘ï¼ˆæ­£æ•°=æ»åï¼Œè´Ÿæ•°=æå‰ï¼‰
        bias = replay_keyon - rec_keyon
        
        # 3. è®¡ç®—åå‘æƒ©ç½š
        if bias >= 0:  # æ»åï¼ˆæ­£å¸¸ç°è±¡ï¼‰
            penalty = 0  # ä¸æƒ©ç½š
        else:  # æå‰ï¼ˆå¯ç–‘ï¼‰
            advance = abs(bias)
            penalty = advance * BIAS_PENALTY_FACTOR  # æå‰æƒ©ç½š
        
        # 4. ç»¼åˆå¾—åˆ†
        total_score = error + penalty
        
        return {
            'candidate': candidate,
            'keyon': replay_keyon,
            'score': total_score,
            'error': error,
            'bias': bias,
            'penalty': penalty
        }

    
    def _check_error_threshold(self, keyon_error_ms: float) -> bool:
        """
        æ£€æŸ¥è¯¯å·®æ˜¯å¦åœ¨é˜ˆå€¼å†…ï¼ˆâ‰¤200msï¼‰
        
        Args:
            keyon_error_ms: keyonè¯¯å·®ï¼ˆæ¯«ç§’ï¼‰
        
        Returns:
            bool: True=åœ¨é˜ˆå€¼å†…, False=è¶…å‡ºé˜ˆå€¼
        """
        keyon_error_units = keyon_error_ms * 10.0
        
        if keyon_error_units > SEVERE_THRESHOLD:
            return False
        
        return True
    

    
    def _create_successful_match(self, rec_note: Note, rep_note: Note,
                                  keyon_error_ms: float, matched_pairs: List,
                                  used_replay_uuids: set, record_heap: List, replay_heap: List) -> Tuple[bool, str]:
        """
        åˆ›å»ºæˆåŠŸåŒ¹é…ï¼ˆæ”¯æŒæ‹†åˆ†ï¼‰
        
        Args:
            rec_note: å½•åˆ¶Noteå¯¹è±¡ï¼ˆåŒ…å«split_seqå±æ€§ï¼‰
            rep_note: æ’­æ”¾Noteå¯¹è±¡ï¼ˆåŒ…å«split_seqå±æ€§ï¼‰
            keyon_error_ms: keyonè¯¯å·®ï¼ˆæ¯«ç§’ï¼‰
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨
            used_replay_uuids: å·²ä½¿ç”¨çš„æ’­æ”¾UUIDé›†åˆ
            record_heap: å½•åˆ¶å †
            replay_heap: æ’­æ”¾å †
        
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, æ‹†åˆ†ç±»å‹: 'none'/'record'/'replay')
        """
        # æ­¥éª¤1: å…ˆæ£€æŸ¥æŒç»­æ—¶é—´å·®å¼‚å¹¶å°è¯•æ‹†åˆ†
        rec_duration = rec_note.duration_ms 
        rep_duration = rep_note.duration_ms
        
        if rec_duration > 0 and rep_duration > 0:
            duration_ratio = max(rec_duration, rep_duration) / min(rec_duration, rep_duration)
            
            should_split = False
            force_record = False
            
            # ä¸»è¦æ¡ä»¶ï¼šæŒç»­æ—¶é—´å·®å¼‚æ˜¾è‘—ï¼ˆ>= 2.0å€ï¼‰
            if duration_ratio >= 2.0:
                should_split = True

            # æ¬¡è¦æ¡ä»¶ï¼šæŒç»­æ—¶é—´ç›¸å·®ä¸å¤§ï¼Œä½†çŸ­æ•°æ®keyoffä¹‹åè¿˜æœ‰hammerå’Œafter_touch
            elif rec_duration != rep_duration:  # ç¡®ä¿æœ‰é•¿çŸ­ä¹‹åˆ†
                long_note = rec_note if rec_duration > rep_duration else rep_note
                short_note = rep_note if rec_duration > rep_duration else rec_note
                
                if self._check_hammer_after_shorter_keyoff(long_note, short_note):
                    should_split = True
                    force_record = True  # æ¬¡è¦æ¡ä»¶è§¦å‘æ—¶éœ€è¦å¼ºåˆ¶è®°å½•

            # å¦‚æœæ»¡è¶³ä»»ä¸€æ¡ä»¶ï¼Œè¿›è¡Œæ‹†åˆ†
            if should_split:
                # é‡è¦ï¼šåœ¨æ‹†åˆ†ä¹‹å‰å…ˆè®°å½•åŸå§‹æ•°æ®åˆ°æŒç»­æ—¶é—´å·®å¼‚åˆ—è¡¨
                # è¿™æ ·å¯ä»¥åœ¨UIä¸­çœ‹åˆ°æ‹†åˆ†å‰çš„åŸå§‹æ›²çº¿
                self._check_duration_difference(rec_note, rep_note, force_record=force_record)

                # å°è¯•æ‹†åˆ†å¹¶ç«‹å³åŒ¹é…ç¬¬ä¸€éƒ¨åˆ†
                split_result = self._try_split_and_match_first(
                    rec_note,
                    rep_note,
                    record_heap, replay_heap, used_replay_uuids,
                    rec_duration, rep_duration
                )
                
                if split_result is not None:
                    # æ‹†åˆ†æˆåŠŸï¼Œæ›´æ–°ä¸ºæ‹†åˆ†åçš„Noteå¯¹è±¡ï¼ˆç¬¬ä¸€éƒ¨åˆ†ï¼‰
                    split_type, match_rec_note, match_rep_note = split_result
                    rec_note = match_rec_note
                    rep_note = match_rep_note
                else:
                    logger.warning(f"      âš ï¸ æ‹†åˆ†å¤±è´¥ï¼ŒæŒ‰åŸåŒ¹é…å¤„ç†")
        
        # æ­¥éª¤2: ç”¨æœ€ç»ˆçš„Noteå¯¹è±¡ï¼ˆæ‹†åˆ†åçš„æˆ–åŸå§‹çš„ï¼‰è®¡ç®—è¯¯å·®å’Œè¯„çº§
        final_keyon_error_ms = abs(rep_note.key_on_ms - rec_note.key_on_ms)
        match_type = self._evaluate_match_quality(final_keyon_error_ms)
        
        # æ­¥éª¤3: æ ¹æ®hammeræ•°æ®åˆ†ç±»åŒ¹é…å¯¹
        rec_hammer = rec_note.get_first_hammer_velocity() or 0
        rep_hammer = rep_note.get_first_hammer_velocity() or 0

        # åˆ†ç±»é€»è¾‘ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
        if rec_hammer <= 0 and rep_hammer <= 0:
            # æƒ…å†µ1ï¼šåŒæ–¹éƒ½æ— hammer â†’ å¼‚å¸¸åŒ¹é…å¯¹
            self.abnormal_matches.append((rec_note, rep_note))
        elif rec_hammer > 0 and rep_hammer <= 0:
            # æƒ…å†µ2ï¼šå½•åˆ¶æœ‰hammerï¼Œæ’­æ”¾æ— hammer â†’ ä¸¢é”¤
            self.drop_hammers.append(rec_note)
        elif rep_hammer > 0 and rec_hammer <= 0:
            # æƒ…å†µ3ï¼šæ’­æ”¾æœ‰hammerï¼Œå½•åˆ¶æ— hammer â†’ å¤šé”¤
            self.multi_hammers.append(rep_note)
        else:
            # æƒ…å†µ4ï¼šåŒæ–¹éƒ½æœ‰hammer â†’ ç²¾ç¡®åŒ¹é…å¯¹
            # ä¿å­˜åŒ¹é…å¯¹ï¼ŒåŒ…å«è¯„çº§ä¿¡æ¯å’Œè¯¯å·®
            self.matched_pairs.append((rec_note, rep_note, match_type, final_keyon_error_ms))

            # æ ¹æ®è¯¯å·®ç­‰çº§ç»Ÿè®¡
            if match_type == MatchType.EXCELLENT:
                self.match_statistics.excellent_matches += 1
            elif match_type == MatchType.GOOD:
                self.match_statistics.good_matches += 1
            elif match_type == MatchType.FAIR:
                self.match_statistics.fair_matches += 1
            elif match_type == MatchType.POOR:
                self.match_statistics.poor_matches += 1
            elif match_type == MatchType.SEVERE:
                self.match_statistics.severe_matches += 1
        
        # æ ‡è®°ä¸ºå·²ä½¿ç”¨
        used_replay_uuids.add(rep_note.uuid)
        
        return (True, 'none')  # æˆåŠŸåˆ›å»ºï¼Œæ— æ‹†åˆ†
    
    def _try_split_and_match_first(self, rec_note: Note,
                                     rep_note: Note,
                                     record_heap: List, replay_heap: List, used_replay_uuids: set,
                                     rec_duration: float, rep_duration: float) -> Optional[Tuple[str, Note, Note]]:
        """
        å°è¯•æ‹†åˆ†å¹¶è¿”å›ç¬¬ä¸€éƒ¨åˆ†ç”¨äºç«‹å³åŒ¹é…
        
        Args:
            rec_note: å½•åˆ¶éŸ³ç¬¦
            rep_note: æ’­æ”¾éŸ³ç¬¦
            record_heap: å½•åˆ¶å †
            replay_heap: æ’­æ”¾å †
            used_replay_uuids: å·²ä½¿ç”¨çš„æ’­æ”¾éŸ³ç¬¦é›†åˆ
            rec_duration: å½•åˆ¶æŒç»­æ—¶é—´
            rep_duration: æ’­æ”¾æŒç»­æ—¶é—´
        
        Returns:
            Optional[Tuple[str, Note, Note]]: (æ‹†åˆ†ç±»å‹, åŒ¹é…ç”¨çš„rec_note, åŒ¹é…ç”¨çš„rep_note) æˆ– None
        """
        from backend.key_splitter_simplified import KeySplitter
        
        # åˆ¤æ–­æ‹†åˆ†æ–¹å‘
        if rec_duration > rep_duration:
            # å½•åˆ¶æ•°æ®æ›´é•¿ â†’ æ‹†åˆ†å½•åˆ¶æ•°æ®
            logger.debug(f"        æ‹†åˆ†å½•åˆ¶æ•°æ®ï¼ˆå½•åˆ¶{rec_duration:.1f}ms > æ’­æ”¾{rep_duration:.1f}msï¼‰")
            result = self._split_record_note_and_return_first(
                rec_note, rep_note, record_heap,
                rec_duration, rep_duration
            )
            if result:
                rec_note_a, rec_note_b = result
                # rec_note_aç”¨äºåŒ¹é…ï¼Œrec_note_bå·²åŠ å…¥å †
                return ('record', rec_note_a, rep_note)
            return None
        else:
            # æ’­æ”¾æ•°æ®æ›´é•¿ â†’ æ‹†åˆ†æ’­æ”¾æ•°æ®
            result = self._split_replay_note_and_return_first(
                rep_note, rec_note, replay_heap, used_replay_uuids,
                rec_duration, rep_duration
            )
            if result:
                rep_note_a, rep_note_b = result
                # rep_note_aç”¨äºåŒ¹é…ï¼Œrep_note_bå·²åŠ å…¥å †
                return ('replay', rec_note, rep_note_a)
            return None
    
    def _split_note_and_return_first(self, long_note: Note, short_note: Note,
                                     target_heap: List,
                                     rec_duration: float, rep_duration: float,
                                     data_type: str) -> Optional[Tuple[Note, Note]]:
        """
        æ‹†åˆ†Noteå¹¶è¿”å›ä¸¤ä¸ªNoteå¯¹è±¡ï¼ˆé€šç”¨æ–¹æ³•ï¼‰
        
        Args:
            long_note: é•¿æ•°æ®ï¼ˆè¦æ‹†åˆ†çš„ï¼‰
            short_note: çŸ­æ•°æ®
            target_heap: ç›®æ ‡å †ï¼ˆå°†note_båŠ å…¥ï¼‰
            rec_duration: å½•åˆ¶æ•°æ®æŒç»­æ—¶é—´
            rep_duration: æ’­æ”¾æ•°æ®æŒç»­æ—¶é—´
            data_type: æ•°æ®ç±»å‹æ ‡è¯†ï¼ˆ"å½•åˆ¶"æˆ–"æ’­æ”¾"ï¼‰ï¼Œç”¨äºæ—¥å¿—
        
        Returns:
            Optional[Tuple[Note, Note]]: (note_aç”¨äºåŒ¹é…, note_bå·²åŠ å…¥å †) æˆ– None
        """
        # æå–hammersï¼ˆåªè€ƒè™‘velocity > 0çš„ï¼‰
        hammer_times_ms = []
        for i in range(len(long_note.hammers)):
            if long_note.hammers.values[i] > 0:
                time_ms = long_note.hammers.values[i]
                hammer_times_ms.append(time_ms)
        
        hammer_times_ms.sort()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„hammerï¼ˆè‡³å°‘2ä¸ªï¼‰
        if len(hammer_times_ms) < 2:
            logger.debug(f"        âœ— {data_type}æ•°æ®hammerä¸è¶³2ä¸ªï¼Œæ— æ³•æ‹†åˆ†")
            return None
        
        # ä½¿ç”¨ç²¾ç»†çš„æ‹†åˆ†ç‚¹æŸ¥æ‰¾ç®—æ³•
        split_time_ms = self._find_best_split_point(
            long_note=long_note,
            short_note=short_note,
            rec_duration=rec_duration,
            rep_duration=rep_duration
        )
        
        if split_time_ms is None:
            logger.debug(f"        âœ— æœªæ‰¾åˆ°åˆé€‚çš„æ‹†åˆ†ç‚¹")
            return None
        
        # æ‰§è¡Œæ‹†åˆ†
        note_a, note_b = self._split_note_at_time(
            long_note, split_time_ms,
            split_seq_a=0,  # ç¬¬ä¸€éƒ¨åˆ†
            split_seq_b=1   # ç¬¬äºŒéƒ¨åˆ†
        )
        
        # å°†note_båŠ å…¥å †ï¼ˆnote_aç”¨äºç«‹å³åŒ¹é…ï¼‰
        heapq.heappush(target_heap, (note_b.key_on_ms, note_b.uuid, note_b, note_b.split_seq if note_b.split_seq is not None else 0))
        
        # âš ï¸ é‡è¦ï¼šä¸è¦å°† note_b æ ‡è®°ä¸º used_uuidsï¼
        # note_b æ˜¯æ‹†åˆ†åçš„ç¬¬äºŒéƒ¨åˆ†ï¼Œéœ€è¦åœ¨åç»­å¾ªç¯ä¸­é‡æ–°åŒ¹é…
        # å¦‚æœæ ‡è®°ä¸º usedï¼Œå®ƒä¼šåœ¨ _clean_used_replay_notes ä¸­è¢«åˆ é™¤
        
        logger.debug(f"[DEBUG]        âœ“ æ‹†åˆ†æˆåŠŸï¼Œnote_b (UUID={note_b.uuid[:8]}...) å·²åŠ å…¥å †ï¼Œç­‰å¾…é‡æ–°åŒ¹é…")
        
        return (note_a, note_b)
    
    def _split_replay_note_and_return_first(self, rep_note: Note, rec_note: Note,
                                              replay_heap: List, used_replay_uuids: set,
                                              rec_duration: float, rep_duration: float) -> Optional[Tuple[Note, Note]]:
        """æ‹†åˆ†æ’­æ”¾æ•°æ®ï¼ˆç®€åŒ–wrapperï¼‰
        
        æ³¨æ„ï¼šused_replay_uuids å‚æ•°ä¿ç•™æ˜¯ä¸ºäº†å…¼å®¹è°ƒç”¨æ¥å£ï¼Œä½†ä¸ä¼šåœ¨æ‹†åˆ†æ—¶ä½¿ç”¨ã€‚
        æ‹†åˆ†åçš„ note_b ä¼šè¢«åŠ å…¥å †ï¼Œåœ¨åç»­å¾ªç¯ä¸­é‡æ–°åŒ¹é…æ—¶æ‰ä¼šè¢«æ ‡è®°ä¸º usedã€‚
        """
        return self._split_note_and_return_first(
            long_note=rep_note, short_note=rec_note,
            target_heap=replay_heap,
            rec_duration=rec_duration, rep_duration=rep_duration,
            data_type="æ’­æ”¾"
        )
    
    def _split_record_note_and_return_first(self, rec_note: Note, rep_note: Note,
                                              record_heap: List,
                                              rec_duration: float, rep_duration: float) -> Optional[Tuple[Note, Note]]:
        """æ‹†åˆ†å½•åˆ¶æ•°æ®ï¼ˆç®€åŒ–wrapperï¼‰
        
        æ‹†åˆ†åçš„ note_b ä¼šè¢«åŠ å…¥å½•åˆ¶å †ï¼Œåœ¨åç»­å¾ªç¯ä¸­é‡æ–°åŒ¹é…ã€‚
        """
        return self._split_note_and_return_first(
            long_note=rec_note, short_note=rep_note,
            target_heap=record_heap,
            rec_duration=rec_duration, rep_duration=rep_duration,
            data_type="å½•åˆ¶"
        )
    
    def _find_best_split_point(self, long_note: Note, short_note: Note, 
                              rec_duration: float, rep_duration: float) -> Optional[float]:
        """
        æŸ¥æ‰¾æœ€ä½³æ‹†åˆ†ç‚¹
        
        Args:
            long_note: è¾ƒé•¿çš„Noteå¯¹è±¡ï¼ˆè¦æ‹†åˆ†çš„åˆå¹¶æ•°æ®ï¼‰
            short_note: è¾ƒçŸ­çš„Noteå¯¹è±¡ï¼ˆæä¾›keyoffä½œä¸ºæœç´¢èµ·ç‚¹ï¼‰
            rec_duration: å½•åˆ¶æ•°æ®æŒç»­æ—¶é—´
            rep_duration: æ’­æ”¾æ•°æ®æŒç»­æ—¶é—´
        
        Returns:
            Optional[float]: æœ€ä½³æ‹†åˆ†ç‚¹çš„ç»å¯¹æ—¶é—´ï¼ˆmsï¼‰ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
            
        Note:
            KeySplitterä½¿ç”¨é€šç”¨çš„å‚æ•°å‘½åï¼š
            - short_note: çŸ­æ•°æ® (å‚è€ƒæ•°æ®)
            - long_note: é•¿æ•°æ® (è¦æ‹†åˆ†çš„åˆå¹¶æ•°æ®)
            è¿™é€‚ç”¨äºå½•åˆ¶å’Œæ’­æ”¾æ•°æ®çš„ä»»æ„ç»„åˆ
        """
        try:
            from backend.key_splitter_simplified import KeySplitter
            
            # åˆ›å»ºKeySplitterå®ä¾‹
            splitter = KeySplitter()
            
            # è°ƒè¯•ä¿¡æ¯ï¼šè¾“å‡ºè¦æ‹†åˆ†çš„æ•°æ®
            logger.debug(f"        ğŸ” æ‹†åˆ†ç‚¹æŸ¥æ‰¾å‚æ•°:")
            logger.debug(f"          çŸ­æ•°æ®: keyon={short_note.key_on_ms:.1f}ms, keyoff={short_note.key_off_ms:.1f}ms")
            logger.debug(f"          é•¿æ•°æ®: keyon={long_note.key_on_ms:.1f}ms, keyoff={long_note.key_off_ms:.1f}ms")
            
            # æå–é•¿æ•°æ®çš„hammersï¼ˆæ£€æŸ¥æ˜¯å¦è¶³å¤Ÿï¼‰
            long_hammers = []
            for i in range(len(long_note.hammers)):
                if long_note.hammers.values[i] > 0:
                    time_ms = long_note.hammers.values[i]
                    long_hammers.append(time_ms)
            long_hammers.sort()
            logger.debug(f"          é•¿æ•°æ®hammers(>0): {[f'{h:.1f}ms' for h in long_hammers]}")
            
            # è°ƒç”¨KeySplitterï¼ˆä½¿ç”¨é€šç”¨æ¥å£ï¼‰
            result = splitter.analyze_split_possibility(
                short_note=short_note,        # çŸ­æ•°æ®ï¼ˆå‚è€ƒæ•°æ®ï¼‰
                long_note=long_note,          # é•¿æ•°æ®ï¼ˆè¦æ‹†åˆ†çš„ï¼‰
                short_duration=min(rec_duration, rep_duration),
                long_duration=max(rec_duration, rep_duration)
            )
            
            # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°æœ€ä½³åˆ†å‰²ç‚¹
            if result and result.get('best_candidate'):
                best = result['best_candidate']
                split_time_ms = best['time']  # æ³¨æ„ï¼šé”®åæ˜¯'time'ä¸æ˜¯'time_ms'
                
                # æ—¥å¿—è¾“å‡º
                if best.get('is_turning', False):  # æ³¨æ„ï¼šé”®åæ˜¯'is_turning'ä¸æ˜¯'is_turning_point'
                    logger.debug(f"        âœ“ æ‰¾åˆ°æœ€ä½³æ‹†åˆ†ç‚¹ï¼ˆæ‹ç‚¹ï¼‰: {split_time_ms:.1f}ms, "
                               f"è§¦åå€¼={best.get('value', 0):.1f}")
                else:
                    logger.debug(f"        âš ï¸ ä½¿ç”¨åå¤‡ç­–ç•¥ï¼ˆè§¦åå€¼æœ€å°ç‚¹ï¼‰: {split_time_ms:.1f}ms, "
                               f"è§¦åå€¼={best.get('value', 0):.1f}")
                
                return split_time_ms
            else:
                if result:
                    logger.debug(f"        âš ï¸ KeySplitterè¿”å›ç»“æœä½†æ— best_candidate: {list(result.keys())}")
                else:
                    logger.debug(f"        âš ï¸ KeySplitterè¿”å›Noneï¼ˆå¯èƒ½åŸå› ï¼šhammerä¸è¶³2ä¸ªæˆ–èŒƒå›´æ— æ•ˆï¼‰")
                return None
                
        except Exception as e:
            logger.error(f"        âœ— æ‹†åˆ†ç‚¹æŸ¥æ‰¾å¤±è´¥: {e}")
            return None
    
    def _split_note_at_time(self, note: Note, split_time_ms: float, 
                           split_seq_a: int, split_seq_b: int) -> Tuple[Note, Note]:
        """
        åœ¨æŒ‡å®šæ—¶é—´ç‚¹æ‹†åˆ†Note
        
        Args:
            note: è¦æ‹†åˆ†çš„Noteå¯¹è±¡
            split_time_ms: æ‹†åˆ†ç‚¹çš„ç»å¯¹æ—¶é—´ï¼ˆmsï¼‰
            split_seq_a: å‰åŠæ®µçš„æ‹†åˆ†åºå·
            split_seq_b: ååŠæ®µçš„æ‹†åˆ†åºå·
        
        Returns:
            Tuple[Note, Note]: (å‰åŠæ®µ, ååŠæ®µ)
        """

        # å°†split_time_msï¼ˆç»å¯¹æ—¶é—´ï¼‰è½¬æ¢ä¸ºç›¸å¯¹äºoffsetçš„ç´¢å¼•ï¼ˆ0.1mså•ä½ï¼‰
        # split_time_msæ˜¯ç»å¯¹æ—¶é—´ï¼Œafter_touch.indexæ˜¯ç›¸å¯¹äºoffsetçš„ç´¢å¼•
        # æ‰€ä»¥ï¼šrelative_index = absolute_time * 10 - offset
        split_time_units = split_time_ms * 10 - note.offset
        
        # logger.debug(f"        æ‹†åˆ†å‚æ•°: split_time={split_time_ms:.1f}ms (ç»å¯¹æ—¶é—´), "
        #             f"offset={note.offset}, split_units={split_time_units} (ç›¸å¯¹ç´¢å¼•)")
        
        # æ‹†åˆ†aftertouchï¼šæ‹†åˆ†ç‚¹åŒæ—¶å‡ºç°åœ¨note_açš„æœ«å°¾å’Œnote_bçš„å¼€å¤´
        # note_a: <= split_timeï¼ˆåŒ…å«æ‹†åˆ†ç‚¹ä½œä¸ºç»“æŸç‚¹ï¼‰
        # note_b: >= split_timeï¼ˆåŒ…å«æ‹†åˆ†ç‚¹ä½œä¸ºèµ·å§‹ç‚¹ï¼‰
        mask1 = note.after_touch.index <= split_time_units
        mask2 = note.after_touch.index >= split_time_units
        
        after_touch_a = note.after_touch[mask1].copy()
        after_touch_b = note.after_touch[mask2].copy()
        
        # å¦‚æœæ‹†åˆ†ç‚¹ä¸åœ¨åŸå§‹after_touchä¸­ï¼Œéœ€è¦æ’å…¥
        if split_time_units not in note.after_touch.index:
            # æ’å€¼è®¡ç®—æ‹†åˆ†ç‚¹çš„è§¦åå€¼
            if not after_touch_a.empty and not after_touch_b.empty:
                # ä½¿ç”¨çº¿æ€§æ’å€¼
                prev_idx = after_touch_a.index[-1]
                next_idx = after_touch_b.index[0]
                prev_val = after_touch_a.iloc[-1]
                next_val = after_touch_b.iloc[0]
                
                if next_idx > prev_idx:
                    ratio = (split_time_units - prev_idx) / (next_idx - prev_idx)
                    split_val = prev_val + ratio * (next_val - prev_val)
                else:
                    split_val = prev_val
                
                # æ’å…¥æ‹†åˆ†ç‚¹åˆ°after_touch_aå’Œafter_touch_b
                after_touch_a = pd.concat([after_touch_a, pd.Series([split_val], index=[split_time_units])]).sort_index()
                after_touch_b = pd.concat([pd.Series([split_val], index=[split_time_units]), after_touch_b]).sort_index()
                logger.debug(f"        â„¹ï¸ åœ¨æ‹†åˆ†ç‚¹{split_time_units}æ’å€¼after_touch={split_val:.1f}")
        
        # æ‹†åˆ†hammersï¼šç¬¬ä¸€ä¸ªæŒ‰é”®åªåŒ…å«ç¬¬ä¸€ä¸ªhammerï¼Œç¬¬äºŒä¸ªæŒ‰é”®åŒ…å«åç»­hammers
        # note_a: < split_timeï¼ˆä¸åŒ…å«æ‹†åˆ†ç‚¹çš„hammerï¼‰
        # note_b: >= split_timeï¼ˆåŒ…å«æ‹†åˆ†ç‚¹åŠä¹‹åçš„hammersï¼‰
        hammers_a = note.hammers[note.hammers.index < split_time_units].copy()
        hammers_b = note.hammers[note.hammers.index >= split_time_units].copy()
        
        # ç¡®ä¿note_bçš„key_onå°±æ˜¯æ‹†åˆ†ç‚¹ï¼š
        # å¦‚æœhammers_bä¸ºç©ºæˆ–ç¬¬ä¸€ä¸ªhammerä¸åœ¨æ‹†åˆ†ç‚¹ï¼Œåœ¨æ‹†åˆ†ç‚¹æ’å…¥hammer
        if hammers_b.empty or hammers_b.index[0] != split_time_units:
            if not after_touch_b.empty:
                # åœ¨æ‹†åˆ†ç‚¹åˆ›å»ºhammerï¼ˆvelocity=0è¡¨ç¤ºè™šæ‹Ÿhammerï¼‰
                split_hammer = pd.Series([0], index=[split_time_units])
                if hammers_b.empty:
                    hammers_b = split_hammer
                    logger.debug(f"        â„¹ï¸ note_bæ— hammerï¼Œåœ¨æ‹†åˆ†ç‚¹{split_time_units}åˆ›å»ºè™šæ‹Ÿhammer")
                else:
                    # åˆå¹¶æ‹†åˆ†ç‚¹hammerå’Œåç»­hammers
                    hammers_b = pd.concat([split_hammer, hammers_b])
                    logger.debug(f"        â„¹ï¸ åœ¨æ‹†åˆ†ç‚¹{split_time_units}æ’å…¥hammerï¼Œç¡®ä¿key_on=æ‹†åˆ†ç‚¹")
        
        # åˆ›å»ºæ–°çš„Noteå¯¹è±¡ï¼ˆè®¾ç½®splitå…ƒæ•°æ®ï¼‰
        # note_aï¼ˆç¬¬ä¸€ä¸ªnoteï¼‰ä¿æŒåŸæœ‰UUIDï¼Œnote_bï¼ˆç¬¬äºŒä¸ªnoteï¼‰åˆ†é…æ–°UUID
        # 
        # UUIDåˆ†é…ç­–ç•¥ï¼š
        # - note_a: ä¿æŒåŸUUIDï¼ˆå¦‚æœåŸnoteå·²ç»æ˜¯æ‹†åˆ†çš„ï¼Œä¿æŒå…¶åŸUUIDï¼‰
        # - note_b: åŸºäºåŸUUID + æ‹†åˆ†åºå·ç”Ÿæˆæ–°UUID
        #   å¦‚æœåŸnoteçš„UUIDå·²ç»åŒ…å«"_split_"ï¼Œéœ€è¦è¿½åŠ æ–°çš„åºå·
        
        # ç”Ÿæˆnote_bçš„UUID
        if "_split_" in note.uuid:
            # å·²ç»æ˜¯æ‹†åˆ†åçš„Noteï¼Œè¿½åŠ æ–°çš„æ‹†åˆ†åºå·
            note_b_uuid = f"{note.uuid}_{split_seq_b}"
        else:
            # ç¬¬ä¸€æ¬¡æ‹†åˆ†ï¼Œä½¿ç”¨æ ‡å‡†æ ¼å¼
            note_b_uuid = f"{note.uuid}_split_{split_seq_b}"
        
        note_a = Note(
            offset=note.offset,
            id=note.id,
            finger=note.finger,
            hammers=hammers_a,
            uuid=note.uuid,  # ç¬¬ä¸€ä¸ªnoteä¿æŒåŸæœ‰UUID
            velocity=note.velocity,
            after_touch=after_touch_a,
            split_parent_idx=None,  # ä¸å†éœ€è¦ç´¢å¼•
            split_seq=split_seq_a,
            is_split=True
        )

        note_b = Note(
            offset=note.offset,  # offsetä¿æŒä¸å˜
            id=note.id,
            finger=note.finger,
            hammers=hammers_b,
            uuid=note_b_uuid,  # ä½¿ç”¨ç”Ÿæˆçš„UUIDï¼Œé¿å…å†²çª
            velocity=note.velocity,
            after_touch=after_touch_b,
            split_parent_idx=None,  # ä¸å†éœ€è¦ç´¢å¼•
            split_seq=split_seq_b,
            is_split=True
        )
        
        logger.debug(f"        âœ“ note_a: key_on={note_a.key_on_ms:.1f}ms, key_off={note_a.key_off_ms:.1f}ms, "
                    f"duration={note_a.duration_ms:.1f}ms")
        logger.debug(f"        âœ“ note_b: key_on={note_b.key_on_ms:.1f}ms, key_off={note_b.key_off_ms:.1f}ms, "
                    f"duration={note_b.duration_ms:.1f}ms")
        
        return note_a, note_b
    
    def _check_hammer_after_shorter_keyoff(self, long_note: Note, short_note: Note) -> bool:
        """
        æ£€æŸ¥åœ¨è¾ƒçŸ­æ•°æ®çš„keyoffä¹‹åï¼Œè¾ƒé•¿æ•°æ®æ˜¯å¦è¿˜æœ‰æœ‰æ•ˆçš„é”¤å‡»å’Œaftertouch
        
        Args:
            long_note: è¾ƒé•¿çš„Noteå¯¹è±¡
            short_note: è¾ƒçŸ­çš„Noteå¯¹è±¡
        
        Returns:
            bool: å¦‚æœåœ¨çŸ­æ•°æ®keyoffä¹‹åè¿˜æœ‰hammerï¼ˆvelocity>0ï¼‰ä¸”after_touchä¸ä¸ºç©ºï¼Œè¿”å›True
        """

        short_keyoff_ms = short_note.key_off_ms
        if short_keyoff_ms is None:
            return False
        
        short_keyoff_units = short_keyoff_ms * 10
        
        # æ£€æŸ¥é•¿æ•°æ®åœ¨æ­¤æ—¶é—´ä¹‹åæ˜¯å¦è¿˜æœ‰hammerï¼ˆvelocity > 0ï¼‰
        has_hammer_after = False
        for i in range(len(long_note.hammers)):
            hammer_time_units = long_note.hammers.index[i] + long_note.offset
            hammer_velocity = long_note.hammers.values[i]
            
            if hammer_time_units > short_keyoff_units and hammer_velocity > 0:
                has_hammer_after = True
                logger.debug(f"        ğŸ”¨ æ£€æµ‹åˆ°çŸ­æ•°æ®keyoff({short_keyoff_ms:.1f}ms)ä¹‹åçš„é”¤å‡»: "
                           f"{hammer_time_units/10:.1f}ms, velocity={hammer_velocity}")
                break
        
        if not has_hammer_after:
            return False
        
        # æ£€æŸ¥é•¿æ•°æ®åœ¨æ­¤æ—¶é—´ä¹‹åæ˜¯å¦è¿˜æœ‰after_touchæ•°æ®
        has_aftertouch_after = False
        for at_time_units in long_note.after_touch.index:
            absolute_time_units = at_time_units + long_note.offset
            if absolute_time_units > short_keyoff_units:
                has_aftertouch_after = True
                logger.debug(f"        ğŸ“Š æ£€æµ‹åˆ°çŸ­æ•°æ®keyoffä¹‹åçš„after_touchæ•°æ®")
                break
        
        return has_hammer_after and has_aftertouch_after
    
    def _check_duration_difference(self, record_note: Note, replay_note: Note, force_record: bool = False):
        """
        æ£€æŸ¥åŒ¹é…å¯¹çš„æŒç»­æ—¶é—´å·®å¼‚ï¼Œå¦‚æœå·®å¼‚æ˜¾è‘—åˆ™è®°å½•

        Args:
            record_note: å½•åˆ¶éŸ³ç¬¦
            replay_note: æ’­æ”¾éŸ³ç¬¦
            force_record: æ˜¯å¦å¼ºåˆ¶è®°å½•ï¼ˆå³ä½¿ä¸æ»¡è¶³ä¸»è¦æ¡ä»¶ï¼‰
        """
        # è·å–æŒç»­æ—¶é—´
        record_duration = record_note.duration_ms
        replay_duration = replay_note.duration_ms

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æŒç»­æ—¶é—´æ•°æ®
        if record_duration is None or replay_duration is None or record_duration <= 0 or replay_duration <= 0:
            return

        # è®¡ç®—æŒç»­æ—¶é—´æ¯”ä¾‹
        duration_ratio = max(record_duration, replay_duration) / min(record_duration, replay_duration)

        # å¦‚æœæŒç»­æ—¶é—´å·®å¼‚æ˜¾è‘—ï¼ˆå¤§çº¦2å€ä»¥ä¸Šï¼‰æˆ–å¼ºåˆ¶è®°å½•ï¼Œè®°å½•ä¸‹æ¥
        if duration_ratio >= 2.0 or force_record:
            # è®°å½•å·®å¼‚åŒ¹é…å¯¹ï¼ˆåŒ…å«keyonå’Œkeyoffï¼‰
            self.duration_diff_pairs.append((
                record_note,
                replay_note,
                duration_ratio,
            ))

            # è¾“å‡ºæ—¥å¿—
            logger.debug(f"ğŸ” å‘ç°æŒç»­æ—¶é—´å·®å¼‚æ˜¾è‘—çš„åŒ¹é…å¯¹: æŒ‰é”®{record_note.uuid} "
                       f"å½•åˆ¶[{record_note.key_on_ms:.2f}-{record_note.key_off_ms:.2f}ms, {record_note.duration_ms:.2f}ms], "
                       f"æ’­æ”¾[{replay_note.key_on_ms:.2f}-{replay_note.key_off_ms:.2f}ms, {replay_note.duration_ms:.2f}ms], "
                        f"æ¯”ä¾‹={duration_ratio:.2f}")


    def _group_notes_by_key(self, notes: List[Note]) -> Dict[int, List[Note]]:
        """
        æŒ‰æŒ‰é”®IDåˆ†ç»„éŸ³ç¬¦æ•°æ®

        Args:
            notes: éŸ³ç¬¦åˆ—è¡¨

        Returns:
            Dict[int, List[Note]]: key=æŒ‰é”®ID, value=éŸ³ç¬¦å¯¹è±¡åˆ—è¡¨
        """
        grouped = defaultdict(list)
        for note in notes:
            grouped[note.id].append(note)
        return dict(grouped)

    def get_key_statistics_for_bar_chart(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯ç”¨äºæ¡å½¢ç»Ÿè®¡å›¾

        ç›´æ¥ä½¿ç”¨é¢„è®¡ç®—çš„æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯ï¼Œé¿å…é‡å¤è®¡ç®—

        Returns:
            List[Dict[str, Union[int, float]]]: æŒ‰é”®ç»Ÿè®¡æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
            - key_id: æŒ‰é”®ID
            - median: ä¸­ä½æ•°åç§» (ms)
            - mean: å‡å€¼åç§» (ms)
            - std: æ ‡å‡†å·® (ms)
            - variance: æ–¹å·® (msÂ²)
            - count: è¯¥æŒ‰é”®æˆåŠŸåŒ¹é…å¯¹æ•°é‡
        """
        result = []

        for key_id, key_stats in self.key_statistics.items():
            # åªåŒ…å«æœ‰åŒ¹é…æ•°æ®çš„æŒ‰é”®
            if key_stats.matched_count > 0 and key_stats.offsets_ms:
                result.append({
                    'key_id': key_id,
                    'count': key_stats.matched_count,
                    'median': round(key_stats.median_offset, 3),
                    'mean': round(key_stats.mean_offset, 3),
                    'std': round(key_stats.std_offset, 3),
                    'variance': round(key_stats.variance_offset, 3),
                    'min': round(key_stats.min_offset, 3),
                    'max': round(key_stats.max_offset, 3),
                    'range': round(key_stats.range_offset, 3),
                    'status': 'matched'
                })

        # æŒ‰æŒ‰é”®IDæ’åº
        result.sort(key=lambda x: x['key_id'])

        logger.debug(f"ğŸ“Š æ¡å½¢ç»Ÿè®¡å›¾æ•°æ®: {len(result)}ä¸ªæŒ‰é”®æœ‰ç»Ÿè®¡ä¿¡æ¯")
        return result


    def _evaluate_match_quality(self, error_ms: float) -> MatchType:
        """
        æ ¹æ®è¯¯å·®è¯„ä¼°åŒ¹é…è´¨é‡ - ç»Ÿä¸€å…­ç­‰çº§æ ‡å‡†
        """
        grade_key = get_grade_by_delay(error_ms)
        # å°† constants ä¸­çš„ key æ˜ å°„åˆ° MatchType æšä¸¾å€¼
        try:
            return MatchType(grade_key)
        except ValueError:
            return MatchType.FAILED

    def _create_match_result(self, match_type: MatchType, record_index: int,
                           replay_index: Optional[int] = None, candidate: Optional[Candidate] = None,
                           record_note: Optional[Note] = None, replay_note: Optional[Note] = None,
                           reason: str = "") -> MatchResult:
        """
        åˆ›å»ºåŒ¹é…ç»“æœå¯¹è±¡

        Args:
            match_type: åŒ¹é…ç±»å‹
            record_index: å½•åˆ¶éŸ³ç¬¦ç´¢å¼•
            replay_index: æ’­æ”¾éŸ³ç¬¦ç´¢å¼•
            candidate: å€™é€‰å¯¹è±¡
            record_note: å½•åˆ¶éŸ³ç¬¦
            replay_note: æ’­æ”¾éŸ³ç¬¦
            reason: å¤±è´¥åŸå› 

        Returns:
            MatchResult: åŒ¹é…ç»“æœå¯¹è±¡
        """
        error_ms = candidate.error_ms if candidate else 0.0
        pair = (record_note, replay_note) if record_note and replay_note else None

        return MatchResult(
            match_type=match_type,
            record_index=record_index,
            replay_index=replay_index,
            error_ms=error_ms,
            pair=pair,
            reason=reason
        )

    
    def get_matched_pairs(self) -> List[Tuple[Note, Note]]:
        """
        è·å–ç²¾ç¡®åŒ¹é…å¯¹åˆ—è¡¨ï¼ˆåŒæ–¹éƒ½æœ‰hammerï¼‰- ä»…è¿”å›Noteå¯¹

        Returns:
            List[Tuple[Note, Note]]: ç²¾ç¡®åŒ¹é…å¯¹åˆ—è¡¨
        """
        return [(rec_note, rep_note) for rec_note, rep_note, _, _ in self.matched_pairs]
    
    def get_matched_pairs_with_grade(self) -> List[Tuple[Note, Note, MatchType, float]]:
        """
        è·å–ç²¾ç¡®åŒ¹é…å¯¹åˆ—è¡¨ï¼ˆåŒ…å«è¯„çº§ä¿¡æ¯ï¼‰

        Returns:
            List[Tuple[Note, Note, MatchType, float]]:
                (record_note, replay_note, match_type, keyon_error_ms)
        """
        return self.matched_pairs.copy()

    def find_matched_pair_by_uuid(self, record_uuid: str, replay_uuid: str) -> Tuple[Note, Note, MatchType, float]:
        """
        é€šè¿‡UUIDæŸ¥æ‰¾åŒ¹é…å¯¹

        Args:
            record_uuid: å½•åˆ¶éŸ³ç¬¦çš„UUID
            replay_uuid: æ’­æ”¾éŸ³ç¬¦çš„UUID

        Returns:
            Tuple[Note, Note, MatchType, float]: åŒ¹é…å¯¹ä¿¡æ¯ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›None
        """
        for rec_note, rep_note, match_type, error_ms in self.matched_pairs:
            if str(rec_note.uuid) == str(record_uuid) and str(rep_note.uuid) == str(replay_uuid):
                return (rec_note, rep_note, match_type, error_ms)
        return None

    def get_failed_matches_count(self) -> int:
        """è·å–å¤±è´¥åŒ¹é…æ•°é‡"""
        return self.match_statistics.failed_matches

    def get_match_quality_counts(self) -> Dict[str, int]:
        """è·å–å„ç­‰çº§åŒ¹é…è´¨é‡ç»Ÿè®¡"""
        return {
            'excellent': self.match_statistics.excellent_matches,
            'good': self.match_statistics.good_matches,
            'fair': self.match_statistics.fair_matches,
            'poor': self.match_statistics.poor_matches,
            'severe': self.match_statistics.severe_matches,
            'failed': self.match_statistics.failed_matches
        }

    def get_error_counts(self) -> Dict[str, int]:
        """è·å–å„ç§é”™è¯¯ç±»å‹çš„ç»Ÿè®¡"""
        return {
            'drop_hammers': len(self.drop_hammers),
            'multi_hammers': len(self.multi_hammers),
            'abnormal_matches': len(self.abnormal_matches)
        }
    
    # ==================== é”™è¯¯è®°å½•æ–¹æ³•ï¼ˆåŸErrorDetectorèŒè´£ï¼‰ ====================
    
    def _analyze_unmatched_notes(self, record_data: List[Note], replay_data: List[Note]) -> None:
        """
        åˆ†ææœªåŒ¹é…çš„éŸ³ç¬¦ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºä¸¢é”¤/å¤šé”¤
        
        ä½¿ç”¨UUIDæ ‡è¯†å·²åŒ¹é…çš„éŸ³ç¬¦ï¼Œåªæœ‰æœªåŒ¹é…ä¸”æœ‰hammerï¼ˆ>0ï¼‰çš„éŸ³ç¬¦æ‰åˆ¤å®šä¸ºä¸¢é”¤/å¤šé”¤
        
        Args:
            record_data: å½•åˆ¶æ•°æ®
            replay_data: æ’­æ”¾æ•°æ®
        """
        # 1. è·å–å·²åŒ¹é…çš„UUIDé›†åˆï¼ˆåŒ…æ‹¬ï¼šç²¾ç¡®åŒ¹é…ã€å¼‚å¸¸åŒ¹é…ã€å·²åˆ¤å®šä¸ºä¸¢é”¤/å¤šé”¤çš„éŸ³ç¬¦ï¼‰
        matched_record_uuids = set()
        matched_replay_uuids = set()
        
        # ä»ç²¾ç¡®åŒ¹é…å¯¹ä¸­è·å–UUID
        for rec_note, rep_note, _, _ in self.matched_pairs:
            matched_record_uuids.add(rec_note.uuid)
            matched_replay_uuids.add(rep_note.uuid)
        
        # ä»å·²è®°å½•çš„å¼‚å¸¸åŒ¹é…å¯¹ã€ä¸¢é”¤ã€å¤šé”¤ä¸­è·å–UUID
        for rec_note, rep_note in self.abnormal_matches:
            matched_record_uuids.add(rec_note.uuid)
            matched_replay_uuids.add(rep_note.uuid)

        for note in self.drop_hammers:
            matched_record_uuids.add(note.uuid)

        for note in self.multi_hammers:
            matched_replay_uuids.add(note.uuid)
        
        # 2. åˆ†ææœªåŒ¹é…çš„å½•åˆ¶éŸ³ç¬¦ï¼ˆä¸¢é”¤ï¼‰
        for record_note in record_data:
            if record_note.uuid not in matched_record_uuids:
                hammer_velocity = record_note.get_first_hammer_velocity()
                if hammer_velocity and hammer_velocity > 0:
                    self.drop_hammers.append(record_note)

        # 3. åˆ†ææœªåŒ¹é…çš„æ’­æ”¾éŸ³ç¬¦ï¼ˆå¤šé”¤ï¼‰
        for replay_note in replay_data:
            if replay_note.uuid not in matched_replay_uuids:
                hammer_velocity = replay_note.get_first_hammer_velocity()
                if hammer_velocity and hammer_velocity > 0:
                    self.multi_hammers.append(replay_note)
                    
    def get_offset_alignment_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–æ‰€æœ‰åŒ¹é…å¯¹çš„åç§»å¯¹é½æ•°æ® - åŒ…å«æ‰€æœ‰æˆåŠŸåŒ¹é…
        
        Returns:
            List[Dict[str, Union[int, float]]]: åç§»å¯¹é½æ•°æ®åˆ—è¡¨
        """
        offset_data = []
        for rec_note, rep_note, match_type, keyon_error_ms in self.matched_pairs:
            record_note = rec_note
            replay_note = rep_note
            
            # è®¡ç®—å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦çš„æ—¶é—´
            record_keyon, record_keyoff = self._calculate_note_times(record_note)
            replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

            # è·å–é”¤é€Ÿä¿¡æ¯
            record_velocity = self._get_velocity_from_note(record_note)
            replay_velocity = self._get_velocity_from_note(replay_note)

            # è®¡ç®—åŸå§‹åç§»é‡
            keyon_offset = replay_keyon - record_keyon
            
            record_duration = record_keyoff - record_keyon
            replay_duration = replay_keyoff - replay_keyon
            duration_diff = replay_duration - record_duration
            
            # è®¡ç®—ç›¸å¯¹å»¶æ—¶ (éœ€è¦åœ¨å¤–éƒ¨è®¡ç®—ï¼Œè¿™é‡Œå…ˆç»™åŸå§‹å€¼)
            # åœ¨DelayAnalysisä¸­ä¼šé‡æ–°è®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼Œè¿™é‡Œåªéœ€æä¾›åŸå§‹æ•°æ®
            # ä¸ºä¿æŒæ ¼å¼ä¸€è‡´ï¼Œå…ˆç»™ä¸€ä¸ªå ä½å€¼
            relative_delay = keyon_offset / 10.0
            
            # è®¡ç®—æŒç»­æ—¶é—´åç§»
            duration_offset = replay_duration - record_duration

            offset_data.append({
                'record_index': record_note.offset,  # è¿™é‡Œçš„indexå…¶å®æ˜¯offset
                'replay_index': replay_note.offset,
                'record_uuid': record_note.uuid,      # å¢åŠ UUIDä»¥ä¾›ç²¾ç¡®æŸ¥æ‰¾
                'replay_uuid': replay_note.uuid,
                'record_id': record_note.id,
                'replay_id': replay_note.id,
                'record_keyon': record_keyon,
                'replay_keyon': replay_keyon,
                'record_velocity': record_velocity,
                'replay_velocity': replay_velocity,
                'velocity_diff': (replay_velocity - record_velocity) if record_velocity is not None and replay_velocity is not None else None,
                'keyon_offset': keyon_offset,
                'corrected_offset': keyon_offset,
                'relative_delay': relative_delay,
                'record_keyoff': record_keyoff,
                'replay_keyoff': replay_keyoff,
                'duration_offset': duration_offset,
                'average_offset': abs(keyon_offset),
                'record_duration': record_duration,
                'replay_duration': replay_duration,
                'duration_diff': duration_diff
            })

        return offset_data


    def get_precision_offset_alignment_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–ç²¾ç¡®åŒ¹é…å¯¹çš„åç§»å¯¹é½æ•°æ® - åŒ…å«ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬åŒ¹é…ï¼ˆè¯¯å·® â‰¤ 50msï¼‰

        ç²¾ç¡®åŒ¹é…ï¼šEXCELLENT (â‰¤20ms) + GOOD (20-30ms) + FAIR (30-50ms)
        ç”¨äºè®¡ç®—å»¶æ—¶è¯¯å·®ç»Ÿè®¡æŒ‡æ ‡ï¼Œç¡®ä¿åªä½¿ç”¨ç›¸å¯¹é«˜è´¨é‡çš„åŒ¹é…æ•°æ®ã€‚

        Returns:
            List[Dict[str, Union[int, float]]]: ç²¾ç¡®åŒ¹é…å¯¹çš„åç§»å¯¹é½æ•°æ®åˆ—è¡¨
        """
        # ä»matched_pairsä¸­ç­›é€‰ç²¾ç¡®åŒ¹é…ï¼ˆEXCELLENT, GOOD, FAIRï¼‰
        offset_data = []
        for rec_note, rep_note, match_type, keyon_error_ms in self.matched_pairs:
            # åªå¤„ç†ç²¾ç¡®åŒ¹é…ï¼ˆâ‰¤50msï¼‰
            if match_type not in [MatchType.EXCELLENT, MatchType.GOOD, MatchType.FAIR]:
                continue
            
            # è®¡ç®—å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦çš„æ—¶é—´
            record_keyon, record_keyoff = self._calculate_note_times(rec_note)
            replay_keyon, replay_keyoff = self._calculate_note_times(rep_note)

            # è·å–é”¤é€Ÿä¿¡æ¯
            record_velocity = self._get_velocity_from_note(rec_note)
            replay_velocity = self._get_velocity_from_note(rep_note)

            # è®¡ç®—åŸå§‹åç§»é‡
            keyon_offset = replay_keyon - record_keyon

            record_duration = record_keyoff - record_keyon
            replay_duration = replay_keyoff - replay_keyon
            duration_diff = replay_duration - record_duration
            
            # è®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼ˆç”¨äºæ‚¬åœæ˜¾ç¤ºï¼Œå•ä½ï¼šmsï¼‰
            relative_delay = keyon_offset / 10.0

            offset_data.append({
                'record_index': rec_note.uuid,
                'replay_index': rep_note.uuid,
                'key_id': rec_note.id,
                'record_keyon': record_keyon,
                'replay_keyon': replay_keyon,
                'record_velocity': record_velocity,
                'replay_velocity': replay_velocity,
                'velocity_diff': (replay_velocity - record_velocity) if record_velocity is not None and replay_velocity is not None else None,
                'keyon_offset': keyon_offset,
                'corrected_offset': keyon_offset,
                'relative_delay': relative_delay,
                'record_keyoff': record_keyoff,
                'replay_keyoff': replay_keyoff,
                'duration_offset': duration_diff,
                'average_offset': abs(keyon_offset),
                'record_duration': record_duration,
                'replay_duration': replay_duration,
                'duration_diff': duration_diff
            })

        return offset_data

    def get_grouped_precision_match_data(self) -> Dict[int, List[float]]:
        """
        è·å–æŒ‰æŒ‰é”®IDåˆ†ç»„çš„ç²¾ç¡®åŒ¹é…å»¶æ—¶æ•°æ®ï¼ˆè¯¯å·® â‰¤ 50msï¼‰
        ç›´æ¥åˆ©ç”¨ NoteMatcher çš„åŒ¹é…ç»“æœï¼Œé¿å…åœ¨å¤–éƒ¨è¿›è¡ŒäºŒæ¬¡éå†å’Œåˆ†ç»„ã€‚

        Returns:
            Dict[int, List[float]]: key_id -> [keyon_offset_ms, ...]
        """
        grouped_data = defaultdict(list)
        for rec_note, rep_note, match_type, _ in self.matched_pairs:
            if match_type in [MatchType.EXCELLENT, MatchType.GOOD, MatchType.FAIR]:
                # è®¡ç®—å»¶æ—¶ (ms)
                offset_ms = (rep_note.key_on_ms - rec_note.key_on_ms)
                grouped_data[rec_note.id].append(offset_ms)
        return grouped_data

    def _get_velocity_from_note(self, note) -> Optional[float]:
        """ä»éŸ³ç¬¦ä¸­è·å–é”¤é€Ÿ"""
        try:
            if not note:
                return None

            # åªä»hammersæ•°æ®ä¸­è·å–é”¤é€Ÿ
            if note.hammers is not None:
                if  len(note.hammers.values) > 0:
                    hammer_velocity = note.hammers.values[0]
                    if hammer_velocity is not None and not pd.isna(hammer_velocity):
                        return float(hammer_velocity)
                elif len(note.hammers) > 0:
                    hammer_velocity = note.hammers.iloc[0]
                    if hammer_velocity is not None and not pd.isna(hammer_velocity):
                        return float(hammer_velocity)

            return None

        except Exception as e:
            logger.warning(f"[WARNING] ä»éŸ³ç¬¦æå–é”¤é€Ÿå¤±è´¥: {e}")
            return None


    def get_graded_error_stats(self) -> Dict[str, Dict[str, Union[int, float]]]:
        """
        è·å–åˆ†çº§è¯¯å·®ç»Ÿè®¡ - æˆåŠŸåŒ¹é…è´¨é‡è¯„çº§

        åªç»Ÿè®¡æˆåŠŸåŒ¹é…å¯¹çš„è´¨é‡åˆ†å¸ƒï¼ˆä¸åŒ…æ‹¬å¤±è´¥åŒ¹é…ï¼‰ï¼š
        - excellent: ä¼˜ç§€ (è¯¯å·® â‰¤ 20ms)
        - good: è‰¯å¥½ (20ms < è¯¯å·® â‰¤ 30ms)
        - fair: ä¸€èˆ¬ (30ms < è¯¯å·® â‰¤ 50ms)
        - poor: è¾ƒå·® (50ms < è¯¯å·® â‰¤ 100ms)
        - severe: ä¸¥é‡ (100ms < è¯¯å·® â‰¤ 200ms)

        Returns:
            Dict: åŒ…å«å„çº§åˆ«çš„è®¡æ•°å’Œç™¾åˆ†æ¯”
        """
        # ç›´æ¥ä» match_statistics è·å–ç»Ÿè®¡æ•°æ® (ä½¿ç”¨ç»Ÿä¸€ key)
        stats = {
            'excellent': self.match_statistics.excellent_matches,
            'good': self.match_statistics.good_matches,
            'fair': self.match_statistics.fair_matches,
            'poor': self.match_statistics.poor_matches,
            'severe': self.match_statistics.severe_matches,
        }

        # æˆåŠŸåŒ¹é…æ€»æ•°ï¼ˆç²¾ç¡®åŒ¹é…å¯¹æ•°é‡ï¼‰
        total_successful_matches = len(self.matched_pairs)
        
        # è®¡ç®—ç™¾åˆ†æ¯”ï¼ˆåŸºäºæˆåŠŸçš„åŒ¹é…å¯¹æ€»æ•°ï¼‰
        result = {}
        for key, count in stats.items():
            result[key] = {
                'count': count,
                'percent': (count / total_successful_matches * 100) if total_successful_matches > 0 else 0.0
            }

        result['total_successful_matches'] = total_successful_matches

        logger.debug(f"ğŸ“Š [åç«¯] åŒ¹é…è´¨é‡è¯„çº§ç»Ÿè®¡: æˆåŠŸé…å¯¹æ•°={total_successful_matches}")

        return result

    def get_invalid_notes_offset_analysis(self, record_data: List[Note], replay_data: List[Note]) -> List[Dict[str, Union[int, float, str]]]:
        """
        è·å–æ— æ•ˆéŸ³ç¬¦çš„åç§»å¯¹é½åˆ†æ
        
        Args:
            record_data: å½•åˆ¶æ•°æ®
            replay_data: æ’­æ”¾æ•°æ®
            
        Returns:
            List[Dict[str, Union[int, float, str]]]: æ— æ•ˆéŸ³ç¬¦åç§»åˆ†ææ•°æ®
        """
        invalid_offset_data = []
        
        # è·å–å·²åŒ¹é…çš„éŸ³ç¬¦ç´¢å¼•
        matched_record_indices = set(pair[0] for pair in self.matched_pairs)
        matched_replay_indices = set(pair[1] for pair in self.matched_pairs)
        
        # åˆ†æå½•åˆ¶æ•°æ®ä¸­çš„æ— æ•ˆéŸ³ç¬¦ï¼ˆæœªåŒ¹é…çš„éŸ³ç¬¦ï¼‰
        invalid_offset_data.extend(
            self._analyze_invalid_notes(record_data, matched_record_indices, 'record', replay_data)
        )
        
        # åˆ†ææ’­æ”¾æ•°æ®ä¸­çš„æ— æ•ˆéŸ³ç¬¦ï¼ˆæœªåŒ¹é…çš„éŸ³ç¬¦ï¼‰
        invalid_offset_data.extend(
            self._analyze_invalid_notes(replay_data, matched_replay_indices, 'replay', record_data)
        )
        
        return invalid_offset_data
    
    def _analyze_invalid_notes(self, notes_data: List[Note], matched_indices: set, data_type: str, 
                              other_notes_data: List[Note] = None) -> List[Dict[str, Union[int, float, str]]]:
        """
        åˆ†ææ— æ•ˆéŸ³ç¬¦çš„é€šç”¨æ–¹æ³•
        
        Args:
            notes_data: éŸ³ç¬¦æ•°æ®åˆ—è¡¨
            matched_indices: å·²åŒ¹é…çš„éŸ³ç¬¦ç´¢å¼•é›†åˆ
            data_type: æ•°æ®ç±»å‹ ('record' æˆ– 'replay')
            other_notes_data: å¦ä¸€ä¸ªæ•°æ®ç±»å‹çš„éŸ³ç¬¦åˆ—è¡¨ï¼Œç”¨äºåˆ†æåŒ¹é…å¤±è´¥åŸå› 
            
        Returns:
            List[Dict[str, Union[int, float, str]]]: æ— æ•ˆéŸ³ç¬¦åˆ†ææ•°æ®
        """
        invalid_notes = []
        
        for i, note in enumerate(notes_data):
            if i not in matched_indices:  # æœªåŒ¹é…çš„éŸ³ç¬¦
                try:
                    keyon_time, keyoff_time = self._calculate_note_times(note)
                    
                    # ä¼˜å…ˆä½¿ç”¨åŒ¹é…é˜¶æ®µè®°å½•çš„çœŸå®å¤±è´¥åŸå› ï¼ˆä»…recordä¾§æœ‰ï¼‰
                    analysis_reason = None
                    if data_type == 'record' and (data_type, i) in self.failure_reasons:
                        analysis_reason = self.failure_reasons[(data_type, i)]
                    else:
                        # å›æ”¾ä¾§æˆ–æ— è®°å½•æ—¶ï¼Œå†åšæ¨æ–­åˆ†æ
                        analysis_reason = self._get_actual_unmatch_reason(note, data_type, i, other_notes_data)
                    
                    invalid_notes.append({
                        'data_type': data_type,
                        'note_index': i,
                        'key_id': note.id,
                        'keyon_time': keyon_time,
                        'keyoff_time': keyoff_time,
                        'status': 'unmatched',
                        'analysis_reason': analysis_reason
                    })
                except (IndexError, AttributeError) as e:
                    # å¤„ç†æ•°æ®å¼‚å¸¸çš„æƒ…å†µ
                    invalid_notes.append({
                        'data_type': data_type,
                        'note_index': i,
                        'key_id': note.id,
                        'keyon_time': 0.0,
                        'keyoff_time': 0.0,
                        'status': 'data_error',
                        'analysis_reason': f'æ•°æ®å¼‚å¸¸: {str(e)}'
                    })
        
        return invalid_notes
    
    def _get_actual_unmatch_reason(self, note: Note, data_type: str, note_index: int, 
                                  other_notes_data: List[Note] = None) -> str:
        """
        åˆ†ææœªåŒ¹é…éŸ³ç¬¦çš„å®é™…å¤±è´¥åŸå› 
        
        Args:
            note: éŸ³ç¬¦å¯¹è±¡
            data_type: æ•°æ®ç±»å‹ ('record' æˆ– 'replay')
            note_index: éŸ³ç¬¦ç´¢å¼•
            other_notes_data: å¦ä¸€ä¸ªæ•°æ®ç±»å‹çš„éŸ³ç¬¦åˆ—è¡¨
            
        Returns:
            str: åŒ¹é…å¤±è´¥åŸå› 
        """
        if other_notes_data is None:
            return "æ— æ³•åˆ†æåŒ¹é…å¤±è´¥åŸå› (ç¼ºå°‘å¯¹æ¯”æ•°æ®)"
        
        try:
            # æå–å½“å‰éŸ³ç¬¦ä¿¡æ¯
            note_info = self._extract_note_info(note, note_index)
            
            # åˆ†æåŒ¹é…å¤±è´¥çš„å…·ä½“åŸå› 
            return self._analyze_match_failure_reason(note_info, other_notes_data, data_type)
            
        except Exception as e:
            return f"åˆ†æåŒ¹é…å¤±è´¥åŸå› æ—¶å‡ºé”™: {str(e)}"
    
    def _analyze_match_failure_reason(self, note_info: Dict, other_notes_data: List[Note], data_type: str) -> str:
        """
        åˆ†æåŒ¹é…å¤±è´¥çš„å…·ä½“åŸå› ï¼ˆå›æ”¾ä¾§æ¨æ–­ç”¨ï¼‰
        
        æ³¨æ„ï¼šå½•åˆ¶ä¾§å·²åœ¨åŒ¹é…é˜¶æ®µè®°å½•çœŸå®åŸå› ï¼Œæ­¤æ–¹æ³•ä¸»è¦ç”¨äºå›æ”¾ä¾§æ¨æ–­
        
        Args:
            note_info: éŸ³ç¬¦ä¿¡æ¯å­—å…¸
            other_notes_data: å¦ä¸€ä¸ªæ•°æ®ç±»å‹çš„éŸ³ç¬¦åˆ—è¡¨
            data_type: æ•°æ®ç±»å‹
            
        Returns:
            str: åŒ¹é…å¤±è´¥åŸå› 
        """
        target_key_id = note_info["key_id"]
        target_keyon = note_info["keyon"]
        target_keyoff = note_info["keyoff"]
        
        # è°ƒç”¨ç›¸åŒçš„å€™é€‰ç”Ÿæˆé€»è¾‘ï¼ˆç¡®ä¿ä¸åŒ¹é…é˜¶æ®µä¸€è‡´ï¼‰
        candidates, threshold, reason_if_empty = self._generate_sorted_candidates_within_threshold(
            other_notes_data,
            target_keyon=target_keyon,
            target_keyoff=target_keyoff,
            target_key_id=target_key_id
        )
        
        if not candidates:
            return reason_if_empty
        
        # æœ‰åœ¨é˜ˆå€¼å†…çš„å€™é€‰ï¼Œä½†æœªè¢«åŒ¹é… -> å¯èƒ½å…¨è¢«å ç”¨ï¼ˆå›æ”¾ä¾§æ— æ³•å¾—çŸ¥å ç”¨æƒ…å†µï¼‰
        return f"å¯èƒ½æ‰€æœ‰å€™é€‰å·²è¢«å ç”¨(å€™é€‰æ•°:{len(candidates)}, é˜ˆå€¼:{threshold:.1f}ms)"
    
    def _get_delay_metrics(self) -> DelayMetrics:
        """
        è·å–å»¶æ—¶æŒ‡æ ‡è®¡ç®—å™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        
        Returns:
            DelayMetrics: å»¶æ—¶æŒ‡æ ‡è®¡ç®—å™¨å®ä¾‹
        """
        if self._delay_metrics is None:
            # ä»matched_pairsä¸­æå–ç²¾ç¡®åŒ¹é…å¯¹ï¼ˆEXCELLENT + GOOD + FAIRï¼‰
            # DelayMetricséœ€è¦çš„æ ¼å¼ï¼š[(record_idx, replay_idx, record_note, replay_note), ...]
            precision_pairs = []
            for rec_note, rep_note, match_type, _ in self.matched_pairs:
                if match_type in [MatchType.EXCELLENT, MatchType.GOOD, MatchType.FAIR]:
                    # DelayMetricså®é™…ä¸Šä¸ä½¿ç”¨indexï¼Œåªä½¿ç”¨Noteå¯¹è±¡
                    precision_pairs.append((0, 0, rec_note, rep_note))
            
            self._delay_metrics = DelayMetrics(precision_pairs)
        return self._delay_metrics
    
    def _calculate_note_times(self, note: Note) -> Tuple[float, float]:
        """
        è·å–éŸ³ç¬¦çš„æŒ‰é”®å¼€å§‹å’Œç»“æŸæ—¶é—´
        
        Args:
            note: éŸ³ç¬¦å¯¹è±¡
            
        Returns:
            Tuple[float, float]: (keyon_time, keyoff_time) å•ä½ï¼š0.1ms
        """
        # ç›´æ¥ä½¿ç”¨Noteå¯¹è±¡çš„é¢„è®¡ç®—å±æ€§ï¼ˆå·²ç»æ˜¯msï¼‰ï¼Œè½¬æ¢ä¸º0.1mså•ä½
        if note.key_on_ms is not None and note.key_off_ms is not None:
            keyon_time = note.key_on_ms * 10.0
            keyoff_time = note.key_off_ms * 10.0
        else:
            logger.waring(f"éŸ³ç¬¦ID {note.id} çš„æ—¶é—´å±æ€§æœªåˆå§‹åŒ–")
        
        return keyon_time, keyoff_time

    
    def get_standard_deviation(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„æ€»ä½“æ ‡å‡†å·®ï¼ˆPopulation Standard Deviationï¼‰
        
        Returns:
            float: æ€»ä½“æ ‡å‡†å·®ï¼ˆå•ä½ï¼š0.1msï¼‰
        """
        return self._get_delay_metrics().get_standard_deviation()
    
    def get_mean_absolute_error(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰
        
        Returns:
            float: å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆå•ä½ï¼š0.1msï¼‰
        """
        return self._get_delay_metrics().get_mean_absolute_error()
    
    def get_coefficient_of_variation(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„å˜å¼‚ç³»æ•°ï¼ˆCVï¼‰
        
        Returns:
            float: å˜å¼‚ç³»æ•°ï¼ˆç™¾åˆ†æ¯”ï¼Œä¾‹å¦‚ 15.5 è¡¨ç¤º 15.5%ï¼‰
        """
        return self._get_delay_metrics().get_coefficient_of_variation()

    def get_root_mean_squared_error(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰
        
        Returns:
            float: å‡æ–¹æ ¹è¯¯å·®ï¼ˆå•ä½ï¼š0.1msï¼‰
        """
        return self._get_delay_metrics().get_root_mean_squared_error()
    
    def get_mean_error(self) -> float:
        """
        è·å–å·²åŒ¹é…æŒ‰é”®å¯¹çš„å¹³å‡è¯¯å·®ï¼ˆMEï¼Œå¸¦ç¬¦å·ï¼‰

        Returns:
            float: å¹³å‡è¯¯å·®MEï¼ˆå•ä½ï¼š0.1msï¼‰
        """
        return self._get_delay_metrics().get_mean_error()

    def get_global_average_delay(self) -> float:
        """è·å–æ•´é¦–æ›²å­çš„å¹³å‡æ—¶å»¶ï¼ˆå…¼å®¹æ€§æ¥å£ï¼‰"""
        return self.get_mean_error()

    def get_variance(self) -> float:
        """è·å–å·²é…å¯¹æŒ‰é”®çš„æ€»ä½“æ–¹å·®"""
        return self._get_delay_metrics().get_variance()

    def get_all_display_data(self) -> Dict[str, List[MatchResult]]:
        """
        è·å–æ‰€æœ‰ç”¨äºæ˜¾ç¤ºçš„æ•°æ®ï¼ˆç»Ÿä¸€æ¥å£ï¼Œä½¿ç”¨ MatchResult å¯¹è±¡ï¼‰

        æä¾›ç»Ÿä¸€çš„ç€‘å¸ƒå›¾æ˜¾ç¤ºæ•°æ®è®¿é—®æ¥å£ï¼Œé¿å…è¡¨ç°å±‚å¤„ç†å¤æ‚çš„å…ƒç»„è§£åŒ…ã€‚

        Returns:
            Dict[str, List[MatchResult]]: åŒ…å«æ‰€æœ‰æ˜¾ç¤ºç›¸å…³ç»“æœçš„å­—å…¸
                - matched_pairs: æ­£å¸¸åŒ¹é…å¯¹
                - drop_hammers: ä¸¢é”¤é”™è¯¯
                - multi_hammers: å¤šé”¤é”™è¯¯
                - abnormal_matches: å¼‚å¸¸åŒ¹é…å¯¹ï¼ˆæ— é”¤é€Ÿï¼‰
        """
        # 1. æ­£å¸¸åŒ¹é…å¯¹
        normal_matches = [
            MatchResult(match_type=mt, record_index=0, replay_index=0, error_ms=err, pair=(rec, rep))
            for rec, rep, mt, err in self.matched_pairs
        ]

        # 2. ä¸¢é”¤æ•°æ®
        drop_hammers = [
            MatchResult(match_type=MatchType.FAILED, record_index=0, pair=(note, None), reason="ä¸¢é”¤ (æ’­æ”¾æ•°æ®ç¼ºå¤±)")
            for note in self.drop_hammers
        ]

        # 3. å¤šé”¤æ•°æ®
        multi_hammers = [
            MatchResult(match_type=MatchType.FAILED, record_index=0, pair=(None, note), reason="å¤šé”¤ (å½•åˆ¶æ•°æ®ç¼ºå¤±)")
            for note in self.multi_hammers
        ]

        # 4. å¼‚å¸¸åŒ¹é…å¯¹
        abnormal_matches = [
            MatchResult(match_type=MatchType.FAILED, record_index=0, replay_index=0, 
                        error_ms=abs(rep.key_on_ms - rec.key_on_ms), pair=(rec, rep), reason="å¼‚å¸¸åŒ¹é… (å‡æ— æœ‰æ•ˆé”¤é€Ÿ)")
            for rec, rep in self.abnormal_matches
        ]

        return {
            'matched_pairs': normal_matches,
            'drop_hammers': drop_hammers,
            'multi_hammers': multi_hammers,
            'abnormal_matches': abnormal_matches
        }

