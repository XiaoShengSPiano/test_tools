#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SPMIDéŸ³ç¬¦åŒ¹é…å™¨

è´Ÿè´£SPMIDæ•°æ®çš„æŒ‰é”®åŒ¹é…ï¼ŒåŒ…æ‹¬ï¼š
- éŸ³ç¬¦åŒ¹é…ç®—æ³•
- åŒ¹é…å¯¹ç”Ÿæˆ
- åŒ¹é…ç»“æœç®¡ç†

åŒ¹é…é€»è¾‘æ¶æ„ï¼š
==========================================

ã€æ ¸å¿ƒç­–ç•¥ã€‘
- è´ªå¿ƒåŒ¹é…ï¼šæ¯ä¸ªå½•åˆ¶éŸ³ç¬¦åªåŒ¹é…ä¸€ä¸ªæœ€ä½³çš„æ’­æ”¾éŸ³ç¬¦
- ä¸‰é˜¶æ®µæœç´¢ï¼šç²¾ç¡®æœç´¢(â‰¤50ms) â†’ è¿‘ä¼¼æœç´¢(50ms-1000ms) â†’ ä¸¥é‡æœç´¢(>1000ms)
- å…­ç­‰çº§é˜ˆå€¼ï¼šæŒ‰è¯¯å·®èŒƒå›´ç²¾ç¡®åˆ†ç±» (20ms, 30ms, 50ms, 1000ms)

ã€åŒ¹é…æµç¨‹ã€‘
1. find_all_matched_pairs() - ä¸»å…¥å£
   â”œâ”€â”€ åˆå§‹åŒ–åŒ¹é…çŠ¶æ€
   â”œâ”€â”€ å¯¹æ¯ä¸ªå½•åˆ¶éŸ³ç¬¦è°ƒç”¨ _find_match_for_single_note()
   â””â”€â”€ ç»Ÿè®¡åŒ¹é…ç»“æœ

2. _find_match_for_single_note() - å•éŸ³ç¬¦åŒ¹é…
   â”œâ”€â”€ æå–éŸ³ç¬¦ä¿¡æ¯ (_extract_note_info)
   â”œâ”€â”€ ç”Ÿæˆå€™é€‰åˆ—è¡¨ (_generate_candidates_for_note)
   â”œâ”€â”€ é€‰æ‹©æœ€ä½³å€™é€‰ (_select_best_candidate)
   â””â”€â”€ å¤„ç†åŒ¹é…ç»“æœ (ç²¾ç¡®åŒ¹é…/è¿‘ä¼¼åŒ¹é…/å¤±è´¥)

3. _generate_candidates_for_note() - å€™é€‰ç”Ÿæˆ
   â”œâ”€â”€ ç¬¬ä¸€é˜¶æ®µï¼šé˜ˆå€¼å†…å€™é€‰ (_generate_sorted_candidates_within_threshold)
   â”œâ”€â”€ ç¬¬äºŒé˜¶æ®µï¼šå¦‚æ— å€™é€‰åˆ™æ‰©å±•åˆ°å…¨å±€ (_generate_all_candidates_sorted)
   â””â”€â”€ ç¬¬ä¸‰é˜¶æ®µï¼šåº”ç”¨æ‰©å±•é˜ˆå€¼è¿‡æ»¤ (â‰¤300ms)

ã€åŒ¹é…åˆ†ç±» - å…­ç­‰çº§ç³»ç»Ÿã€‘
- ä¼˜ç§€åŒ¹é… (â‰¤20ms)ï¼šé«˜è´¨é‡åŒ¹é…
- è‰¯å¥½åŒ¹é… (20-30ms)ï¼šè¾ƒé«˜è´¨é‡åŒ¹é…
- ä¸€èˆ¬åŒ¹é… (30-50ms)ï¼šå¯æ¥å—åŒ¹é…
- è¾ƒå·®åŒ¹é… (50-1000ms)ï¼šéœ€è¦æ”¹è¿›çš„åŒ¹é…
- ä¸¥é‡åŒ¹é… (>1000ms)ï¼šè´¨é‡æå·®ä½†æ‰¾åˆ°çš„åŒ¹é…
- å¤±è´¥åŒ¹é… (æ— å€™é€‰)ï¼šå®Œå…¨æ‰¾ä¸åˆ°åŒ¹é…ï¼Œæ ‡è®°ä¸ºä¸¢é”¤/å¤šé”¤å¼‚å¸¸

ã€æœç´¢ç­–ç•¥ - ä¸‰é˜¶æ®µåˆ†å±‚æœç´¢ã€‘
- ç¬¬ä¸€é˜¶æ®µï¼šç²¾ç¡®æœç´¢ (â‰¤50ms) - å¯»æ‰¾ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬åŒ¹é…
- ç¬¬äºŒé˜¶æ®µï¼šè¿‘ä¼¼æœç´¢ (50-1000ms) - å¯»æ‰¾è¾ƒå·®åŒ¹é…
- ç¬¬ä¸‰é˜¶æ®µï¼šä¸¥é‡æœç´¢ (>1000ms) - å¯»æ‰¾ä¸¥é‡è¯¯å·®åŒ¹é…

ã€é˜ˆå€¼ä½“ç³» - å…­ç­‰çº§ç²¾ç¡®åˆ†ç±»ã€‘
- ä¼˜ç§€é˜ˆå€¼ï¼šâ‰¤20ms
- è‰¯å¥½é˜ˆå€¼ï¼š20-30ms
- ä¸€èˆ¬é˜ˆå€¼ï¼š30-50ms
- è¾ƒå·®é˜ˆå€¼ï¼š50-1000ms
- ä¸¥é‡é˜ˆå€¼ï¼š>1000ms
- å¤±è´¥é˜ˆå€¼ï¼šæ— åŒ¹é…

ã€é”™è¯¯æ£€æµ‹ã€‘
- ä¸¢é”¤ï¼šå½•åˆ¶æ•°æ®ä¸­æœªåŒ¹é…çš„æŒ‰é”®
- å¤šé”¤ï¼šæ’­æ”¾æ•°æ®ä¸­æœªåŒ¹é…çš„æŒ‰é”®
- åŸºäºä¸¤é˜¶æ®µåŒ¹é…åçš„å‰©ä½™éŸ³ç¬¦ç›´æ¥åˆ¤æ–­ï¼Œæ— éœ€å¤æ‚ç»Ÿè®¡
"""

import pandas as pd
import numpy as np
from .spmid_reader import Note
from typing import List, Tuple, Dict, Union, Optional
from utils.logger import Logger
from enum import Enum
from collections import defaultdict

logger = Logger.get_logger()

# åŒ¹é…é˜ˆå€¼å¸¸é‡ (0.1mså•ä½) - äº”ç­‰çº§åŒ¹é…ç³»ç»Ÿ
# ä¼˜ç§€åŒ¹é…ï¼šâ‰¤20ms
EXCELLENT_THRESHOLD = 200.0
# è‰¯å¥½åŒ¹é…ï¼š20-30ms
GOOD_THRESHOLD = 300.0
# ä¸€èˆ¬åŒ¹é…ï¼š30-50ms
FAIR_THRESHOLD = 500.0
# è¾ƒå·®åŒ¹é…ï¼š50-1000ms
POOR_THRESHOLD = 10000.0
# ä¸¥é‡è¯¯å·®ï¼š>1000ms
SEVERE_THRESHOLD = 10000.0
# å¤±è´¥åŒ¹é…ï¼šæ— å€™é€‰

# å…¼å®¹æ€§å¸¸é‡ (å‘åå…¼å®¹)
PRECISION_THRESHOLD = FAIR_THRESHOLD      # 50ms - ç²¾ç¡®åŒ¹é…ä¸Šé™
APPROXIMATE_THRESHOLD = POOR_THRESHOLD    # 1000ms - è¿‘ä¼¼åŒ¹é…ä¸Šé™

# åŒ¹é…ç±»å‹æšä¸¾ - æŒ‰è¯¯å·®ç­‰çº§ç»†åˆ†
class MatchType(Enum):
    """åŒ¹é…ç»“æœç±»å‹ - æŒ‰è¯¯å·®ç­‰çº§åˆ†ç±»"""
    EXCELLENT = "excellent"      # ä¼˜ç§€åŒ¹é… (è¯¯å·® â‰¤ 20ms)
    GOOD = "good"               # è‰¯å¥½åŒ¹é… (20ms < è¯¯å·® â‰¤ 30ms)
    FAIR = "fair"               # ä¸€èˆ¬åŒ¹é… (30ms < è¯¯å·® â‰¤ 50ms)
    POOR = "poor"               # è¾ƒå·®åŒ¹é… (50ms < è¯¯å·® â‰¤ 1000ms)
    SEVERE = "severe"           # ä¸¥é‡è¯¯å·® (è¯¯å·® > 1000ms)
    FAILED = "failed"           # å¤±è´¥åŒ¹é… (æ— å€™é€‰)

# åŒ¹é…ç»“æœç±»
class MatchResult:
    """åŒ¹é…ç»“æœå°è£…ç±»"""
    def __init__(self, match_type: MatchType, record_index: int,
                 replay_index: Optional[int] = None, error_ms: float = 0.0,
                 pair: Optional[Tuple[Note, Note]] = None, reason: str = ""):
        self.match_type = match_type
        self.record_index = record_index
        self.replay_index = replay_index
        self.error_ms = error_ms  # è¯¯å·®(æ¯«ç§’)
        self.pair = pair  # åŒ¹é…å¯¹ (record_note, replay_note)
        self.reason = reason  # å¤±è´¥åŸå› 

    @property
    def is_success(self) -> bool:
        """æ˜¯å¦åŒ¹é…æˆåŠŸ"""
        return self.match_type != MatchType.FAILED

# å€™é€‰ä¿¡æ¯ç±»
class Candidate:
    """å€™é€‰åŒ¹é…ä¿¡æ¯"""
    def __init__(self, index: int, total_error: float, note: Optional[Note] = None):
        self.index = index
        self.total_error = total_error
        self.note = note

    @property
    def error_ms(self) -> float:
        """è¯¯å·®è½¬æ¢ä¸ºæ¯«ç§’"""
        return self.total_error / 10.0

# æŒ‰é”®åŒ¹é…ç»Ÿè®¡ç±» - æ–°å¢ï¼šæŒ‰é”®çº§åˆ«çš„ç»Ÿè®¡ä¿¡æ¯
class KeyMatchStatistics:
    """å•ä¸ªæŒ‰é”®çš„åŒ¹é…ç»Ÿè®¡ä¿¡æ¯"""

    def __init__(self, key_id: int):
        self.key_id = key_id
        self.total_record_notes = 0    # è¯¥æŒ‰é”®å½•åˆ¶éŸ³ç¬¦æ€»æ•°
        self.total_replay_notes = 0    # è¯¥æŒ‰é”®æ’­æ”¾éŸ³ç¬¦æ€»æ•°
        self.matched_count = 0         # æˆåŠŸåŒ¹é…æ•°
        self.failed_count = 0          # å¤±è´¥åŒ¹é…æ•°
        self.extra_hammers = 0         # å¤šé”¤æ•°ï¼ˆæœªä½¿ç”¨çš„æ’­æ”¾éŸ³ç¬¦ï¼‰

        # è¯¯å·®ç»Ÿè®¡ï¼ˆåªç»Ÿè®¡æˆåŠŸåŒ¹é…ï¼‰
        self.offsets_ms: List[float] = []  # æ ¡å‡†ååç§»ï¼ˆmsï¼‰
        self.median_offset = 0.0
        self.mean_offset = 0.0
        self.std_offset = 0.0
        self.variance_offset = 0.0

        # åŒ¹é…è´¨é‡åˆ†å¸ƒ
        self.excellent_count = 0
        self.good_count = 0
        self.fair_count = 0
        self.poor_count = 0
        self.severe_count = 0

    def add_match_result(self, match_result: MatchResult, corrected_offset_ms: float):
        """æ·»åŠ åŒ¹é…ç»“æœ"""
        if match_result.is_success:
            self.matched_count += 1
            self.offsets_ms.append(corrected_offset_ms)

            # ç»Ÿè®¡åŒ¹é…è´¨é‡
            if match_result.match_type == MatchType.EXCELLENT:
                self.excellent_count += 1
            elif match_result.match_type == MatchType.GOOD:
                self.good_count += 1
            elif match_result.match_type == MatchType.FAIR:
                self.fair_count += 1
            elif match_result.match_type == MatchType.POOR:
                self.poor_count += 1
            elif match_result.match_type == MatchType.SEVERE:
                self.severe_count += 1
        else:
            self.failed_count += 1

    def calculate_statistics(self):
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        if self.offsets_ms:
            import statistics
            self.median_offset = statistics.median(self.offsets_ms)
            self.mean_offset = statistics.mean(self.offsets_ms)

            if len(self.offsets_ms) > 1:
                self.std_offset = statistics.stdev(self.offsets_ms)
                self.variance_offset = statistics.variance(self.offsets_ms)
            else:
                self.std_offset = 0.0
                self.variance_offset = 0.0

    def __str__(self):
        return f"æŒ‰é”®{self.key_id}: å½•åˆ¶{self.total_record_notes}, æ’­æ”¾{self.total_replay_notes}, åŒ¹é…{self.matched_count}, å¤±è´¥{self.failed_count}, å‡å€¼{self.mean_offset:.2f}ms"

# åŒ¹é…ç»Ÿè®¡ç±»
class MatchStatistics:
    """åŒ¹é…ç»Ÿè®¡ä¿¡æ¯ - å…­ç­‰çº§ç³»ç»Ÿ"""

    def __init__(self):
        # å…­ç­‰çº§åŒ¹é…ç»Ÿè®¡
        self.excellent_matches = 0    # ä¼˜ç§€åŒ¹é… (â‰¤20ms)
        self.good_matches = 0         # è‰¯å¥½åŒ¹é… (20-30ms)
        self.fair_matches = 0         # ä¸€èˆ¬åŒ¹é… (30-50ms)
        self.poor_matches = 0         # è¾ƒå·®åŒ¹é… (50-1000ms)
        self.severe_matches = 0       # ä¸¥é‡è¯¯å·® (>1000ms)
        self.failed_matches = 0       # å¤±è´¥åŒ¹é… (æ— å€™é€‰)

        # å…¼å®¹æ€§å­—æ®µ - ä¿æŒå‘åå…¼å®¹
        self.precision_matches = 0    # ç²¾ç¡®åŒ¹é…æ€»æ•° (â‰¤50ms)
        self.approximate_matches = 0  # è¿‘ä¼¼åŒ¹é…æ€»æ•° (50-1000ms)
        self.large_error_matches = 0  # å¤§è¯¯å·®åŒ¹é…æ€»æ•° (>1000ms)

        self.total_attempts = 0       # æ€»å°è¯•æ•°

    def add_result(self, result: MatchResult):
        """æ·»åŠ åŒ¹é…ç»“æœåˆ°ç»Ÿè®¡"""
        self.total_attempts += 1

        if result.match_type == MatchType.EXCELLENT:
            self.excellent_matches += 1
            self.precision_matches += 1
        elif result.match_type == MatchType.GOOD:
            self.good_matches += 1
            self.precision_matches += 1
        elif result.match_type == MatchType.FAIR:
            self.fair_matches += 1
            self.precision_matches += 1
        elif result.match_type == MatchType.POOR:
            self.poor_matches += 1
            self.approximate_matches += 1
        elif result.match_type == MatchType.SEVERE:
            self.severe_matches += 1
            self.large_error_matches += 1
        elif result.match_type == MatchType.FAILED:
            self.failed_matches += 1

    def __str__(self):
        return f"ä¼˜ç§€:{self.excellent_matches}, è‰¯å¥½:{self.good_matches}, ä¸€èˆ¬:{self.fair_matches}, è¾ƒå·®:{self.poor_matches}, ä¸¥é‡:{self.severe_matches}, å¤±è´¥:{self.failed_matches}"

class NoteMatcher:
    """SPMIDéŸ³ç¬¦åŒ¹é…å™¨ç±»"""
    
    def __init__(self, global_time_offset: float = 0.0):
        """
        åˆå§‹åŒ–éŸ³ç¬¦åŒ¹é…å™¨ - äº”ç­‰çº§åŒ¹é…ç³»ç»Ÿ

        Args:
            global_time_offset: åˆå§‹å…¨å±€æ—¶é—´åç§»é‡ï¼ˆå¯é€‰ï¼Œä¼šåœ¨åŒ¹é…è¿‡ç¨‹ä¸­é‡æ–°è®¡ç®—ï¼‰
        """
        self.global_time_offset = global_time_offset

        # æ ¸å¿ƒåŒ¹é…ç»“æœå­˜å‚¨
        self.matched_pairs: List[Tuple[int, int, Note, Note]] = []  # æ‰€æœ‰æˆåŠŸåŒ¹é…å¯¹ (record_idx, replay_idx, record_note, replay_note)
        self.match_results: List[MatchResult] = []  # æ‰€æœ‰åŒ¹é…ç»“æœè¯¦æƒ… (åŒ…å«åŒ¹é…ç±»å‹ã€è¯¯å·®ç­‰)

        # åŒ¹é…å¤±è´¥ä¿¡æ¯
        self.failure_reasons: Dict[Tuple[str, int], str] = {}  # key=(data_type, index)ï¼Œvalue=str

        # åˆ†ç±»å­˜å‚¨ - æŒ‰æœç´¢é˜¶æ®µåˆ†ç»„ï¼ˆç”¨äºæ•°æ®è·å–ä¼˜åŒ–ï¼‰
        self.precision_matched_pairs: List[Tuple[int, int, Note, Note]] = []  # ç²¾ç¡®æœç´¢é˜¶æ®µåŒ¹é… (â‰¤50ms)
        self.approximate_matched_pairs: List[Tuple[int, int, Note, Note]] = []  # è¿‘ä¼¼æœç´¢é˜¶æ®µåŒ¹é… (50-1000ms)
        self.severe_matched_pairs: List[Tuple[int, int, Note, Note]] = []  # ä¸¥é‡è¯¯å·®æœç´¢é˜¶æ®µåŒ¹é… (>1000ms)

        # æŒ‰é”®åˆ†ç»„ç»Ÿè®¡ä¿¡æ¯ - æ–°å¢ï¼šé¢„è®¡ç®—çš„æŒ‰é”®çº§åˆ«ç»Ÿè®¡æ•°æ®
        self.key_statistics: Dict[int, KeyMatchStatistics] = {}  # key=key_id, value=è¯¥æŒ‰é”®çš„ç»Ÿè®¡ä¿¡æ¯

        # ç»Ÿè®¡ä¿¡æ¯
        self.match_statistics = MatchStatistics()

        # æ•°æ®å¼•ç”¨ç¼“å­˜
        self._record_data: Optional[List[Note]] = None
        self._replay_data: Optional[List[Note]] = None

        # è®¡ç®—ç¼“å­˜
        self._mean_error_cached: Optional[float] = None
    
    def find_all_matched_pairs(self, record_data: List[Note], replay_data: List[Note]) -> List[Tuple[int, int, Note, Note]]:
        """
        æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…å¯¹ï¼šæŒ‰é”®åˆ†ç»„è´ªå¿ƒåŒ¹é…

        åŒ¹é…é€»è¾‘ï¼š
        1. æŒ‰æŒ‰é”®IDåˆ†ç»„å½•åˆ¶å’Œæ’­æ”¾æ•°æ®
        2. å¯¹æ¯ä¸ªæŒ‰é”®åˆ†åˆ«è¿›è¡Œè´ªå¿ƒåŒ¹é…ï¼ˆåŒæŒ‰é”®IDçš„å½•åˆ¶éŸ³ç¬¦ vs åŒæŒ‰é”®IDçš„æ’­æ”¾éŸ³ç¬¦ï¼‰
        3. æŒ‰é”®ä¹‹é—´å®Œå…¨ç‹¬ç«‹ï¼Œä¸å…è®¸è·¨æŒ‰é”®é…å¯¹

        Args:
            record_data: å½•åˆ¶æ•°æ®
            replay_data: æ’­æ”¾æ•°æ®

        Returns:
            List[Tuple[int, int, Note, Note]]: åŒ¹é…å¯¹åˆ—è¡¨ (record_index, replay_index, record_note, replay_note)
        """
        # åˆå§‹åŒ–çŠ¶æ€
        self._initialize_matching_state()

        logger.info(f"ğŸ¯ å¼€å§‹æŒ‰é”®åˆ†ç»„è´ªå¿ƒåŒ¹é…: å½•åˆ¶æ•°æ®{len(record_data)}ä¸ªéŸ³ç¬¦, å›æ”¾æ•°æ®{len(replay_data)}ä¸ªéŸ³ç¬¦")

        # ä¿å­˜åŸå§‹æ•°æ®å¼•ç”¨ï¼ˆç”¨äºå¤±è´¥åŒ¹é…è¯¦æƒ…ï¼‰
        self._record_data = record_data
        self._replay_data = replay_data

        # 1. æŒ‰æŒ‰é”®IDåˆ†ç»„æ•°æ®
        record_by_key = self._group_notes_by_key(record_data)
        replay_by_key = self._group_notes_by_key(replay_data)

        logger.info(f"ğŸ“Š æŒ‰é”®åˆ†ç»„å®Œæˆ: å½•åˆ¶æ•°æ®{len(record_by_key)}ä¸ªæŒ‰é”®, æ’­æ”¾æ•°æ®{len(replay_by_key)}ä¸ªæŒ‰é”®")

        # 2. å¯¹æ¯ä¸ªæŒ‰é”®åˆ†åˆ«è¿›è¡Œè´ªå¿ƒåŒ¹é…
        all_matched_pairs = []

        for key_id in record_by_key.keys():
            logger.debug(f"ğŸ¹ å¼€å§‹åŒ¹é…æŒ‰é”®{key_id}")

            # è·å–è¯¥æŒ‰é”®çš„æ‰€æœ‰å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦
            key_record_notes = record_by_key[key_id]  # [(original_index, note), ...]
            key_replay_notes = replay_by_key.get(key_id, [])  # [(original_index, note), ...]

            # å¯¹è¯¥æŒ‰é”®è¿›è¡Œè´ªå¿ƒåŒ¹é…
            key_matched_pairs, extra_hammers = self._match_notes_for_single_key_group(
                key_id, key_record_notes, key_replay_notes
            )

            all_matched_pairs.extend(key_matched_pairs)

            # æ›´æ–°æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯ä¸­çš„å¤šé”¤æ•°é‡
            if key_id not in self.key_statistics:
                self.key_statistics[key_id] = KeyMatchStatistics(key_id)
                self.key_statistics[key_id].total_record_notes = len(key_record_notes)
                self.key_statistics[key_id].total_replay_notes = len(key_replay_notes)
            self.key_statistics[key_id].extra_hammers = extra_hammers

            matched_count = len(key_matched_pairs)
            record_count = len(key_record_notes)
            replay_count = len(key_replay_notes)

            logger.debug(f"ğŸ æŒ‰é”®{key_id}åŒ¹é…å®Œæˆ: å½•åˆ¶{record_count}ä¸ª, æ’­æ”¾{replay_count}ä¸ª, åŒ¹é…{matched_count}ä¸ª")

        # ä¿å­˜æ‰€æœ‰åŒ¹é…å¯¹
        self.matched_pairs = all_matched_pairs

        # 3. åŸºäºåŒ¹é…ç»“æœè®¡ç®—æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯
        self._calculate_key_statistics_from_matches(record_by_key, replay_by_key)

        # è®°å½•æŒ‰é”®çº§åˆ«çš„åŒ¹é…ç»Ÿè®¡
        self._log_key_matching_statistics()

        # åŒ¹é…å®Œæˆåè®¡ç®—å¹¶ç¼“å­˜å¹³å‡è¯¯å·®
        self._mean_error_cached = self._calculate_mean_error()

        # æ‰“å°åŒ¹é…ç»Ÿè®¡ä¿¡æ¯
        print(f"[åŒ¹é…ç»Ÿè®¡] ç²¾ç¡®åŒ¹é…: {self.match_statistics.precision_matches} ä¸ª")
        print(f"[åŒ¹é…ç»Ÿè®¡] è¿‘ä¼¼åŒ¹é…: {self.match_statistics.approximate_matches} ä¸ª")
        print(f"[åŒ¹é…ç»Ÿè®¡] å¤§è¯¯å·®åŒ¹é…: {self.match_statistics.large_error_matches} ä¸ª")
        print(f"[åŒ¹é…ç»Ÿè®¡] å¤±è´¥åŒ¹é…: {self.match_statistics.failed_matches} ä¸ª")
        print(f"[åŒ¹é…ç»Ÿè®¡] æ€»åŒ¹é…å¯¹: {len(all_matched_pairs)} ä¸ª (å‡†ç¡®ç‡åˆ†å­)")

        return all_matched_pairs

    def _match_notes_for_single_key_group(self, key_id: int,
                                        record_notes_with_indices: List[Tuple[int, Note]],
                                        replay_notes_with_indices: List[Tuple[int, Note]]) -> Tuple[List[Tuple[int, int, Note, Note]], int]:
        """
        å¯¹å•ä¸ªæŒ‰é”®ç»„è¿›è¡Œè´ªå¿ƒåŒ¹é…

        åŒ¹é…ç­–ç•¥ï¼š
        1. ç²¾ç¡®åŒ¹é… (â‰¤50ms)
        2. è¿‘ä¼¼åŒ¹é… (50ms-1000ms)
        3. ä¸¥é‡è¯¯å·®åŒ¹é… (>1000ms) - ç†è®ºä¸Šåº”è¯¥åŒ¹é…æ‰€æœ‰å‰©ä½™æŒ‰é”®

        åŒ¹é…å®Œæˆåç»Ÿä¸€åˆ†æï¼š
        - å½•åˆ¶ä¸­æœªåŒ¹é…çš„ï¼šä¸¢é”¤
        - æ’­æ”¾ä¸­æœªä½¿ç”¨çš„ï¼šå¤šé”¤

        Args:
            key_id: æŒ‰é”®ID
            record_notes_with_indices: è¯¥æŒ‰é”®çš„å½•åˆ¶éŸ³ç¬¦åˆ—è¡¨ [(original_index, note), ...]
            replay_notes_with_indices: è¯¥æŒ‰é”®çš„æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨ [(original_index, note), ...]

        Returns:
            List[Tuple[int, int, Note, Note]]: è¯¥æŒ‰é”®çš„åŒ¹é…å¯¹åˆ—è¡¨
        """
        key_matched_pairs = []

        # åˆå§‹åŒ–çŠ¶æ€è·Ÿè¸ª - ä½¿ç”¨åŸå§‹ç´¢å¼•ä½œä¸ºé”®ï¼Œç¡®ä¿å”¯ä¸€æ€§
        record_match_status = {record_idx: False for record_idx, _ in record_notes_with_indices}  # False=æœªåŒ¹é…
        replay_match_status = {replay_idx: False for replay_idx, _ in replay_notes_with_indices}  # False=æœªä½¿ç”¨

        logger.debug(f"ğŸ¹ å¼€å§‹æŒ‰é”®{key_id}è´ªå¿ƒåŒ¹é…: å½•åˆ¶{len(record_notes_with_indices)}ä¸ª, æ’­æ”¾{len(replay_notes_with_indices)}ä¸ª")

        # åˆ†ç­‰çº§è´ªå¿ƒåŒ¹é…ç­–ç•¥
        match_strategies = [
            ("precision", "ç²¾ç¡®åŒ¹é…", [MatchType.EXCELLENT, MatchType.GOOD, MatchType.FAIR]),
            ("approximate", "è¿‘ä¼¼åŒ¹é…", [MatchType.POOR]),
            ("severe", "ä¸¥é‡è¯¯å·®åŒ¹é…", [MatchType.SEVERE])
        ]

        # è·å–å¾…åŒ¹é…çš„å½•åˆ¶éŸ³ç¬¦åˆ—è¡¨ï¼ˆæœªåŒ¹é…çš„ï¼‰
        unmatched_record_notes = [(idx, note) for idx, note in record_notes_with_indices]

        # æŒ‰ç­‰çº§é¡ºåºè¿›è¡ŒåŒ¹é…
        for strategy_name, strategy_desc, allowed_types in match_strategies:
            if not unmatched_record_notes:
                logger.debug(f"ğŸ¯ æŒ‰é”®{key_id}æ‰€æœ‰å½•åˆ¶éŸ³ç¬¦å·²åŒ¹é…å®Œæˆ")
                break

            logger.debug(f"ğŸª æŒ‰é”®{key_id}å¼€å§‹{strategy_desc}è½®: å‰©ä½™å½•åˆ¶{len(unmatched_record_notes)}ä¸ª")

            # æœ¬è½®æˆåŠŸåŒ¹é…çš„å½•åˆ¶éŸ³ç¬¦ï¼ˆä»åˆ—è¡¨ä¸­ç§»é™¤ï¼‰
            matched_in_this_round = []

            # éå†æ‰€æœ‰æœªåŒ¹é…çš„å½•åˆ¶éŸ³ç¬¦ï¼Œè®©å®ƒä»¬éƒ½å°è¯•å½“å‰ç­‰çº§çš„åŒ¹é…
            for record_orig_idx, record_note in unmatched_record_notes:
                # è·å–å½“å‰å¯ç”¨çš„æ’­æ”¾éŸ³ç¬¦åŠå…¶åŸå§‹ç´¢å¼•ï¼ˆæœªè¢«ä½¿ç”¨çš„ï¼‰
                available_replay_notes_with_indices = []
                for replay_orig_idx, replay_note in replay_notes_with_indices:
                    if not replay_match_status[replay_orig_idx]:  # æœªè¢«ä½¿ç”¨
                        available_replay_notes_with_indices.append((replay_orig_idx, replay_note))

                # åœ¨è¯¥æŒ‰é”®çš„å¯ç”¨æ’­æ”¾éŸ³ç¬¦ä¸­è¿›è¡ŒæŒ‡å®šç­‰çº§çš„åŒ¹é…
                match_result = self._perform_single_note_matching_in_strategy(
                    record_note, record_orig_idx, available_replay_notes_with_indices,
                    strategy_name, len(replay_notes_with_indices) > 0
                )

                # æ›´æ–°å…¨å±€ç»Ÿè®¡ä¿¡æ¯
                self.match_statistics.add_result(match_result)
                self.match_results.append(match_result)

                # å¤„ç†åŒ¹é…ç»“æœ
                if match_result.is_success and match_result.match_type in allowed_types:
                    # ä»MatchResultä¸­ç›´æ¥è·å–æ’­æ”¾éŸ³ç¬¦ç´¢å¼•
                    matched_replay_orig_idx = match_result.replay_index
                    matched_replay_note = match_result.pair[1]

                    key_matched_pairs.append((
                        record_orig_idx,
                        matched_replay_orig_idx,
                        record_note,
                        matched_replay_note
                    ))

                    # æ›´æ–°åŒ¹é…çŠ¶æ€
                    record_match_status[record_orig_idx] = True
                    replay_match_status[matched_replay_orig_idx] = True

                    # è®°å½•æŒ‰é”®é…å¯¹è¯¦æƒ…æ—¥å¿—
                    logger.debug(f"ğŸ”— æŒ‰é”®é…å¯¹: å½•åˆ¶æŒ‰é”®{key_id}(ç´¢å¼•{record_orig_idx}) â†” æ’­æ”¾æŒ‰é”®{key_id}(ç´¢å¼•{matched_replay_orig_idx}), "
                               f"è¯¯å·®={match_result.error_ms:.2f}ms, ç±»å‹={match_result.match_type.value}")

                    # è®°å½•åˆ°å¯¹åº”çš„åˆ†ç±»åˆ—è¡¨
                    if match_result.match_type in [MatchType.EXCELLENT, MatchType.GOOD, MatchType.FAIR]:
                        self.precision_matched_pairs.append(key_matched_pairs[-1])
                    elif match_result.match_type == MatchType.POOR:
                        self.approximate_matched_pairs.append(key_matched_pairs[-1])
                    elif match_result.match_type == MatchType.SEVERE:
                        self.severe_matched_pairs.append(key_matched_pairs[-1])

                    # æ ‡è®°æœ¬è½®æˆåŠŸåŒ¹é…
                    matched_in_this_round.append((record_orig_idx, record_note))
                # else: åŒ¹é…å¤±è´¥ï¼Œç»§ç»­ç•™åœ¨æœªåŒ¹é…åˆ—è¡¨ä¸­ï¼Œç­‰å¾…ä¸‹ä¸€è½®

            # ä»æœªåŒ¹é…åˆ—è¡¨ä¸­ç§»é™¤æœ¬è½®æˆåŠŸåŒ¹é…çš„éŸ³ç¬¦
            for matched_record in matched_in_this_round:
                unmatched_record_notes.remove(matched_record)

            logger.debug(f"ğŸ æŒ‰é”®{key_id}{strategy_desc}è½®å®Œæˆ: æœ¬è½®åŒ¹é…{matched_in_this_round.__len__()}ä¸ª, å‰©ä½™{len(unmatched_record_notes)}ä¸ª")

        # ç¬¬äºŒé˜¶æ®µï¼šç»Ÿä¸€åˆ†æä¸¢é”¤å’Œå¤šé”¤
        extra_hammers = self._analyze_key_group_hammer_status(key_id, record_match_status, replay_match_status)

        return key_matched_pairs, extra_hammers

    def _analyze_key_group_hammer_status(self, key_id: int,
                                        record_match_status: Dict[int, bool],
                                        replay_match_status: Dict[int, bool]) -> int:
        """
        åˆ†ææŒ‰é”®ç»„çš„é”¤å­çŠ¶æ€ï¼ˆä¸¢é”¤å’Œå¤šé”¤ï¼‰

        Args:
            key_id: æŒ‰é”®ID
            record_match_status: å½•åˆ¶éŸ³ç¬¦åŒ¹é…çŠ¶æ€ {record_orig_idx: is_matched}
            replay_match_status: æ’­æ”¾éŸ³ç¬¦ä½¿ç”¨çŠ¶æ€ {replay_orig_idx: is_used}

        Returns:
            int: å¤šé”¤æ•°é‡
        """
        # åˆ†æä¸¢é”¤ï¼šå½•åˆ¶äº†ä½†æœªåŒ¹é…
        dropped_hammers = [idx for idx, matched in record_match_status.items() if not matched]

        # åˆ†æå¤šé”¤ï¼šæ’­æ”¾äº†ä½†æœªè¢«ä½¿ç”¨
        extra_hammers = [idx for idx, matched in replay_match_status.items() if not matched]

        # è®°å½•åˆ†æç»“æœ
        logger.debug(f"ğŸ¯ æŒ‰é”®{key_id}åŒ¹é…å®Œæˆ:")
        logger.debug(f"  ğŸ“ å½•åˆ¶: {len(record_match_status)}ä¸ª, åŒ¹é…: {sum(record_match_status.values())}ä¸ª")
        logger.debug(f"  ğŸµ æ’­æ”¾: {len(replay_match_status)}ä¸ª, ä½¿ç”¨: {sum(replay_match_status.values())}ä¸ª")
        logger.debug(f"  ğŸ”¨ ä¸¢é”¤: {len(dropped_hammers)}ä¸ª, å¤šé”¤: {len(extra_hammers)}ä¸ª")

        # ä¸ºä¸¢é”¤åˆ›å»ºå¤±è´¥è®°å½•
        for record_idx in dropped_hammers:
            match_result = MatchResult(
                MatchType.FAILED,
                record_idx,
                reason=f"æŒ‰é”®{key_id}å½•åˆ¶éŸ³ç¬¦æœªåŒ¹é…(ä¸¢é”¤)"
            )
            self.match_results.append(match_result)
            self.match_statistics.add_result(match_result)

        # è¿”å›å¤šé”¤æ•°é‡ï¼Œç”¨äºæ›´æ–°æŒ‰é”®ç»Ÿè®¡
        return len(extra_hammers)

    def _perform_single_note_matching_in_strategy(self, record_note: Note, record_index: int,
                                                     replay_notes_with_indices: List[Tuple[int, Note]],
                                                     strategy_name: str,
                                                     has_any_replay_notes: bool = True) -> MatchResult:
        """
        åœ¨æŒ‰é”®ç»„å†…éƒ¨è¿›è¡Œå•ä¸ªéŸ³ç¬¦çš„æŒ‡å®šç­–ç•¥åŒ¹é…

        Args:
            record_note: å½•åˆ¶éŸ³ç¬¦
            record_index: å½•åˆ¶éŸ³ç¬¦çš„åŸå§‹ç´¢å¼•
            replay_notes_with_indices: è¯¥æŒ‰é”®çš„æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨ï¼ˆå·²è¿‡æ»¤æœªä½¿ç”¨çš„ï¼‰[(orig_idx, note), ...]
            strategy_name: åŒ¹é…ç­–ç•¥åç§° ("precision", "approximate", "severe")
            has_any_replay_notes: æ˜¯å¦æœ‰æ’­æ”¾éŸ³ç¬¦

        Returns:
            MatchResult: åŒ¹é…ç»“æœ
        """
        note_info = self._extract_note_info(record_note, record_index)

        # åªåœ¨æŒ‡å®šçš„ç­–ç•¥ä¸­è¿›è¡ŒåŒ¹é…
        replay_notes_only = [note for _, note in replay_notes_with_indices]
        candidates, reason = self._find_candidates_in_key_group(
            replay_notes_only, note_info["keyon"], note_info["keyoff"],
            note_info["key_id"], search_mode=strategy_name
        )

        if candidates:
            # ä»å€™é€‰åˆ—è¡¨ä¸­é€‰æ‹©æœ€ä½³çš„ï¼ˆç¬¬ä¸€ä¸ªï¼Œå› ä¸ºå·²ç»æŒ‰è¯¯å·®æ’åºï¼‰
            chosen = candidates[0]  # è´ªå¿ƒé€‰æ‹©ï¼šé€‰æ‹©è¯¯å·®æœ€å°çš„ä¸€ä¸ª

            # æ„å»ºåŒ¹é…å¯¹
            replay_note = chosen.note
            pair = (record_note, replay_note)

            # æ ¹æ®å®é™…è¯¯å·®ç¡®å®šåŒ¹é…ç±»å‹
            actual_match_type = self._evaluate_match_quality(chosen.error_ms)

            # ä»è¿‡æ»¤åˆ—è¡¨ä¸­æ‰¾åˆ°å¯¹åº”çš„åŸå§‹ç´¢å¼•
            replay_orig_idx = replay_notes_with_indices[chosen.index][0]

            return self._create_match_result(
                actual_match_type, record_index, replay_orig_idx, chosen,
                record_note, replay_note
            )

        # å½“å‰ç­–ç•¥åŒ¹é…å¤±è´¥
        return self._create_match_result(
            MatchType.FAILED, record_index, reason=f"{strategy_name}ç­–ç•¥æ— ç¬¦åˆå€™é€‰"
        )

    def _perform_single_note_matching_within_key_group(self, record_note: Note, record_index: int,
                                                     replay_notes_with_indices: List[Tuple[int, Note]],
                                                     has_any_replay_notes: bool = True) -> MatchResult:
        """
        åœ¨æŒ‰é”®ç»„å†…éƒ¨è¿›è¡Œå•ä¸ªéŸ³ç¬¦åŒ¹é…

        Args:
            record_note: å½•åˆ¶éŸ³ç¬¦
            record_index: å½•åˆ¶éŸ³ç¬¦çš„åŸå§‹ç´¢å¼•
            replay_notes_with_indices: è¯¥æŒ‰é”®çš„æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨ï¼ˆå·²è¿‡æ»¤æœªä½¿ç”¨çš„ï¼‰[(orig_idx, note), ...]

        Returns:
            MatchResult: åŒ¹é…ç»“æœ
        """
        note_info = self._extract_note_info(record_note, record_index)

        # å®šä¹‰åŒ¹é…ç­–ç•¥ï¼šåˆ†å±‚æœç´¢ï¼Œç¡®ä¿æ‰¾åˆ°æœ€ä½³åŒ¹é…
        match_strategies = [
            ("precision", self.precision_matched_pairs),     # ç¬¬ä¸€ä¼˜å…ˆçº§: ç²¾ç¡®æœç´¢ (â‰¤50ms)
            ("approximate", self.approximate_matched_pairs), # ç¬¬äºŒä¼˜å…ˆçº§: æ‰©å±•æœç´¢ (50ms-1000ms)
            ("severe", self.severe_matched_pairs),          # ç¬¬ä¸‰ä¼˜å…ˆçº§: ä¸¥é‡è¯¯å·®æœç´¢ (>1000ms)
        ]

        # æŒ‰é¡ºåºå°è¯•æ¯ç§åŒ¹é…ç­–ç•¥
        for search_mode, record_list in match_strategies:
            # åªä¼ å…¥éŸ³ç¬¦åˆ—è¡¨ç»™ _find_candidates_in_key_group
            replay_notes_only = [note for _, note in replay_notes_with_indices]
            candidates, reason = self._find_candidates_in_key_group(
                replay_notes_only, note_info["keyon"], note_info["keyoff"],
                note_info["key_id"], search_mode=search_mode
            )

            if candidates:
                # ä»å€™é€‰åˆ—è¡¨ä¸­é€‰æ‹©æœ€ä½³çš„ï¼ˆç¬¬ä¸€ä¸ªï¼Œå› ä¸ºå·²ç»æŒ‰è¯¯å·®æ’åºï¼‰
                chosen = candidates[0]  # è´ªå¿ƒé€‰æ‹©ï¼šé€‰æ‹©è¯¯å·®æœ€å°çš„ä¸€ä¸ª

                # æ„å»ºåŒ¹é…å¯¹
                replay_note = chosen.note
                pair = (record_note, replay_note)

                # æ ¹æ®å®é™…è¯¯å·®ç¡®å®šåŒ¹é…ç±»å‹
                actual_match_type = self._evaluate_match_quality(chosen.error_ms)

                # ä»è¿‡æ»¤åˆ—è¡¨ä¸­æ‰¾åˆ°å¯¹åº”çš„åŸå§‹ç´¢å¼•
                replay_orig_idx = replay_notes_with_indices[chosen.index][0]

                return self._create_match_result(
                    actual_match_type, record_index, replay_orig_idx, chosen,
                    record_note, replay_note
                )

        # æ‰€æœ‰æœç´¢éƒ½å¤±è´¥ - ç”±ä¸Šçº§ç»Ÿä¸€åˆ†æä¸¢é”¤å¤šé”¤
        return self._create_match_result(
            MatchType.FAILED, record_index, reason="æ— ç¬¦åˆè¯¯å·®èŒƒå›´çš„å€™é€‰"
        )

    def _find_candidates_in_key_group(self, replay_notes: List[Note], target_keyon: float, target_keyoff: float,
                                    target_key_id: int, search_mode: str = "precision") -> Tuple[List[Candidate], str]:
        """
        åœ¨æŒ‰é”®ç»„å†…éƒ¨å¯»æ‰¾å€™é€‰åŒ¹é…

        Args:
            replay_notes: è¯¥æŒ‰é”®çš„æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨
            target_keyon: ç›®æ ‡æŒ‰é”®å¼€å§‹æ—¶é—´
            target_keyoff: ç›®æ ‡æŒ‰é”®ç»“æŸæ—¶é—´
            target_key_id: ç›®æ ‡æŒ‰é”®ID
            search_mode: æœç´¢æ¨¡å¼

        Returns:
            Tuple[List[Candidate], str]: (å€™é€‰åˆ—è¡¨, å¤±è´¥åŸå› )
        """
        candidates = []

        for idx, replay_note in enumerate(replay_notes):
            # éªŒè¯æŒ‰é”®IDåŒ¹é…ï¼ˆè™½ç„¶ç†è®ºä¸Šåº”è¯¥éƒ½åŒ¹é…ï¼‰
            if getattr(replay_note, 'id', None) != target_key_id:
                continue

            # è®¡ç®—æ—¶é—´è¯¯å·®ï¼ˆåªä½¿ç”¨keyon_offsetï¼‰
            replay_keyon, _ = self._calculate_note_times(replay_note)
            keyon_offset = replay_keyon - target_keyon
            total_error = abs(keyon_offset)

            candidates.append(Candidate(idx, total_error, replay_note))

        # æŒ‰è¯¯å·®å‡åºæ’åº
        candidates.sort(key=lambda x: x.total_error)

        # æ ¹æ®æœç´¢æ¨¡å¼åº”ç”¨é˜ˆå€¼è¿‡æ»¤
        if search_mode == "precision":
            filtered = [c for c in candidates if c.total_error <= FAIR_THRESHOLD]
            if not filtered:
                best_error = min(c.error_ms for c in candidates) if candidates else 0
                return [], f"æ— ç²¾ç¡®å€™é€‰(æœ€ä½³è¯¯å·®:{best_error:.1f}ms, é˜ˆå€¼:{FAIR_THRESHOLD/10:.1f}ms)"
        elif search_mode == "approximate":
            filtered = [c for c in candidates if FAIR_THRESHOLD < c.total_error <= POOR_THRESHOLD]
            if not filtered:
                return [], f"æ— è¿‘ä¼¼å€™é€‰(é˜ˆå€¼:{FAIR_THRESHOLD/10:.1f}-{POOR_THRESHOLD/10:.1f}ms)"
        elif search_mode == "severe":
            filtered = [c for c in candidates if c.total_error > POOR_THRESHOLD]
            if not filtered:
                return [], f"æ— ä¸¥é‡è¯¯å·®å€™é€‰(é˜ˆå€¼:>{POOR_THRESHOLD/10:.1f}ms)"
        else:
            filtered = candidates

        return filtered, ""

    def _group_notes_by_key(self, notes: List[Note]) -> Dict[int, List[Tuple[int, Note]]]:
        """
        æŒ‰æŒ‰é”®IDåˆ†ç»„éŸ³ç¬¦æ•°æ®

        Args:
            notes: éŸ³ç¬¦åˆ—è¡¨

        Returns:
            Dict[int, List[Tuple[int, Note]]]: key=æŒ‰é”®ID, value=(åŸå§‹ç´¢å¼•, éŸ³ç¬¦)åˆ—è¡¨
        """
        grouped = defaultdict(list)
        for i, note in enumerate(notes):
            grouped[note.id].append((i, note))
        return dict(grouped)

    def _calculate_global_statistics(self):
        """è®¡ç®—å…¨å±€ç»Ÿè®¡ä¿¡æ¯ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        # è¿™ä¸ªæ–¹æ³•ä¸»è¦ç”¨äºä¿æŒå‘åå…¼å®¹æ€§
        # å®é™…çš„ç»Ÿè®¡ä¿¡æ¯å·²ç»åœ¨_match_notes_for_single_keyä¸­è®¡ç®—äº†
        pass

    def _calculate_key_statistics_from_matches(self, record_by_key: Dict[int, List[Tuple[int, Note]]],
                                             replay_by_key: Dict[int, List[Tuple[int, Note]]]):
        """åŸºäºåŒ¹é…ç»“æœè®¡ç®—æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("ğŸ“Š å¼€å§‹è®¡ç®—æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯...")

        # åˆå§‹åŒ–æ‰€æœ‰æŒ‰é”®çš„ç»Ÿè®¡ä¿¡æ¯
        for key_id in set(record_by_key.keys()) | set(replay_by_key.keys()):
            key_stats = KeyMatchStatistics(key_id)
            key_stats.total_record_notes = len(record_by_key.get(key_id, []))
            key_stats.total_replay_notes = len(replay_by_key.get(key_id, []))
            self.key_statistics[key_id] = key_stats

        # åŸºäºåŒ¹é…ç»“æœæ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        for match_result in self.match_results:
            # è·å–å½•åˆ¶éŸ³ç¬¦çš„æŒ‰é”®ID
            record_note = self._record_data[match_result.record_index]
            key_id = record_note.id

            if key_id not in self.key_statistics:
                continue

            key_stats = self.key_statistics[key_id]

            if match_result.is_success:
                # è®¡ç®—æ ¡å‡†ååç§»
                record_keyon, _ = self._calculate_note_times(record_note)
                replay_keyon, _ = self._calculate_note_times(match_result.pair[1])
                raw_offset = replay_keyon - record_keyon
                corrected_offset = raw_offset - self.global_time_offset
                corrected_offset_ms = corrected_offset / 10.0

                # åªç»Ÿè®¡è¯¯å·®â‰¤50msçš„åŒ¹é…å¯¹ç”¨äºæ¡å½¢å›¾
                if abs(corrected_offset_ms) <= 50.0:
                    key_stats.add_match_result(match_result, corrected_offset_ms)
            else:
                # è®°å½•å¤±è´¥åŒ¹é…
                key_stats.failed_count += 1

        # è®¡ç®—æ¯ä¸ªæŒ‰é”®çš„ç»Ÿè®¡å€¼
        for key_stats in self.key_statistics.values():
            if key_stats.matched_count > 0:
                key_stats.calculate_statistics()

    def _log_key_matching_statistics(self):
        """è®°å½•æŒ‰é”®çº§åˆ«çš„åŒ¹é…ç»Ÿè®¡æ—¥å¿—"""
        logger.info("ğŸ“Š æŒ‰é”®åŒ¹é…ç»Ÿè®¡æ±‡æ€»:")

        # æŒ‰æŒ‰é”®IDæ’åºè¾“å‡º
        for key_id in sorted(self.key_statistics.keys()):
            key_stats = self.key_statistics[key_id]
            match_rate = (key_stats.matched_count / key_stats.total_record_notes * 100) if key_stats.total_record_notes > 0 else 0

            if key_stats.matched_count > 0:
                logger.info(f"ğŸ¹ æŒ‰é”®{key_id}: å½•åˆ¶{key_stats.total_record_notes} â†’ åŒ¹é…{key_stats.matched_count} â†’ "
                           f"å¤±è´¥{key_stats.failed_count} (åŒ¹é…ç‡: {match_rate:.1f}%, "
                           f"å‡å€¼: {key_stats.mean_offset:.2f}ms, æ ‡å‡†å·®: {key_stats.std_offset:.2f}ms)")
            else:
                logger.info(f"ğŸ¹ æŒ‰é”®{key_id}: å½•åˆ¶{key_stats.total_record_notes} â†’ åŒ¹é…{key_stats.matched_count} â†’ "
                           f"å¤±è´¥{key_stats.failed_count} (åŒ¹é…ç‡: {match_rate:.1f}%)")

        # æ€»ä½“ç»Ÿè®¡
        total_keys = len(self.key_statistics)
        keys_with_matches = sum(1 for stats in self.key_statistics.values() if stats.matched_count > 0)
        total_record_notes = sum(stats.total_record_notes for stats in self.key_statistics.values())
        total_matched = sum(stats.matched_count for stats in self.key_statistics.values())
        total_failed = sum(stats.failed_count for stats in self.key_statistics.values())

        overall_match_rate = (total_matched / total_record_notes * 100) if total_record_notes > 0 else 0

        logger.info(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡: {total_keys}ä¸ªæŒ‰é”®, {keys_with_matches}ä¸ªæŒ‰é”®æœ‰åŒ¹é…, "
                   f"æ€»å½•åˆ¶éŸ³ç¬¦: {total_record_notes}, æˆåŠŸåŒ¹é…: {total_matched}, å¤±è´¥: {total_failed}, "
                   f"æ•´ä½“åŒ¹é…ç‡: {overall_match_rate:.1f}%")


    def get_key_statistics_for_bar_chart(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯ç”¨äºæ¡å½¢ç»Ÿè®¡å›¾

        ç›´æ¥ä½¿ç”¨é¢„è®¡ç®—çš„æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯ï¼Œé¿å…é‡å¤è®¡ç®—

        Returns:
            List[Dict[str, Union[int, float]]]: æŒ‰é”®ç»Ÿè®¡æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
            - key_id: æŒ‰é”®ID
            - median: ä¸­ä½æ•°åç§» (ms)
            - mean: å‡å€¼åç§» (ms)
            - std: æ ‡å‡†å·® (ms)
            - variance: æ–¹å·® (msÂ²)
            - count: è¯¥æŒ‰é”®æˆåŠŸåŒ¹é…å¯¹æ•°é‡
        """
        result = []

        for key_id, key_stats in self.key_statistics.items():
            # åªåŒ…å«æœ‰åŒ¹é…æ•°æ®çš„æŒ‰é”®
            if key_stats.matched_count > 0 and key_stats.offsets_ms:
                result.append({
                    'key_id': key_id,
                    'median': key_stats.median_offset,
                    'mean': key_stats.mean_offset,
                    'std': key_stats.std_offset,
                    'variance': key_stats.variance_offset,
                    'count': key_stats.matched_count,
                    'status': 'matched'
                })

        # æŒ‰æŒ‰é”®IDæ’åº
        result.sort(key=lambda x: x['key_id'])

        logger.debug(f"ğŸ“Š æ¡å½¢ç»Ÿè®¡å›¾æ•°æ®: {len(result)}ä¸ªæŒ‰é”®æœ‰ç»Ÿè®¡ä¿¡æ¯")
        return result

    def _find_candidates(self, notes_list: List[Note], target_keyon: float, target_keyoff: float,
                        target_key_id: int, time_offset: float = 0.0, search_mode: str = "precision") -> Tuple[List[Candidate], str]:
        """
        ç”Ÿæˆå€™é€‰åˆ—è¡¨ï¼Œæ”¯æŒä¸åŒçš„æœç´¢æ¨¡å¼ã€‚

        å‚æ•°å•ä½ï¼š
            - target_keyon/target_keyoffï¼š0.1msï¼ˆç»å¯¹æ—¶é—´ = after_touch.index + offsetï¼‰
            - è¯¯å·®ï¼š0.1msï¼ˆå†…éƒ¨ç»Ÿä¸€å•ä½ï¼‰

        Args:
            notes_list: éŸ³ç¬¦åˆ—è¡¨
            target_keyon: ç›®æ ‡æŒ‰é”®å¼€å§‹æ—¶é—´
            target_keyoff: ç›®æ ‡æŒ‰é”®ç»“æŸæ—¶é—´
            target_key_id: ç›®æ ‡æŒ‰é”®ID
            time_offset: æ—¶é—´åç§»
            search_mode: æœç´¢æ¨¡å¼ ("precision" æˆ– "approximate")

        Returns:
            (candidates, reason_if_empty)
        """
        # 1) è¿‡æ»¤åŒé”®IDçš„éŸ³ç¬¦
        matching_notes = []
        for idx, note in enumerate(notes_list):
            if getattr(note, 'id', None) == target_key_id:
                matching_notes.append((idx, note))

        if not matching_notes:
            return [], f"æ²¡æœ‰æ‰¾åˆ°é”®ID {target_key_id} çš„éŸ³ç¬¦"

        # 2) æ„å»ºå€™é€‰å¹¶è®¡ç®—è¯¯å·®
        candidates: List[Candidate] = []
        for idx, note in matching_notes:
            # è®¡ç®—æŒ‰é”®å¼€å§‹æ—¶é—´ï¼ˆåº”ç”¨æ—¶é—´åç§»ï¼‰
            try:
                current_keyon = note.after_touch.index[0] + note.offset + time_offset
            except (IndexError, AttributeError) as e:
                raise ValueError(f"éŸ³ç¬¦ID {note.id} çš„after_touchæ•°æ®æ— æ•ˆ: {e}") from e

            # åªä½¿ç”¨keyon_offsetè®¡ç®—è¯¯å·®
            keyon_offset = current_keyon - target_keyon
            total_error = abs(keyon_offset)

            candidates.append(Candidate(idx, total_error))

        # 3) æ ¹æ®æœç´¢æ¨¡å¼åº”ç”¨é˜ˆå€¼è¿‡æ»¤ - åˆ†å±‚æœç´¢ç­–ç•¥
        if search_mode == "precision":
            # ç²¾ç¡®æœç´¢ï¼šä¼˜å…ˆå¯»æ‰¾é«˜è´¨é‡åŒ¹é… (â‰¤ FAIR_THRESHOLD = 50ms)
            # è¿™ä¸ªé˜ˆå€¼ä¸è¯„çº§ä¸­çš„fairé˜ˆå€¼ä¸€è‡´ï¼Œç¡®ä¿ä¸ä¼šå½±å“è¯„çº§åˆ†å¸ƒ
            filtered = [c for c in candidates if c.total_error <= FAIR_THRESHOLD]
            if not filtered:
                # æ²¡æœ‰ç²¾ç¡®å€™é€‰ï¼Œè¿”å›ç©ºåˆ—è¡¨å’ŒåŸå› 
                best_error = min(c.error_ms for c in candidates) if candidates else 0
                return [], f"æ— ç²¾ç¡®å€™é€‰(æœ€ä½³è¯¯å·®:{best_error:.1f}ms, é˜ˆå€¼:{FAIR_THRESHOLD/10:.1f}ms)"
        elif search_mode == "approximate":
            # è¿‘ä¼¼æœç´¢ï¼šå½“ç²¾ç¡®æœç´¢å¤±è´¥æ—¶ï¼Œå¯»æ‰¾å¯æ¥å—çš„åŒ¹é… (50ms-1000ms)
            # é¿å…ä¸precisionæ¨¡å¼é‡å ï¼Œç¡®ä¿è¯„çº§é€»è¾‘ä¸å—å½±å“
            filtered = [c for c in candidates if FAIR_THRESHOLD < c.total_error <= POOR_THRESHOLD]
            if not filtered:
                return [], f"æ— è¿‘ä¼¼å€™é€‰(é˜ˆå€¼:{FAIR_THRESHOLD/10:.1f}-{POOR_THRESHOLD/10:.1f}ms)"
        elif search_mode == "severe":
            # ä¸¥é‡è¯¯å·®æœç´¢ï¼šåªæ¥å—è¯¯å·®å¾ˆå¤§çš„åŒ¹é… (>1000ms)
            # è¿™äº›åŒ¹é…ä¼šè¢«è¯„ä¸ºSEVEREç±»å‹
            filtered = [c for c in candidates if c.total_error > POOR_THRESHOLD]
            if not filtered:
                return [], f"æ— ä¸¥é‡è¯¯å·®å€™é€‰(é˜ˆå€¼:>{POOR_THRESHOLD/10:.1f}ms)"
        else:
            filtered = candidates

        # æŒ‰è¯¯å·®å‡åºæ’åº
        filtered.sort(key=lambda x: x.total_error)
        return filtered, ""

    def _evaluate_match_quality(self, error_ms: float) -> MatchType:
        """
        æ ¹æ®è¯¯å·®è¯„ä¼°åŒ¹é…è´¨é‡ - å…­ç­‰çº§æ ‡å‡†

        Args:
            error_ms: è¯¯å·®(æ¯«ç§’)

        Returns:
            MatchType: åŒ¹é…ç±»å‹
        """
        error_units = error_ms * 10.0  # è½¬æ¢ä¸ºå†…éƒ¨å•ä½

        if error_units <= EXCELLENT_THRESHOLD:
            return MatchType.EXCELLENT
        elif error_units <= GOOD_THRESHOLD:
            return MatchType.GOOD
        elif error_units <= FAIR_THRESHOLD:
            return MatchType.FAIR
        elif error_units <= POOR_THRESHOLD:
            return MatchType.POOR
        else:
            return MatchType.SEVERE

    def _create_match_result(self, match_type: MatchType, record_index: int,
                           replay_index: Optional[int] = None, candidate: Optional[Candidate] = None,
                           record_note: Optional[Note] = None, replay_note: Optional[Note] = None,
                           reason: str = "") -> MatchResult:
        """
        åˆ›å»ºåŒ¹é…ç»“æœå¯¹è±¡

        Args:
            match_type: åŒ¹é…ç±»å‹
            record_index: å½•åˆ¶éŸ³ç¬¦ç´¢å¼•
            replay_index: æ’­æ”¾éŸ³ç¬¦ç´¢å¼•
            candidate: å€™é€‰å¯¹è±¡
            record_note: å½•åˆ¶éŸ³ç¬¦
            replay_note: æ’­æ”¾éŸ³ç¬¦
            reason: å¤±è´¥åŸå› 

        Returns:
            MatchResult: åŒ¹é…ç»“æœå¯¹è±¡
        """
        error_ms = candidate.error_ms if candidate else 0.0
        pair = (record_note, replay_note) if record_note and replay_note else None

        return MatchResult(
            match_type=match_type,
            record_index=record_index,
            replay_index=replay_index,
            error_ms=error_ms,
            pair=pair,
            reason=reason
        )

    def _calculate_global_time_offset(self, record_data: List[Note], replay_data: List[Note]) -> float:
        """
        è®¡ç®—å…¨å±€æ—¶é—´åç§»é‡ï¼ˆç³»ç»Ÿå›ºå®šå»¶æ—¶ï¼‰

        ç›®å‰ï¼šæš‚æ—¶ç¦ç”¨DTWç®—æ³•ï¼Œç›´æ¥è¿”å›0
        ä¹‹å‰çš„ç­–ç•¥ï¼ˆå·²æ³¨é‡Šï¼‰ï¼š
        1. æå–å½•åˆ¶å’Œæ’­æ”¾çš„æŒ‰é”®æ—¶é—´åºåˆ—
        2. ä½¿ç”¨DTWç®—æ³•è®¡ç®—åºåˆ—é—´çš„å¯¹åº”å…³ç³»
        3. ä»DTWè·¯å¾„ä¸­æ¨å¯¼å‡ºå…¨å±€æ—¶é—´åç§»

        DTWä¼˜ç‚¹ï¼šå¯ä»¥å¤„ç†å¤æ‚çš„æ—¶åºå¯¹é½ï¼Œä¸ä»…ä»…æ˜¯å›ºå®šåç§»
        è™½ç„¶DTWä¼šäº§ç”Ÿä¸€å¯¹å¤šçš„æƒ…å†µï¼Œä½†è¿™é‡Œåªæ˜¯ä¼°ç®—å…¨å±€åç§»ï¼Œåç»­åŒ¹é…ä¼šé‡æ–°å¤„ç†

        Returns:
            float: å…¨å±€æ—¶é—´åç§»é‡ï¼ˆ0.1mså•ä½ï¼‰ï¼Œç›®å‰å›ºå®šè¿”å›0
        """

        # æš‚æ—¶ç¦ç”¨DTWç®—æ³•ï¼Œç›´æ¥è¿”å›0
        logger.info("â„¹ï¸ å…¨å±€æ—¶é—´åç§»è®¡ç®—å·²ç¦ç”¨ï¼Œè¿”å›0ï¼ˆDTWç®—æ³•å·²æ³¨é‡Šï¼‰")
        return 0.0

        # ==================== DTWç®—æ³•ä»£ç å·²æ³¨é‡Š ====================
        #
        # # 1. æå–æ—¶é—´åºåˆ—ï¼ˆæŒ‰é”®å¼€å§‹æ—¶é—´ï¼‰
        # record_times = []
        # replay_times = []
        #
        # # æŒ‰æ—¶é—´æ’åºå½•åˆ¶éŸ³ç¬¦
        # sorted_record = sorted(record_data, key=lambda n: n.after_touch.index[0] + n.offset)
        # for note in sorted_record:
        #     start_time, _ = self._calculate_note_times(note)
        #     record_times.append(start_time)
        #
        # # æŒ‰æ—¶é—´æ’åºæ’­æ”¾éŸ³ç¬¦
        # sorted_replay = sorted(replay_data, key=lambda n: n.after_touch.index[0] + n.offset)
        # for note in sorted_replay:
        #     start_time, _ = self._calculate_note_times(note)
        #     replay_times.append(start_time)
        #
        #
        # # 2. è®¡ç®—DTWè·ç¦»çŸ©é˜µ
        # record_array = np.array(record_times)
        # replay_array = np.array(replay_times)
        #
        # # å½’ä¸€åŒ–æ—¶é—´åºåˆ—ï¼ˆå‡å»å„è‡ªçš„èµ·å§‹æ—¶é—´ï¼‰
        # record_norm = record_array - record_array[0]
        # replay_norm = replay_array - replay_array[0]
        #
        # # è®¡ç®—è·ç¦»çŸ©é˜µ
        # distances = np.abs(record_norm[:, np.newaxis] - replay_norm[np.newaxis, :])
        #
        # # 3. DTWåŠ¨æ€è§„åˆ’
        # n, m = len(record_norm), len(replay_norm)
        # dtw_matrix = np.full((n, m), np.inf)
        # dtw_matrix[0, 0] = distances[0, 0]
        #
        # # å¡«å……ç¬¬ä¸€è¡Œå’Œç¬¬ä¸€åˆ—
        # for i in range(1, n):
        #     dtw_matrix[i, 0] = dtw_matrix[i-1, 0] + distances[i, 0]
        # for j in range(1, m):
        #     dtw_matrix[0, j] = dtw_matrix[0, j-1] + distances[0, j]
        #
        # # å¡«å……å…¶ä½™éƒ¨åˆ†
        # for i in range(1, n):
        #     for j in range(1, m):
        #         cost = distances[i, j]
        #         dtw_matrix[i, j] = cost + min(
        #             dtw_matrix[i-1, j],    # ä¸Šæ–¹
        #             dtw_matrix[i, j-1],    # å·¦æ–¹
        #             dtw_matrix[i-1, j-1]   # å¯¹è§’çº¿
        #         )
        #
        # # 4. å›æº¯æ‰¾åˆ°æœ€ä¼˜è·¯å¾„
        # path = []
        # i, j = n-1, m-1
        # path.append((i, j))
        #
        # while i > 0 or j > 0:
        #     if i == 0:
        #         j -= 1
        #     elif j == 0:
        #         i -= 1
        #     else:
        #         min_prev = min(
        #             dtw_matrix[i-1, j],    # ä¸Šæ–¹
        #             dtw_matrix[i, j-1],    # å·¦æ–¹
        #             dtw_matrix[i-1, j-1]   # å¯¹è§’çº¿
        #         )
        #         if dtw_matrix[i-1, j-1] == min_prev:
        #             i, j = i-1, j-1
        #         elif dtw_matrix[i-1, j] == min_prev:
        #             i -= 1
        #         else:
        #             j -= 1
        #     path.append((i, j))
        #
        # path.reverse()
        #
        # # 5. ä»DTWè·¯å¾„è®¡ç®—æ—¶é—´åç§»
        # time_diffs = []
        # for rec_idx, rep_idx in path:
        #     if rec_idx < len(record_times) and rep_idx < len(replay_times):
        #         diff = replay_times[rep_idx] - record_times[rec_idx]
        #         time_diffs.append(diff)
        #
        # if not time_diffs:
        #     logger.warning("âš ï¸ DTWè·¯å¾„ä¸ºç©ºï¼Œå›é€€åˆ°ç®€å•æ–¹æ³•")
        #     return self._calculate_global_time_offset_simple(record_data, replay_data)
        #
        # # 6. æ£€æŸ¥è·¯å¾„è´¨é‡
        # # 6.2 æ£€æŸ¥æ—¶é—´å·®æ–¹å·®æ˜¯å¦å¤ªå¤§ï¼ˆæ–¹å·®è¿‡å¤§è¡¨ç¤ºå¯¹é½è´¨é‡å·®ï¼‰
        # # å°†æ—¶é—´å·®è½¬æ¢ä¸ºmså•ä½è¿›è¡Œæ–¹å·®è®¡ç®—
        # # time_diffs_ms = np.array(time_diffs) / 10.0
        # # variance_ms = float(np.var(time_diffs_ms))
        #
        # # # æ–¹å·®é˜ˆå€¼ï¼šå¦‚æœæ—¶é—´å·®çš„æ ‡å‡†å·®è¶…è¿‡50msï¼Œè®¤ä¸ºå¯¹é½è´¨é‡å¤ªå·®
        # # # (50ms)^2 = 2500 msÂ²
        # # max_variance_threshold = 2500.0
        # # if variance_ms > max_variance_threshold:
        # #     logger.warning(f"âš ï¸ DTWè·¯å¾„æ–¹å·®å¤ªå¤§({variance_ms:.1f} > {max_variance_threshold} msÂ²)ï¼Œè´¨é‡ä¸è¶³ï¼Œå›é€€åˆ°ç®€å•æ–¹æ³•")
        # #     return self._calculate_global_time_offset_simple(record_data, replay_data)
        #
        # # 6.3 è®¡ç®—åŠ æƒå¹³å‡åç§»ï¼ˆè€ƒè™‘DTWè·¯å¾„çš„å±€éƒ¨å·®å¼‚ï¼‰
        # # ä½¿ç”¨ä¸­ä½æ•°é¿å…å¼‚å¸¸å€¼å½±å“
        # median_offset = float(np.median(time_diffs))
        #
        # # 6.4 åˆç†æ€§æ£€æŸ¥ï¼šå…¨å±€åç§»ä¸åº”è¶…è¿‡åˆç†èŒƒå›´
        # # å¦‚æœåç§»è¿‡å¤§ï¼Œè¯´æ˜DTWå¯¹é½å¯èƒ½æœ‰é—®é¢˜ï¼Œå›é€€åˆ°ç®€å•æ–¹æ³•
        # max_reasonable_offset = 5000.0  # 500ms (0.1mså•ä½)
        # if abs(median_offset) > max_reasonable_offset:
        #     logger.warning(f"âš ï¸ DTWè®¡ç®—çš„å…¨å±€åç§»è¿‡å¤§({median_offset/10:.2f}ms > {max_reasonable_offset/10:.0f}ms)ï¼Œ"
        #                  f"å¯èƒ½å¯¹é½æœ‰é—®é¢˜ï¼Œå›é€€åˆ°ç®€å•æ–¹æ³•")
        #     return self._calculate_global_time_offset_simple(record_data, replay_data)
        #
        # logger.info(f"ğŸ¯ DTWè®¡ç®—å¾—åˆ°å…¨å±€æ—¶é—´åç§»(Median): {median_offset/10:.2f}ms (åŸºäº {len(time_diffs)} ä¸ªè·¯å¾„ç‚¹)")
        #
        # return median_offset
        #
        # ==================== DTWç®—æ³•ä»£ç å·²æ³¨é‡Šç»“æŸ ====================

    # def _calculate_global_time_offset_simple(self, record_data: List[Note], replay_data: List[Note]) -> float:
    #     """
    #     ç®€å•çš„å…¨å±€æ—¶é—´åç§»è®¡ç®—æ–¹æ³•ï¼ˆå½“DTWä¸å¯ç”¨æ—¶çš„å›é€€æ–¹æ¡ˆï¼‰

    #     ç­–ç•¥ï¼š
    #     1. éå†å½•åˆ¶éŸ³ç¬¦
    #     2. åœ¨æ’­æ”¾æ•°æ®ä¸­å¯»æ‰¾ç›¸åŒKeyIDä¸”æ—¶é—´æœ€è¿‘çš„éŸ³ç¬¦
    #     3. æ”¶é›†æ—¶é—´å·®
    #     4. å–ä¸­ä½æ•°ä½œä¸ºå…¨å±€åç§»

    #     Returns:
    #         float: å…¨å±€æ—¶é—´åç§»é‡ï¼ˆ0.1mså•ä½ï¼‰
    #     """
    #     time_diffs = []

    #     # å»ºç«‹æ’­æ”¾æ•°æ®çš„å¿«é€ŸæŸ¥æ‰¾ç´¢å¼•ï¼šKeyID -> List[Note]
    #     replay_map = {}
    #     for r_note in replay_data:
    #         if r_note.id not in replay_map:
    #             replay_map[r_note.id] = []
    #         replay_map[r_note.id].append(r_note)

    #     for record_note in record_data:
    #         # å¯»æ‰¾ç›¸åŒKeyIDçš„æ’­æ”¾éŸ³ç¬¦
    #         if record_note.id not in replay_map:
    #             continue

    #         candidates = replay_map[record_note.id]
    #         if not candidates:
    #             continue

    #         # è®¡ç®—å½•åˆ¶æ—¶é—´
    #         rec_start, _ = self._calculate_note_times(record_note)

    #         # å¯»æ‰¾æœ€è¿‘çš„å€™é€‰
    #         best_diff = None
    #         min_abs_diff = float('inf')

    #         for replay_note in candidates:
    #             rep_start, _ = self._calculate_note_times(replay_note)
    #             diff = rep_start - rec_start
    #             abs_diff = abs(diff)

    #             # ä½¿ç”¨ä¸€ä¸ªè¾ƒå®½çš„çª—å£ï¼ˆä¾‹å¦‚2ç§’ï¼‰ï¼Œé¿å…åŒ¹é…åˆ°å®Œå…¨ä¸ç›¸å…³çš„éŸ³ç¬¦
    #             # 20000 = 2000ms = 2s
    #             if abs_diff < 20000:
    #                 if abs_diff < min_abs_diff:
    #                     min_abs_diff = abs_diff
    #                     best_diff = diff

    #         if best_diff is not None:
    #             time_diffs.append(best_diff)

    #     if not time_diffs:
    #         logger.warning("âš ï¸ æ— æ³•è®¡ç®—å…¨å±€åç§»ï¼šæ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ¹é…çš„æŒ‰é”®å¯¹")
    #         return 0.0

    #     # ä½¿ç”¨numpyè®¡ç®—ä¸­ä½æ•°ï¼ˆå¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿï¼‰
    #     median_offset = float(np.median(time_diffs))

    #     # åˆç†æ€§æ£€æŸ¥ï¼šå…¨å±€åç§»ä¸åº”è¶…è¿‡åˆç†èŒƒå›´
    #     max_reasonable_offset = 5000.0  # 500ms (0.1mså•ä½)
    #     if abs(median_offset) > max_reasonable_offset:
    #         logger.warning(f"âš ï¸ ç®€å•æ–¹æ³•è®¡ç®—çš„å…¨å±€åç§»è¿‡å¤§({median_offset/10:.2f}ms > {max_reasonable_offset/10:.0f}ms)ï¼Œ"
    #                      f"é™åˆ¶ä¸ºåˆç†èŒƒå›´")
    #         median_offset = max(-max_reasonable_offset, min(max_reasonable_offset, median_offset))

    #     logger.info(f"ğŸ“Š ç®€å•æ–¹æ³•è®¡ç®—å¾—åˆ°å…¨å±€æ—¶é—´åç§»(Median): {median_offset/10:.2f}ms (åŸºäº {len(time_diffs)} ä¸ªæ ·æœ¬)")

    #     return median_offset

    def _initialize_matching_state(self) -> None:
        """åˆå§‹åŒ–åŒ¹é…çŠ¶æ€"""
        self.failure_reasons.clear()
        self._clear_mean_error_cache()

    def _perform_single_note_matching(self, record_note: Note, record_index: int,
                                     replay_data: List[Note], used_replay_indices: set) -> MatchResult:
        """
        æ‰§è¡Œå•ä¸ªéŸ³ç¬¦çš„åŒ¹é…è¿‡ç¨‹

        æŒ‰ä¼˜å…ˆçº§é¡ºåºå°è¯•ä¸åŒç±»å‹çš„åŒ¹é…ï¼š
        1. ç²¾ç¡®åŒ¹é… (â‰¤50ms)
        2. è¿‘ä¼¼åŒ¹é… (50ms-300ms)
        3. å¤§è¯¯å·®åŒ¹é… (>300ms)
        4. å¤±è´¥

        Args:
            record_note: å½•åˆ¶éŸ³ç¬¦
            record_index: å½•åˆ¶éŸ³ç¬¦ç´¢å¼•
            replay_data: æ’­æ”¾æ•°æ®
            used_replay_indices: å·²ä½¿ç”¨çš„æ’­æ”¾éŸ³ç¬¦ç´¢å¼•é›†åˆ

        Returns:
            MatchResult: åŒ¹é…ç»“æœ
        """
        note_info = self._extract_note_info(record_note, record_index)

        # å®šä¹‰åŒ¹é…ç­–ç•¥ï¼šåˆ†å±‚æœç´¢ï¼Œç¡®ä¿æ‰¾åˆ°æœ€ä½³åŒ¹é…
        # æœç´¢ç­–ç•¥ä¸è¯„çº§é€»è¾‘è§£è€¦ï¼Œé¿å…é˜ˆå€¼å½±å“è¯„çº§åˆ†å¸ƒ
        match_strategies = [
            ("precision", self.precision_matched_pairs),     # ç¬¬ä¸€ä¼˜å…ˆçº§: ç²¾ç¡®æœç´¢ (â‰¤50ms)
            ("approximate", self.approximate_matched_pairs), # ç¬¬äºŒä¼˜å…ˆçº§: æ‰©å±•æœç´¢ (50ms-1000ms)
            ("severe", self.severe_matched_pairs),          # ç¬¬ä¸‰ä¼˜å…ˆçº§: ä¸¥é‡è¯¯å·®æœç´¢ (>1000ms)
        ]

        # æŒ‰é¡ºåºå°è¯•æ¯ç§åŒ¹é…ç­–ç•¥
        for search_mode, record_list in match_strategies:
            candidates, reason = self._find_candidates(
                replay_data, note_info["keyon"], note_info["keyoff"],
                note_info["key_id"], time_offset=0, search_mode=search_mode
            )

            if candidates:
                chosen = self._select_best_candidate_from_list(candidates, used_replay_indices)
                if chosen:
                    # åŒ¹é…æˆåŠŸ
                    replay_index = chosen.index
                    replay_note = replay_data[replay_index]

                    # å¦‚æœéœ€è¦è®°å½•åˆ°ç‰¹æ®Šåˆ—è¡¨ï¼ˆå¦‚è¿‘ä¼¼åŒ¹é…æˆ–å¤§è¯¯å·®åŒ¹é…ï¼‰
                    if record_list is not None:
                        match_pair = (record_index, replay_index, record_note, replay_note)
                        record_list.append(match_pair)

                    used_replay_indices.add(replay_index)

                    # æ ¹æ®å®é™…è¯¯å·®ç¡®å®šåŒ¹é…ç±»å‹
                    actual_match_type = self._evaluate_match_quality(chosen.error_ms)

                    return self._create_match_result(
                        actual_match_type, record_index, replay_index, chosen,
                        record_note, replay_note
                    )

        # æ‰€æœ‰æœç´¢éƒ½å¤±è´¥
        # å¦‚æœæœ‰å€™é€‰ä½†éƒ½è¢«è¿‡æ»¤æ‰äº†ï¼Œè¯´æ˜è¯¯å·®éƒ½ä¸åœ¨æ¥å—èŒƒå›´å†…
        # å¦‚æœæ²¡æœ‰å€™é€‰ï¼Œè¯´æ˜æŒ‰é”®æ²¡æœ‰å¯ç”¨çš„æ’­æ”¾éŸ³ç¬¦
        if candidates:
            # æœ‰å€™é€‰ä½†éƒ½ä¸æ»¡è¶³ä»»ä½•æœç´¢æ¨¡å¼ï¼Œè¯´æ˜è¯¯å·®èŒƒå›´ä¸ç¬¦åˆ
            failure_reason = reason if reason else f"æŒ‰é”®{note_info['key_id']} æ— ç¬¦åˆè¯¯å·®èŒƒå›´çš„å€™é€‰"
        else:
            # æ²¡æœ‰å€™é€‰ï¼Œè¯´æ˜è¯¥æŒ‰é”®æ²¡æœ‰å¯ç”¨çš„æ’­æ”¾éŸ³ç¬¦
            failure_reason = f"æŒ‰é”®{note_info['key_id']} æ— å¯ç”¨æ’­æ”¾éŸ³ç¬¦"

        return self._create_match_result(
            MatchType.FAILED, record_index, reason=failure_reason
        )

    def _select_best_candidate_from_list(self, candidates: List[Candidate], used_indices: set) -> Optional[Candidate]:
        """
        ä»å€™é€‰åˆ—è¡¨ä¸­é€‰æ‹©æœ€ä½³çš„æœªä½¿ç”¨å€™é€‰

        Args:
            candidates: å€™é€‰åˆ—è¡¨ï¼ˆå·²æŒ‰è¯¯å·®æ’åºï¼‰
            used_indices: å·²ä½¿ç”¨çš„ç´¢å¼•é›†åˆ

        Returns:
            Optional[Candidate]: æœ€ä½³å€™é€‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        for candidate in candidates:
            if candidate.index not in used_indices:
                return candidate
        return None



    def _log_successful_match(self, match_pair: Tuple, expanded_candidates: bool) -> None:
        """
        è®°å½•æˆåŠŸçš„åŒ¹é…

        Args:
            match_pair: åŒ¹é…å¯¹
            expanded_candidates: æ˜¯å¦ä¸ºæ‰©å±•å€™é€‰åŒ¹é…
        """
        record_idx, replay_idx, record_note, replay_note = match_pair

        status = "ğŸ”„ åŒ¹é…æˆåŠŸï¼ˆæ‰©å±•å€™é€‰ï¼‰" if expanded_candidates else "âœ… åŒ¹é…æˆåŠŸ"

        # è®¡ç®—æ—¶é—´ä¿¡æ¯ç”¨äºæ—¥å¿—
        record_keyon, record_keyoff = self._calculate_note_times(record_note)
        replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

        # logger.info(f"{status}: é”®ID={record_note.id}, å½•åˆ¶ç´¢å¼•={record_idx}, å›æ”¾ç´¢å¼•={replay_idx}")

    def _log_failed_match(self, record_index: int, record_note: Note, reason: str,
                         candidates: List[Dict], replay_data: List[Note]) -> None:
        """
        è®°å½•å¤±è´¥çš„åŒ¹é…

        Args:
            record_index: å½•åˆ¶éŸ³ç¬¦ç´¢å¼•
            record_note: å½•åˆ¶éŸ³ç¬¦
            reason: å¤±è´¥åŸå› 
            candidates: å€™é€‰åˆ—è¡¨
            replay_data: æ’­æ”¾æ•°æ®
        """
        note_info = self._extract_note_info(record_note, record_index)

        logger.info(f"âŒ åŒ¹é…å¤±è´¥: é”®ID={note_info['key_id']}, å½•åˆ¶ç´¢å¼•={record_index}, "
                   f"å½•åˆ¶æ—¶é—´=({note_info['keyon']/10:.2f}ms, {note_info['keyoff']/10:.2f}ms), "
                   f"åŸå› : {reason}")

        # è®°å½•è¢«å ç”¨çš„å€™é€‰è¯¦ç»†ä¿¡æ¯
        for j, cand in enumerate(candidates[:3]):
            cand_note = replay_data[cand['index']]
            cand_keyon, cand_keyoff = self._calculate_note_times(cand_note)
            logger.info(f"   å€™é€‰{j+1}: å›æ”¾ç´¢å¼•={cand['index']}, "
                       f"å›æ”¾æ—¶é—´=({cand_keyon/10:.2f}ms, {cand_keyoff/10:.2f}ms), "
                       f"æ€»è¯¯å·®={cand['total_error']/10:.2f}ms")

    def _log_matching_statistics(self, record_data: List[Note], replay_data: List[Note],
                                matched_pairs: List, used_replay_indices: set) -> None:
        """
        è®°å½•åŒ¹é…ç»Ÿè®¡ä¿¡æ¯

        Args:
            record_data: å½•åˆ¶æ•°æ®
            replay_data: æ’­æ”¾æ•°æ®
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨
            used_replay_indices: å·²ä½¿ç”¨çš„æ’­æ”¾ç´¢å¼•
        """
        success_count = len(matched_pairs)
        failure_count = len(record_data) - success_count

        logger.info(f"ğŸ“Š åŒ¹é…å®Œæˆ: æˆåŠŸ{success_count}å¯¹, å¤±è´¥{failure_count}å¯¹, "
                   f"æ€»è®¡{len(record_data)}ä¸ªå½•åˆ¶éŸ³ç¬¦, ä½¿ç”¨{len(used_replay_indices)}/{len(replay_data)}ä¸ªæ’­æ”¾éŸ³ç¬¦")

    
    def _extract_note_info(self, note: Note, index: int) -> Dict:
        """
        æå–éŸ³ç¬¦åŸºæœ¬ä¿¡æ¯
        
        Args:
            note: éŸ³ç¬¦å¯¹è±¡
            index: éŸ³ç¬¦ç´¢å¼•
            
        Returns:
            Dict: éŸ³ç¬¦ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ç»å¯¹æ—¶é—´æˆ³
        """
        # è®¡ç®—ç»å¯¹æ—¶é—´æˆ³ï¼ˆafter_touch.index + offsetï¼‰
        # è¿™æ˜¯éŸ³ç¬¦åœ¨æ•´ä¸ªæ—¶é—´çº¿ä¸Šçš„å®é™…å‘ç”Ÿæ—¶é—´
        try:
            absolute_keyon = note.after_touch.index[0] + note.offset
            absolute_keyoff = note.after_touch.index[-1] + note.offset
        except (IndexError, AttributeError) as e:
            raise ValueError(f"éŸ³ç¬¦ID {note.id} çš„after_touchæ•°æ®æ— æ•ˆ: {e}") from e
        
        return {
            'keyon': absolute_keyon,      # ç»å¯¹æ—¶é—´æˆ³ï¼šæŒ‰é”®å¼€å§‹æ—¶é—´
            'keyoff': absolute_keyoff,    # ç»å¯¹æ—¶é—´æˆ³ï¼šæŒ‰é”®ç»“æŸæ—¶é—´
            'key_id': note.id,            # æŒ‰é”®ID
            'index': index                # éŸ³ç¬¦åœ¨åˆ—è¡¨ä¸­çš„ç´¢å¼•
        }
    
    def extract_normal_matched_pairs(self, matched_pairs: List[Tuple[int, int, Note, Note]], 
                                   multi_hammers: List, drop_hammers: List) -> Tuple[List[Note], List[Note]]:
        """
        ä»åŒ¹é…å¯¹ä¸­æå–æ­£å¸¸åŒ¹é…çš„éŸ³ç¬¦å¯¹
        
        Args:
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨
            multi_hammers: å¤šé”¤åˆ—è¡¨
            drop_hammers: ä¸¢é”¤åˆ—è¡¨
            
        Returns:
            Tuple[List[Note], List[Note]]: (matched_record_data, matched_replay_data)
        """
        matched_record_data = []
        matched_replay_data = []
        
        for record_index, replay_index, record_note, replay_note in matched_pairs:
            matched_record_data.append(record_note)
            matched_replay_data.append(replay_note)
        
        return matched_record_data, matched_replay_data
    
    def get_matched_pairs(self) -> List[Tuple[int, int, Note, Note]]:
        """
        è·å–ç²¾ç¡®åŒ¹é…å¯¹åˆ—è¡¨ï¼ˆâ‰¤50msï¼‰

        åªè¿”å›ç²¾ç¡®åŒ¹é…çš„é…å¯¹ï¼Œç”¨äºæŒ‡æ ‡è®¡ç®—å’Œå›¾è¡¨æ˜¾ç¤º

        Returns:
            List[Tuple[int, int, Note, Note]]: ç²¾ç¡®åŒ¹é…å¯¹åˆ—è¡¨
        """
        return self.matched_pairs.copy()
    
    # TODO
    def get_offset_alignment_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–åç§»å¯¹é½æ•°æ® - è®¡ç®—æ¯ä¸ªåŒ¹é…å¯¹çš„æ—¶é—´åç§»ï¼ˆåŒ…æ‹¬è¶…è¿‡é˜ˆå€¼çš„åŒ¹é…å¯¹ï¼‰
        
        Returns:
            List[Dict[str, Union[int, float]]]: åç§»å¯¹é½æ•°æ®åˆ—è¡¨
        """
        offset_data: List[Dict[str, Union[int, float]]] = []
        
        # æ‰€æœ‰åŒ¹é…å¯¹éƒ½åœ¨ matched_pairs ä¸­
        all_matched_pairs = self.matched_pairs

        for record_idx, replay_idx, record_note, replay_note in all_matched_pairs:
            # è®¡ç®—å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦çš„æ—¶é—´
            record_keyon, record_keyoff = self._calculate_note_times(record_note)
            replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

            # è®¡ç®—åŸå§‹åç§»é‡
            keyon_offset = replay_keyon - record_keyon

            # è®¡ç®—æ ¡å‡†åçš„åç§»ï¼ˆå»é™¤å…¨å±€å›ºå®šå»¶æ—¶ï¼‰
            # è¿™åæ˜ äº†éŸ³ç¬¦ç›¸å¯¹äºç³»ç»Ÿå¹³å‡å»¶æ—¶çš„"æŠ–åŠ¨"æˆ–"è¯¯å·®"
            corrected_offset = keyon_offset - self.global_time_offset


            record_duration = record_keyoff - record_keyon
            replay_duration = replay_keyoff - replay_keyon
            duration_diff = replay_duration - record_duration
            duration_offset = duration_diff
            # ä½¿ç”¨æ ¡å‡†åçš„ç»å¯¹è¯¯å·®
            avg_offset = abs(corrected_offset)


            offset_data.append({
                'record_index': record_idx,
                'replay_index': replay_idx,
                'key_id': record_note.id,
                'record_keyon': record_keyon,
                'replay_keyon': replay_keyon,
                'keyon_offset': keyon_offset,       # åŸå§‹åç§»
                'corrected_offset': corrected_offset, # æ ¡å‡†ååç§»ï¼ˆç”¨äºåˆ†æï¼‰
                'record_keyoff': record_keyoff,
                'replay_keyoff': replay_keyoff,
                'duration_offset': duration_offset,
                'average_offset': avg_offset,
                'record_duration': record_duration,
                'replay_duration': replay_duration,
                'duration_diff': duration_diff
            })

        return offset_data

    def get_precision_offset_alignment_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–ç²¾ç¡®æœç´¢é˜¶æ®µåŒ¹é…å¯¹çš„åç§»å¯¹é½æ•°æ® - åŒ…å«æ‰€æœ‰ç²¾ç¡®æœç´¢é˜¶æ®µçš„åŒ¹é…ï¼ˆè¯¯å·® â‰¤ 50msï¼‰

        ç²¾ç¡®æœç´¢é˜¶æ®µï¼šå°è¯•æ‰¾åˆ°è¯¯å·® â‰¤ 50ms çš„åŒ¹é…ï¼Œæœ€ç»ˆåŒ¹é…ç±»å‹å¯èƒ½æ˜¯ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬
        ç”¨äºè®¡ç®—å»¶æ—¶è¯¯å·®ç»Ÿè®¡æŒ‡æ ‡ï¼Œç¡®ä¿åªä½¿ç”¨ç›¸å¯¹é«˜è´¨é‡çš„åŒ¹é…æ•°æ®ã€‚

        Returns:
            List[Dict[str, Union[int, float]]]: ç²¾ç¡®æœç´¢é˜¶æ®µåŒ¹é…å¯¹çš„åç§»å¯¹é½æ•°æ®åˆ—è¡¨
        """
        # ç›´æ¥å¤„ç†precision_matched_pairsä¸­çš„æ‰€æœ‰åŒ¹é…ï¼ˆâ‰¤50msï¼‰
        offset_data = []
        for record_idx, replay_idx, record_note, replay_note in self.precision_matched_pairs:
            # è®¡ç®—å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦çš„æ—¶é—´
            record_keyon, record_keyoff = self._calculate_note_times(record_note)
            replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

            # è·å–é”¤é€Ÿä¿¡æ¯
            record_velocity = self._get_velocity_from_note(record_note)
            replay_velocity = self._get_velocity_from_note(replay_note)

            # è®¡ç®—åŸå§‹åç§»é‡
            keyon_offset = replay_keyon - record_keyon

            # è®¡ç®—æ ¡å‡†åçš„åç§»ï¼ˆå»é™¤å…¨å±€å›ºå®šå»¶æ—¶ï¼‰
            corrected_offset = keyon_offset - self.global_time_offset

            record_duration = record_keyoff - record_keyon
            replay_duration = replay_keyoff - replay_keyon
            duration_diff = replay_duration - record_duration
            duration_offset = duration_diff

            # è®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼ˆç”¨äºæ‚¬åœæ˜¾ç¤ºï¼‰
            relative_delay = corrected_offset / 10.0  # è½¬æ¢ä¸ºms

            offset_data.append({
                'record_index': record_idx,
                'replay_index': replay_idx,
                'key_id': record_note.id,
                'record_keyon': record_keyon,
                'replay_keyon': replay_keyon,
                'record_velocity': record_velocity,    # å½•åˆ¶é”¤é€Ÿ
                'replay_velocity': replay_velocity,    # æ’­æ”¾é”¤é€Ÿ
                'velocity_diff': (replay_velocity - record_velocity) if record_velocity is not None and replay_velocity is not None else None,  # é”¤é€Ÿå·®å€¼
                'keyon_offset': keyon_offset,       # åŸå§‹åç§»
                'corrected_offset': corrected_offset, # æ ¡å‡†ååç§»ï¼ˆç”¨äºåˆ†æï¼‰
                'relative_delay': relative_delay,     # ç›¸å¯¹å»¶æ—¶ï¼ˆmsï¼‰
                'record_keyoff': record_keyoff,
                'replay_keyoff': replay_keyoff,
                'duration_offset': duration_offset,
                'average_offset': abs(corrected_offset),
                'record_duration': record_duration,
                'replay_duration': replay_duration,
                'duration_diff': duration_diff
            })

        return offset_data

    def _get_velocity_from_note(self, note) -> Optional[float]:
        """ä»éŸ³ç¬¦ä¸­è·å–é”¤é€Ÿ"""
        try:
            if not note:
                return None

            # åªä»hammersæ•°æ®ä¸­è·å–é”¤é€Ÿ
            if hasattr(note, 'hammers') and note.hammers is not None:
                if hasattr(note.hammers, 'values') and len(note.hammers.values) > 0:
                    hammer_velocity = note.hammers.values[0]
                    if hammer_velocity is not None and not pd.isna(hammer_velocity):
                        return float(hammer_velocity)
                elif hasattr(note.hammers, 'iloc') and len(note.hammers) > 0:
                    hammer_velocity = note.hammers.iloc[0]
                    if hammer_velocity is not None and not pd.isna(hammer_velocity):
                        return float(hammer_velocity)

            return None

        except Exception as e:
            logger.warning(f"[WARNING] ä»éŸ³ç¬¦æå–é”¤é€Ÿå¤±è´¥: {e}")
            return None

    def get_normal_offset_alignment_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–æ­£å¸¸åŒ¹é…å¯¹çš„åç§»å¯¹é½æ•°æ® - åªè®¡ç®—åœ¨é˜ˆå€¼å†…çš„åŒ¹é…å¯¹çš„æ—¶é—´åç§»

        æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•åªå¤„ç†æ­£å¸¸åŒ¹é…å¯¹ï¼Œä¸åŒ…æ‹¬è¶…è¿‡é˜ˆå€¼çš„åŒ¹é…å¯¹ã€‚
        ç”¨äºè®¡ç®—å‡†ç¡®çš„å»¶æ—¶æŒ‡æ ‡ï¼Œé¿å…å¼‚å¸¸æ•°æ®å½±å“ç»Ÿè®¡ç»“æœã€‚

        Returns:
            List[Dict[str, Union[int, float]]]: æ­£å¸¸åŒ¹é…å¯¹çš„åç§»å¯¹é½æ•°æ®åˆ—è¡¨
        """
        offset_data: List[Dict[str, Union[int, float]]] = []

        # åªå¤„ç†æ­£å¸¸åŒ¹é…å¯¹ï¼ˆåœ¨é˜ˆå€¼å†…çš„åŒ¹é…å¯¹ï¼‰
        for record_idx, replay_idx, record_note, replay_note in self.matched_pairs:
            # è®¡ç®—å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦çš„æ—¶é—´
            record_keyon, record_keyoff = self._calculate_note_times(record_note)
            replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

            # è®¡ç®—åŸå§‹åç§»é‡
            keyon_offset = replay_keyon - record_keyon

            # è®¡ç®—æ ¡å‡†åçš„åç§»ï¼ˆå»é™¤å…¨å±€å›ºå®šå»¶æ—¶ï¼‰
            # ç”±äºDTWå·²ç¦ç”¨ï¼Œå…¨å±€åç§»ä¸º0ï¼Œæ‰€ä»¥corrected_offset = keyon_offset
            corrected_offset = keyon_offset - self.global_time_offset

            # å®‰å…¨æ£€æŸ¥ï¼šæ­£å¸¸åŒ¹é…å¯¹çš„åç§»åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
            # å¦‚æœè¶…è¿‡1000msï¼Œè¯´æ˜æ•°æ®æˆ–åŒ¹é…é€»è¾‘æœ‰ä¸¥é‡é—®é¢˜
            max_reasonable_offset = 10000.0  # 1000ms
            if abs(corrected_offset) > max_reasonable_offset:
                logger.error(f"ğŸš¨ æ£€æµ‹åˆ°å¼‚å¸¸å¤§çš„æ ¡å‡†åç§»: {corrected_offset/10:.2f}ms, "
                           f"é”®ID={record_note.id}, å½•åˆ¶ç´¢å¼•={record_idx}, æ’­æ”¾ç´¢å¼•={replay_idx}, "
                           f"è¿™è¡¨æ˜åŒ¹é…é€»è¾‘æˆ–æ•°æ®æœ‰ä¸¥é‡é—®é¢˜")
                # è·³è¿‡è¿™ä¸ªå¼‚å¸¸åŒ¹é…å¯¹ï¼Œä¸å°†å…¶åŒ…å«åœ¨ç»Ÿè®¡ä¸­
                continue

            record_duration = record_keyoff - record_keyon
            replay_duration = replay_keyoff - replay_keyon
            duration_diff = replay_duration - record_duration
            duration_offset = duration_diff
            # ä½¿ç”¨æ ¡å‡†åçš„ç»å¯¹è¯¯å·®
            avg_offset = abs(corrected_offset)
    
            
            offset_data.append({
                'record_index': record_idx,
                'replay_index': replay_idx,
                'key_id': record_note.id,
                'record_keyon': record_keyon,
                'replay_keyon': replay_keyon,
                'keyon_offset': keyon_offset,       # åŸå§‹åç§»
                'corrected_offset': corrected_offset, # æ ¡å‡†ååç§»ï¼ˆç”¨äºåˆ†æï¼‰
                'record_keyoff': record_keyoff,
                'replay_keyoff': replay_keyoff,
                'duration_offset': duration_offset,
                'average_offset': avg_offset,  
                'record_duration': record_duration,
                'replay_duration': replay_duration,
                'duration_diff': duration_diff
            })
        
        return offset_data



    def get_graded_error_stats(self) -> Dict[str, Dict[str, Union[int, float]]]:
        """
        è·å–åˆ†çº§è¯¯å·®ç»Ÿè®¡ - æˆåŠŸåŒ¹é…è´¨é‡è¯„çº§

        åªç»Ÿè®¡æˆåŠŸåŒ¹é…å¯¹çš„è´¨é‡åˆ†å¸ƒï¼ˆä¸åŒ…æ‹¬å¤±è´¥åŒ¹é…ï¼‰ï¼š
        - correct: ä¼˜ç§€ (è¯¯å·® â‰¤ 20ms)
        - minor: è‰¯å¥½ (20ms < è¯¯å·® â‰¤ 30ms)
        - moderate: ä¸€èˆ¬ (30ms < è¯¯å·® â‰¤ 50ms)
        - large: è¾ƒå·® (50ms < è¯¯å·® â‰¤ 1000ms)
        - severe: ä¸¥é‡ (è¯¯å·® > 1000ms)

        æ³¨æ„ï¼šåªç»Ÿè®¡æˆåŠŸåŒ¹é…çš„è´¨é‡åˆ†å¸ƒï¼Œå¤±è´¥åŒ¹é…ä¸å‚ä¸è¯„çº§ç»Ÿè®¡

        Returns:
            Dict: åŒ…å«å„çº§åˆ«çš„è®¡æ•°å’Œç™¾åˆ†æ¯”
        """
        # è·å–æ‰€æœ‰æˆåŠŸçš„åŒ¹é…å¯¹æ•°æ®ç”¨äºè¯„çº§
        # ç›´æ¥ä»match_resultsä¸­è·å–æ‰€æœ‰æˆåŠŸåŒ¹é…çš„æ•°æ®
        all_matched_data = []
        for result in self.match_results:
            if result.is_success:
                # ä¸ºè¯„çº§ç»Ÿè®¡åˆ›å»ºæ•°æ®é¡¹
                item = self._create_offset_data_item(result)
                all_matched_data.append(item)

        # æ€»é…å¯¹æ•° = æˆåŠŸçš„åŒ¹é…å¯¹æ•°
        total_successful_matches = len(all_matched_data)

        # åˆå§‹åŒ–ç»Ÿè®¡ - åªç»Ÿè®¡æˆåŠŸåŒ¹é…çš„è¯„çº§åˆ†å¸ƒ
        stats = {
            'correct': 0,      # ä¼˜ç§€ (â‰¤20ms)
            'minor': 0,        # è‰¯å¥½ (20-30ms)
            'moderate': 0,     # ä¸€èˆ¬ (30-50ms)
            'large': 0,        # è¾ƒå·® (50-1000ms)
            'severe': 0,       # ä¸¥é‡ (>1000ms)
            # æ³¨æ„ï¼šä¸å†ç»Ÿè®¡å¤±è´¥åŒ¹é…ï¼Œå› ä¸ºå¤±è´¥åŒ¹é…ä¸å‚ä¸è´¨é‡è¯„çº§
        }

        # åŸºäºè¯¯å·®èŒƒå›´å¯¹æ‰€æœ‰æˆåŠŸåŒ¹é…è¿›è¡Œè¯„çº§
        for item in all_matched_data:
            error_abs = abs(item['corrected_offset'])
            error_ms = error_abs / 10.0

            if error_ms <= 20:
                stats['correct'] += 1      # ä¼˜ç§€
            elif error_ms > 20 and error_ms <= 30:
                stats['minor'] += 1        # è‰¯å¥½
            elif error_ms > 30 and error_ms <= 50:
                stats['moderate'] += 1     # ä¸€èˆ¬
            elif error_ms > 50 and error_ms <= 1000:
                stats['large'] += 1        # è¾ƒå·®
            else:  # error_ms > 1000
                stats['severe'] += 1       # ä¸¥é‡

        # è®¡ç®—ç™¾åˆ†æ¯”ï¼ˆåŸºäºæˆåŠŸçš„åŒ¹é…å¯¹æ€»æ•°ï¼‰
        # è¯„çº§ç»Ÿè®¡åªåæ˜ æˆåŠŸåŒ¹é…çš„è´¨é‡åˆ†å¸ƒï¼Œä¸åŒ…æ‹¬å¤±è´¥åŒ¹é…
        result = {}
        for key, count in stats.items():
            result[key] = {
                'count': count,
                'percent': (count / total_successful_matches * 100) if total_successful_matches > 0 else 0.0
            }

        result['total_successful_matches'] = total_successful_matches  # æˆåŠŸåŒ¹é…æ€»æ•°
        result['global_offset_ms'] = self.global_time_offset / 10.0

        logger.info(f"ğŸ“Š [åç«¯] åŒ¹é…è´¨é‡è¯„çº§ç»Ÿè®¡: æˆåŠŸé…å¯¹æ•°={total_successful_matches} (åªç»Ÿè®¡æˆåŠŸåŒ¹é…çš„è´¨é‡åˆ†å¸ƒ)")

        return result

    def _get_precision_matches_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–ç²¾ç¡®åŒ¹é…å¯¹çš„åç§»æ•°æ®

        Returns:
            List[Dict]: ç²¾ç¡®åŒ¹é…å¯¹çš„åç§»æ•°æ®
        """
        return self._get_matches_data_by_type(MatchType.PRECISION)

    def _get_approximate_matches_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–è¿‘ä¼¼åŒ¹é…å¯¹çš„åç§»æ•°æ® (50-1000ms)

        Returns:
            List[Dict]: è¿‘ä¼¼åŒ¹é…å¯¹çš„åç§»æ•°æ®
        """
        return self._get_matches_data_by_type(MatchType.POOR)

    def _get_large_error_matches_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–å¤§è¯¯å·®åŒ¹é…å¯¹çš„åç§»æ•°æ® (>1000ms)

        Returns:
            List[Dict]: å¤§è¯¯å·®åŒ¹é…å¯¹çš„åç§»æ•°æ®
        """
        return self._get_matches_data_by_type(MatchType.FAILED)

    def _get_matches_data_by_type(self, match_type: MatchType) -> List[Dict[str, Union[int, float]]]:
        """
        æ ¹æ®åŒ¹é…ç±»å‹è·å–å¯¹åº”çš„åç§»æ•°æ®

        Args:
            match_type: åŒ¹é…ç±»å‹

        Returns:
            List[Dict]: è¯¥ç±»å‹åŒ¹é…å¯¹çš„åç§»æ•°æ®
        """
        offset_data = []

        # ç¡®å®šæ•°æ®æºå’Œç­›é€‰æ¡ä»¶ - åŸºäºæ–°çš„åŒ¹é…ç±»å‹
        pairs_source = []
        error_filter = None

        if match_type == MatchType.EXCELLENT:
            # ä¼˜ç§€åŒ¹é…ï¼šä»precision_matched_pairsä¸­ç­›é€‰ â‰¤20ms çš„
            pairs_source = self.precision_matched_pairs
            error_filter = lambda error_ms: error_ms <= 20
        elif match_type == MatchType.GOOD:
            # è‰¯å¥½åŒ¹é…ï¼šä»precision_matched_pairsä¸­ç­›é€‰ 20-30ms çš„
            pairs_source = self.precision_matched_pairs
            error_filter = lambda error_ms: 20 < error_ms <= 30
        elif match_type == MatchType.FAIR:
            # ä¸€èˆ¬åŒ¹é…ï¼šä»precision_matched_pairsä¸­ç­›é€‰ 30-50ms çš„
            pairs_source = self.precision_matched_pairs
            error_filter = lambda error_ms: 30 < error_ms <= 50
        elif match_type == MatchType.POOR:
            # è¾ƒå·®åŒ¹é…ï¼šæ‰€æœ‰æ¥è‡ªloose_matched_pairsçš„åŒ¹é…
            pairs_source = self.loose_matched_pairs
            error_filter = lambda error_ms: True  # ä¸éœ€è¦é¢å¤–ç­›é€‰
        elif match_type == MatchType.SEVERE:
            # ä¸¥é‡è¯¯å·®ï¼šæ‰€æœ‰æ¥è‡ªsevere_matched_pairsçš„åŒ¹é…
            pairs_source = self.severe_matched_pairs
            error_filter = lambda error_ms: True  # ä¸éœ€è¦é¢å¤–ç­›é€‰
        elif match_type == MatchType.FAILED:
            # å¤±è´¥åŒ¹é…ï¼šæ— åŒ¹é…çš„æƒ…å†µï¼Œä¸åœ¨æ­¤å¤„ç†
            return []
        else:
            return []

        for record_idx, replay_idx, record_note, replay_note in pairs_source:
            # è®¡ç®—å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦çš„æ—¶é—´
            record_keyon, record_keyoff = self._calculate_note_times(record_note)
            replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

            # è®¡ç®—åŸå§‹åç§»é‡
            keyon_offset = replay_keyon - record_keyon

            # è®¡ç®—æ ¡å‡†åçš„åç§»ï¼ˆå»é™¤å…¨å±€å›ºå®šå»¶æ—¶ï¼‰
            corrected_offset = keyon_offset - self.global_time_offset

            # è®¡ç®—è¯¯å·®ï¼ˆæ¯«ç§’ï¼‰
            error_ms = abs(corrected_offset) / 10.0

            # æ ¹æ®åŒ¹é…ç±»å‹ç­›é€‰
            if not error_filter(error_ms):
                continue

            record_duration = record_keyoff - record_keyon
            replay_duration = replay_keyoff - replay_keyon
            duration_diff = replay_duration - record_duration
            duration_offset = duration_diff

            offset_data.append({
                'record_index': record_idx,
                'replay_index': replay_idx,
                'key_id': record_note.id,
                'record_keyon': record_keyon,
                'replay_keyon': replay_keyon,
                'keyon_offset': keyon_offset,       # åŸå§‹åç§»
                'corrected_offset': corrected_offset, # æ ¡å‡†ååç§»ï¼ˆç”¨äºåˆ†æï¼‰
                'record_keyoff': record_keyoff,
                'replay_keyoff': replay_keyoff,
                'duration_offset': duration_offset,
                'average_offset': abs(corrected_offset),
                'record_duration': record_duration,
                'replay_duration': replay_duration,
                'duration_diff': duration_diff
            })

        return offset_data
    
    def get_invalid_notes_offset_analysis(self, record_data: List[Note], replay_data: List[Note]) -> List[Dict[str, Union[int, float, str]]]:
        """
        è·å–æ— æ•ˆéŸ³ç¬¦çš„åç§»å¯¹é½åˆ†æ
        
        Args:
            record_data: å½•åˆ¶æ•°æ®
            replay_data: æ’­æ”¾æ•°æ®
            
        Returns:
            List[Dict[str, Union[int, float, str]]]: æ— æ•ˆéŸ³ç¬¦åç§»åˆ†ææ•°æ®
        """
        invalid_offset_data = []
        
        # è·å–å·²åŒ¹é…çš„éŸ³ç¬¦ç´¢å¼•
        matched_record_indices = set(pair[0] for pair in self.matched_pairs)
        matched_replay_indices = set(pair[1] for pair in self.matched_pairs)
        
        # åˆ†æå½•åˆ¶æ•°æ®ä¸­çš„æ— æ•ˆéŸ³ç¬¦ï¼ˆæœªåŒ¹é…çš„éŸ³ç¬¦ï¼‰
        invalid_offset_data.extend(
            self._analyze_invalid_notes(record_data, matched_record_indices, 'record', replay_data)
        )
        
        # åˆ†ææ’­æ”¾æ•°æ®ä¸­çš„æ— æ•ˆéŸ³ç¬¦ï¼ˆæœªåŒ¹é…çš„éŸ³ç¬¦ï¼‰
        invalid_offset_data.extend(
            self._analyze_invalid_notes(replay_data, matched_replay_indices, 'replay', record_data)
        )
        
        return invalid_offset_data
    
    def _analyze_invalid_notes(self, notes_data: List[Note], matched_indices: set, data_type: str, 
                              other_notes_data: List[Note] = None) -> List[Dict[str, Union[int, float, str]]]:
        """
        åˆ†ææ— æ•ˆéŸ³ç¬¦çš„é€šç”¨æ–¹æ³•
        
        Args:
            notes_data: éŸ³ç¬¦æ•°æ®åˆ—è¡¨
            matched_indices: å·²åŒ¹é…çš„éŸ³ç¬¦ç´¢å¼•é›†åˆ
            data_type: æ•°æ®ç±»å‹ ('record' æˆ– 'replay')
            other_notes_data: å¦ä¸€ä¸ªæ•°æ®ç±»å‹çš„éŸ³ç¬¦åˆ—è¡¨ï¼Œç”¨äºåˆ†æåŒ¹é…å¤±è´¥åŸå› 
            
        Returns:
            List[Dict[str, Union[int, float, str]]]: æ— æ•ˆéŸ³ç¬¦åˆ†ææ•°æ®
        """
        invalid_notes = []
        
        for i, note in enumerate(notes_data):
            if i not in matched_indices:  # æœªåŒ¹é…çš„éŸ³ç¬¦
                try:
                    keyon_time, keyoff_time = self._calculate_note_times(note)
                    
                    # ä¼˜å…ˆä½¿ç”¨åŒ¹é…é˜¶æ®µè®°å½•çš„çœŸå®å¤±è´¥åŸå› ï¼ˆä»…recordä¾§æœ‰ï¼‰
                    analysis_reason = None
                    if data_type == 'record' and (data_type, i) in self.failure_reasons:
                        analysis_reason = self.failure_reasons[(data_type, i)]
                    else:
                        # å›æ”¾ä¾§æˆ–æ— è®°å½•æ—¶ï¼Œå†åšæ¨æ–­åˆ†æ
                        analysis_reason = self._get_actual_unmatch_reason(note, data_type, i, other_notes_data)
                    
                    invalid_notes.append({
                        'data_type': data_type,
                        'note_index': i,
                        'key_id': note.id,
                        'keyon_time': keyon_time,
                        'keyoff_time': keyoff_time,
                        'status': 'unmatched',
                        'analysis_reason': analysis_reason
                    })
                except (IndexError, AttributeError) as e:
                    # å¤„ç†æ•°æ®å¼‚å¸¸çš„æƒ…å†µ
                    invalid_notes.append({
                        'data_type': data_type,
                        'note_index': i,
                        'key_id': note.id,
                        'keyon_time': 0.0,
                        'keyoff_time': 0.0,
                        'status': 'data_error',
                        'analysis_reason': f'æ•°æ®å¼‚å¸¸: {str(e)}'
                    })
        
        return invalid_notes
    
    def _get_actual_unmatch_reason(self, note: Note, data_type: str, note_index: int, 
                                  other_notes_data: List[Note] = None) -> str:
        """
        åˆ†ææœªåŒ¹é…éŸ³ç¬¦çš„å®é™…å¤±è´¥åŸå› 
        
        Args:
            note: éŸ³ç¬¦å¯¹è±¡
            data_type: æ•°æ®ç±»å‹ ('record' æˆ– 'replay')
            note_index: éŸ³ç¬¦ç´¢å¼•
            other_notes_data: å¦ä¸€ä¸ªæ•°æ®ç±»å‹çš„éŸ³ç¬¦åˆ—è¡¨
            
        Returns:
            str: åŒ¹é…å¤±è´¥åŸå› 
        """
        if other_notes_data is None:
            return "æ— æ³•åˆ†æåŒ¹é…å¤±è´¥åŸå› (ç¼ºå°‘å¯¹æ¯”æ•°æ®)"
        
        try:
            # æå–å½“å‰éŸ³ç¬¦ä¿¡æ¯
            note_info = self._extract_note_info(note, note_index)
            
            # åˆ†æåŒ¹é…å¤±è´¥çš„å…·ä½“åŸå› 
            return self._analyze_match_failure_reason(note_info, other_notes_data, data_type)
            
        except Exception as e:
            return f"åˆ†æåŒ¹é…å¤±è´¥åŸå› æ—¶å‡ºé”™: {str(e)}"
    
    def _analyze_match_failure_reason(self, note_info: Dict, other_notes_data: List[Note], data_type: str) -> str:
        """
        åˆ†æåŒ¹é…å¤±è´¥çš„å…·ä½“åŸå› ï¼ˆå›æ”¾ä¾§æ¨æ–­ç”¨ï¼‰
        
        æ³¨æ„ï¼šå½•åˆ¶ä¾§å·²åœ¨åŒ¹é…é˜¶æ®µè®°å½•çœŸå®åŸå› ï¼Œæ­¤æ–¹æ³•ä¸»è¦ç”¨äºå›æ”¾ä¾§æ¨æ–­
        
        Args:
            note_info: éŸ³ç¬¦ä¿¡æ¯å­—å…¸
            other_notes_data: å¦ä¸€ä¸ªæ•°æ®ç±»å‹çš„éŸ³ç¬¦åˆ—è¡¨
            data_type: æ•°æ®ç±»å‹
            
        Returns:
            str: åŒ¹é…å¤±è´¥åŸå› 
        """
        target_key_id = note_info["key_id"]
        target_keyon = note_info["keyon"]
        target_keyoff = note_info["keyoff"]
        
        # è°ƒç”¨ç›¸åŒçš„å€™é€‰ç”Ÿæˆé€»è¾‘ï¼ˆç¡®ä¿ä¸åŒ¹é…é˜¶æ®µä¸€è‡´ï¼‰
        candidates, threshold, reason_if_empty = self._generate_sorted_candidates_within_threshold(
            other_notes_data,
            target_keyon=target_keyon,
            target_keyoff=target_keyoff,
            target_key_id=target_key_id
        )
        
        if not candidates:
            return reason_if_empty
        
        # æœ‰åœ¨é˜ˆå€¼å†…çš„å€™é€‰ï¼Œä½†æœªè¢«åŒ¹é… -> å¯èƒ½å…¨è¢«å ç”¨ï¼ˆå›æ”¾ä¾§æ— æ³•å¾—çŸ¥å ç”¨æƒ…å†µï¼‰
        return f"å¯èƒ½æ‰€æœ‰å€™é€‰å·²è¢«å ç”¨(å€™é€‰æ•°:{len(candidates)}, é˜ˆå€¼:{threshold:.1f}ms)"
    
    def _calculate_note_times(self, note: Note) -> Tuple[float, float]:
        """
        è®¡ç®—éŸ³ç¬¦çš„æŒ‰é”®å¼€å§‹å’Œç»“æŸæ—¶é—´
        
        Args:
            note: éŸ³ç¬¦å¯¹è±¡
            
        Returns:
            Tuple[float, float]: (keyon_time, keyoff_time)
        """

        try:
            keyon_time = note.after_touch.index[0] + note.offset
            keyoff_time = note.after_touch.index[-1] + note.offset
        except (IndexError, AttributeError) as e:
            raise ValueError(f"éŸ³ç¬¦ID {note.id} çš„after_touchæ•°æ®æ— æ•ˆ: {e}") from e
        
        return keyon_time, keyoff_time
    
    # TODO  
    def get_global_average_delay(self) -> float:
        """
        è®¡ç®—æ•´é¦–æ›²å­çš„å¹³å‡æ—¶å»¶ï¼ˆåŸºäºå·²é…å¯¹æ•°æ®ï¼‰
        
        ä½¿ç”¨å¸¦ç¬¦å·çš„ keyon_offset è®¡ç®—ï¼šå…¨å±€å¹³å‡æ—¶å»¶ = mean(keyon_offset)
        æ­£å€¼è¡¨ç¤º replay å»¶è¿Ÿï¼Œè´Ÿå€¼è¡¨ç¤º replay æå‰
        
        æ³¨æ„ï¼šæ­¤æŒ‡æ ‡ä¸å¹³å‡è¯¯å·®ï¼ˆMEï¼Œget_mean_error()ï¼‰åœ¨è®¡ç®—å’Œæ¦‚å¿µä¸Šå®Œå…¨ç›¸åŒï¼Œ
        éƒ½æ˜¯å¯¹æ‰€æœ‰ keyon_offset æ±‚ç®—æœ¯å¹³å‡ï¼Œåæ˜ æ•´ä½“çš„æå‰/æ»åæ–¹å‘æ€§ã€‚
        å¦‚æœéœ€è¦ä¸è€ƒè™‘æ–¹å‘çš„å¹³å‡å»¶æ—¶å¹…åº¦ï¼Œåº”ä½¿ç”¨å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ã€‚
        
        Returns:
            float: å¹³å‡æ—¶å»¶ï¼ˆ0.1mså•ä½ï¼Œå¸¦ç¬¦å·ï¼‰
        """
        if not self.matched_pairs:
            return 0.0

        # è·å–åç§»æ•°æ®ï¼ˆåªä½¿ç”¨ç²¾ç¡®åŒ¹é…å¯¹ï¼Œè¯¯å·® â‰¤ 50msï¼‰
        offset_data = self.get_precision_offset_alignment_data()

        # ä½¿ç”¨å¸¦ç¬¦å·çš„æ ¡å‡†ååç§»ï¼ˆä¸å–ç»å¯¹å€¼ï¼Œå»é™¤å…¨å±€ç³»ç»Ÿå»¶æ—¶ï¼‰
        corrected_offsets = [item.get('corrected_offset', 0) for item in offset_data if item.get('corrected_offset') is not None]
        
        if not corrected_offsets:
            return 0.0

        # è®¡ç®—å¹³å‡å€¼ï¼ˆ0.1mså•ä½ï¼Œå¸¦ç¬¦å·ï¼‰
        average_delay = sum(corrected_offsets) / len(corrected_offsets)

        logger.info(f"ğŸ“Š [åç«¯] å…¨å±€å¹³å‡å»¶æ—¶: {average_delay/10:.2f}ms ({average_delay:.1f}å•ä½ï¼ŒåŸºäº{len(corrected_offsets)}ä¸ªç²¾ç¡®åŒ¹é…å¯¹)")
        
        return average_delay
    
    def get_variance(self) -> float:
        """
        è®¡ç®—å·²åŒ¹é…æŒ‰é”®å¯¹çš„æ€»ä½“æ–¹å·®ï¼ˆPopulation Varianceï¼‰
        
        è¯´æ˜ï¼š
        - "åŒ¹é…å¯¹"æŒ‡çš„æ˜¯matched_pairsä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œæ˜¯ä¸€ä¸ª(record_note, replay_note)çš„é…å¯¹
        - å¯¹æ¯ä¸ªåŒ¹é…å¯¹è®¡ç®—keyon_offset = replay_keyon - record_keyon
        - ä½¿ç”¨å¸¦ç¬¦å·çš„keyon_offsetè®¡ç®—æ–¹å·®ï¼ŒæŒ‰ç…§æ ‡å‡†æ€»ä½“æ–¹å·®å…¬å¼
        
        æ ‡å‡†æ•°å­¦å…¬å¼ï¼š
        ÏƒÂ² = (1/n) * Î£(x_i - Î¼)Â²
        å…¶ä¸­ x_i æ˜¯å¸¦ç¬¦å·çš„keyon_offsetï¼ŒÎ¼ = (1/n) * Î£ x_iï¼ˆæ€»ä½“å‡å€¼ï¼‰
        
        Returns:
            float: æ€»ä½“æ–¹å·®ï¼ˆå•ä½ï¼š(0.1ms)Â²ï¼Œè½¬æ¢ä¸ºmsÂ²éœ€è¦é™¤ä»¥100ï¼‰
        """
        if not self.matched_pairs:
            return 0.0

        # è·å–åç§»å¯¹é½æ•°æ®ï¼ˆåªä½¿ç”¨ç²¾ç¡®åŒ¹é…å¯¹ï¼Œè¯¯å·® â‰¤ 50msï¼‰
        offset_data = self.get_precision_offset_alignment_data()

        # æå–æ‰€æœ‰å¸¦ç¬¦å·çš„æ ¡å‡†ååç§»ï¼ˆå»é™¤å…¨å±€ç³»ç»Ÿå»¶æ—¶ï¼‰
        offsets = []
        for item in offset_data:
            corrected_offset = item.get('corrected_offset', 0)
            offsets.append(corrected_offset)  # ä½¿ç”¨æ ¡å‡†åçš„åç§»å€¼
        
        if len(offsets) <= 1:
            return 0.0
        
        # è®¡ç®—æ€»ä½“æ–¹å·®ï¼ˆä½¿ç”¨æ ‡å‡†å…¬å¼ï¼Œåˆ†æ¯ nï¼‰
        # å…¬å¼ï¼šÏƒÂ² = (1/n) * Î£(x_i - Î¼)Â²
        # å…¶ä¸­ Î¼ = (1/n) * Î£ x_iï¼ˆæ€»ä½“å‡å€¼ï¼‰
        mean = sum(offsets) / len(offsets)  # æ€»ä½“å‡å€¼ï¼ˆå¸¦ç¬¦å·ï¼‰
        variance = sum((x - mean) ** 2 for x in offsets) / len(offsets)  # æ€»ä½“æ–¹å·®ä½¿ç”¨ n
        return variance
    
    def get_standard_deviation(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„æ€»ä½“æ ‡å‡†å·®ï¼ˆPopulation Standard Deviationï¼‰
        å¯¹æ‰€æœ‰å·²åŒ¹é…æŒ‰é”®å¯¹çš„å¸¦ç¬¦å·keyon_offsetè®¡ç®—æ€»ä½“æ ‡å‡†å·®
        æ€»ä½“æ ‡å‡†å·® = sqrt(æ€»ä½“æ–¹å·®)
        
        æŒ‰ç…§æ ‡å‡†æ•°å­¦å…¬å¼ï¼šÏƒ = âˆš(ÏƒÂ²) = âˆš((1/n) * Î£(x_i - Î¼)Â²)
        å…¶ä¸­ x_i æ˜¯å¸¦ç¬¦å·çš„keyon_offsetï¼ŒÎ¼ = (1/n) * Î£ x_iï¼ˆæ€»ä½“å‡å€¼ï¼‰
        
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ç›´æ¥è°ƒç”¨ get_variance() ç„¶åå¼€å¹³æ–¹æ ¹ï¼Œç¡®ä¿ä¸æ–¹å·®è®¡ç®—çš„ä¸€è‡´æ€§
        ç”±äº get_variance() ä½¿ç”¨å¸¦ç¬¦å·å€¼è®¡ç®—ï¼Œæ­¤æ–¹æ³•ä¹Ÿä½¿ç”¨å¸¦ç¬¦å·å€¼
        
        Returns:
            float: æ€»ä½“æ ‡å‡†å·®ï¼ˆå•ä½ï¼š0.1msï¼Œè½¬æ¢ä¸ºmséœ€è¦é™¤ä»¥10ï¼‰
        """
        variance = self.get_variance()
        if variance < 0:
            # ç†è®ºä¸Šä¸åº”è¯¥å‡ºç°è´Ÿæ•°ï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§
            logger.warning(f"âš ï¸ æ€»ä½“æ–¹å·®ä¸ºè´Ÿæ•°: {variance}ï¼Œè¿”å›0")
            return 0.0
        std = variance ** 0.5
        logger.info(f"ğŸ“Š [åç«¯] æ€»ä½“æ ‡å‡†å·®: {std/10:.2f}ms ({std:.1f}å•ä½ï¼ŒåŸºäºç²¾ç¡®åŒ¹é…æ•°æ®)")
        return std
    
    def get_mean_absolute_error(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰
        å¯¹æ‰€æœ‰å·²åŒ¹é…æŒ‰é”®å¯¹çš„å»¶æ—¶ç»å¯¹å€¼æ±‚å¹³å‡
        
        Returns:
            float: å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆå•ä½ï¼š0.1msï¼Œè½¬æ¢ä¸ºmséœ€è¦é™¤ä»¥10ï¼‰
        """
        if not self.matched_pairs:
            return 0.0

        # è·å–åç§»å¯¹é½æ•°æ®ï¼ˆåªä½¿ç”¨ç²¾ç¡®åŒ¹é…å¯¹ï¼Œè¯¯å·® â‰¤ 50msï¼‰
        offset_data = self.get_precision_offset_alignment_data()

        # æå–æ‰€æœ‰æ ¡å‡†åå»¶æ—¶çš„ç»å¯¹å€¼ï¼ˆå»é™¤å…¨å±€ç³»ç»Ÿå»¶æ—¶ï¼‰
        abs_errors = []
        for item in offset_data:
            corrected_offset = item.get('corrected_offset', 0)
            abs_error = abs(corrected_offset)
            abs_errors.append(abs_error)
        
        # è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·®
        if abs_errors:
            mae = sum(abs_errors) / len(abs_errors)
            logger.info(f"ğŸ“Š [åç«¯] å¹³å‡ç»å¯¹è¯¯å·® MAE: {mae/10:.2f}ms ({mae:.1f}å•ä½ï¼ŒåŸºäº{len(abs_errors)}ä¸ªç²¾ç¡®åŒ¹é…å¯¹)")
            return mae
        else:
            return 0.0
    
    def get_coefficient_of_variation(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„å˜å¼‚ç³»æ•°ï¼ˆCoefficient of Variation, CVï¼‰
        å˜å¼‚ç³»æ•° = æ€»ä½“æ ‡å‡†å·®ï¼ˆÏƒï¼‰/ |æ€»ä½“å‡å€¼ï¼ˆÎ¼ï¼‰| Ã— 100%
        
        ä½¿ç”¨æ€»ä½“æ ‡å‡†å·®ï¼ˆÏƒï¼‰ä¸æ€»ä½“å‡å€¼ï¼ˆÎ¼ï¼‰è®¡ç®—ï¼Œåæ˜ ç›¸å¯¹å˜å¼‚ç¨‹åº¦
        
        æ³¨æ„ï¼šå¦‚æœæ€»ä½“å‡å€¼ï¼ˆÎ¼ï¼‰ä¸º0æˆ–æ¥è¿‘0ï¼Œå˜å¼‚ç³»æ•°å¯èƒ½æ— æ„ä¹‰æˆ–éå¸¸å¤§
        
        Returns:
            float: å˜å¼‚ç³»æ•°ï¼ˆç™¾åˆ†æ¯”ï¼Œä¾‹å¦‚ 15.5 è¡¨ç¤º 15.5%ï¼‰
        """
        if not self.matched_pairs:
            return 0.0
        
        # è·å–æ€»ä½“å‡å€¼ï¼ˆÎ¼ï¼Œå¸¦ç¬¦å·ï¼‰
        mean_0_1ms = self.get_mean_error()
        if abs(mean_0_1ms) < 1e-6:  # å¦‚æœå‡å€¼æ¥è¿‘0ï¼Œæ— æ³•è®¡ç®—CV
            return 0.0
        
        # è·å–æ€»ä½“æ ‡å‡†å·®ï¼ˆÏƒï¼‰
        std_0_1ms = self.get_standard_deviation()
        if std_0_1ms == 0:
            return 0.0
        
        # è®¡ç®—å˜å¼‚ç³»æ•°ï¼šCV = (Ïƒ / |Î¼|) Ã— 100%
        cv = (std_0_1ms / abs(mean_0_1ms)) * 100.0
        return cv
    
    def get_mean_squared_error(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰
        å¯¹æ‰€æœ‰å·²åŒ¹é…æŒ‰é”®å¯¹çš„å»¶æ—¶çš„å¹³æ–¹æ±‚å¹³å‡
        
        Returns:
            float: å‡æ–¹è¯¯å·®ï¼ˆå•ä½ï¼š(0.1ms)Â²ï¼Œè½¬æ¢ä¸ºmsÂ²éœ€è¦é™¤ä»¥100ï¼‰
        """
        if not self.matched_pairs:
            return 0.0
        
        # è·å–åç§»å¯¹é½æ•°æ®ï¼ˆåªä½¿ç”¨ç²¾ç¡®åŒ¹é…å¯¹ï¼Œè¯¯å·® â‰¤ 50msï¼‰
        offset_data = self.get_precision_offset_alignment_data()
        
        # æå–æ‰€æœ‰æ ¡å‡†åå»¶æ—¶çš„å¹³æ–¹å€¼ï¼ˆå»é™¤å…¨å±€ç³»ç»Ÿå»¶æ—¶ï¼‰
        squared_errors = []
        for item in offset_data:
            corrected_offset = item.get('corrected_offset', 0)
            squared_error = corrected_offset ** 2  # ä½¿ç”¨æ ¡å‡†åçš„åç§»å€¼
            squared_errors.append(squared_error)
        
        # è®¡ç®—å‡æ–¹è¯¯å·®
        if squared_errors:
            mse = sum(squared_errors) / len(squared_errors)
            return mse
        else:
            return 0.0

    def get_root_mean_squared_error(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰
        RMSE = sqrt(MSE) = sqrt(mean((keyon_offset)^2))
        
        Returns:
            float: å‡æ–¹æ ¹è¯¯å·®ï¼ˆå•ä½ï¼š0.1msï¼Œè½¬æ¢ä¸ºmséœ€è¦é™¤ä»¥10ï¼‰
        """
        if not self.matched_pairs:
            return 0.0
        
        # è·å–MSE
        mse = self.get_mean_squared_error()
        
        # è®¡ç®—RMSE = sqrt(MSE)
        import math
        rmse = math.sqrt(mse) if mse > 0 else 0.0
        
        return rmse
    
    def get_mean_error(self) -> float:
        """
        è·å–å·²åŒ¹é…æŒ‰é”®å¯¹çš„å¹³å‡è¯¯å·®ï¼ˆMEï¼Œå¸¦ç¬¦å·çš„å¹³å‡åå·®ï¼‰
        å¯¹æ‰€æœ‰åŒ¹é…å¯¹çš„keyon_offsetï¼ˆreplay_keyon - record_keyonï¼‰æ±‚ç®—æœ¯å¹³å‡ã€‚

        Returns:
            float: å¹³å‡è¯¯å·®MEï¼ˆå•ä½ï¼š0.1msï¼ŒUIæ˜¾ç¤ºä¸ºmséœ€é™¤ä»¥10ï¼‰
        """
        # è¿”å›ç¼“å­˜çš„å¹³å‡è¯¯å·®ï¼Œå¦‚æœæ²¡æœ‰ç¼“å­˜åˆ™è®¡ç®—
        if self._mean_error_cached is None:
            self._mean_error_cached = self._calculate_mean_error()
        return self._mean_error_cached

    def _calculate_mean_error(self) -> float:
        """
        è®¡ç®—å·²åŒ¹é…æŒ‰é”®å¯¹çš„å¹³å‡è¯¯å·®ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        Returns:
            float: å¹³å‡è¯¯å·®MEï¼ˆå•ä½ï¼š0.1msï¼‰
        """
        if not self.matched_pairs:
            return 0.0

        offset_data = self.get_precision_offset_alignment_data()
        offsets = [item.get('corrected_offset', 0) for item in offset_data]
        if not offsets:
            return 0.0
        mean_error = sum(offsets) / len(offsets)
        logger.info(f"ğŸ“Š [åç«¯] å¹³å‡è¯¯å·® ME: {mean_error/10:.2f}ms ({mean_error:.1f}å•ä½ï¼ŒåŸºäº{len(offsets)}ä¸ªç²¾ç¡®åŒ¹é…å¯¹)")
        return mean_error

    def _clear_mean_error_cache(self) -> None:
        """
        æ¸…é™¤å¹³å‡è¯¯å·®ç¼“å­˜
        å½“åŒ¹é…å¯¹å‘ç”Ÿå˜åŒ–æ—¶è°ƒç”¨æ­¤æ–¹æ³•
        """
        self._mean_error_cached = None
    
    def get_offset_statistics(self) -> Dict[str, Union[int, Dict[str, float]]]:
        """
        è·å–åç§»ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Union[int, Dict[str, float]]]: åç§»ç»Ÿè®¡ä¿¡æ¯
        """
        if not self.matched_pairs:
            return {
                'total_pairs': 0,
                'keyon_offset_stats': {'average': 0.0, 'max': 0.0, 'min': 0.0, 'std': 0.0},
                'duration_offset_stats': {'average': 0.0, 'max': 0.0, 'min': 0.0, 'std': 0.0},
                'overall_offset_stats': {'average': 0.0, 'max': 0.0, 'min': 0.0, 'std': 0.0}
            }
        
        # è·å–åç§»æ•°æ®ï¼ˆåªä½¿ç”¨ç²¾ç¡®åŒ¹é…å¯¹ï¼Œè¯¯å·® â‰¤ 50msï¼‰
        offset_data = self.get_precision_offset_alignment_data()
        
        # æå–åç§»å€¼ï¼ˆä½¿ç”¨æ ¡å‡†åçš„keyon_offsetï¼‰
        corrected_offsets = [item['corrected_offset'] for item in offset_data]
        duration_offsets = [item.get('duration_offset', 0.0) for item in offset_data]
        # æ•´ä½“ç»Ÿè®¡åªä½¿ç”¨æ ¡å‡†ååç§»çš„ç»å¯¹å€¼
        overall_offsets = [abs(item.get('corrected_offset', 0)) for item in offset_data if item.get('corrected_offset') is not None]
        
        return {
            'total_pairs': len(self.matched_pairs),
            'keyon_offset_stats': self._calculate_offset_stats(corrected_offsets),
            'duration_offset_stats': self._calculate_offset_stats(duration_offsets),
            'overall_offset_stats': self._calculate_offset_stats(overall_offsets)  # ä½¿ç”¨æ ¡å‡†åçš„åç§»
        }
    
    def _calculate_offset_stats(self, offsets: List[float]) -> Dict[str, float]:
        """
        è®¡ç®—åç§»ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            offsets: åç§»å€¼åˆ—è¡¨
            
        Returns:
            Dict[str, float]: ç»Ÿè®¡ä¿¡æ¯
        """
        if not offsets:
            return {'average': 0.0, 'max': 0.0, 'min': 0.0, 'std': 0.0}
        
        average = sum(offsets) / len(offsets)
        max_val = max(offsets)
        min_val = min(offsets)
        
        # è®¡ç®—æ ‡å‡†å·®
        if len(offsets) <= 1:
            std = 0.0
        else:
            variance = sum((x - average) ** 2 for x in offsets) / (len(offsets) - 1)
            std = variance ** 0.5
        
        return {
            'average': average,
            'max': max_val,
            'min': min_val,
            'std': std
        }

    def _create_offset_data_item(self, match_result: MatchResult) -> Dict[str, Union[int, float]]:
        """
        ä¸ºè¯„çº§ç»Ÿè®¡åˆ›å»ºåç§»æ•°æ®é¡¹

        Args:
            match_result: åŒ¹é…ç»“æœ

        Returns:
            Dict: åŒ…å«åç§»æ•°æ®çš„å­—å…¸
        """
        record_note, replay_note = match_result.pair
        record_keyon, record_keyoff = self._calculate_note_times(record_note)
        replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

        # è®¡ç®—åŸå§‹åç§»é‡
        keyon_offset = replay_keyon - record_keyon

        # è®¡ç®—æ ¡å‡†åçš„åç§»ï¼ˆå»é™¤å…¨å±€å›ºå®šå»¶æ—¶ï¼‰
        corrected_offset = keyon_offset - self.global_time_offset

        record_duration = record_keyoff - record_keyon
        replay_duration = replay_keyoff - replay_keyon
        duration_diff = replay_duration - record_duration
        duration_offset = duration_diff

        return {
            'record_index': match_result.record_index,
            'replay_index': match_result.replay_index,
            'key_id': record_note.id,
            'record_keyon': record_keyon,
            'replay_keyon': replay_keyon,
            'keyon_offset': keyon_offset,       # åŸå§‹åç§»
            'corrected_offset': corrected_offset, # æ ¡å‡†ååç§»ï¼ˆç”¨äºåˆ†æï¼‰
            'record_keyoff': record_keyoff,
            'replay_keyoff': replay_keyoff,
            'duration_offset': duration_offset,
            'average_offset': abs(corrected_offset),
            'record_duration': record_duration,
            'replay_duration': replay_duration,
            'duration_diff': duration_diff
        }
