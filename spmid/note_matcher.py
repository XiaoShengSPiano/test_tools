#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
SPMIDéŸ³ç¬¦åŒ¹é…å™¨

è´Ÿè´£SPMIDæ•°æ®çš„æŒ‰é”®åŒ¹é…ï¼ŒåŒ…æ‹¬ï¼š
- éŸ³ç¬¦åŒ¹é…ç®—æ³•
- åŒ¹é…å¯¹ç”Ÿæˆ
- åŒ¹é…ç»“æœç®¡ç†

åŒ¹é…é€»è¾‘æ¶æ„ï¼š
==========================================

ã€æ ¸å¿ƒç­–ç•¥ã€‘
- è´ªå¿ƒåŒ¹é…ï¼šæ¯ä¸ªå½•åˆ¶éŸ³ç¬¦åªåŒ¹é…ä¸€ä¸ªæœ€ä½³çš„æ’­æ”¾éŸ³ç¬¦
- ä¸‰é˜¶æ®µæœç´¢ï¼šç²¾ç¡®æœç´¢(â‰¤50ms) â†’ è¾ƒå·®æœç´¢(50ms-100ms) â†’ ä¸¥é‡æœç´¢(100ms-200ms)
- å…­ç­‰çº§é˜ˆå€¼ï¼šæŒ‰è¯¯å·®èŒƒå›´ç²¾ç¡®åˆ†ç±» (20ms, 30ms, 50ms, 100ms, 200ms)

ã€åŒ¹é…æµç¨‹ã€‘
1. find_all_matched_pairs() - ä¸»å…¥å£
   â”œâ”€â”€ åˆå§‹åŒ–åŒ¹é…çŠ¶æ€
   â”œâ”€â”€ å¯¹æ¯ä¸ªå½•åˆ¶éŸ³ç¬¦è°ƒç”¨ _find_match_for_single_note()
   â””â”€â”€ ç»Ÿè®¡åŒ¹é…ç»“æœ

2. _find_match_for_single_note() - å•éŸ³ç¬¦åŒ¹é…
   â”œâ”€â”€ æå–éŸ³ç¬¦ä¿¡æ¯ (_extract_note_info)
   â”œâ”€â”€ ç”Ÿæˆå€™é€‰åˆ—è¡¨ (_generate_candidates_for_note)
   â”œâ”€â”€ é€‰æ‹©æœ€ä½³å€™é€‰ (_select_best_candidate)
   â””â”€â”€ å¤„ç†åŒ¹é…ç»“æœ (ç²¾ç¡®åŒ¹é…/è¿‘ä¼¼åŒ¹é…/å¤±è´¥)

3. _generate_candidates_for_note() - å€™é€‰ç”Ÿæˆ
   â”œâ”€â”€ ç¬¬ä¸€é˜¶æ®µï¼šé˜ˆå€¼å†…å€™é€‰ (_generate_sorted_candidates_within_threshold)
   â”œâ”€â”€ ç¬¬äºŒé˜¶æ®µï¼šå¦‚æ— å€™é€‰åˆ™æ‰©å±•åˆ°å…¨å±€ (_generate_all_candidates_sorted)
   â””â”€â”€ ç¬¬ä¸‰é˜¶æ®µï¼šåº”ç”¨æ‰©å±•é˜ˆå€¼è¿‡æ»¤ (â‰¤300ms)

ã€åŒ¹é…åˆ†ç±» - å…­ç­‰çº§ç³»ç»Ÿã€‘
- ä¼˜ç§€åŒ¹é… (â‰¤20ms)ï¼šé«˜è´¨é‡åŒ¹é…
- è‰¯å¥½åŒ¹é… (20-30ms)ï¼šè¾ƒé«˜è´¨é‡åŒ¹é…
- ä¸€èˆ¬åŒ¹é… (30-50ms)ï¼šå¯æ¥å—åŒ¹é…
- è¾ƒå·®åŒ¹é… (50-100ms)ï¼šéœ€è¦æ”¹è¿›çš„åŒ¹é…
- ä¸¥é‡åŒ¹é… (100-200ms)ï¼šè´¨é‡æå·®ä½†æ‰¾åˆ°çš„åŒ¹é…
- å¤±è´¥åŒ¹é… (>200ms)ï¼šè¯¯å·®è¿‡å¤§ï¼Œæ ‡è®°ä¸ºä¸¢é”¤/å¤šé”¤å¼‚å¸¸

ã€æœç´¢ç­–ç•¥ - ä¸‰é˜¶æ®µåˆ†å±‚æœç´¢ã€‘
- ç¬¬ä¸€é˜¶æ®µï¼šç²¾ç¡®æœç´¢ (â‰¤50ms) - å¯»æ‰¾ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬åŒ¹é…
- ç¬¬äºŒé˜¶æ®µï¼šè¾ƒå·®æœç´¢ (50-100ms) - å¯»æ‰¾è¾ƒå·®åŒ¹é…
- ç¬¬ä¸‰é˜¶æ®µï¼šä¸¥é‡æœç´¢ (100-200ms) - å¯»æ‰¾ä¸¥é‡è¯¯å·®åŒ¹é…

ã€é˜ˆå€¼ä½“ç³» - å…­ç­‰çº§ç²¾ç¡®åˆ†ç±»ã€‘
- ä¼˜ç§€é˜ˆå€¼ï¼šâ‰¤20ms
- è‰¯å¥½é˜ˆå€¼ï¼š20-30ms
- ä¸€èˆ¬é˜ˆå€¼ï¼š30-50ms
- è¾ƒå·®é˜ˆå€¼ï¼š50-100ms
- ä¸¥é‡é˜ˆå€¼ï¼š100-200ms
- å¤±è´¥é˜ˆå€¼ï¼š>200ms

ã€é”™è¯¯æ£€æµ‹ã€‘
- ä¸¢é”¤ï¼šå½•åˆ¶æ•°æ®ä¸­æœªåŒ¹é…çš„æŒ‰é”®
- å¤šé”¤ï¼šæ’­æ”¾æ•°æ®ä¸­æœªåŒ¹é…çš„æŒ‰é”®
- åŸºäºä¸¤é˜¶æ®µåŒ¹é…åçš„å‰©ä½™éŸ³ç¬¦ç›´æ¥åˆ¤æ–­ï¼Œæ— éœ€å¤æ‚ç»Ÿè®¡
"""

import pandas as pd
import numpy as np
from .spmid_reader import Note
from typing import List, Tuple, Dict, Union, Optional
from utils.logger import Logger
from enum import Enum
from collections import defaultdict
import heapq
import time

logger = Logger.get_logger()

# åŒ¹é…é˜ˆå€¼å¸¸é‡ (0.1mså•ä½) - å…­ç­‰çº§åŒ¹é…ç³»ç»Ÿ
# ä¼˜ç§€åŒ¹é…ï¼šâ‰¤20ms
EXCELLENT_THRESHOLD = 200.0
# è‰¯å¥½åŒ¹é…ï¼š20-30ms
GOOD_THRESHOLD = 300.0
# ä¸€èˆ¬åŒ¹é…ï¼š30-50ms
FAIR_THRESHOLD = 500.0
# è¾ƒå·®åŒ¹é…ï¼š50-100ms
POOR_THRESHOLD = 1000.0
# ä¸¥é‡åŒ¹é…ï¼š100-200ms
SEVERE_THRESHOLD = 2000.0
# å¤±è´¥åŒ¹é…ï¼š>200ms

# å¤šé”¤æ£€æµ‹é˜ˆå€¼ (ms) - æ’­æ”¾æå‰å½•åˆ¶çš„é˜ˆå€¼
# å¦‚æœæ’­æ”¾keyon < å½•åˆ¶keyon - ADVANCE_THRESHOLDï¼Œè®¤ä¸ºæ˜¯å¯ç–‘çš„å¤šé”¤
ADVANCE_THRESHOLD = 200.0  # 200ms

# Lookaheadçª—å£é…ç½® - å‰ç»æ£€æŸ¥ä¼˜åŒ–
# æŸ¥çœ‹å †é¡¶å‰Nä¸ªå€™é€‰ï¼Œé€‰æ‹©ç»¼åˆå¾—åˆ†æœ€ä¼˜çš„
LOOKAHEAD_WINDOW_SIZE = 3  # çª—å£å¤§å°ï¼šæŸ¥çœ‹å‰3ä¸ªå€™é€‰
# æ’­æ”¾æå‰å½•åˆ¶æ—¶çš„æƒ©ç½šç³»æ•°
# score = error + (advance_time * BIAS_PENALTY_FACTOR)
BIAS_PENALTY_FACTOR = 2.0  # æå‰æƒ©ç½šç³»æ•°ï¼š2å€

# å…¼å®¹æ€§å¸¸é‡ (å‘åå…¼å®¹)
PRECISION_THRESHOLD = FAIR_THRESHOLD      # 50ms - ç²¾ç¡®åŒ¹é…ä¸Šé™
APPROXIMATE_THRESHOLD = POOR_THRESHOLD    # 100ms - è¾ƒå·®åŒ¹é…ä¸Šé™

# åŒ¹é…ç±»å‹æšä¸¾ - æŒ‰è¯¯å·®ç­‰çº§ç»†åˆ†
class MatchType(Enum):
    """åŒ¹é…ç»“æœç±»å‹ - æŒ‰è¯¯å·®ç­‰çº§åˆ†ç±»"""
    EXCELLENT = "excellent"      # ä¼˜ç§€åŒ¹é… (è¯¯å·® â‰¤ 20ms)
    GOOD = "good"               # è‰¯å¥½åŒ¹é… (20ms < è¯¯å·® â‰¤ 30ms)
    FAIR = "fair"               # ä¸€èˆ¬åŒ¹é… (30ms < è¯¯å·® â‰¤ 50ms)
    POOR = "poor"               # è¾ƒå·®åŒ¹é… (50ms < è¯¯å·® â‰¤ 100ms)
    SEVERE = "severe"           # ä¸¥é‡åŒ¹é… (100ms < è¯¯å·® â‰¤ 200ms)
    FAILED = "failed"           # å¤±è´¥åŒ¹é… (è¯¯å·® > 200ms æˆ–æ— å€™é€‰)

# åŒ¹é…ç»“æœç±»
class MatchResult:
    """åŒ¹é…ç»“æœå°è£…ç±»"""
    def __init__(self, match_type: MatchType, record_index: int,
                 replay_index: Optional[int] = None, error_ms: float = 0.0,
                 pair: Optional[Tuple[Note, Note]] = None, reason: str = ""):
        self.match_type = match_type
        self.record_index = record_index
        self.replay_index = replay_index
        self.error_ms = error_ms  # è¯¯å·®(æ¯«ç§’)
        self.pair = pair  # åŒ¹é…å¯¹ (record_note, replay_note)
        self.reason = reason  # å¤±è´¥åŸå› 

    @property
    def is_success(self) -> bool:
        """æ˜¯å¦åŒ¹é…æˆåŠŸ"""
        return self.match_type != MatchType.FAILED

# å€™é€‰ä¿¡æ¯ç±»
class Candidate:
    """å€™é€‰åŒ¹é…ä¿¡æ¯"""
    def __init__(self, index: int, total_error: float, note: Optional[Note] = None):
        self.index = index
        self.total_error = total_error
        self.note = note

    @property
    def error_ms(self) -> float:
        """è¯¯å·®è½¬æ¢ä¸ºæ¯«ç§’"""
        return self.total_error / 10.0

# æŒ‰é”®åŒ¹é…ç»Ÿè®¡ç±» - æ–°å¢ï¼šæŒ‰é”®çº§åˆ«çš„ç»Ÿè®¡ä¿¡æ¯
class KeyMatchStatistics:
    """å•ä¸ªæŒ‰é”®çš„åŒ¹é…ç»Ÿè®¡ä¿¡æ¯"""

    def __init__(self, key_id: int):
        self.key_id = key_id
        self.total_record_notes = 0    # è¯¥æŒ‰é”®å½•åˆ¶éŸ³ç¬¦æ€»æ•°
        self.total_replay_notes = 0    # è¯¥æŒ‰é”®æ’­æ”¾éŸ³ç¬¦æ€»æ•°
        self.matched_count = 0         # æˆåŠŸåŒ¹é…æ•°
        self.failed_count = 0          # å¤±è´¥åŒ¹é…æ•°
        self.extra_hammers = 0         # å¤šé”¤æ•°ï¼ˆæœªä½¿ç”¨çš„æ’­æ”¾éŸ³ç¬¦ï¼‰

        # è¯¯å·®ç»Ÿè®¡ï¼ˆåªç»Ÿè®¡æˆåŠŸåŒ¹é…ï¼‰
        self.offsets_ms: List[float] = []  # æ ¡å‡†ååç§»ï¼ˆmsï¼‰
        self.median_offset = 0.0
        self.mean_offset = 0.0
        self.std_offset = 0.0
        self.variance_offset = 0.0

        # åŒ¹é…è´¨é‡åˆ†å¸ƒ
        self.excellent_count = 0
        self.good_count = 0
        self.fair_count = 0
        self.poor_count = 0
        self.severe_count = 0

    def add_match_result(self, match_result: MatchResult, corrected_offset_ms: float):
        """æ·»åŠ åŒ¹é…ç»“æœ"""
        if match_result.is_success:
            self.matched_count += 1
            self.offsets_ms.append(corrected_offset_ms)

            # ç»Ÿè®¡åŒ¹é…è´¨é‡
            if match_result.match_type == MatchType.EXCELLENT:
                self.excellent_count += 1
            elif match_result.match_type == MatchType.GOOD:
                self.good_count += 1
            elif match_result.match_type == MatchType.FAIR:
                self.fair_count += 1
            elif match_result.match_type == MatchType.POOR:
                self.poor_count += 1
            elif match_result.match_type == MatchType.SEVERE:
                self.severe_count += 1
        else:
            self.failed_count += 1

    def calculate_statistics(self):
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        if self.offsets_ms:
            import statistics
            self.median_offset = statistics.median(self.offsets_ms)
            self.mean_offset = statistics.mean(self.offsets_ms)

            if len(self.offsets_ms) > 1:
                self.std_offset = statistics.stdev(self.offsets_ms)
                self.variance_offset = statistics.variance(self.offsets_ms)
            else:
                self.std_offset = 0.0
                self.variance_offset = 0.0

    def __str__(self):
        return f"æŒ‰é”®{self.key_id}: å½•åˆ¶{self.total_record_notes}, æ’­æ”¾{self.total_replay_notes}, åŒ¹é…{self.matched_count}, å¤±è´¥{self.failed_count}, å‡å€¼{self.mean_offset:.2f}ms"

# åŒ¹é…ç»Ÿè®¡ç±»
class MatchStatistics:
    """åŒ¹é…ç»Ÿè®¡ä¿¡æ¯ - å…­ç­‰çº§ç³»ç»Ÿ"""

    def __init__(self):
        # å…­ç­‰çº§åŒ¹é…ç»Ÿè®¡
        self.excellent_matches = 0    # ä¼˜ç§€åŒ¹é… (â‰¤20ms)
        self.good_matches = 0         # è‰¯å¥½åŒ¹é… (20-30ms)
        self.fair_matches = 0         # ä¸€èˆ¬åŒ¹é… (30-50ms)
        self.poor_matches = 0         # è¾ƒå·®åŒ¹é… (50-100ms)
        self.severe_matches = 0       # ä¸¥é‡è¯¯å·® (100-200ms)
        self.failed_matches = 0       # å¤±è´¥åŒ¹é… (>200msæˆ–æ— å€™é€‰)

        # å…¼å®¹æ€§å­—æ®µ - ä¿æŒå‘åå…¼å®¹
        self.precision_matches = 0    # ç²¾ç¡®åŒ¹é…æ€»æ•° (â‰¤50ms)
        self.approximate_matches = 0  # è¾ƒå·®åŒ¹é…æ€»æ•° (50-100ms)
        self.large_error_matches = 0  # ä¸¥é‡è¯¯å·®åŒ¹é…æ€»æ•° (100-200ms)

        self.total_attempts = 0       # æ€»å°è¯•æ•°

    def add_result(self, result: MatchResult):
        """æ·»åŠ åŒ¹é…ç»“æœåˆ°ç»Ÿè®¡"""
        self.total_attempts += 1

        if result.match_type == MatchType.EXCELLENT:
            self.excellent_matches += 1
            self.precision_matches += 1
        elif result.match_type == MatchType.GOOD:
            self.good_matches += 1
            self.precision_matches += 1
        elif result.match_type == MatchType.FAIR:
            self.fair_matches += 1
            self.precision_matches += 1
        elif result.match_type == MatchType.POOR:
            self.poor_matches += 1
            self.approximate_matches += 1
        elif result.match_type == MatchType.SEVERE:
            self.severe_matches += 1
            self.large_error_matches += 1
        elif result.match_type == MatchType.FAILED:
            self.failed_matches += 1

    def __str__(self):
        return f"ä¼˜ç§€:{self.excellent_matches}, è‰¯å¥½:{self.good_matches}, ä¸€èˆ¬:{self.fair_matches}, è¾ƒå·®:{self.poor_matches}, ä¸¥é‡:{self.severe_matches}, å¤±è´¥:{self.failed_matches}"

class NoteMatcher:
    """SPMIDéŸ³ç¬¦åŒ¹é…å™¨ç±»"""
    
    def __init__(self, global_time_offset: float = 0.0):
        """
        åˆå§‹åŒ–éŸ³ç¬¦åŒ¹é…å™¨ - äº”ç­‰çº§åŒ¹é…ç³»ç»Ÿ

        Args:
            global_time_offset: åˆå§‹å…¨å±€æ—¶é—´åç§»é‡ï¼ˆå¯é€‰ï¼Œä¼šåœ¨åŒ¹é…è¿‡ç¨‹ä¸­é‡æ–°è®¡ç®—ï¼‰
        """
        self.global_time_offset = global_time_offset

        # æ ¸å¿ƒåŒ¹é…ç»“æœå­˜å‚¨
        self.matched_pairs: List[Tuple[int, int, Note, Note]] = []  # æ‰€æœ‰æˆåŠŸåŒ¹é…å¯¹ (record_idx, replay_idx, record_note, replay_note)
        self.match_results: List[MatchResult] = []  # æ‰€æœ‰åŒ¹é…ç»“æœè¯¦æƒ… (åŒ…å«åŒ¹é…ç±»å‹ã€è¯¯å·®ç­‰)

        # æŒç»­æ—¶é—´å·®å¼‚æ£€æµ‹ç»“æœ
        # (record_idx, replay_idx, record_note, replay_note, 
        #  record_duration, replay_duration, duration_ratio,
        #  record_keyon, record_keyoff, replay_keyon, replay_keyoff)
        self.duration_diff_pairs: List[Tuple[int, int, Note, Note, float, float, float, float, float, float, float]] = []

        # åŒ¹é…å¤±è´¥ä¿¡æ¯
        self.failure_reasons: Dict[Tuple[str, int], str] = {}  # key=(data_type, index)ï¼Œvalue=str

        # åˆ†ç±»å­˜å‚¨ - æŒ‰æœç´¢é˜¶æ®µåˆ†ç»„ï¼ˆç”¨äºæ•°æ®è·å–ä¼˜åŒ–ï¼‰
        self.precision_matched_pairs: List[Tuple[int, int, Note, Note]] = []  # ç²¾ç¡®æœç´¢é˜¶æ®µåŒ¹é… (â‰¤50ms)
        self.approximate_matched_pairs: List[Tuple[int, int, Note, Note]] = []  # è¿‘ä¼¼æœç´¢é˜¶æ®µåŒ¹é… (50-1000ms)
        self.severe_matched_pairs: List[Tuple[int, int, Note, Note]] = []  # ä¸¥é‡è¯¯å·®æœç´¢é˜¶æ®µåŒ¹é… (>1000ms)

        # æŒ‰é”®åˆ†ç»„ç»Ÿè®¡ä¿¡æ¯ - æ–°å¢ï¼šé¢„è®¡ç®—çš„æŒ‰é”®çº§åˆ«ç»Ÿè®¡æ•°æ®
        self.key_statistics: Dict[int, KeyMatchStatistics] = {}  # key=key_id, value=è¯¥æŒ‰é”®çš„ç»Ÿè®¡ä¿¡æ¯

        # ç»Ÿè®¡ä¿¡æ¯
        self.match_statistics = MatchStatistics()

        # æ•°æ®å¼•ç”¨ç¼“å­˜
        self._record_data: Optional[List[Note]] = None
        self._replay_data: Optional[List[Note]] = None

        # è®¡ç®—ç¼“å­˜
        self._mean_error_cached: Optional[float] = None
    
        # æ‹†åˆ†ç´¢å¼•èµ·å§‹å€¼ï¼ˆä½¿ç”¨å¤§æ•°å­—é¿å…ä¸åŸå§‹ç´¢å¼•å†²çªï¼‰
        self._split_index_offset = 1000000
        self._split_counter = 0  # å…¨å±€æ‹†åˆ†è®¡æ•°å™¨ï¼Œç¡®ä¿è·¨key_groupçš„å”¯ä¸€ç´¢å¼•
    
    def find_all_matched_pairs_legacy(self, record_data: List[Note], replay_data: List[Note]) -> List[Tuple[int, int, Note, Note]]:
        """
        ã€æ—§ç‰ˆç®—æ³• - å·²å¼ƒç”¨ã€‘æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…å¯¹ï¼šæŒ‰é”®åˆ†ç»„è´ªå¿ƒåŒ¹é…

        æ³¨æ„ï¼šæ­¤æ–¹æ³•å·²è¢«æ–°ç®—æ³•æ›¿ä»£ï¼Œä¿ç•™ä»…ç”¨äºå…¼å®¹æ€§æµ‹è¯•ã€‚
        æ–°ç®—æ³•ä½¿ç”¨åŸºäºå †çš„keyonä¼˜å…ˆåŒ¹é…ï¼Œæ”¯æŒåŒå‘æ‹†åˆ†ã€‚

        åŒ¹é…é€»è¾‘ï¼š
        1. æŒ‰æŒ‰é”®IDåˆ†ç»„å½•åˆ¶å’Œæ’­æ”¾æ•°æ®
        2. å¯¹æ¯ä¸ªæŒ‰é”®åˆ†åˆ«è¿›è¡Œè´ªå¿ƒåŒ¹é…ï¼ˆåŒæŒ‰é”®IDçš„å½•åˆ¶éŸ³ç¬¦ vs åŒæŒ‰é”®IDçš„æ’­æ”¾éŸ³ç¬¦ï¼‰
        3. æŒ‰é”®ä¹‹é—´å®Œå…¨ç‹¬ç«‹ï¼Œä¸å…è®¸è·¨æŒ‰é”®é…å¯¹

        Args:
            record_data: å½•åˆ¶æ•°æ®
            replay_data: æ’­æ”¾æ•°æ®

        Returns:
            List[Tuple[int, int, Note, Note]]: åŒ¹é…å¯¹åˆ—è¡¨ (record_index, replay_index, record_note, replay_note)
        """
        import time
        matching_start_time = time.time()

        # åˆå§‹åŒ–çŠ¶æ€
        self._initialize_matching_state()

        logger.info(f"å¼€å§‹æŒ‰é”®åˆ†ç»„è´ªå¿ƒåŒ¹é…: å½•åˆ¶æ•°æ®{len(record_data)}ä¸ªéŸ³ç¬¦, å›æ”¾æ•°æ®{len(replay_data)}ä¸ªéŸ³ç¬¦")

        # ä¿å­˜åŸå§‹æ•°æ®å¼•ç”¨ï¼ˆç”¨äºå¤±è´¥åŒ¹é…è¯¦æƒ…ï¼‰
        self._record_data = record_data
        self._replay_data = replay_data

        # 1. æŒ‰æŒ‰é”®IDåˆ†ç»„æ•°æ®
        record_by_key = self._group_notes_by_key(record_data)
        replay_by_key = self._group_notes_by_key(replay_data)

        logger.info(f"æŒ‰é”®åˆ†ç»„å®Œæˆ: å½•åˆ¶æ•°æ®{len(record_by_key)}ä¸ªæŒ‰é”®, æ’­æ”¾æ•°æ®{len(replay_by_key)}ä¸ªæŒ‰é”®")

        # 2. å¯¹æ¯ä¸ªæŒ‰é”®åˆ†åˆ«è¿›è¡Œè´ªå¿ƒåŒ¹é…
        all_matched_pairs = []

        for key_id in record_by_key.keys():
            # è·å–è¯¥æŒ‰é”®çš„æ‰€æœ‰å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦
            key_record_notes = record_by_key[key_id]  # [(original_index, note), ...]
            key_replay_notes = replay_by_key.get(key_id, [])  # [(original_index, note), ...]

            # å¯¹è¯¥æŒ‰é”®è¿›è¡Œè´ªå¿ƒåŒ¹é…
            key_matched_pairs, extra_hammers = self._match_notes_for_single_key_group(
                key_id, key_record_notes, key_replay_notes
            )

            all_matched_pairs.extend(key_matched_pairs)

            # æ›´æ–°æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯ä¸­çš„å¤šé”¤æ•°é‡
            if key_id not in self.key_statistics:
                self.key_statistics[key_id] = KeyMatchStatistics(key_id)
                self.key_statistics[key_id].total_record_notes = len(key_record_notes)
                self.key_statistics[key_id].total_replay_notes = len(key_replay_notes)
            self.key_statistics[key_id].extra_hammers = extra_hammers

            matched_count = len(key_matched_pairs)
            record_count = len(key_record_notes)
            replay_count = len(key_replay_notes)

            logger.debug(f"æŒ‰é”®{key_id}åŒ¹é…å®Œæˆ: å½•åˆ¶{record_count}ä¸ª, æ’­æ”¾{replay_count}ä¸ª, åŒ¹é…{matched_count}ä¸ª")

        # ä¿å­˜æ‰€æœ‰åŒ¹é…å¯¹
        self.matched_pairs = all_matched_pairs

        # 3. åŸºäºåŒ¹é…ç»“æœè®¡ç®—æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯
        self._calculate_key_statistics_from_matches(record_by_key, replay_by_key)

        # è®°å½•æŒ‰é”®çº§åˆ«çš„åŒ¹é…ç»Ÿè®¡
        self._log_key_matching_statistics()

        # åŒ¹é…å®Œæˆåè®¡ç®—å¹¶ç¼“å­˜å¹³å‡è¯¯å·®
        self._mean_error_cached = self._calculate_mean_error()

        # è®¡ç®—å¹¶è®°å½•æ€§èƒ½ç»Ÿè®¡
        matching_end_time = time.time()
        matching_duration = matching_end_time - matching_start_time

        # æ‰“å°åŒ¹é…ç»Ÿè®¡ä¿¡æ¯
        logger.info(f"æŒ‰é”®åŒ¹é…æ€§èƒ½ç»Ÿè®¡: è€—æ—¶{matching_duration:.3f}ç§’")
        logger.info(f"åŒ¹é…ç»“æœ: ç²¾ç¡®{self.match_statistics.precision_matches} | è¿‘ä¼¼{self.match_statistics.approximate_matches} | å¤§è¯¯å·®{self.match_statistics.large_error_matches} | å¤±è´¥{self.match_statistics.failed_matches} | æ€»æ•°{len(all_matched_pairs)}")

        # è¾“å‡ºæŒç»­æ—¶é—´å·®å¼‚ç»Ÿè®¡
        duration_diff_count = len(self.duration_diff_pairs)
        if duration_diff_count > 0:
            logger.info(f"æŒç»­æ—¶é—´å·®å¼‚æ£€æµ‹: å‘ç°{duration_diff_count}ä¸ªæŒç»­æ—¶é—´å·®å¼‚æ˜¾è‘—çš„åŒ¹é…å¯¹")
        else:
            logger.info("æŒç»­æ—¶é—´å·®å¼‚æ£€æµ‹: æœªå‘ç°æŒç»­æ—¶é—´å·®å¼‚æ˜¾è‘—çš„åŒ¹é…å¯¹")

        # æ€§èƒ½è¯¦æƒ…è¾“å‡ºåˆ°æ§åˆ¶å°
        print(f"[åŒ¹é…ç»Ÿè®¡] ç²¾ç¡®åŒ¹é…: {self.match_statistics.precision_matches} ä¸ª")
        print(f"[åŒ¹é…ç»Ÿè®¡] è¾ƒå·®åŒ¹é…: {self.match_statistics.approximate_matches} ä¸ª")
        print(f"[åŒ¹é…ç»Ÿè®¡] ä¸¥é‡è¯¯å·®: {self.match_statistics.large_error_matches} ä¸ª")
        print(f"[åŒ¹é…ç»Ÿè®¡] å¤±è´¥åŒ¹é…: {self.match_statistics.failed_matches} ä¸ª")
        print(f"[åŒ¹é…ç»Ÿè®¡] æ€»åŒ¹é…å¯¹: {len(all_matched_pairs)} ä¸ª (å‡†ç¡®ç‡åˆ†å­)")
        print(f"[æŒç»­æ—¶é—´å·®å¼‚] æ£€æµ‹åˆ°: {duration_diff_count} ä¸ªæŒç»­æ—¶é—´å·®å¼‚æ˜¾è‘—çš„åŒ¹é…å¯¹")
        print(f"[æ€§èƒ½ç»Ÿè®¡] æŒ‰é”®åŒ¹é…è€—æ—¶: {matching_duration:.3f} ç§’")

        return all_matched_pairs

    # ========== ä¸»ç®—æ³•ï¼šåŸºäºå †çš„keyonä¼˜å…ˆåŒ¹é…ï¼ˆæ”¯æŒæ‹†åˆ†ï¼‰ ==========
    # æ³¨æ„ï¼šæ—§ç®—æ³•å·²é‡å‘½åä¸º find_all_matched_pairs_legacy
    
    def find_all_matched_pairs(self, record_data: List[Note], replay_data: List[Note]) -> List[Tuple[int, int, Note, Note]]:
        """
        æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…å¯¹ï¼šåŸºäºæœ€å°å †çš„keyonä¼˜å…ˆåŒ¹é…ï¼ˆæ”¯æŒåŒå‘æ‹†åˆ†ï¼‰
        
        æ ¸å¿ƒç‰¹æ€§ï¼š
        1. æŒ‰keyonæ—¶é—´é¡ºåºå¤„ç†ï¼ˆæœ€å°å †ï¼‰
        2. è´ªå¿ƒç­–ç•¥ï¼škeyonæœ€å°ï¼ˆåœ¨é˜ˆå€¼å†…ï¼‰
        3. æ”¯æŒåŒå‘æ‹†åˆ†ï¼ˆå½•åˆ¶/æ’­æ”¾éƒ½å¯æ‹†åˆ†ï¼‰
        4. ä¿ç•™6ç­‰çº§è´¨é‡è¯„åˆ¤
        5. åŠ¨æ€é‡æ–°åŒ¹é…
        
        åŒ¹é…æµç¨‹ï¼š
        1. æŒ‰key_idåˆ†ç»„
        2. å¯¹æ¯ä¸ªæŒ‰é”®æ„å»ºæœ€å°å †ï¼ˆæŒ‰keyonæ’åºï¼‰
        3. æŒ‰keyoné¡ºåºåŒ¹é…ï¼Œæ£€æµ‹æŒç»­æ—¶é—´å·®å¼‚å¹¶æ‹†åˆ†
        4. æ‹†åˆ†åçš„æ•°æ®é‡æ–°åŠ å…¥å †
        
        ç®—æ³•ä¼˜åŠ¿ï¼š
        - è§£å†³äº†æ—§ç®—æ³•æ— æ³•å¤„ç†åŒå‘åˆå¹¶çš„é—®é¢˜
        - ä¸¥æ ¼æŒ‰keyonæ—¶é—´æ’åºï¼Œé¿å…åŒ¹é…é”™è¯¯
        - æ”¯æŒæ™ºèƒ½æ‹†åˆ†ï¼ˆæ‹ç‚¹ä¼˜å…ˆï¼Œè§¦åå€¼æœ€å°åå¤‡ï¼‰
        
        Args:
            record_data: å½•åˆ¶æ•°æ®
            replay_data: æ’­æ”¾æ•°æ®
            
        Returns:
            List[Tuple[int, int, Note, Note]]: åŒ¹é…å¯¹åˆ—è¡¨ (record_index, replay_index, record_note, replay_note)
        """
        matching_start_time = time.time()
        
        # åˆå§‹åŒ–çŠ¶æ€
        self._initialize_matching_state()
        
        logger.info(f"ğŸš€ å¼€å§‹æ–°ç®—æ³•åŒ¹é…ï¼ˆåŸºäºå †çš„keyonä¼˜å…ˆï¼‰: å½•åˆ¶{len(record_data)}ä¸ªéŸ³ç¬¦, æ’­æ”¾{len(replay_data)}ä¸ªéŸ³ç¬¦")
        
        # ä¿å­˜åŸå§‹æ•°æ®å¼•ç”¨
        self._record_data = record_data
        self._replay_data = replay_data
        
        # 1. æŒ‰key_idåˆ†ç»„
        record_by_key = self._group_notes_by_key(record_data)
        replay_by_key = self._group_notes_by_key(replay_data)
        
        logger.info(f"æŒ‰é”®åˆ†ç»„å®Œæˆ: å½•åˆ¶{len(record_by_key)}ä¸ªæŒ‰é”®, æ’­æ”¾{len(replay_by_key)}ä¸ªæŒ‰é”®")
        
        # 2. å¯¹æ¯ä¸ªæŒ‰é”®åˆ†åˆ«è¿›è¡Œå †åŒ¹é…
        all_matched_pairs = []
        
        for key_id in sorted(record_by_key.keys()):
            key_record_notes = record_by_key[key_id]
            key_replay_notes = replay_by_key.get(key_id, [])
            
            logger.info(f"ğŸ“Œ å¤„ç†æŒ‰é”®{key_id}: å½•åˆ¶{len(key_record_notes)}ä¸ª, æ’­æ”¾{len(key_replay_notes)}ä¸ª")
            
            # å¯¹è¯¥æŒ‰é”®è¿›è¡Œå †åŒ¹é…
            key_matched_pairs = self._match_single_key_with_heap(
                key_id, key_record_notes, key_replay_notes
            )
            
            all_matched_pairs.extend(key_matched_pairs)
            
            logger.info(f"âœ… æŒ‰é”®{key_id}åŒ¹é…å®Œæˆ: åŒ¹é…{len(key_matched_pairs)}å¯¹")
        
        # ä¿å­˜åŒ¹é…å¯¹
        self.matched_pairs = all_matched_pairs
        
        # 3. è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        self._calculate_key_statistics_from_matches(record_by_key, replay_by_key)
        
        # ç¼“å­˜å¹³å‡è¯¯å·®
        self._mean_error_cached = self._calculate_mean_error()
        
        # æ€§èƒ½ç»Ÿè®¡
        matching_end_time = time.time()
        matching_duration = matching_end_time - matching_start_time
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info(f"ğŸ¯ æ–°ç®—æ³•åŒ¹é…å®Œæˆ: æ€»åŒ¹é…å¯¹{len(all_matched_pairs)}ä¸ª, è€—æ—¶{matching_duration:.3f}ç§’")
        logger.info(f"è´¨é‡åˆ†å¸ƒ: ä¼˜ç§€{self.match_statistics.precision_matches} | "
                   f"è¿‘ä¼¼{self.match_statistics.approximate_matches} | "
                   f"å¤§è¯¯å·®{self.match_statistics.large_error_matches} | "
                   f"å¤±è´¥{self.match_statistics.failed_matches}")
        
        duration_diff_count = len(self.duration_diff_pairs)
        if duration_diff_count > 0:
            logger.info(f"æŒç»­æ—¶é—´å·®å¼‚: æ£€æµ‹åˆ°{duration_diff_count}ä¸ªï¼ˆæ‹†åˆ†å¤„ç†åï¼‰")
        
        # æ§åˆ¶å°è¾“å‡º
        print(f"\n{'='*60}")
        print(f"[æ–°ç®—æ³•] åŒ¹é…å®Œæˆ")
        print(f"{'='*60}")
        print(f"[åŒ¹é…ç»Ÿè®¡] æ€»åŒ¹é…å¯¹: {len(all_matched_pairs)} ä¸ª")
        print(f"[è´¨é‡åˆ†å¸ƒ] ä¼˜ç§€: {self.match_statistics.precision_matches} ä¸ª")
        print(f"[è´¨é‡åˆ†å¸ƒ] è¿‘ä¼¼: {self.match_statistics.approximate_matches} ä¸ª")
        print(f"[è´¨é‡åˆ†å¸ƒ] å¤§è¯¯å·®: {self.match_statistics.large_error_matches} ä¸ª")
        print(f"[è´¨é‡åˆ†å¸ƒ] å¤±è´¥: {self.match_statistics.failed_matches} ä¸ª")
        print(f"[æŒç»­æ—¶é—´å·®å¼‚] æ£€æµ‹åˆ°: {duration_diff_count} ä¸ª")
        print(f"[æ€§èƒ½ç»Ÿè®¡] åŒ¹é…è€—æ—¶: {matching_duration:.3f} ç§’")
        print(f"{'='*60}\n")
        
        return all_matched_pairs
    
    def _match_single_key_with_heap(self, key_id: int, 
                                     record_notes: List[Tuple[int, Note]], 
                                     replay_notes: List[Tuple[int, Note]]) -> List[Tuple[int, int, Note, Note]]:
        """
        ä½¿ç”¨æœ€å°å †å¯¹å•ä¸ªæŒ‰é”®è¿›è¡ŒåŒ¹é…ï¼ˆæ”¯æŒæ‹†åˆ†ï¼‰
        
        Args:
            key_id: æŒ‰é”®ID
            record_notes: è¯¥æŒ‰é”®çš„å½•åˆ¶éŸ³ç¬¦åˆ—è¡¨ [(åŸå§‹ç´¢å¼•, Note), ...]
            replay_notes: è¯¥æŒ‰é”®çš„æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨ [(åŸå§‹ç´¢å¼•, Note), ...]
            
        Returns:
            List[Tuple[int, int, Note, Note]]: è¯¥æŒ‰é”®çš„åŒ¹é…å¯¹åˆ—è¡¨
        """
        logger.debug(f"  ğŸ”§ åˆå§‹åŒ–æŒ‰é”®{key_id}çš„å †ç»“æ„...")
        
        # æ„å»ºæœ€å°å †
        record_heap, replay_heap = self._build_matching_heaps(key_id, record_notes, replay_notes)
        
        # åˆå§‹åŒ–çŠ¶æ€
        matched_pairs = []
        used_replay_indices = set()
        skipped_replay_indices = set()  # è·³è¿‡çš„æ’­æ”¾æ•°æ®ç´¢å¼•ï¼ˆå¯ç–‘çš„å¤šé”¤ï¼‰
        
        logger.debug(f"  ğŸ”„ å¼€å§‹ä¸»å¾ªç¯åŒ¹é…...")
        
        # ä¸»å¾ªç¯ï¼šå¤„ç†æ‰€æœ‰å½•åˆ¶æ•°æ®
        match_count, failed_count = self._process_record_notes(
            key_id, record_heap, replay_heap, used_replay_indices, 
            skipped_replay_indices, matched_pairs
        )
        
        # å¤„ç†è·³è¿‡çš„æ’­æ”¾æ•°æ®ï¼ˆå¤šé”¤ï¼‰
        extra_hammer_count = self._process_skipped_replays(
            key_id, skipped_replay_indices, replay_notes
        )
        
        logger.debug(f"  âœ… æŒ‰é”®{key_id}åŒ¹é…å®Œæˆ: æˆåŠŸ{match_count}ä¸ª, å¤±è´¥{failed_count}ä¸ª, å¤šé”¤{extra_hammer_count}ä¸ª")
        
        return matched_pairs
    
    def _build_matching_heaps(self, key_id: int, 
                               record_notes: List[Tuple[int, Note]], 
                               replay_notes: List[Tuple[int, Note]]) -> Tuple[List, List]:
        """
        æ„å»ºå½•åˆ¶å’Œæ’­æ”¾çš„æœ€å°å †
        
        Args:
            key_id: æŒ‰é”®ID
            record_notes: å½•åˆ¶éŸ³ç¬¦åˆ—è¡¨
            replay_notes: æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨
            
        Returns:
            Tuple[List, List]: (record_heap, replay_heap)
        """
        # å †å…ƒç´ æ ¼å¼: (keyon_time, parent_index, note_object, split_seq)
        # split_seq: None=åŸå§‹æ•°æ®, 0/1/2...=æ‹†åˆ†åºå·
        
        # å½•åˆ¶å †
        record_heap = []
        for orig_idx, note in record_notes:
            if note.key_on_ms is not None:
                heapq.heappush(record_heap, (note.key_on_ms, orig_idx, note, None))
            else:
                logger.warning(f"  âš ï¸ æŒ‰é”®{key_id}çš„å½•åˆ¶éŸ³ç¬¦ç´¢å¼•{orig_idx}æ²¡æœ‰key_on_msï¼Œè·³è¿‡")
        
        # æ’­æ”¾å †
        replay_heap = []
        for orig_idx, note in replay_notes:
            if note.key_on_ms is not None:
                heapq.heappush(replay_heap, (note.key_on_ms, orig_idx, note, None))
            else:
                logger.warning(f"  âš ï¸ æŒ‰é”®{key_id}çš„æ’­æ”¾éŸ³ç¬¦ç´¢å¼•{orig_idx}æ²¡æœ‰key_on_msï¼Œè·³è¿‡")
        
        logger.debug(f"  ğŸ“Š å †æ„å»ºå®Œæˆ: å½•åˆ¶å †{len(record_heap)}ä¸ª, æ’­æ”¾å †{len(replay_heap)}ä¸ª")
        
        return record_heap, replay_heap
    
    def _process_record_notes(self, key_id: int, record_heap: List, replay_heap: List,
                               used_replay_indices: set, skipped_replay_indices: set,
                               matched_pairs: List) -> Tuple[int, int]:
        """
        å¤„ç†æ‰€æœ‰å½•åˆ¶æ•°æ®çš„ä¸»å¾ªç¯
        
        Args:
            key_id: æŒ‰é”®ID
            record_heap: å½•åˆ¶å †
            replay_heap: æ’­æ”¾å †
            used_replay_indices: å·²ä½¿ç”¨çš„æ’­æ”¾ç´¢å¼•é›†åˆ
            skipped_replay_indices: è·³è¿‡çš„æ’­æ”¾ç´¢å¼•é›†åˆï¼ˆå¯ç–‘çš„å¤šé”¤ï¼‰
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨ï¼ˆè¾“å‡ºï¼‰
            
        Returns:
            Tuple[int, int]: (æˆåŠŸåŒ¹é…æ•°, å¤±è´¥åŒ¹é…æ•°)
        """
        match_count = 0
        failed_count = 0
        
        while record_heap:
            # å–å‡ºå½•åˆ¶æ•°æ®
            rec_keyon, rec_idx, rec_note, rec_split_seq = heapq.heappop(record_heap)
            self._log_processing_record(rec_idx, rec_note, rec_keyon)
            
            # æ¸…ç†å·²ä½¿ç”¨çš„æ’­æ”¾æ•°æ®
            self._clean_used_replay_notes(replay_heap, used_replay_indices)
            
            # æŸ¥æ‰¾æ’­æ”¾å€™é€‰ï¼ˆæ”¯æŒè·³è¿‡å¯ç–‘çš„å¤šé”¤ï¼‰
            replay_candidate = self._find_replay_candidate(
                key_id, replay_heap, rec_keyon, skipped_replay_indices
            )
            
            if replay_candidate is None:
                # æ— å¯ç”¨å€™é€‰ â†’ å¤±è´¥
                self._create_failed_match(rec_idx, None, "æ— å¯ç”¨æ’­æ”¾æ•°æ®")
                failed_count += 1
                continue
            
            rep_keyon, rep_idx, rep_note, rep_split_seq, keyon_error_ms = replay_candidate
            
            # æ£€æŸ¥è¯¯å·®é˜ˆå€¼
            if not self._check_error_threshold(keyon_error_ms, rec_idx, rep_idx, rep_split_seq):
                # è¶…å‡ºé˜ˆå€¼ â†’ å¤±è´¥
                failed_count += 1
                continue
            
            # åˆ›å»ºæˆåŠŸåŒ¹é…ï¼ˆæ”¯æŒæ‹†åˆ†ï¼Œåœ¨popæ’­æ”¾æ•°æ®ä¹‹å‰æ£€æŸ¥æ˜¯å¦éœ€è¦æ‹†åˆ†ï¼‰
            success, split_type = self._create_successful_match(
                rec_idx, rec_note, rec_split_seq,
                rep_idx, rep_note, rep_split_seq,
                keyon_error_ms, matched_pairs, used_replay_indices,
                record_heap, replay_heap
            )
            
            if success:
                # åŒ¹é…æˆåŠŸï¼šæ¶ˆè´¹æ’­æ”¾æ•°æ®
                heapq.heappop(replay_heap)
                match_count += 1
        
        return match_count, failed_count
    
    def _log_processing_record(self, rec_idx: int, rec_note: Note, rec_keyon: float):
        """è®°å½•å½“å‰å¤„ç†çš„å½•åˆ¶æ•°æ®"""
        if rec_note.is_split:
            parent_idx = rec_note.split_parent_idx if rec_note.split_parent_idx is not None else rec_idx
            split_seq = rec_note.split_seq if rec_note.split_seq is not None else 0
            logger.debug(f"    å¤„ç†å½•åˆ¶[{parent_idx}:æ‹†åˆ†{split_seq}] keyon={rec_keyon:.1f}ms")
        else:
            logger.debug(f"    å¤„ç†å½•åˆ¶[{rec_idx}] keyon={rec_keyon:.1f}ms")
    
    def _clean_used_replay_notes(self, replay_heap: List, used_replay_indices: set):
        """æ¸…ç†æ’­æ”¾å †é¡¶çš„å·²ä½¿ç”¨æ•°æ®ï¼ˆæƒ°æ€§åˆ é™¤ï¼‰"""
        while replay_heap:
            rep_keyon, rep_idx, rep_note, rep_split_seq = replay_heap[0]
            
            if rep_idx in used_replay_indices:
                heapq.heappop(replay_heap)
                logger.debug(f"      æ¸…ç†å·²ä½¿ç”¨çš„æ’­æ”¾[{rep_idx}]")
                continue
            else:
                break
    
    def _find_replay_candidate(self, key_id: int, replay_heap: List, rec_keyon: float,
                                skipped_replay_indices: set) -> Optional[Tuple]:
        """
        ä½¿ç”¨Lookaheadçª—å£æŸ¥æ‰¾æœ€ä½³æ’­æ”¾å€™é€‰
        
        ç­–ç•¥ï¼š
        1. å…ˆè·³è¿‡æå‰è¶…è¿‡200msçš„å€™é€‰ï¼ˆADVANCE_THRESHOLDæ£€æµ‹ï¼‰
        2. Peekå‰Nä¸ªå€™é€‰è¿›è¡Œç»¼åˆè¯„åˆ†
        3. é€‰æ‹©å¾—åˆ†æœ€ä½çš„å€™é€‰
        4. è·³è¿‡å‰é¢çš„æ¬¡ä¼˜å€™é€‰
        
        Args:
            key_id: æŒ‰é”®ID
            replay_heap: æ’­æ”¾å †
            rec_keyon: å½•åˆ¶keyonæ—¶é—´ï¼ˆmsï¼‰
            skipped_replay_indices: è·³è¿‡çš„æ’­æ”¾ç´¢å¼•é›†åˆï¼ˆè¾“å‡ºï¼‰
            
        Returns:
            Optional[Tuple]: (rep_keyon, rep_idx, rep_note, rep_split_seq, error_ms) æˆ– None
        """
        if not replay_heap:
            logger.debug(f"      âœ— æ— å¯ç”¨æ’­æ”¾æ•°æ® â†’ å¤±è´¥")
            return None
        
        # ã€ç¬¬ä¸€é“é˜²çº¿ã€‘å¾ªç¯è·³è¿‡"æå‰è¿‡å¤š"çš„æ’­æ”¾æ•°æ®ï¼ˆ>200msï¼Œæç«¯æƒ…å†µï¼‰
        while replay_heap:
            rep_keyon, rep_idx, rep_note, rep_split_seq = replay_heap[0]
            
            # æ£€æŸ¥ï¼šæ’­æ”¾æ˜¯å¦"æå‰"è¿‡å¤šï¼Ÿ
            if rep_keyon < rec_keyon - ADVANCE_THRESHOLD:
                # æ’­æ”¾æ˜æ˜¾æå‰å½•åˆ¶ï¼Œå¯èƒ½æ˜¯å¤šé”¤
                advance_ms = rec_keyon - rep_keyon
                
                # æ—¥å¿—
                if rep_note.is_split:
                    parent_idx = rep_note.split_parent_idx if rep_note.split_parent_idx is not None else rep_idx
                    split_seq = rep_note.split_seq if rep_note.split_seq is not None else 0
                    logger.debug(f"      âš ï¸ [é˜²çº¿1] è·³è¿‡æç«¯å¤šé”¤ æ’­æ”¾[{parent_idx}:æ‹†åˆ†{split_seq}] "
                               f"keyon={rep_keyon:.1f}ms æå‰å½•åˆ¶{advance_ms:.1f}ms > é˜ˆå€¼{ADVANCE_THRESHOLD:.1f}ms")
                else:
                    logger.debug(f"      âš ï¸ [é˜²çº¿1] è·³è¿‡æç«¯å¤šé”¤ æ’­æ”¾[{rep_idx}] "
                               f"keyon={rep_keyon:.1f}ms æå‰å½•åˆ¶{advance_ms:.1f}ms > é˜ˆå€¼{ADVANCE_THRESHOLD:.1f}ms")
                
                # ç§»é™¤å¹¶è®°å½•
                heapq.heappop(replay_heap)
                skipped_replay_indices.add((rep_idx, rep_note.key_on_ms, rep_split_seq, rep_note.is_split))
                continue
            else:
                break
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¯ç”¨å€™é€‰
        if not replay_heap:
            logger.debug(f"      âœ— è·³è¿‡å¤šé”¤åæ— å¯ç”¨æ’­æ”¾æ•°æ® â†’ å¤±è´¥")
            return None
        
        # ã€ç¬¬äºŒé“é˜²çº¿ã€‘Lookaheadçª—å£è¯„åˆ†ï¼Œé€‰æ‹©æœ€ä½³å€™é€‰
        best_candidate = self._select_best_candidate_with_lookahead(
            replay_heap, rec_keyon, skipped_replay_indices
        )
        
        if best_candidate is None:
            logger.debug(f"      âœ— Lookaheadè¯„åˆ†åæ— å¯æ¥å—å€™é€‰ â†’ å¤±è´¥")
            return None
        
        return best_candidate
    
    def _select_best_candidate_with_lookahead(self, replay_heap: List, rec_keyon: float,
                                               skipped_replay_indices: set) -> Optional[Tuple]:
        """
        ä½¿ç”¨Lookaheadçª—å£è¯„åˆ†å¹¶é€‰æ‹©æœ€ä½³å€™é€‰
        
        Args:
            replay_heap: æ’­æ”¾å †
            rec_keyon: å½•åˆ¶keyonæ—¶é—´ï¼ˆmsï¼‰
            skipped_replay_indices: è·³è¿‡çš„æ’­æ”¾ç´¢å¼•é›†åˆï¼ˆè¾“å‡ºï¼‰
            
        Returns:
            Optional[Tuple]: (rep_keyon, rep_idx, rep_note, rep_split_seq, error_ms) æˆ– None
        """
        # 1. Peekå‰Nä¸ªå€™é€‰
        window_size = min(LOOKAHEAD_WINDOW_SIZE, len(replay_heap))
        candidates = []
        
        for i in range(window_size):
            rep_keyon, rep_idx, rep_note, rep_split_seq = replay_heap[i]
            candidates.append({
                'heap_index': i,
                'keyon': rep_keyon,
                'idx': rep_idx,
                'note': rep_note,
                'split_seq': rep_split_seq
            })
        
        # 2. è¯„åˆ†æ¯ä¸ªå€™é€‰
        logger.debug(f"      ğŸ“Š [Lookahead] è¯„ä¼°å‰{window_size}ä¸ªå€™é€‰:")
        
        scored_candidates = []
        for candidate in candidates:
            score_result = self._calculate_candidate_score(candidate, rec_keyon)
            scored_candidates.append(score_result)
            
            # è¯¦ç»†æ—¥å¿—
            c = score_result['candidate']
            idx_str = self._format_note_index(c['idx'], c['note'], c['split_seq'])
            logger.debug(f"        æ’­æ”¾{idx_str} "
                        f"keyon={score_result['keyon']:.1f}ms "
                        f"è¯¯å·®={score_result['error']:.1f}ms "
                        f"åå‘={score_result['bias']:+.1f}ms "
                        f"æƒ©ç½š={score_result['penalty']:.1f} "
                        f"â†’ æ€»åˆ†={score_result['score']:.1f}")
        
        # 3. é€‰æ‹©å¾—åˆ†æœ€ä½çš„
        scored_candidates.sort(key=lambda x: x['score'])
        best = scored_candidates[0]
        best_index = best['candidate']['heap_index']
        
        # æ—¥å¿—ï¼šé€‰æ‹©ç»“æœ
        best_c = best['candidate']
        best_idx_str = self._format_note_index(best_c['idx'], best_c['note'], best_c['split_seq'])
        logger.debug(f"      âœ“ [Lookahead] é€‰æ‹©æ’­æ”¾{best_idx_str} keyon={best['keyon']:.1f}ms (æ€»åˆ†={best['score']:.1f})")
        
        # 4. è·³è¿‡å‰é¢çš„æ¬¡ä¼˜å€™é€‰
        if best_index > 0:
            logger.debug(f"      âš ï¸ [Lookahead] è·³è¿‡å‰{best_index}ä¸ªæ¬¡ä¼˜å€™é€‰:")
            for i in range(best_index):
                rep_keyon, rep_idx, rep_note, rep_split_seq = heapq.heappop(replay_heap)
                skipped_replay_indices.add((rep_idx, rep_keyon, rep_split_seq, rep_note.is_split))
                
                idx_str = self._format_note_index(rep_idx, rep_note, rep_split_seq)
                logger.debug(f"        æ’­æ”¾{idx_str} keyon={rep_keyon:.1f}ms (ç»¼åˆå¾—åˆ†ä¸å¦‚åç»­å€™é€‰)")
        
        # 5. è¿”å›æœ€ä½³å€™é€‰ï¼ˆç°åœ¨åœ¨å †é¡¶ï¼‰
        rep_keyon, rep_idx, rep_note, rep_split_seq = replay_heap[0]
        keyon_error_ms = best['error']
        
        return (rep_keyon, rep_idx, rep_note, rep_split_seq, keyon_error_ms)
    
    def _calculate_candidate_score(self, candidate: dict, rec_keyon: float) -> dict:
        """
        è®¡ç®—å€™é€‰çš„ç»¼åˆå¾—åˆ†
        
        è¯„åˆ†å…¬å¼ï¼šscore = error + bias_penalty
        - error: ç»å¯¹è¯¯å·®
        - bias_penalty: åå‘æƒ©ç½šï¼ˆæå‰æ—¶åŠ å€æƒ©ç½šï¼‰
        
        Args:
            candidate: å€™é€‰ä¿¡æ¯å­—å…¸
            rec_keyon: å½•åˆ¶keyonæ—¶é—´ï¼ˆmsï¼‰
            
        Returns:
            dict: è¯„åˆ†ç»“æœ
        """
        replay_keyon = candidate['keyon']
        
        # 1. åŸºç¡€è¯¯å·®
        error = abs(replay_keyon - rec_keyon)
        
        # 2. è®¡ç®—åå‘ï¼ˆæ­£æ•°=æ»åï¼Œè´Ÿæ•°=æå‰ï¼‰
        bias = replay_keyon - rec_keyon
        
        # 3. è®¡ç®—åå‘æƒ©ç½š
        if bias >= 0:  # æ»åï¼ˆæ­£å¸¸ç°è±¡ï¼‰
            penalty = 0  # ä¸æƒ©ç½š
        else:  # æå‰ï¼ˆå¯ç–‘ï¼‰
            advance = abs(bias)
            penalty = advance * BIAS_PENALTY_FACTOR  # æå‰æƒ©ç½š
        
        # 4. ç»¼åˆå¾—åˆ†
        total_score = error + penalty
        
        return {
            'candidate': candidate,
            'keyon': replay_keyon,
            'score': total_score,
            'error': error,
            'bias': bias,
            'penalty': penalty
        }
    
    def _format_note_index(self, idx: int, note: Note, split_seq: Optional[int]) -> str:
        """
        æ ¼å¼åŒ–éŸ³ç¬¦ç´¢å¼•æ˜¾ç¤º
        
        Args:
            idx: éŸ³ç¬¦ç´¢å¼•
            note: Noteå¯¹è±¡
            split_seq: æ‹†åˆ†åºå·
            
        Returns:
            str: æ ¼å¼åŒ–çš„ç´¢å¼•å­—ç¬¦ä¸²
        """
        if note.is_split and split_seq is not None:
            parent_idx = note.split_parent_idx if note.split_parent_idx is not None else idx
            return f"[{parent_idx}:æ‹†åˆ†{split_seq}]"
        else:
            return f"[{idx}]"
    
    def _check_error_threshold(self, keyon_error_ms: float, rec_idx: int, 
                                rep_idx: int, rep_split_seq: Optional[int]) -> bool:
        """
        æ£€æŸ¥è¯¯å·®æ˜¯å¦åœ¨é˜ˆå€¼å†…ï¼ˆâ‰¤200msï¼‰
        
        Returns:
            bool: True=åœ¨é˜ˆå€¼å†…, False=è¶…å‡ºé˜ˆå€¼
        """
        keyon_error_units = keyon_error_ms * 10.0
        
        if keyon_error_units > SEVERE_THRESHOLD:
            logger.debug(f"      âœ— è¯¯å·®{keyon_error_ms:.1f}msè¶…å‡ºé˜ˆå€¼{SEVERE_THRESHOLD/10:.1f}ms â†’ å¤±è´¥")
            
            self._create_failed_match(
                rec_idx, keyon_error_ms,
                f"æ‰€æœ‰å€™é€‰è¯¯å·®è¶…è¿‡é˜ˆå€¼ï¼ˆ{keyon_error_ms:.1f}ms > {SEVERE_THRESHOLD/10:.1f}msï¼‰"
            )
            return False
        
        return True
    
    def _process_skipped_replays(self, key_id: int, skipped_replay_indices: set,
                                  replay_notes: List[Tuple[int, Note]]) -> int:
        """
        å¤„ç†è·³è¿‡çš„æ’­æ”¾æ•°æ®ï¼Œæ ‡è®°ä¸ºå¤šé”¤
        
        Args:
            key_id: æŒ‰é”®ID
            skipped_replay_indices: è·³è¿‡çš„æ’­æ”¾æ•°æ®é›†åˆ {(idx, keyon_ms, split_seq, is_split), ...}
            replay_notes: åŸå§‹æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
            
        Returns:
            int: å¤šé”¤æ•°é‡
        """
        if not skipped_replay_indices:
            return 0
        
        logger.debug(f"  ğŸ“‹ å¤„ç†æŒ‰é”®{key_id}è·³è¿‡çš„æ’­æ”¾æ•°æ®: {len(skipped_replay_indices)}ä¸ª")
        
        # ç»Ÿè®¡å¤šé”¤
        for rep_idx, keyon_ms, rep_split_seq, is_split in skipped_replay_indices:
            # æ—¥å¿—
            if is_split and rep_split_seq is not None:
                logger.info(f"  ğŸ”¨ ç¡®è®¤å¤šé”¤: æŒ‰é”®{key_id} æ’­æ”¾[{rep_idx}:æ‹†åˆ†{rep_split_seq}] "
                           f"keyon={keyon_ms:.1f}msï¼ˆæå‰è¿‡å¤šï¼Œæ— å¯¹åº”å½•åˆ¶æ•°æ®ï¼‰")
            else:
                logger.info(f"  ğŸ”¨ ç¡®è®¤å¤šé”¤: æŒ‰é”®{key_id} æ’­æ”¾[{rep_idx}] "
                           f"keyon={keyon_ms:.1f}msï¼ˆæå‰è¿‡å¤šï¼Œæ— å¯¹åº”å½•åˆ¶æ•°æ®ï¼‰")
        
        return len(skipped_replay_indices)
    
    def _create_failed_match(self, rec_idx: int, error_ms: Optional[float], reason: str):
        """åˆ›å»ºå¤±è´¥åŒ¹é…ç»“æœ"""
        match_result = MatchResult(
            match_type=MatchType.FAILED,
            record_index=rec_idx,
            replay_index=None,
            error_ms=error_ms,
            pair=None,
            reason=reason
        )
        self.match_results.append(match_result)
        self.match_statistics.add_result(match_result)
    
    def _create_successful_match(self, rec_idx: int, rec_note: Note, rec_split_seq: Optional[int],
                                  rep_idx: int, rep_note: Note, rep_split_seq: Optional[int],
                                  keyon_error_ms: float, matched_pairs: List,
                                  used_replay_indices: set, record_heap: List, replay_heap: List) -> Tuple[bool, str]:
        """
        åˆ›å»ºæˆåŠŸåŒ¹é…ï¼ˆæ”¯æŒæ‹†åˆ†ï¼‰
        
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, æ‹†åˆ†ç±»å‹: 'none'/'record'/'replay')
        """
        # è¯„åˆ¤è´¨é‡
        match_type = self._evaluate_match_quality(keyon_error_ms)
        
        # æ£€æŸ¥æŒç»­æ—¶é—´å·®å¼‚å¹¶å°è¯•æ‹†åˆ†
        rec_duration = rec_note.duration_ms if rec_note.duration_ms else 0
        rep_duration = rep_note.duration_ms if rep_note.duration_ms else 0
        
        if rec_duration > 0 and rep_duration > 0:
            duration_ratio = max(rec_duration, rep_duration) / min(rec_duration, rep_duration)
            
            should_split = False
            trigger_reason = ""
            force_record = False
            
            # ä¸»è¦æ¡ä»¶ï¼šæŒç»­æ—¶é—´å·®å¼‚æ˜¾è‘—ï¼ˆ>= 2.0å€ï¼‰
            if duration_ratio >= 2.0:
                should_split = True
                trigger_reason = "ä¸»è¦æ¡ä»¶"
                logger.debug(f"      âš ï¸ ã€ä¸»è¦æ¡ä»¶ã€‘æŒç»­æ—¶é—´å·®å¼‚æ˜¾è‘—: {duration_ratio:.2f}å€ï¼Œå°è¯•æ‹†åˆ†...")
            
            # æ¬¡è¦æ¡ä»¶ï¼šæŒç»­æ—¶é—´ç›¸å·®ä¸å¤§ï¼Œä½†çŸ­æ•°æ®keyoffä¹‹åè¿˜æœ‰hammerå’Œafter_touch
            elif rec_duration != rep_duration:  # ç¡®ä¿æœ‰é•¿çŸ­ä¹‹åˆ†
                long_note = rec_note if rec_duration > rep_duration else rep_note
                short_note = rep_note if rec_duration > rep_duration else rec_note
                
                if self._check_hammer_after_shorter_keyoff(long_note, short_note):
                    should_split = True
                    trigger_reason = "æ¬¡è¦æ¡ä»¶"
                    force_record = True  # æ¬¡è¦æ¡ä»¶è§¦å‘æ—¶éœ€è¦å¼ºåˆ¶è®°å½•
                    logger.debug(f"      âš ï¸ ã€æ¬¡è¦æ¡ä»¶ã€‘æŒç»­æ—¶é—´ç›¸å·®ä¸å¤§({duration_ratio:.2f}å€)ï¼Œ"
                               f"ä½†æ£€æµ‹åˆ°çŸ­æ•°æ®keyoffåä»æœ‰é”¤å‡»å’Œafter_touchï¼Œå°è¯•æ‹†åˆ†...")
            
            # å¦‚æœæ»¡è¶³ä»»ä¸€æ¡ä»¶ï¼Œè¿›è¡Œæ‹†åˆ†
            if should_split:
                # é‡è¦ï¼šåœ¨æ‹†åˆ†ä¹‹å‰å…ˆè®°å½•åŸå§‹æ•°æ®åˆ°æŒç»­æ—¶é—´å·®å¼‚åˆ—è¡¨
                # è¿™æ ·å¯ä»¥åœ¨UIä¸­çœ‹åˆ°æ‹†åˆ†å‰çš„åŸå§‹æ›²çº¿
                self._check_duration_difference(rec_note, rep_note, rec_idx, rep_idx, force_record=force_record)
                logger.debug(f"      ğŸ“ å·²è®°å½•æ‹†åˆ†å‰çš„åŸå§‹æ•°æ®ï¼ˆè§¦å‘åŸå› ï¼š{trigger_reason}ï¼‰")
                
                # å°è¯•æ‹†åˆ†å¹¶ç«‹å³åŒ¹é…ç¬¬ä¸€éƒ¨åˆ†
                split_result = self._try_split_and_match_first(
                    rec_idx, rec_note, rec_split_seq,
                    rep_idx, rep_note, rep_split_seq,
                    record_heap, replay_heap, used_replay_indices,
                    rec_duration, rep_duration
                )
                
                if split_result is not None:
                    # æ‹†åˆ†æˆåŠŸï¼Œè¿”å›ç”¨äºåŒ¹é…çš„Noteï¼ˆç¬¬ä¸€éƒ¨åˆ†ï¼‰
                    split_type, match_rec_note, match_rep_note = split_result
                    logger.debug(f"      â†º æ‹†åˆ†æˆåŠŸï¼ˆæ‹†åˆ†{split_type}æ•°æ®ï¼‰ï¼Œç«‹å³åŒ¹é…ç¬¬ä¸€éƒ¨åˆ†")
                    # æ›´æ–°rec_noteå’Œrep_noteä¸ºæ‹†åˆ†åçš„ç¬¬ä¸€éƒ¨åˆ†
                    rec_note = match_rec_note
                    rep_note = match_rep_note
                    # ç»§ç»­ä¸‹é¢çš„åŒ¹é…é€»è¾‘
                else:
                    logger.debug(f"      âš ï¸ æ‹†åˆ†å¤±è´¥ï¼ŒæŒ‰åŸåŒ¹é…å¤„ç†")
        
        # åˆ›å»ºåŒ¹é…å¯¹ï¼ˆä½¿ç”¨çˆ¶ç´¢å¼•ï¼‰
        final_rec_idx = rec_note.split_parent_idx if rec_note.is_split else rec_idx
        final_rep_idx = rep_note.split_parent_idx if rep_note.is_split else rep_idx
        matched_pairs.append((final_rec_idx, final_rep_idx, rec_note, rep_note))
        
        # åˆ›å»ºåŒ¹é…ç»“æœï¼ˆä½¿ç”¨çˆ¶ç´¢å¼•ï¼‰
        match_result = MatchResult(
            match_type=match_type,
            record_index=final_rec_idx,
            replay_index=final_rep_idx,
            error_ms=keyon_error_ms,
            pair=(rec_note, rep_note),
            reason=""
        )
        self.match_results.append(match_result)
        self.match_statistics.add_result(match_result)
        
        # æ ‡è®°ä¸ºå·²ä½¿ç”¨
        used_replay_indices.add(rep_idx)
        
        # æ—¥å¿—
        rec_display = f"[{rec_note.split_parent_idx}:æ‹†åˆ†{rec_note.split_seq}]" if rec_note.is_split else f"[{rec_idx}]"
        rep_display = f"[{rep_note.split_parent_idx}:æ‹†åˆ†{rep_note.split_seq}]" if rep_note.is_split else f"[{rep_idx}]"
        logger.debug(f"      âœ“ åŒ¹é…æˆåŠŸ: å½•åˆ¶{rec_display} â†” æ’­æ”¾{rep_display} ({match_type.value}, {keyon_error_ms:.1f}ms)")
        
        return (True, 'none')  # æˆåŠŸåˆ›å»ºï¼Œæ— æ‹†åˆ†
    
    def _try_split_and_match_first(self, rec_idx: int, rec_note: Note, rec_split_seq: Optional[int],
                                     rep_idx: int, rep_note: Note, rep_split_seq: Optional[int],
                                     record_heap: List, replay_heap: List, used_replay_indices: set,
                                     rec_duration: float, rep_duration: float) -> Optional[Tuple[str, Note, Note]]:
        """
        å°è¯•æ‹†åˆ†å¹¶è¿”å›ç¬¬ä¸€éƒ¨åˆ†ç”¨äºç«‹å³åŒ¹é…
        
        Returns:
            Optional[Tuple[str, Note, Note]]: (æ‹†åˆ†ç±»å‹, åŒ¹é…ç”¨çš„rec_note, åŒ¹é…ç”¨çš„rep_note) æˆ– None
        """
        from backend.key_splitter_simplified import KeySplitter
        
        # åˆ¤æ–­æ‹†åˆ†æ–¹å‘
        if rec_duration > rep_duration:
            # å½•åˆ¶æ•°æ®æ›´é•¿ â†’ æ‹†åˆ†å½•åˆ¶æ•°æ®
            logger.debug(f"        æ‹†åˆ†å½•åˆ¶æ•°æ®ï¼ˆå½•åˆ¶{rec_duration:.1f}ms > æ’­æ”¾{rep_duration:.1f}msï¼‰")
            result = self._split_record_note_and_return_first(
                rec_idx, rec_note, rep_note, record_heap,
                rec_duration, rep_duration
            )
            if result:
                rec_note_a, rec_note_b = result
                # rec_note_aç”¨äºåŒ¹é…ï¼Œrec_note_bå·²åŠ å…¥å †
                return ('record', rec_note_a, rep_note)
            return None
        else:
            # æ’­æ”¾æ•°æ®æ›´é•¿ â†’ æ‹†åˆ†æ’­æ”¾æ•°æ®
            logger.debug(f"        æ‹†åˆ†æ’­æ”¾æ•°æ®ï¼ˆæ’­æ”¾{rep_duration:.1f}ms > å½•åˆ¶{rec_duration:.1f}msï¼‰")
            result = self._split_replay_note_and_return_first(
                rep_idx, rep_note, rec_note, replay_heap, used_replay_indices,
                rec_duration, rep_duration
            )
            if result:
                rep_note_a, rep_note_b = result
                # rep_note_aç”¨äºåŒ¹é…ï¼Œrep_note_bå·²åŠ å…¥å †
                return ('replay', rec_note, rep_note_a)
            return None
    
    def _split_note_and_return_first(self, long_note: Note, long_idx: int, short_note: Note,
                                     target_heap: List,
                                     rec_duration: float, rep_duration: float,
                                     data_type: str, used_indices: Optional[set] = None) -> Optional[Tuple[Note, Note]]:
        """
        æ‹†åˆ†Noteå¹¶è¿”å›ä¸¤ä¸ªNoteå¯¹è±¡ï¼ˆé€šç”¨æ–¹æ³•ï¼‰
        
        Args:
            long_note: é•¿æ•°æ®ï¼ˆè¦æ‹†åˆ†çš„ï¼‰
            long_idx: é•¿æ•°æ®çš„ç´¢å¼•
            short_note: çŸ­æ•°æ®
            target_heap: ç›®æ ‡å †ï¼ˆå°†note_båŠ å…¥ï¼‰
            split_counter: æ‹†åˆ†è®¡æ•°å™¨
            rec_duration: å½•åˆ¶æ•°æ®æŒç»­æ—¶é—´
            rep_duration: æ’­æ”¾æ•°æ®æŒç»­æ—¶é—´
            data_type: æ•°æ®ç±»å‹æ ‡è¯†ï¼ˆ"å½•åˆ¶"æˆ–"æ’­æ”¾"ï¼‰ï¼Œç”¨äºæ—¥å¿—
            used_indices: å¯é€‰çš„å·²ä½¿ç”¨ç´¢å¼•é›†åˆ
        
        Returns:
            Optional[Tuple[Note, Note]]: (note_aç”¨äºåŒ¹é…, note_bå·²åŠ å…¥å †) æˆ– None
        """
        # æå–hammersï¼ˆåªè€ƒè™‘velocity > 0çš„ï¼‰
        hammer_times_ms = []
        for i in range(len(long_note.hammers)):
            if long_note.hammers.values[i] > 0:
                time_ms = (long_note.hammers.index[i] + long_note.offset) / 10.0
                hammer_times_ms.append(time_ms)
        
        hammer_times_ms.sort()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„hammerï¼ˆè‡³å°‘2ä¸ªï¼‰
        if len(hammer_times_ms) < 2:
            logger.debug(f"        âœ— {data_type}æ•°æ®hammerä¸è¶³2ä¸ªï¼Œæ— æ³•æ‹†åˆ†")
            return None
        
        # ä½¿ç”¨ç²¾ç»†çš„æ‹†åˆ†ç‚¹æŸ¥æ‰¾ç®—æ³•
        split_time_ms = self._find_best_split_point(
            long_note=long_note,
            short_note=short_note,
            rec_duration=rec_duration,
            rep_duration=rep_duration
        )
        
        if split_time_ms is None:
            logger.debug(f"        âœ— æœªæ‰¾åˆ°åˆé€‚çš„æ‹†åˆ†ç‚¹")
            return None
        
        # æ‰§è¡Œæ‹†åˆ†
        note_a, note_b = self._split_note_at_time(
            long_note, split_time_ms,
            parent_idx=long_idx,
            split_seq_a=0,  # ç¬¬ä¸€éƒ¨åˆ†
            split_seq_b=1   # ç¬¬äºŒéƒ¨åˆ†
        )
        
        # ç”Ÿæˆæ‹†åˆ†æ•°æ®çš„å”¯ä¸€ç´¢å¼•ï¼ˆä½¿ç”¨å¤§åç§»é‡é¿å…ä¸åŸå§‹ç´¢å¼•å†²çªï¼‰
        split_idx_b = self._split_index_offset + self._split_counter * 2 + 1
        self._split_counter += 1
        
        # è®¾ç½®æ‹†åˆ†å…ƒæ•°æ®ï¼ˆå®é™…ä¸Š_split_note_at_timeå·²ç»è®¾ç½®äº†ï¼Œè¿™é‡Œæ˜¯å†—ä½™çš„ï¼‰
        note_a.split_parent_idx = long_idx
        note_a.split_seq = 0
        note_a.is_split = True
        
        note_b.split_parent_idx = long_idx
        note_b.split_seq = 1
        note_b.is_split = True
        
        # æ ‡è®°åŸæ•°æ®ä¸ºå·²ä½¿ç”¨ï¼ˆå¦‚æœæä¾›äº†used_indicesï¼‰
        if used_indices is not None:
            used_indices.add(long_idx)
        
        # åªå°†note_bï¼ˆç¬¬äºŒéƒ¨åˆ†ï¼‰åŠ å…¥å †ï¼Œnote_aç”¨äºç«‹å³åŒ¹é…
        if note_b.key_on_ms is not None:
            heapq.heappush(target_heap, (note_b.key_on_ms, split_idx_b, note_b, 1))
            logger.debug(f"        â†º {data_type}æ•°æ®æ‹†åˆ†: note_aç«‹å³åŒ¹é…, note_b({note_b.key_on_ms:.1f}ms)åŠ å…¥å †")
        else:
            logger.warning(f"        âš ï¸ æ‹†åˆ†åçš„{data_type}æ•°æ®Bæ²¡æœ‰key_on_msï¼Œè·³è¿‡")
        
        # è¿”å›ä¸¤ä¸ªNoteå¯¹è±¡
        return (note_a, note_b)
    
    def _split_replay_note_and_return_first(self, rep_idx: int, rep_note: Note, rec_note: Note,
                                              replay_heap: List, used_replay_indices: set,
                                              rec_duration: float, rep_duration: float) -> Optional[Tuple[Note, Note]]:
        """æ‹†åˆ†æ’­æ”¾æ•°æ®ï¼ˆç®€åŒ–wrapperï¼‰"""
        return self._split_note_and_return_first(
            long_note=rep_note, long_idx=rep_idx, short_note=rec_note,
            target_heap=replay_heap,
            rec_duration=rec_duration, rep_duration=rep_duration,
            data_type="æ’­æ”¾", used_indices=used_replay_indices
        )
    
    def _split_record_note_and_return_first(self, rec_idx: int, rec_note: Note, rep_note: Note,
                                              record_heap: List,
                                              rec_duration: float, rep_duration: float) -> Optional[Tuple[Note, Note]]:
        """æ‹†åˆ†å½•åˆ¶æ•°æ®ï¼ˆç®€åŒ–wrapperï¼‰"""
        return self._split_note_and_return_first(
            long_note=rec_note, long_idx=rec_idx, short_note=rep_note,
            target_heap=record_heap,
            rec_duration=rec_duration, rep_duration=rep_duration,
            data_type="å½•åˆ¶", used_indices=None
        )
    
    def _find_best_split_point(self, long_note: Note, short_note: Note, 
                              rec_duration: float, rep_duration: float) -> Optional[float]:
        """
        æŸ¥æ‰¾æœ€ä½³æ‹†åˆ†ç‚¹
        
        Args:
            long_note: è¾ƒé•¿çš„Noteå¯¹è±¡ï¼ˆè¦æ‹†åˆ†çš„åˆå¹¶æ•°æ®ï¼‰
            short_note: è¾ƒçŸ­çš„Noteå¯¹è±¡ï¼ˆæä¾›keyoffä½œä¸ºæœç´¢èµ·ç‚¹ï¼‰
            rec_duration: å½•åˆ¶æ•°æ®æŒç»­æ—¶é—´
            rep_duration: æ’­æ”¾æ•°æ®æŒç»­æ—¶é—´
        
        Returns:
            Optional[float]: æœ€ä½³æ‹†åˆ†ç‚¹çš„ç»å¯¹æ—¶é—´ï¼ˆmsï¼‰ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
            
        Note:
            KeySplitterä½¿ç”¨é€šç”¨çš„å‚æ•°å‘½åï¼š
            - short_note: çŸ­æ•°æ®ï¼ˆå‚è€ƒæ•°æ®ï¼‰
            - long_note: é•¿æ•°æ®ï¼ˆè¦æ‹†åˆ†çš„åˆå¹¶æ•°æ®ï¼‰
            è¿™é€‚ç”¨äºå½•åˆ¶å’Œæ’­æ”¾æ•°æ®çš„ä»»æ„ç»„åˆ
        """
        try:
            from backend.key_splitter_simplified import KeySplitter
            
            # åˆ›å»ºKeySplitterå®ä¾‹
            splitter = KeySplitter()
            
            # è°ƒè¯•ä¿¡æ¯ï¼šè¾“å‡ºè¦æ‹†åˆ†çš„æ•°æ®
            logger.debug(f"        ğŸ” æ‹†åˆ†ç‚¹æŸ¥æ‰¾å‚æ•°:")
            logger.debug(f"          çŸ­æ•°æ®: keyon={short_note.key_on_ms:.1f}ms, keyoff={short_note.key_off_ms:.1f}ms")
            logger.debug(f"          é•¿æ•°æ®: keyon={long_note.key_on_ms:.1f}ms, keyoff={long_note.key_off_ms:.1f}ms")
            
            # æå–é•¿æ•°æ®çš„hammersï¼ˆæ£€æŸ¥æ˜¯å¦è¶³å¤Ÿï¼‰
            long_hammers = []
            for i in range(len(long_note.hammers)):
                if long_note.hammers.values[i] > 0:
                    time_ms = (long_note.hammers.index[i] + long_note.offset) / 10.0
                    long_hammers.append(time_ms)
            long_hammers.sort()
            logger.debug(f"          é•¿æ•°æ®hammers(>0): {[f'{h:.1f}ms' for h in long_hammers]}")
            
            # è°ƒç”¨KeySplitterï¼ˆä½¿ç”¨é€šç”¨æ¥å£ï¼‰
            result = splitter.analyze_split_possibility(
                short_note=short_note,        # çŸ­æ•°æ®ï¼ˆå‚è€ƒæ•°æ®ï¼‰
                long_note=long_note,          # é•¿æ•°æ®ï¼ˆè¦æ‹†åˆ†çš„ï¼‰
                short_duration=min(rec_duration, rep_duration),
                long_duration=max(rec_duration, rep_duration)
            )
            
            # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°æœ€ä½³åˆ†å‰²ç‚¹
            if result and result.get('best_candidate'):
                best = result['best_candidate']
                split_time_ms = best['time']  # æ³¨æ„ï¼šé”®åæ˜¯'time'ä¸æ˜¯'time_ms'
                
                # æ—¥å¿—è¾“å‡º
                if best.get('is_turning', False):  # æ³¨æ„ï¼šé”®åæ˜¯'is_turning'ä¸æ˜¯'is_turning_point'
                    logger.debug(f"        âœ“ æ‰¾åˆ°æœ€ä½³æ‹†åˆ†ç‚¹ï¼ˆæ‹ç‚¹ï¼‰: {split_time_ms:.1f}ms, "
                               f"è§¦åå€¼={best.get('value', 0):.1f}")
                else:
                    logger.debug(f"        âš ï¸ ä½¿ç”¨åå¤‡ç­–ç•¥ï¼ˆè§¦åå€¼æœ€å°ç‚¹ï¼‰: {split_time_ms:.1f}ms, "
                               f"è§¦åå€¼={best.get('value', 0):.1f}")
                
                return split_time_ms
            else:
                if result:
                    logger.debug(f"        âš ï¸ KeySplitterè¿”å›ç»“æœä½†æ— best_candidate: {list(result.keys())}")
                else:
                    logger.debug(f"        âš ï¸ KeySplitterè¿”å›Noneï¼ˆå¯èƒ½åŸå› ï¼šhammerä¸è¶³2ä¸ªæˆ–èŒƒå›´æ— æ•ˆï¼‰")
                return None
                
        except Exception as e:
            logger.error(f"        âœ— æ‹†åˆ†ç‚¹æŸ¥æ‰¾å¤±è´¥: {e}")
            return None
    
    def _split_note_at_time(self, note: Note, split_time_ms: float, 
                           parent_idx: int, split_seq_a: int, split_seq_b: int) -> Tuple[Note, Note]:
        """
        åœ¨æŒ‡å®šæ—¶é—´ç‚¹æ‹†åˆ†Note
        
        Args:
            note: è¦æ‹†åˆ†çš„Noteå¯¹è±¡
            split_time_ms: æ‹†åˆ†ç‚¹çš„ç»å¯¹æ—¶é—´ï¼ˆmsï¼‰
            parent_idx: çˆ¶ç´¢å¼•ï¼ˆåŸå§‹æ•°æ®çš„ç´¢å¼•ï¼‰
            split_seq_a: å‰åŠæ®µçš„æ‹†åˆ†åºå·
            split_seq_b: ååŠæ®µçš„æ‹†åˆ†åºå·
        
        Returns:
            Tuple[Note, Note]: (å‰åŠæ®µ, ååŠæ®µ)
        """
        import pandas as pd
        from dataclasses import replace
        
        # å°†split_time_msï¼ˆç»å¯¹æ—¶é—´ï¼‰è½¬æ¢ä¸ºç›¸å¯¹äºoffsetçš„ç´¢å¼•ï¼ˆ0.1mså•ä½ï¼‰
        # split_time_msæ˜¯ç»å¯¹æ—¶é—´ï¼Œafter_touch.indexæ˜¯ç›¸å¯¹äºoffsetçš„ç´¢å¼•
        # æ‰€ä»¥ï¼šrelative_index = absolute_time * 10 - offset
        split_time_units = int(split_time_ms * 10) - note.offset
        
        logger.debug(f"        æ‹†åˆ†å‚æ•°: split_time={split_time_ms:.1f}ms (ç»å¯¹æ—¶é—´), "
                    f"offset={note.offset}, split_units={split_time_units} (ç›¸å¯¹ç´¢å¼•)")
        
        # æ‹†åˆ†aftertouchï¼šæ‹†åˆ†ç‚¹åŒæ—¶å‡ºç°åœ¨note_açš„æœ«å°¾å’Œnote_bçš„å¼€å¤´
        # note_a: <= split_timeï¼ˆåŒ…å«æ‹†åˆ†ç‚¹ä½œä¸ºç»“æŸç‚¹ï¼‰
        # note_b: >= split_timeï¼ˆåŒ…å«æ‹†åˆ†ç‚¹ä½œä¸ºèµ·å§‹ç‚¹ï¼‰
        mask1 = note.after_touch.index <= split_time_units
        mask2 = note.after_touch.index >= split_time_units
        
        after_touch_a = note.after_touch[mask1].copy()
        after_touch_b = note.after_touch[mask2].copy()
        
        # å¦‚æœæ‹†åˆ†ç‚¹ä¸åœ¨åŸå§‹after_touchä¸­ï¼Œéœ€è¦æ’å…¥
        if split_time_units not in note.after_touch.index:
            # æ’å€¼è®¡ç®—æ‹†åˆ†ç‚¹çš„è§¦åå€¼
            if not after_touch_a.empty and not after_touch_b.empty:
                # ä½¿ç”¨çº¿æ€§æ’å€¼
                prev_idx = after_touch_a.index[-1]
                next_idx = after_touch_b.index[0]
                prev_val = after_touch_a.iloc[-1]
                next_val = after_touch_b.iloc[0]
                
                if next_idx > prev_idx:
                    ratio = (split_time_units - prev_idx) / (next_idx - prev_idx)
                    split_val = prev_val + ratio * (next_val - prev_val)
                else:
                    split_val = prev_val
                
                # æ’å…¥æ‹†åˆ†ç‚¹åˆ°after_touch_aå’Œafter_touch_b
                after_touch_a = pd.concat([after_touch_a, pd.Series([split_val], index=[split_time_units])]).sort_index()
                after_touch_b = pd.concat([pd.Series([split_val], index=[split_time_units]), after_touch_b]).sort_index()
                logger.debug(f"        â„¹ï¸ åœ¨æ‹†åˆ†ç‚¹{split_time_units}æ’å€¼after_touch={split_val:.1f}")
        
        # æ‹†åˆ†hammersï¼šç¬¬ä¸€ä¸ªæŒ‰é”®åªåŒ…å«ç¬¬ä¸€ä¸ªhammerï¼Œç¬¬äºŒä¸ªæŒ‰é”®åŒ…å«åç»­hammers
        # note_a: < split_timeï¼ˆä¸åŒ…å«æ‹†åˆ†ç‚¹çš„hammerï¼‰
        # note_b: >= split_timeï¼ˆåŒ…å«æ‹†åˆ†ç‚¹åŠä¹‹åçš„hammersï¼‰
        hammers_a = note.hammers[note.hammers.index < split_time_units].copy()
        hammers_b = note.hammers[note.hammers.index >= split_time_units].copy()
        
        # ç¡®ä¿note_bçš„key_onå°±æ˜¯æ‹†åˆ†ç‚¹ï¼š
        # å¦‚æœhammers_bä¸ºç©ºæˆ–ç¬¬ä¸€ä¸ªhammerä¸åœ¨æ‹†åˆ†ç‚¹ï¼Œåœ¨æ‹†åˆ†ç‚¹æ’å…¥hammer
        if hammers_b.empty or hammers_b.index[0] != split_time_units:
            if not after_touch_b.empty:
                # åœ¨æ‹†åˆ†ç‚¹åˆ›å»ºhammerï¼ˆvelocity=0è¡¨ç¤ºè™šæ‹Ÿhammerï¼‰
                split_hammer = pd.Series([0], index=[split_time_units])
                if hammers_b.empty:
                    hammers_b = split_hammer
                    logger.debug(f"        â„¹ï¸ note_bæ— hammerï¼Œåœ¨æ‹†åˆ†ç‚¹{split_time_units}åˆ›å»ºè™šæ‹Ÿhammer")
                else:
                    # åˆå¹¶æ‹†åˆ†ç‚¹hammerå’Œåç»­hammers
                    hammers_b = pd.concat([split_hammer, hammers_b])
                    logger.debug(f"        â„¹ï¸ åœ¨æ‹†åˆ†ç‚¹{split_time_units}æ’å…¥hammerï¼Œç¡®ä¿key_on=æ‹†åˆ†ç‚¹")
        
        # åˆ›å»ºæ–°çš„Noteå¯¹è±¡ï¼ˆè®¾ç½®splitå…ƒæ•°æ®ï¼‰
        note_a = Note(
            offset=note.offset,
            id=note.id,
            finger=note.finger,
            hammers=hammers_a,
            uuid=f"{note.uuid}_split_{split_seq_a}",
            velocity=note.velocity,
            after_touch=after_touch_a,
            split_parent_idx=parent_idx,
            split_seq=split_seq_a,
            is_split=True
        )
        
        note_b = Note(
            offset=note.offset,  # offsetä¿æŒä¸å˜
            id=note.id,
            finger=note.finger,
            hammers=hammers_b,
            uuid=f"{note.uuid}_split_{split_seq_b}",
            velocity=note.velocity,
            after_touch=after_touch_b,
            split_parent_idx=parent_idx,
            split_seq=split_seq_b,
            is_split=True
        )
        
        logger.debug(f"        âœ“ note_a: key_on={note_a.key_on_ms:.1f}ms, key_off={note_a.key_off_ms:.1f}ms, "
                    f"duration={note_a.duration_ms:.1f}ms")
        logger.debug(f"        âœ“ note_b: key_on={note_b.key_on_ms:.1f}ms, key_off={note_b.key_off_ms:.1f}ms, "
                    f"duration={note_b.duration_ms:.1f}ms")
        
        return note_a, note_b
    
    def _check_hammer_after_shorter_keyoff(self, long_note: Note, short_note: Note) -> bool:
        """
        æ£€æŸ¥åœ¨è¾ƒçŸ­æ•°æ®çš„keyoffä¹‹åï¼Œè¾ƒé•¿æ•°æ®æ˜¯å¦è¿˜æœ‰æœ‰æ•ˆçš„é”¤å‡»å’Œaftertouch
        
        Args:
            long_note: è¾ƒé•¿çš„Noteå¯¹è±¡
            short_note: è¾ƒçŸ­çš„Noteå¯¹è±¡
        
        Returns:
            bool: å¦‚æœåœ¨çŸ­æ•°æ®keyoffä¹‹åè¿˜æœ‰hammerï¼ˆvelocity>0ï¼‰ä¸”after_touchä¸ä¸ºç©ºï¼Œè¿”å›True
        """
        # è·å–çŸ­æ•°æ®çš„keyoffï¼ˆç»å¯¹æ—¶é—´ï¼Œ0.1mså•ä½ï¼‰
        short_keyoff_ms = short_note.key_off_ms
        if short_keyoff_ms is None:
            return False
        
        short_keyoff_units = int(short_keyoff_ms * 10)
        
        # æ£€æŸ¥é•¿æ•°æ®åœ¨æ­¤æ—¶é—´ä¹‹åæ˜¯å¦è¿˜æœ‰hammerï¼ˆvelocity > 0ï¼‰
        has_hammer_after = False
        for i in range(len(long_note.hammers)):
            hammer_time_units = long_note.hammers.index[i] + long_note.offset
            hammer_velocity = long_note.hammers.values[i]
            
            if hammer_time_units > short_keyoff_units and hammer_velocity > 0:
                has_hammer_after = True
                logger.debug(f"        ğŸ”¨ æ£€æµ‹åˆ°çŸ­æ•°æ®keyoff({short_keyoff_ms:.1f}ms)ä¹‹åçš„é”¤å‡»: "
                           f"{hammer_time_units/10:.1f}ms, velocity={hammer_velocity}")
                break
        
        if not has_hammer_after:
            return False
        
        # æ£€æŸ¥é•¿æ•°æ®åœ¨æ­¤æ—¶é—´ä¹‹åæ˜¯å¦è¿˜æœ‰after_touchæ•°æ®
        has_aftertouch_after = False
        for at_time_units in long_note.after_touch.index:
            absolute_time_units = at_time_units + long_note.offset
            if absolute_time_units > short_keyoff_units:
                has_aftertouch_after = True
                logger.debug(f"        ğŸ“Š æ£€æµ‹åˆ°çŸ­æ•°æ®keyoffä¹‹åçš„after_touchæ•°æ®")
                break
        
        return has_hammer_after and has_aftertouch_after
    
    def _check_duration_difference(self, record_note: Note, replay_note: Note, record_idx: int, replay_idx: int, force_record: bool = False):
        """
        æ£€æŸ¥åŒ¹é…å¯¹çš„æŒç»­æ—¶é—´å·®å¼‚ï¼Œå¦‚æœå·®å¼‚æ˜¾è‘—åˆ™è®°å½•

        Args:
            record_note: å½•åˆ¶éŸ³ç¬¦
            replay_note: æ’­æ”¾éŸ³ç¬¦
            record_idx: å½•åˆ¶éŸ³ç¬¦åŸå§‹ç´¢å¼•
            replay_idx: æ’­æ”¾éŸ³ç¬¦åŸå§‹ç´¢å¼•
            force_record: æ˜¯å¦å¼ºåˆ¶è®°å½•ï¼ˆå³ä½¿ä¸æ»¡è¶³ä¸»è¦æ¡ä»¶ï¼‰
        """
        # è·å–æŒç»­æ—¶é—´
        record_duration = getattr(record_note, 'duration_ms', None)
        replay_duration = getattr(replay_note, 'duration_ms', None)

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æŒç»­æ—¶é—´æ•°æ®
        if record_duration is None or replay_duration is None or record_duration <= 0 or replay_duration <= 0:
            return

        # è®¡ç®—æŒç»­æ—¶é—´æ¯”ä¾‹
        duration_ratio = max(record_duration, replay_duration) / min(record_duration, replay_duration)

        # å¦‚æœæŒç»­æ—¶é—´å·®å¼‚æ˜¾è‘—ï¼ˆå¤§çº¦2å€ä»¥ä¸Šï¼‰æˆ–å¼ºåˆ¶è®°å½•ï¼Œè®°å½•ä¸‹æ¥
        if duration_ratio >= 2.0 or force_record:
            # è·å–keyonå’Œkeyoffæ—¶é—´
            record_keyon = getattr(record_note, 'key_on_ms', None)
            record_keyoff = getattr(record_note, 'key_off_ms', None)
            replay_keyon = getattr(replay_note, 'key_on_ms', None)
            replay_keyoff = getattr(replay_note, 'key_off_ms', None)
            
            # è®°å½•å·®å¼‚åŒ¹é…å¯¹ï¼ˆåŒ…å«keyonå’Œkeyoffï¼‰
            self.duration_diff_pairs.append((
                record_idx,
                replay_idx,
                record_note,
                replay_note,
                record_duration,
                replay_duration,
                duration_ratio,
                record_keyon,
                record_keyoff,
                replay_keyon,
                replay_keyoff
            ))

            # è¾“å‡ºæ—¥å¿—
            logger.info(f"ğŸ” å‘ç°æŒç»­æ—¶é—´å·®å¼‚æ˜¾è‘—çš„åŒ¹é…å¯¹: æŒ‰é”®{record_note.id} "
                       f"å½•åˆ¶[{record_keyon:.1f}-{record_keyoff:.1f}ms, {record_duration:.1f}ms], "
                       f"æ’­æ”¾[{replay_keyon:.1f}-{replay_keyoff:.1f}ms, {replay_duration:.1f}ms], "
                       f"æ¯”ä¾‹={duration_ratio:.2f}")

    def _match_notes_for_single_key_group(self, key_id: int,
                                        record_notes_with_indices: List[Tuple[int, Note]],
                                        replay_notes_with_indices: List[Tuple[int, Note]]) -> Tuple[List[Tuple[int, int, Note, Note]], int]:
        """
        å¯¹å•ä¸ªæŒ‰é”®ç»„è¿›è¡Œè´ªå¿ƒåŒ¹é…

        åŒ¹é…ç­–ç•¥ï¼š
        1. ç²¾ç¡®åŒ¹é… (â‰¤50ms)
        2. è¾ƒå·®åŒ¹é… (50ms-100ms)
        3. ä¸¥é‡è¯¯å·®åŒ¹é… (100ms-200ms) - ç†è®ºä¸Šåº”è¯¥åŒ¹é…æ‰€æœ‰å‰©ä½™æŒ‰é”®

        åŒ¹é…å®Œæˆåç»Ÿä¸€åˆ†æï¼š
        - å½•åˆ¶ä¸­æœªåŒ¹é…çš„ï¼šä¸¢é”¤
        - æ’­æ”¾ä¸­æœªä½¿ç”¨çš„ï¼šå¤šé”¤

        Args:
            key_id: æŒ‰é”®ID
            record_notes_with_indices: è¯¥æŒ‰é”®çš„å½•åˆ¶éŸ³ç¬¦åˆ—è¡¨ [(original_index, note), ...]
            replay_notes_with_indices: è¯¥æŒ‰é”®çš„æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨ [(original_index, note), ...]

        Returns:
            List[Tuple[int, int, Note, Note]]: è¯¥æŒ‰é”®çš„åŒ¹é…å¯¹åˆ—è¡¨
        """
        key_matched_pairs = []

        # åˆå§‹åŒ–çŠ¶æ€è·Ÿè¸ª - ä½¿ç”¨åŸå§‹ç´¢å¼•ä½œä¸ºé”®ï¼Œç¡®ä¿å”¯ä¸€æ€§
        record_match_status = {record_idx: False for record_idx, _ in record_notes_with_indices}  # False=æœªåŒ¹é…
        replay_match_status = {replay_idx: False for replay_idx, _ in replay_notes_with_indices}  # False=æœªä½¿ç”¨

        logger.debug(f"ğŸ¹ å¼€å§‹æŒ‰é”®{key_id}è´ªå¿ƒåŒ¹é…: å½•åˆ¶{len(record_notes_with_indices)}ä¸ª, æ’­æ”¾{len(replay_notes_with_indices)}ä¸ª")

        # åˆ†ç­‰çº§è´ªå¿ƒåŒ¹é…ç­–ç•¥
        match_strategies = [
            ("precision", "ç²¾ç¡®åŒ¹é…", [MatchType.EXCELLENT, MatchType.GOOD, MatchType.FAIR]),
            ("approximate", "è¾ƒå·®åŒ¹é…", [MatchType.POOR]),
            ("severe", "ä¸¥é‡è¯¯å·®åŒ¹é…", [MatchType.SEVERE])
        ]

        # è·å–å¾…åŒ¹é…çš„å½•åˆ¶éŸ³ç¬¦åˆ—è¡¨ï¼ˆæœªåŒ¹é…çš„ï¼‰
        unmatched_record_notes = [(idx, note) for idx, note in record_notes_with_indices]

        # æŒ‰ç­‰çº§é¡ºåºè¿›è¡ŒåŒ¹é…
        for strategy_name, strategy_desc, allowed_types in match_strategies:
            if not unmatched_record_notes:
                break

            # æœ¬è½®æˆåŠŸåŒ¹é…çš„å½•åˆ¶éŸ³ç¬¦ï¼ˆä»åˆ—è¡¨ä¸­ç§»é™¤ï¼‰
            matched_in_this_round = []

            # éå†æ‰€æœ‰æœªåŒ¹é…çš„å½•åˆ¶éŸ³ç¬¦ï¼Œè®©å®ƒä»¬éƒ½å°è¯•å½“å‰ç­‰çº§çš„åŒ¹é…
            for record_orig_idx, record_note in unmatched_record_notes:
                # è·å–å½“å‰å¯ç”¨çš„æ’­æ”¾éŸ³ç¬¦åŠå…¶åŸå§‹ç´¢å¼•ï¼ˆæœªè¢«ä½¿ç”¨çš„ï¼‰
                available_replay_notes_with_indices = []
                for replay_orig_idx, replay_note in replay_notes_with_indices:
                    if not replay_match_status[replay_orig_idx]:  # æœªè¢«ä½¿ç”¨
                        available_replay_notes_with_indices.append((replay_orig_idx, replay_note))

                # åœ¨è¯¥æŒ‰é”®çš„å¯ç”¨æ’­æ”¾éŸ³ç¬¦ä¸­è¿›è¡ŒæŒ‡å®šç­‰çº§çš„åŒ¹é…
                match_result = self._perform_single_note_matching_in_strategy(
                    record_note, record_orig_idx, available_replay_notes_with_indices,
                    strategy_name, len(replay_notes_with_indices) > 0
                )

                # åªæœ‰æˆåŠŸçš„åŒ¹é…æ‰è®°å½•åˆ°å…¨å±€ç»Ÿè®¡ä¸­
                # å¤±è´¥çš„åŒ¹é…ä¼šåœ¨æ‰€æœ‰ç­–ç•¥å°è¯•å®Œåï¼Œç”± _analyze_key_group_hammer_status ç»Ÿä¸€å¤„ç†

                # å¤„ç†åŒ¹é…ç»“æœ
                if match_result.is_success and match_result.match_type in allowed_types:
                    # æ›´æ–°å…¨å±€ç»Ÿè®¡ä¿¡æ¯ï¼ˆåªè®°å½•æˆåŠŸçš„åŒ¹é…ï¼‰
                    self.match_statistics.add_result(match_result)
                    self.match_results.append(match_result)
                    # ä»MatchResultä¸­ç›´æ¥è·å–æ’­æ”¾éŸ³ç¬¦ç´¢å¼•
                    matched_replay_orig_idx = match_result.replay_index
                    matched_replay_note = match_result.pair[1]

                    key_matched_pairs.append((
                        record_orig_idx,
                        matched_replay_orig_idx,
                        record_note,
                        matched_replay_note
                    ))

                    # æ£€æŸ¥æŒç»­æ—¶é—´å·®å¼‚
                    self._check_duration_difference(record_note, matched_replay_note, record_orig_idx, matched_replay_orig_idx)

                    # æ›´æ–°åŒ¹é…çŠ¶æ€
                    record_match_status[record_orig_idx] = True
                    replay_match_status[matched_replay_orig_idx] = True

                    # è®°å½•æŒ‰é”®é…å¯¹è¯¦æƒ…æ—¥å¿—
                    logger.debug(f"ğŸ”— æŒ‰é”®é…å¯¹: å½•åˆ¶æŒ‰é”®{key_id}(ç´¢å¼•{record_orig_idx}) â†” æ’­æ”¾æŒ‰é”®{key_id}(ç´¢å¼•{matched_replay_orig_idx}), "
                               f"è¯¯å·®={match_result.error_ms:.2f}ms, ç±»å‹={match_result.match_type.value}")

                    # è®°å½•åˆ°å¯¹åº”çš„åˆ†ç±»åˆ—è¡¨
                    if match_result.match_type in [MatchType.EXCELLENT, MatchType.GOOD, MatchType.FAIR]:
                        self.precision_matched_pairs.append(key_matched_pairs[-1])
                    elif match_result.match_type == MatchType.POOR:
                        self.approximate_matched_pairs.append(key_matched_pairs[-1])
                    elif match_result.match_type == MatchType.SEVERE:
                        self.severe_matched_pairs.append(key_matched_pairs[-1])

                    # æ ‡è®°æœ¬è½®æˆåŠŸåŒ¹é…
                    matched_in_this_round.append((record_orig_idx, record_note))
                # else: åŒ¹é…å¤±è´¥ï¼Œç»§ç»­ç•™åœ¨æœªåŒ¹é…åˆ—è¡¨ä¸­ï¼Œç­‰å¾…ä¸‹ä¸€è½®

            # ä»æœªåŒ¹é…åˆ—è¡¨ä¸­ç§»é™¤æœ¬è½®æˆåŠŸåŒ¹é…çš„éŸ³ç¬¦
            for matched_record in matched_in_this_round:
                unmatched_record_notes.remove(matched_record)

            logger.debug(f"ğŸ æŒ‰é”®{key_id}{strategy_desc}è½®å®Œæˆ: æœ¬è½®åŒ¹é…{matched_in_this_round.__len__()}ä¸ª, å‰©ä½™{len(unmatched_record_notes)}ä¸ª")

        # ç¬¬äºŒé˜¶æ®µï¼šç»Ÿä¸€åˆ†æä¸¢é”¤å’Œå¤šé”¤
        extra_hammers = self._analyze_key_group_hammer_status(key_id, record_match_status, replay_match_status)

        return key_matched_pairs, extra_hammers

    def _analyze_key_group_hammer_status(self, key_id: int,
                                        record_match_status: Dict[int, bool],
                                        replay_match_status: Dict[int, bool]) -> int:
        """
        åˆ†ææŒ‰é”®ç»„çš„é”¤å­çŠ¶æ€ï¼ˆä¸¢é”¤å’Œå¤šé”¤ï¼‰

        Args:
            key_id: æŒ‰é”®ID
            record_match_status: å½•åˆ¶éŸ³ç¬¦åŒ¹é…çŠ¶æ€ {record_orig_idx: is_matched}
            replay_match_status: æ’­æ”¾éŸ³ç¬¦ä½¿ç”¨çŠ¶æ€ {replay_orig_idx: is_used}

        Returns:
            int: å¤šé”¤æ•°é‡
        """
        # åˆ†æä¸¢é”¤ï¼šå½•åˆ¶äº†ä½†æœªåŒ¹é…
        dropped_hammers = [idx for idx, matched in record_match_status.items() if not matched]

        # åˆ†æå¤šé”¤ï¼šæ’­æ”¾äº†ä½†æœªè¢«ä½¿ç”¨
        extra_hammers = [idx for idx, matched in replay_match_status.items() if not matched]

        # ä¸ºä¸¢é”¤åˆ›å»ºå¤±è´¥è®°å½•
        for record_idx in dropped_hammers:
            match_result = MatchResult(
                MatchType.FAILED,
                record_idx,
                reason=f"æŒ‰é”®{key_id}å½•åˆ¶éŸ³ç¬¦æœªåŒ¹é…(ä¸¢é”¤)"
            )
            self.match_results.append(match_result)
            self.match_statistics.add_result(match_result)

        # è¿”å›å¤šé”¤æ•°é‡ï¼Œç”¨äºæ›´æ–°æŒ‰é”®ç»Ÿè®¡
        return len(extra_hammers)

    def _perform_single_note_matching_in_strategy(self, record_note: Note, record_index: int,
                                                     replay_notes_with_indices: List[Tuple[int, Note]],
                                                     strategy_name: str,
                                                     has_any_replay_notes: bool = True) -> MatchResult:
        """
        åœ¨æŒ‰é”®ç»„å†…éƒ¨è¿›è¡Œå•ä¸ªéŸ³ç¬¦çš„æŒ‡å®šç­–ç•¥åŒ¹é…

        Args:
            record_note: å½•åˆ¶éŸ³ç¬¦
            record_index: å½•åˆ¶éŸ³ç¬¦çš„åŸå§‹ç´¢å¼•
            replay_notes_with_indices: è¯¥æŒ‰é”®çš„æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨ï¼ˆå·²è¿‡æ»¤æœªä½¿ç”¨çš„ï¼‰[(orig_idx, note), ...]
            strategy_name: åŒ¹é…ç­–ç•¥åç§° ("precision", "approximate", "severe")
            has_any_replay_notes: æ˜¯å¦æœ‰æ’­æ”¾éŸ³ç¬¦

        Returns:
            MatchResult: åŒ¹é…ç»“æœ
        """
        note_info = self._extract_note_info(record_note, record_index)

        # åªåœ¨æŒ‡å®šçš„ç­–ç•¥ä¸­è¿›è¡ŒåŒ¹é…
        replay_notes_only = [note for _, note in replay_notes_with_indices]
        candidates, reason = self._find_candidates_in_key_group(
            replay_notes_only, note_info["keyon"], note_info["keyoff"],
            note_info["key_id"], search_mode=strategy_name
        )

        if candidates:
            # ä»å€™é€‰åˆ—è¡¨ä¸­é€‰æ‹©æœ€ä½³çš„ï¼ˆç¬¬ä¸€ä¸ªï¼Œå› ä¸ºå·²ç»æŒ‰è¯¯å·®æ’åºï¼‰
            chosen = candidates[0]  # è´ªå¿ƒé€‰æ‹©ï¼šé€‰æ‹©è¯¯å·®æœ€å°çš„ä¸€ä¸ª

            # æ„å»ºåŒ¹é…å¯¹
            replay_note = chosen.note
            pair = (record_note, replay_note)

            # æ ¹æ®å®é™…è¯¯å·®ç¡®å®šåŒ¹é…ç±»å‹
            actual_match_type = self._evaluate_match_quality(chosen.error_ms)

            # ä»è¿‡æ»¤åˆ—è¡¨ä¸­æ‰¾åˆ°å¯¹åº”çš„åŸå§‹ç´¢å¼•
            replay_orig_idx = replay_notes_with_indices[chosen.index][0]

            return self._create_match_result(
                actual_match_type, record_index, replay_orig_idx, chosen,
                record_note, replay_note
            )

        # å½“å‰ç­–ç•¥åŒ¹é…å¤±è´¥
        return self._create_match_result(
            MatchType.FAILED, record_index, reason=f"{strategy_name}ç­–ç•¥æ— ç¬¦åˆå€™é€‰"
        )

    def _perform_single_note_matching_within_key_group(self, record_note: Note, record_index: int,
                                                     replay_notes_with_indices: List[Tuple[int, Note]],
                                                     has_any_replay_notes: bool = True) -> MatchResult:
        """
        åœ¨æŒ‰é”®ç»„å†…éƒ¨è¿›è¡Œå•ä¸ªéŸ³ç¬¦åŒ¹é…

        Args:
            record_note: å½•åˆ¶éŸ³ç¬¦
            record_index: å½•åˆ¶éŸ³ç¬¦çš„åŸå§‹ç´¢å¼•
            replay_notes_with_indices: è¯¥æŒ‰é”®çš„æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨ï¼ˆå·²è¿‡æ»¤æœªä½¿ç”¨çš„ï¼‰[(orig_idx, note), ...]

        Returns:
            MatchResult: åŒ¹é…ç»“æœ
        """
        note_info = self._extract_note_info(record_note, record_index)

        # å®šä¹‰åŒ¹é…ç­–ç•¥ï¼šåˆ†å±‚æœç´¢ï¼Œç¡®ä¿æ‰¾åˆ°æœ€ä½³åŒ¹é…
        match_strategies = [
            ("precision", self.precision_matched_pairs),     # ç¬¬ä¸€ä¼˜å…ˆçº§: ç²¾ç¡®æœç´¢ (â‰¤50ms)
            ("approximate", self.approximate_matched_pairs), # ç¬¬äºŒä¼˜å…ˆçº§: è¾ƒå·®æœç´¢ (50ms-100ms)
            ("severe", self.severe_matched_pairs),          # ç¬¬ä¸‰ä¼˜å…ˆçº§: ä¸¥é‡è¯¯å·®æœç´¢ (100ms-200ms)
        ]

        # æŒ‰é¡ºåºå°è¯•æ¯ç§åŒ¹é…ç­–ç•¥
        for search_mode, record_list in match_strategies:
            # åªä¼ å…¥éŸ³ç¬¦åˆ—è¡¨ç»™ _find_candidates_in_key_group
            replay_notes_only = [note for _, note in replay_notes_with_indices]
            candidates, reason = self._find_candidates_in_key_group(
                replay_notes_only, note_info["keyon"], note_info["keyoff"],
                note_info["key_id"], search_mode=search_mode
            )

            if candidates:
                # ä»å€™é€‰åˆ—è¡¨ä¸­é€‰æ‹©æœ€ä½³çš„ï¼ˆç¬¬ä¸€ä¸ªï¼Œå› ä¸ºå·²ç»æŒ‰è¯¯å·®æ’åºï¼‰
                chosen = candidates[0]  # è´ªå¿ƒé€‰æ‹©ï¼šé€‰æ‹©è¯¯å·®æœ€å°çš„ä¸€ä¸ª

                # æ„å»ºåŒ¹é…å¯¹
                replay_note = chosen.note
                pair = (record_note, replay_note)

                # æ ¹æ®å®é™…è¯¯å·®ç¡®å®šåŒ¹é…ç±»å‹
                actual_match_type = self._evaluate_match_quality(chosen.error_ms)

                # ä»è¿‡æ»¤åˆ—è¡¨ä¸­æ‰¾åˆ°å¯¹åº”çš„åŸå§‹ç´¢å¼•
                replay_orig_idx = replay_notes_with_indices[chosen.index][0]

                return self._create_match_result(
                    actual_match_type, record_index, replay_orig_idx, chosen,
                    record_note, replay_note
                )

        # æ‰€æœ‰æœç´¢éƒ½å¤±è´¥ - ç”±ä¸Šçº§ç»Ÿä¸€åˆ†æä¸¢é”¤å¤šé”¤
        return self._create_match_result(
            MatchType.FAILED, record_index, reason="æ— ç¬¦åˆè¯¯å·®èŒƒå›´çš„å€™é€‰"
        )

    def _find_candidates_in_key_group(self, replay_notes: List[Note], target_keyon: float, target_keyoff: float,
                                    target_key_id: int, search_mode: str = "precision") -> Tuple[List[Candidate], str]:
        """
        åœ¨æŒ‰é”®ç»„å†…éƒ¨å¯»æ‰¾å€™é€‰åŒ¹é…

        Args:
            replay_notes: è¯¥æŒ‰é”®çš„æ’­æ”¾éŸ³ç¬¦åˆ—è¡¨
            target_keyon: ç›®æ ‡æŒ‰é”®å¼€å§‹æ—¶é—´
            target_keyoff: ç›®æ ‡æŒ‰é”®ç»“æŸæ—¶é—´
            target_key_id: ç›®æ ‡æŒ‰é”®ID
            search_mode: æœç´¢æ¨¡å¼

        Returns:
            Tuple[List[Candidate], str]: (å€™é€‰åˆ—è¡¨, å¤±è´¥åŸå› )
        """
        candidates = []

        for idx, replay_note in enumerate(replay_notes):
            # éªŒè¯æŒ‰é”®IDåŒ¹é…ï¼ˆè™½ç„¶ç†è®ºä¸Šåº”è¯¥éƒ½åŒ¹é…ï¼‰
            if getattr(replay_note, 'id', None) != target_key_id:
                continue

            # è®¡ç®—æ—¶é—´è¯¯å·®ï¼ˆåªä½¿ç”¨keyon_offsetï¼‰
            replay_keyon, _ = self._calculate_note_times(replay_note)
            keyon_offset = replay_keyon - target_keyon
            total_error = abs(keyon_offset)

            candidates.append(Candidate(idx, total_error, replay_note))

        # æŒ‰è¯¯å·®å‡åºæ’åº
        candidates.sort(key=lambda x: x.total_error)

        # æ ¹æ®æœç´¢æ¨¡å¼åº”ç”¨é˜ˆå€¼è¿‡æ»¤
        if search_mode == "precision":
            filtered = [c for c in candidates if c.total_error <= FAIR_THRESHOLD]
            if not filtered:
                best_error = min(c.error_ms for c in candidates) if candidates else 0
                return [], f"æ— ç²¾ç¡®å€™é€‰(æœ€ä½³è¯¯å·®:{best_error:.1f}ms, é˜ˆå€¼:{FAIR_THRESHOLD/10:.1f}ms)"
        elif search_mode == "approximate":
            filtered = [c for c in candidates if FAIR_THRESHOLD < c.total_error <= POOR_THRESHOLD]
            if not filtered:
                return [], f"æ— è¿‘ä¼¼å€™é€‰(é˜ˆå€¼:{FAIR_THRESHOLD/10:.1f}-{POOR_THRESHOLD/10:.1f}ms)"
        elif search_mode == "severe":
            filtered = [c for c in candidates if c.total_error > POOR_THRESHOLD]
            if not filtered:
                return [], f"æ— ä¸¥é‡è¯¯å·®å€™é€‰(é˜ˆå€¼:>{POOR_THRESHOLD/10:.1f}ms)"
        else:
            filtered = candidates

        return filtered, ""

    def _group_notes_by_key(self, notes: List[Note]) -> Dict[int, List[Tuple[int, Note]]]:
        """
        æŒ‰æŒ‰é”®IDåˆ†ç»„éŸ³ç¬¦æ•°æ®

        Args:
            notes: éŸ³ç¬¦åˆ—è¡¨

        Returns:
            Dict[int, List[Tuple[int, Note]]]: key=æŒ‰é”®ID, value=(åŸå§‹ç´¢å¼•, éŸ³ç¬¦)åˆ—è¡¨
        """
        grouped = defaultdict(list)
        for i, note in enumerate(notes):
            grouped[note.id].append((i, note))
        return dict(grouped)

    def _calculate_global_statistics(self):
        """è®¡ç®—å…¨å±€ç»Ÿè®¡ä¿¡æ¯ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        # è¿™ä¸ªæ–¹æ³•ä¸»è¦ç”¨äºä¿æŒå‘åå…¼å®¹æ€§
        # å®é™…çš„ç»Ÿè®¡ä¿¡æ¯å·²ç»åœ¨_match_notes_for_single_keyä¸­è®¡ç®—äº†
        pass

    def _calculate_key_statistics_from_matches(self, record_by_key: Dict[int, List[Tuple[int, Note]]],
                                             replay_by_key: Dict[int, List[Tuple[int, Note]]]):
        """åŸºäºåŒ¹é…ç»“æœè®¡ç®—æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("ğŸ“Š å¼€å§‹è®¡ç®—æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯...")

        # åˆå§‹åŒ–æ‰€æœ‰æŒ‰é”®çš„ç»Ÿè®¡ä¿¡æ¯
        for key_id in set(record_by_key.keys()) | set(replay_by_key.keys()):
            key_stats = KeyMatchStatistics(key_id)
            key_stats.total_record_notes = len(record_by_key.get(key_id, []))
            key_stats.total_replay_notes = len(replay_by_key.get(key_id, []))
            self.key_statistics[key_id] = key_stats

        # åŸºäºåŒ¹é…ç»“æœæ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        for match_result in self.match_results:
            # è·å–å½•åˆ¶éŸ³ç¬¦ï¼ˆä»match_result.pairï¼Œæ”¯æŒæ‹†åˆ†æ•°æ®ï¼‰
            if match_result.pair is None:
                # å¤±è´¥åŒ¹é…ï¼Œä»åŸå§‹æ•°æ®è·å–
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ‹†åˆ†ç´¢å¼•ï¼ˆ>= 1000000ï¼‰æˆ–æ— æ•ˆç´¢å¼•
                if match_result.record_index >= 1000000 or \
                   match_result.record_index < 0 or \
                   match_result.record_index >= len(self._record_data):
                    continue  # æ‹†åˆ†ç´¢å¼•æˆ–æ— æ•ˆç´¢å¼•ï¼Œè·³è¿‡
                record_note = self._record_data[match_result.record_index]
            else:
                # æˆåŠŸåŒ¹é…ï¼Œä»pairè·å–ï¼ˆæ”¯æŒæ‹†åˆ†ï¼‰
                record_note = match_result.pair[0]
            
            key_id = record_note.id

            if key_id not in self.key_statistics:
                continue

            key_stats = self.key_statistics[key_id]

            if match_result.is_success:
                # è®¡ç®—æ ¡å‡†ååç§»
                record_keyon, _ = self._calculate_note_times(record_note)
                replay_keyon, _ = self._calculate_note_times(match_result.pair[1])
                raw_offset = replay_keyon - record_keyon
                corrected_offset = raw_offset - self.global_time_offset
                corrected_offset_ms = corrected_offset / 10.0

                # åªç»Ÿè®¡è¯¯å·®â‰¤50msçš„åŒ¹é…å¯¹ç”¨äºæ¡å½¢å›¾
                if abs(corrected_offset_ms) <= 50.0:
                    key_stats.add_match_result(match_result, corrected_offset_ms)
            else:
                # è®°å½•å¤±è´¥åŒ¹é…
                key_stats.failed_count += 1

        # è®¡ç®—æ¯ä¸ªæŒ‰é”®çš„ç»Ÿè®¡å€¼
        for key_stats in self.key_statistics.values():
            if key_stats.matched_count > 0:
                key_stats.calculate_statistics()

    def _log_key_matching_statistics(self):
        """è®°å½•æŒ‰é”®çº§åˆ«çš„åŒ¹é…ç»Ÿè®¡æ—¥å¿—"""
        logger.info("ğŸ“Š æŒ‰é”®åŒ¹é…ç»Ÿè®¡æ±‡æ€»:")

        # æŒ‰æŒ‰é”®IDæ’åºè¾“å‡º
        for key_id in sorted(self.key_statistics.keys()):
            key_stats = self.key_statistics[key_id]
            match_rate = (key_stats.matched_count / key_stats.total_record_notes * 100) if key_stats.total_record_notes > 0 else 0

            if key_stats.matched_count > 0:
                logger.info(f"ğŸ¹ æŒ‰é”®{key_id}: å½•åˆ¶{key_stats.total_record_notes} â†’ åŒ¹é…{key_stats.matched_count} â†’ "
                           f"å¤±è´¥{key_stats.failed_count} (åŒ¹é…ç‡: {match_rate:.1f}%, "
                           f"å‡å€¼: {key_stats.mean_offset:.2f}ms, æ ‡å‡†å·®: {key_stats.std_offset:.2f}ms)")
            else:
                logger.info(f"ğŸ¹ æŒ‰é”®{key_id}: å½•åˆ¶{key_stats.total_record_notes} â†’ åŒ¹é…{key_stats.matched_count} â†’ "
                           f"å¤±è´¥{key_stats.failed_count} (åŒ¹é…ç‡: {match_rate:.1f}%)")

        # æ€»ä½“ç»Ÿè®¡
        total_keys = len(self.key_statistics)
        keys_with_matches = sum(1 for stats in self.key_statistics.values() if stats.matched_count > 0)
        total_record_notes = sum(stats.total_record_notes for stats in self.key_statistics.values())
        total_matched = sum(stats.matched_count for stats in self.key_statistics.values())
        total_failed = sum(stats.failed_count for stats in self.key_statistics.values())

        overall_match_rate = (total_matched / total_record_notes * 100) if total_record_notes > 0 else 0

        logger.info(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡: {total_keys}ä¸ªæŒ‰é”®, {keys_with_matches}ä¸ªæŒ‰é”®æœ‰åŒ¹é…, "
                   f"æ€»å½•åˆ¶éŸ³ç¬¦: {total_record_notes}, æˆåŠŸåŒ¹é…: {total_matched}, å¤±è´¥: {total_failed}, "
                   f"æ•´ä½“åŒ¹é…ç‡: {overall_match_rate:.1f}%")


    def get_key_statistics_for_bar_chart(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯ç”¨äºæ¡å½¢ç»Ÿè®¡å›¾

        ç›´æ¥ä½¿ç”¨é¢„è®¡ç®—çš„æŒ‰é”®ç»Ÿè®¡ä¿¡æ¯ï¼Œé¿å…é‡å¤è®¡ç®—

        Returns:
            List[Dict[str, Union[int, float]]]: æŒ‰é”®ç»Ÿè®¡æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
            - key_id: æŒ‰é”®ID
            - median: ä¸­ä½æ•°åç§» (ms)
            - mean: å‡å€¼åç§» (ms)
            - std: æ ‡å‡†å·® (ms)
            - variance: æ–¹å·® (msÂ²)
            - count: è¯¥æŒ‰é”®æˆåŠŸåŒ¹é…å¯¹æ•°é‡
        """
        result = []

        for key_id, key_stats in self.key_statistics.items():
            # åªåŒ…å«æœ‰åŒ¹é…æ•°æ®çš„æŒ‰é”®
            if key_stats.matched_count > 0 and key_stats.offsets_ms:
                result.append({
                    'key_id': key_id,
                    'median': key_stats.median_offset,
                    'mean': key_stats.mean_offset,
                    'std': key_stats.std_offset,
                    'variance': key_stats.variance_offset,
                    'count': key_stats.matched_count,
                    'status': 'matched'
                })

        # æŒ‰æŒ‰é”®IDæ’åº
        result.sort(key=lambda x: x['key_id'])

        logger.debug(f"ğŸ“Š æ¡å½¢ç»Ÿè®¡å›¾æ•°æ®: {len(result)}ä¸ªæŒ‰é”®æœ‰ç»Ÿè®¡ä¿¡æ¯")
        return result

    def _find_candidates(self, notes_list: List[Note], target_keyon: float, target_keyoff: float,
                        target_key_id: int, time_offset: float = 0.0, search_mode: str = "precision") -> Tuple[List[Candidate], str]:
        """
        ç”Ÿæˆå€™é€‰åˆ—è¡¨ï¼Œæ”¯æŒä¸åŒçš„æœç´¢æ¨¡å¼ã€‚

        å‚æ•°å•ä½ï¼š
            - target_keyon/target_keyoffï¼š0.1msï¼ˆç»å¯¹æ—¶é—´ = after_touch.index + offsetï¼‰
            - è¯¯å·®ï¼š0.1msï¼ˆå†…éƒ¨ç»Ÿä¸€å•ä½ï¼‰

        Args:
            notes_list: éŸ³ç¬¦åˆ—è¡¨
            target_keyon: ç›®æ ‡æŒ‰é”®å¼€å§‹æ—¶é—´
            target_keyoff: ç›®æ ‡æŒ‰é”®ç»“æŸæ—¶é—´
            target_key_id: ç›®æ ‡æŒ‰é”®ID
            time_offset: æ—¶é—´åç§»
            search_mode: æœç´¢æ¨¡å¼ ("precision" æˆ– "approximate")

        Returns:
            (candidates, reason_if_empty)
        """
        # 1) è¿‡æ»¤åŒé”®IDçš„éŸ³ç¬¦
        matching_notes = []
        for idx, note in enumerate(notes_list):
            if getattr(note, 'id', None) == target_key_id:
                matching_notes.append((idx, note))

        if not matching_notes:
            return [], f"æ²¡æœ‰æ‰¾åˆ°é”®ID {target_key_id} çš„éŸ³ç¬¦"

        # 2) æ„å»ºå€™é€‰å¹¶è®¡ç®—è¯¯å·®
        candidates: List[Candidate] = []
        for idx, note in matching_notes:
            # è®¡ç®—æŒ‰é”®å¼€å§‹æ—¶é—´ï¼ˆåº”ç”¨æ—¶é—´åç§»ï¼‰
            try:
                current_keyon = note.after_touch.index[0] + note.offset + time_offset
            except (IndexError, AttributeError) as e:
                raise ValueError(f"éŸ³ç¬¦ID {note.id} çš„after_touchæ•°æ®æ— æ•ˆ: {e}") from e

            # åªä½¿ç”¨keyon_offsetè®¡ç®—è¯¯å·®
            keyon_offset = current_keyon - target_keyon
            total_error = abs(keyon_offset)

            candidates.append(Candidate(idx, total_error))

        # 3) æ ¹æ®æœç´¢æ¨¡å¼åº”ç”¨é˜ˆå€¼è¿‡æ»¤ - åˆ†å±‚æœç´¢ç­–ç•¥
        if search_mode == "precision":
            # ç²¾ç¡®æœç´¢ï¼šä¼˜å…ˆå¯»æ‰¾é«˜è´¨é‡åŒ¹é… (â‰¤ FAIR_THRESHOLD = 50ms)
            # è¿™ä¸ªé˜ˆå€¼ä¸è¯„çº§ä¸­çš„fairé˜ˆå€¼ä¸€è‡´ï¼Œç¡®ä¿ä¸ä¼šå½±å“è¯„çº§åˆ†å¸ƒ
            filtered = [c for c in candidates if c.total_error <= FAIR_THRESHOLD]
            if not filtered:
                # æ²¡æœ‰ç²¾ç¡®å€™é€‰ï¼Œè¿”å›ç©ºåˆ—è¡¨å’ŒåŸå› 
                best_error = min(c.error_ms for c in candidates) if candidates else 0
                return [], f"æ— ç²¾ç¡®å€™é€‰(æœ€ä½³è¯¯å·®:{best_error:.1f}ms, é˜ˆå€¼:{FAIR_THRESHOLD/10:.1f}ms)"
        elif search_mode == "approximate":
            # è¾ƒå·®æœç´¢ï¼šå½“ç²¾ç¡®æœç´¢å¤±è´¥æ—¶ï¼Œå¯»æ‰¾å¯æ¥å—çš„åŒ¹é… (50ms-100ms)
            # é¿å…ä¸precisionæ¨¡å¼é‡å ï¼Œç¡®ä¿è¯„çº§é€»è¾‘ä¸å—å½±å“
            filtered = [c for c in candidates if FAIR_THRESHOLD < c.total_error <= POOR_THRESHOLD]
            if not filtered:
                return [], f"æ— è¾ƒå·®å€™é€‰(é˜ˆå€¼:{FAIR_THRESHOLD/10:.1f}-{POOR_THRESHOLD/10:.1f}ms)"
        elif search_mode == "severe":
            # ä¸¥é‡è¯¯å·®æœç´¢ï¼šåªæ¥å—è¯¯å·®å¾ˆå¤§çš„åŒ¹é… (100ms-200ms)
            # è¿™äº›åŒ¹é…ä¼šè¢«è¯„ä¸ºSEVEREç±»å‹
            filtered = [c for c in candidates if POOR_THRESHOLD < c.total_error <= SEVERE_THRESHOLD]
            if not filtered:
                return [], f"æ— ä¸¥é‡è¯¯å·®å€™é€‰(é˜ˆå€¼:{POOR_THRESHOLD/10:.1f}-{SEVERE_THRESHOLD/10:.1f}ms)"
        else:
            filtered = candidates

        # æŒ‰è¯¯å·®å‡åºæ’åº
        filtered.sort(key=lambda x: x.total_error)
        return filtered, ""

    def _evaluate_match_quality(self, error_ms: float) -> MatchType:
        """
        æ ¹æ®è¯¯å·®è¯„ä¼°åŒ¹é…è´¨é‡ - å…­ç­‰çº§æ ‡å‡†

        Args:
            error_ms: è¯¯å·®(æ¯«ç§’)

        Returns:
            MatchType: åŒ¹é…ç±»å‹
        """
        error_units = error_ms * 10.0  # è½¬æ¢ä¸ºå†…éƒ¨å•ä½

        if error_units <= EXCELLENT_THRESHOLD:
            return MatchType.EXCELLENT
        elif error_units <= GOOD_THRESHOLD:
            return MatchType.GOOD
        elif error_units <= FAIR_THRESHOLD:
            return MatchType.FAIR
        elif error_units <= POOR_THRESHOLD:
            return MatchType.POOR
        elif error_units <= SEVERE_THRESHOLD:
            return MatchType.SEVERE
        else:
            return MatchType.FAILED

    def _create_match_result(self, match_type: MatchType, record_index: int,
                           replay_index: Optional[int] = None, candidate: Optional[Candidate] = None,
                           record_note: Optional[Note] = None, replay_note: Optional[Note] = None,
                           reason: str = "") -> MatchResult:
        """
        åˆ›å»ºåŒ¹é…ç»“æœå¯¹è±¡

        Args:
            match_type: åŒ¹é…ç±»å‹
            record_index: å½•åˆ¶éŸ³ç¬¦ç´¢å¼•
            replay_index: æ’­æ”¾éŸ³ç¬¦ç´¢å¼•
            candidate: å€™é€‰å¯¹è±¡
            record_note: å½•åˆ¶éŸ³ç¬¦
            replay_note: æ’­æ”¾éŸ³ç¬¦
            reason: å¤±è´¥åŸå› 

        Returns:
            MatchResult: åŒ¹é…ç»“æœå¯¹è±¡
        """
        error_ms = candidate.error_ms if candidate else 0.0
        pair = (record_note, replay_note) if record_note and replay_note else None

        return MatchResult(
            match_type=match_type,
            record_index=record_index,
            replay_index=replay_index,
            error_ms=error_ms,
            pair=pair,
            reason=reason
        )


    def _initialize_matching_state(self) -> None:
        """åˆå§‹åŒ–åŒ¹é…çŠ¶æ€"""
        self.failure_reasons.clear()
        self._clear_mean_error_cache()
        self._split_counter = 0  # é‡ç½®å…¨å±€æ‹†åˆ†è®¡æ•°å™¨

    def _perform_single_note_matching(self, record_note: Note, record_index: int,
                                     replay_data: List[Note], used_replay_indices: set) -> MatchResult:
        """
        æ‰§è¡Œå•ä¸ªéŸ³ç¬¦çš„åŒ¹é…è¿‡ç¨‹

        æŒ‰ä¼˜å…ˆçº§é¡ºåºå°è¯•ä¸åŒç±»å‹çš„åŒ¹é…ï¼š
        1. ç²¾ç¡®åŒ¹é… (â‰¤50ms)
        2. è¾ƒå·®åŒ¹é… (50ms-100ms)
        3. ä¸¥é‡è¯¯å·®åŒ¹é… (100ms-200ms)
        4. å¤±è´¥ (>200ms)

        Args:
            record_note: å½•åˆ¶éŸ³ç¬¦
            record_index: å½•åˆ¶éŸ³ç¬¦ç´¢å¼•
            replay_data: æ’­æ”¾æ•°æ®
            used_replay_indices: å·²ä½¿ç”¨çš„æ’­æ”¾éŸ³ç¬¦ç´¢å¼•é›†åˆ

        Returns:
            MatchResult: åŒ¹é…ç»“æœ
        """
        note_info = self._extract_note_info(record_note, record_index)

        # å®šä¹‰åŒ¹é…ç­–ç•¥ï¼šåˆ†å±‚æœç´¢ï¼Œç¡®ä¿æ‰¾åˆ°æœ€ä½³åŒ¹é…
        # æœç´¢ç­–ç•¥ä¸è¯„çº§é€»è¾‘è§£è€¦ï¼Œé¿å…é˜ˆå€¼å½±å“è¯„çº§åˆ†å¸ƒ
        match_strategies = [
            ("precision", self.precision_matched_pairs),     # ç¬¬ä¸€ä¼˜å…ˆçº§: ç²¾ç¡®æœç´¢ (â‰¤50ms)
            ("approximate", self.approximate_matched_pairs), # ç¬¬äºŒä¼˜å…ˆçº§: è¾ƒå·®æœç´¢ (50ms-100ms)
            ("severe", self.severe_matched_pairs),          # ç¬¬ä¸‰ä¼˜å…ˆçº§: ä¸¥é‡è¯¯å·®æœç´¢ (100ms-200ms)
        ]

        # æŒ‰é¡ºåºå°è¯•æ¯ç§åŒ¹é…ç­–ç•¥
        for search_mode, record_list in match_strategies:
            candidates, reason = self._find_candidates(
                replay_data, note_info["keyon"], note_info["keyoff"],
                note_info["key_id"], time_offset=0, search_mode=search_mode
            )

            if candidates:
                chosen = self._select_best_candidate_from_list(candidates, used_replay_indices)
                if chosen:
                    # åŒ¹é…æˆåŠŸ
                    replay_index = chosen.index
                    replay_note = replay_data[replay_index]

                    # å¦‚æœéœ€è¦è®°å½•åˆ°ç‰¹æ®Šåˆ—è¡¨ï¼ˆå¦‚è¿‘ä¼¼åŒ¹é…æˆ–å¤§è¯¯å·®åŒ¹é…ï¼‰
                    if record_list is not None:
                        match_pair = (record_index, replay_index, record_note, replay_note)
                        record_list.append(match_pair)

                    used_replay_indices.add(replay_index)

                    # æ ¹æ®å®é™…è¯¯å·®ç¡®å®šåŒ¹é…ç±»å‹
                    actual_match_type = self._evaluate_match_quality(chosen.error_ms)

                    return self._create_match_result(
                        actual_match_type, record_index, replay_index, chosen,
                        record_note, replay_note
                    )

        # æ‰€æœ‰æœç´¢éƒ½å¤±è´¥
        # å¦‚æœæœ‰å€™é€‰ä½†éƒ½è¢«è¿‡æ»¤æ‰äº†ï¼Œè¯´æ˜è¯¯å·®éƒ½ä¸åœ¨æ¥å—èŒƒå›´å†…
        # å¦‚æœæ²¡æœ‰å€™é€‰ï¼Œè¯´æ˜æŒ‰é”®æ²¡æœ‰å¯ç”¨çš„æ’­æ”¾éŸ³ç¬¦
        if candidates:
            # æœ‰å€™é€‰ä½†éƒ½ä¸æ»¡è¶³ä»»ä½•æœç´¢æ¨¡å¼ï¼Œè¯´æ˜è¯¯å·®èŒƒå›´ä¸ç¬¦åˆ
            failure_reason = reason if reason else f"æŒ‰é”®{note_info['key_id']} æ— ç¬¦åˆè¯¯å·®èŒƒå›´çš„å€™é€‰"
        else:
            # æ²¡æœ‰å€™é€‰ï¼Œè¯´æ˜è¯¥æŒ‰é”®æ²¡æœ‰å¯ç”¨çš„æ’­æ”¾éŸ³ç¬¦
            failure_reason = f"æŒ‰é”®{note_info['key_id']} æ— å¯ç”¨æ’­æ”¾éŸ³ç¬¦"

        return self._create_match_result(
            MatchType.FAILED, record_index, reason=failure_reason
        )

    def _select_best_candidate_from_list(self, candidates: List[Candidate], used_indices: set) -> Optional[Candidate]:
        """
        ä»å€™é€‰åˆ—è¡¨ä¸­é€‰æ‹©æœ€ä½³çš„æœªä½¿ç”¨å€™é€‰

        Args:
            candidates: å€™é€‰åˆ—è¡¨ï¼ˆå·²æŒ‰è¯¯å·®æ’åºï¼‰
            used_indices: å·²ä½¿ç”¨çš„ç´¢å¼•é›†åˆ

        Returns:
            Optional[Candidate]: æœ€ä½³å€™é€‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        for candidate in candidates:
            if candidate.index not in used_indices:
                return candidate
        return None



    def _log_successful_match(self, match_pair: Tuple, expanded_candidates: bool) -> None:
        """
        è®°å½•æˆåŠŸçš„åŒ¹é…

        Args:
            match_pair: åŒ¹é…å¯¹
            expanded_candidates: æ˜¯å¦ä¸ºæ‰©å±•å€™é€‰åŒ¹é…
        """
        record_idx, replay_idx, record_note, replay_note = match_pair

        status = "ğŸ”„ åŒ¹é…æˆåŠŸï¼ˆæ‰©å±•å€™é€‰ï¼‰" if expanded_candidates else "âœ… åŒ¹é…æˆåŠŸ"

        # è®¡ç®—æ—¶é—´ä¿¡æ¯ç”¨äºæ—¥å¿—
        record_keyon, record_keyoff = self._calculate_note_times(record_note)
        replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

        # logger.info(f"{status}: é”®ID={record_note.id}, å½•åˆ¶ç´¢å¼•={record_idx}, å›æ”¾ç´¢å¼•={replay_idx}")

    def _log_failed_match(self, record_index: int, record_note: Note, reason: str,
                         candidates: List[Dict], replay_data: List[Note]) -> None:
        """
        è®°å½•å¤±è´¥çš„åŒ¹é…

        Args:
            record_index: å½•åˆ¶éŸ³ç¬¦ç´¢å¼•
            record_note: å½•åˆ¶éŸ³ç¬¦
            reason: å¤±è´¥åŸå› 
            candidates: å€™é€‰åˆ—è¡¨
            replay_data: æ’­æ”¾æ•°æ®
        """
        note_info = self._extract_note_info(record_note, record_index)

        logger.info(f"âŒ åŒ¹é…å¤±è´¥: é”®ID={note_info['key_id']}, å½•åˆ¶ç´¢å¼•={record_index}, "
                   f"å½•åˆ¶æ—¶é—´=({note_info['keyon']/10:.2f}ms, {note_info['keyoff']/10:.2f}ms), "
                   f"åŸå› : {reason}")

        # è®°å½•è¢«å ç”¨çš„å€™é€‰è¯¦ç»†ä¿¡æ¯
        for j, cand in enumerate(candidates[:3]):
            cand_note = replay_data[cand['index']]
            cand_keyon, cand_keyoff = self._calculate_note_times(cand_note)
            logger.info(f"   å€™é€‰{j+1}: å›æ”¾ç´¢å¼•={cand['index']}, "
                       f"å›æ”¾æ—¶é—´=({cand_keyon/10:.2f}ms, {cand_keyoff/10:.2f}ms), "
                       f"æ€»è¯¯å·®={cand['total_error']/10:.2f}ms")

    def _log_matching_statistics(self, record_data: List[Note], replay_data: List[Note],
                                matched_pairs: List, used_replay_indices: set) -> None:
        """
        è®°å½•åŒ¹é…ç»Ÿè®¡ä¿¡æ¯

        Args:
            record_data: å½•åˆ¶æ•°æ®
            replay_data: æ’­æ”¾æ•°æ®
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨
            used_replay_indices: å·²ä½¿ç”¨çš„æ’­æ”¾ç´¢å¼•
        """
        success_count = len(matched_pairs)
        failure_count = len(record_data) - success_count

        logger.info(f"ğŸ“Š åŒ¹é…å®Œæˆ: æˆåŠŸ{success_count}å¯¹, å¤±è´¥{failure_count}å¯¹, "
                   f"æ€»è®¡{len(record_data)}ä¸ªå½•åˆ¶éŸ³ç¬¦, ä½¿ç”¨{len(used_replay_indices)}/{len(replay_data)}ä¸ªæ’­æ”¾éŸ³ç¬¦")

    
    def _extract_note_info(self, note: Note, index: int) -> Dict:
        """
        æå–éŸ³ç¬¦åŸºæœ¬ä¿¡æ¯
        
        Args:
            note: éŸ³ç¬¦å¯¹è±¡
            index: éŸ³ç¬¦ç´¢å¼•
            
        Returns:
            Dict: éŸ³ç¬¦ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ç»å¯¹æ—¶é—´æˆ³
        """
        # è®¡ç®—ç»å¯¹æ—¶é—´æˆ³ï¼ˆafter_touch.index + offsetï¼‰
        # è¿™æ˜¯éŸ³ç¬¦åœ¨æ•´ä¸ªæ—¶é—´çº¿ä¸Šçš„å®é™…å‘ç”Ÿæ—¶é—´
        try:
            absolute_keyon = note.after_touch.index[0] + note.offset
            absolute_keyoff = note.after_touch.index[-1] + note.offset
        except (IndexError, AttributeError) as e:
            raise ValueError(f"éŸ³ç¬¦ID {note.id} çš„after_touchæ•°æ®æ— æ•ˆ: {e}") from e
        
        return {
            'keyon': absolute_keyon,      # ç»å¯¹æ—¶é—´æˆ³ï¼šæŒ‰é”®å¼€å§‹æ—¶é—´
            'keyoff': absolute_keyoff,    # ç»å¯¹æ—¶é—´æˆ³ï¼šæŒ‰é”®ç»“æŸæ—¶é—´
            'key_id': note.id,            # æŒ‰é”®ID
            'index': index                # éŸ³ç¬¦åœ¨åˆ—è¡¨ä¸­çš„ç´¢å¼•
        }
    
    def extract_normal_matched_pairs(self, matched_pairs: List[Tuple[int, int, Note, Note]], 
                                   multi_hammers: List, drop_hammers: List) -> Tuple[List[Note], List[Note]]:
        """
        ä»åŒ¹é…å¯¹ä¸­æå–æ­£å¸¸åŒ¹é…çš„éŸ³ç¬¦å¯¹
        
        Args:
            matched_pairs: åŒ¹é…å¯¹åˆ—è¡¨
            multi_hammers: å¤šé”¤åˆ—è¡¨
            drop_hammers: ä¸¢é”¤åˆ—è¡¨
            
        Returns:
            Tuple[List[Note], List[Note]]: (matched_record_data, matched_replay_data)
        """
        matched_record_data = []
        matched_replay_data = []
        
        for record_index, replay_index, record_note, replay_note in matched_pairs:
            matched_record_data.append(record_note)
            matched_replay_data.append(replay_note)
        
        return matched_record_data, matched_replay_data
    
    def get_matched_pairs(self) -> List[Tuple[int, int, Note, Note]]:
        """
        è·å–ç²¾ç¡®åŒ¹é…å¯¹åˆ—è¡¨ï¼ˆâ‰¤50msï¼‰

        åªè¿”å›ç²¾ç¡®åŒ¹é…çš„é…å¯¹ï¼Œç”¨äºæŒ‡æ ‡è®¡ç®—å’Œå›¾è¡¨æ˜¾ç¤º

        Returns:
            List[Tuple[int, int, Note, Note]]: ç²¾ç¡®åŒ¹é…å¯¹åˆ—è¡¨
        """
        return self.matched_pairs.copy()
    
    # TODO
    def get_offset_alignment_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–åç§»å¯¹é½æ•°æ® - è®¡ç®—æ¯ä¸ªåŒ¹é…å¯¹çš„æ—¶é—´åç§»ï¼ˆåŒ…æ‹¬è¶…è¿‡é˜ˆå€¼çš„åŒ¹é…å¯¹ï¼‰
        
        Returns:
            List[Dict[str, Union[int, float]]]: åç§»å¯¹é½æ•°æ®åˆ—è¡¨
        """
        offset_data: List[Dict[str, Union[int, float]]] = []
        
        # æ‰€æœ‰åŒ¹é…å¯¹éƒ½åœ¨ matched_pairs ä¸­
        all_matched_pairs = self.matched_pairs

        for record_idx, replay_idx, record_note, replay_note in all_matched_pairs:
            # è®¡ç®—å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦çš„æ—¶é—´
            record_keyon, record_keyoff = self._calculate_note_times(record_note)
            replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

            # è®¡ç®—åŸå§‹åç§»é‡
            keyon_offset = replay_keyon - record_keyon

            # è®¡ç®—æ ¡å‡†åçš„åç§»ï¼ˆå»é™¤å…¨å±€å›ºå®šå»¶æ—¶ï¼‰
            # è¿™åæ˜ äº†éŸ³ç¬¦ç›¸å¯¹äºç³»ç»Ÿå¹³å‡å»¶æ—¶çš„"æŠ–åŠ¨"æˆ–"è¯¯å·®"
            corrected_offset = keyon_offset - self.global_time_offset


            record_duration = record_keyoff - record_keyon
            replay_duration = replay_keyoff - replay_keyon
            duration_diff = replay_duration - record_duration
            duration_offset = duration_diff
            # ä½¿ç”¨æ ¡å‡†åçš„ç»å¯¹è¯¯å·®
            avg_offset = abs(corrected_offset)


            offset_data.append({
                'record_index': record_idx,
                'replay_index': replay_idx,
                'key_id': record_note.id,
                'record_keyon': record_keyon,
                'replay_keyon': replay_keyon,
                'keyon_offset': keyon_offset,       # åŸå§‹åç§»
                'corrected_offset': corrected_offset, # æ ¡å‡†ååç§»ï¼ˆç”¨äºåˆ†æï¼‰
                'record_keyoff': record_keyoff,
                'replay_keyoff': replay_keyoff,
                'duration_offset': duration_offset,
                'average_offset': avg_offset,
                'record_duration': record_duration,
                'replay_duration': replay_duration,
                'duration_diff': duration_diff
            })

        return offset_data

    def get_precision_offset_alignment_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–ç²¾ç¡®æœç´¢é˜¶æ®µåŒ¹é…å¯¹çš„åç§»å¯¹é½æ•°æ® - åŒ…å«æ‰€æœ‰ç²¾ç¡®æœç´¢é˜¶æ®µçš„åŒ¹é…ï¼ˆè¯¯å·® â‰¤ 50msï¼‰

        ç²¾ç¡®æœç´¢é˜¶æ®µï¼šå°è¯•æ‰¾åˆ°è¯¯å·® â‰¤ 50ms çš„åŒ¹é…ï¼Œæœ€ç»ˆåŒ¹é…ç±»å‹å¯èƒ½æ˜¯ä¼˜ç§€/è‰¯å¥½/ä¸€èˆ¬
        ç”¨äºè®¡ç®—å»¶æ—¶è¯¯å·®ç»Ÿè®¡æŒ‡æ ‡ï¼Œç¡®ä¿åªä½¿ç”¨ç›¸å¯¹é«˜è´¨é‡çš„åŒ¹é…æ•°æ®ã€‚

        Returns:
            List[Dict[str, Union[int, float]]]: ç²¾ç¡®æœç´¢é˜¶æ®µåŒ¹é…å¯¹çš„åç§»å¯¹é½æ•°æ®åˆ—è¡¨
        """
        # ç›´æ¥å¤„ç†precision_matched_pairsä¸­çš„æ‰€æœ‰åŒ¹é…ï¼ˆâ‰¤50msï¼‰
        offset_data = []
        for record_idx, replay_idx, record_note, replay_note in self.precision_matched_pairs:
            # è®¡ç®—å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦çš„æ—¶é—´
            record_keyon, record_keyoff = self._calculate_note_times(record_note)
            replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

            # è·å–é”¤é€Ÿä¿¡æ¯
            record_velocity = self._get_velocity_from_note(record_note)
            replay_velocity = self._get_velocity_from_note(replay_note)

            # è®¡ç®—åŸå§‹åç§»é‡
            keyon_offset = replay_keyon - record_keyon

            # è®¡ç®—æ ¡å‡†åçš„åç§»ï¼ˆå»é™¤å…¨å±€å›ºå®šå»¶æ—¶ï¼‰
            corrected_offset = keyon_offset - self.global_time_offset

            record_duration = record_keyoff - record_keyon
            replay_duration = replay_keyoff - replay_keyon
            duration_diff = replay_duration - record_duration
            duration_offset = duration_diff

            # è®¡ç®—ç›¸å¯¹å»¶æ—¶ï¼ˆç”¨äºæ‚¬åœæ˜¾ç¤ºï¼‰
            relative_delay = corrected_offset / 10.0  # è½¬æ¢ä¸ºms

            offset_data.append({
                'record_index': record_idx,
                'replay_index': replay_idx,
                'key_id': record_note.id,
                'record_keyon': record_keyon,
                'replay_keyon': replay_keyon,
                'record_velocity': record_velocity,    # å½•åˆ¶é”¤é€Ÿ
                'replay_velocity': replay_velocity,    # æ’­æ”¾é”¤é€Ÿ
                'velocity_diff': (replay_velocity - record_velocity) if record_velocity is not None and replay_velocity is not None else None,  # é”¤é€Ÿå·®å€¼
                'keyon_offset': keyon_offset,       # åŸå§‹åç§»
                'corrected_offset': corrected_offset, # æ ¡å‡†ååç§»ï¼ˆç”¨äºåˆ†æï¼‰
                'relative_delay': relative_delay,     # ç›¸å¯¹å»¶æ—¶ï¼ˆmsï¼‰
                'record_keyoff': record_keyoff,
                'replay_keyoff': replay_keyoff,
                'duration_offset': duration_offset,
                'average_offset': abs(corrected_offset),
                'record_duration': record_duration,
                'replay_duration': replay_duration,
                'duration_diff': duration_diff
            })

        return offset_data

    def _get_velocity_from_note(self, note) -> Optional[float]:
        """ä»éŸ³ç¬¦ä¸­è·å–é”¤é€Ÿ"""
        try:
            if not note:
                return None

            # åªä»hammersæ•°æ®ä¸­è·å–é”¤é€Ÿ
            if hasattr(note, 'hammers') and note.hammers is not None:
                if hasattr(note.hammers, 'values') and len(note.hammers.values) > 0:
                    hammer_velocity = note.hammers.values[0]
                    if hammer_velocity is not None and not pd.isna(hammer_velocity):
                        return float(hammer_velocity)
                elif hasattr(note.hammers, 'iloc') and len(note.hammers) > 0:
                    hammer_velocity = note.hammers.iloc[0]
                    if hammer_velocity is not None and not pd.isna(hammer_velocity):
                        return float(hammer_velocity)

            return None

        except Exception as e:
            logger.warning(f"[WARNING] ä»éŸ³ç¬¦æå–é”¤é€Ÿå¤±è´¥: {e}")
            return None

    def get_normal_offset_alignment_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–æ­£å¸¸åŒ¹é…å¯¹çš„åç§»å¯¹é½æ•°æ® - åªè®¡ç®—åœ¨é˜ˆå€¼å†…çš„åŒ¹é…å¯¹çš„æ—¶é—´åç§»

        æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•åªå¤„ç†æ­£å¸¸åŒ¹é…å¯¹ï¼Œä¸åŒ…æ‹¬è¶…è¿‡é˜ˆå€¼çš„åŒ¹é…å¯¹ã€‚
        ç”¨äºè®¡ç®—å‡†ç¡®çš„å»¶æ—¶æŒ‡æ ‡ï¼Œé¿å…å¼‚å¸¸æ•°æ®å½±å“ç»Ÿè®¡ç»“æœã€‚

        Returns:
            List[Dict[str, Union[int, float]]]: æ­£å¸¸åŒ¹é…å¯¹çš„åç§»å¯¹é½æ•°æ®åˆ—è¡¨
        """
        offset_data: List[Dict[str, Union[int, float]]] = []

        # åªå¤„ç†æ­£å¸¸åŒ¹é…å¯¹ï¼ˆåœ¨é˜ˆå€¼å†…çš„åŒ¹é…å¯¹ï¼‰
        for record_idx, replay_idx, record_note, replay_note in self.matched_pairs:
            # è®¡ç®—å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦çš„æ—¶é—´
            record_keyon, record_keyoff = self._calculate_note_times(record_note)
            replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

            # è®¡ç®—åŸå§‹åç§»é‡
            keyon_offset = replay_keyon - record_keyon

            # è®¡ç®—æ ¡å‡†åçš„åç§»ï¼ˆå»é™¤å…¨å±€å›ºå®šå»¶æ—¶ï¼‰
            # ç”±äºDTWå·²ç¦ç”¨ï¼Œå…¨å±€åç§»ä¸º0ï¼Œæ‰€ä»¥corrected_offset = keyon_offset
            corrected_offset = keyon_offset - self.global_time_offset

            # å®‰å…¨æ£€æŸ¥ï¼šæ­£å¸¸åŒ¹é…å¯¹çš„åç§»åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
            # å¦‚æœè¶…è¿‡1000msï¼Œè¯´æ˜æ•°æ®æˆ–åŒ¹é…é€»è¾‘æœ‰ä¸¥é‡é—®é¢˜
            max_reasonable_offset = 10000.0  # 1000ms
            if abs(corrected_offset) > max_reasonable_offset:
                logger.error(f"ğŸš¨ æ£€æµ‹åˆ°å¼‚å¸¸å¤§çš„æ ¡å‡†åç§»: {corrected_offset/10:.2f}ms, "
                           f"é”®ID={record_note.id}, å½•åˆ¶ç´¢å¼•={record_idx}, æ’­æ”¾ç´¢å¼•={replay_idx}, "
                           f"è¿™è¡¨æ˜åŒ¹é…é€»è¾‘æˆ–æ•°æ®æœ‰ä¸¥é‡é—®é¢˜")
                # è·³è¿‡è¿™ä¸ªå¼‚å¸¸åŒ¹é…å¯¹ï¼Œä¸å°†å…¶åŒ…å«åœ¨ç»Ÿè®¡ä¸­
                continue

            record_duration = record_keyoff - record_keyon
            replay_duration = replay_keyoff - replay_keyon
            duration_diff = replay_duration - record_duration
            duration_offset = duration_diff
            # ä½¿ç”¨æ ¡å‡†åçš„ç»å¯¹è¯¯å·®
            avg_offset = abs(corrected_offset)
    
            
            offset_data.append({
                'record_index': record_idx,
                'replay_index': replay_idx,
                'key_id': record_note.id,
                'record_keyon': record_keyon,
                'replay_keyon': replay_keyon,
                'keyon_offset': keyon_offset,       # åŸå§‹åç§»
                'corrected_offset': corrected_offset, # æ ¡å‡†ååç§»ï¼ˆç”¨äºåˆ†æï¼‰
                'record_keyoff': record_keyoff,
                'replay_keyoff': replay_keyoff,
                'duration_offset': duration_offset,
                'average_offset': avg_offset,  
                'record_duration': record_duration,
                'replay_duration': replay_duration,
                'duration_diff': duration_diff
            })
        
        return offset_data



    def get_graded_error_stats(self) -> Dict[str, Dict[str, Union[int, float]]]:
        """
        è·å–åˆ†çº§è¯¯å·®ç»Ÿè®¡ - æˆåŠŸåŒ¹é…è´¨é‡è¯„çº§

        åªç»Ÿè®¡æˆåŠŸåŒ¹é…å¯¹çš„è´¨é‡åˆ†å¸ƒï¼ˆä¸åŒ…æ‹¬å¤±è´¥åŒ¹é…ï¼‰ï¼š
        - correct: ä¼˜ç§€ (è¯¯å·® â‰¤ 20ms)
        - minor: è‰¯å¥½ (20ms < è¯¯å·® â‰¤ 30ms)
        - moderate: ä¸€èˆ¬ (30ms < è¯¯å·® â‰¤ 50ms)
        - large: è¾ƒå·® (50ms < è¯¯å·® â‰¤ 1000ms)
        - severe: ä¸¥é‡ (è¯¯å·® > 1000ms)

        æ³¨æ„ï¼šåªç»Ÿè®¡æˆåŠŸåŒ¹é…çš„è´¨é‡åˆ†å¸ƒï¼Œå¤±è´¥åŒ¹é…ä¸å‚ä¸è¯„çº§ç»Ÿè®¡

        Returns:
            Dict: åŒ…å«å„çº§åˆ«çš„è®¡æ•°å’Œç™¾åˆ†æ¯”
        """
        # è·å–æ‰€æœ‰æˆåŠŸçš„åŒ¹é…å¯¹æ•°æ®ç”¨äºè¯„çº§
        # ç›´æ¥ä»match_resultsä¸­è·å–æ‰€æœ‰æˆåŠŸåŒ¹é…çš„æ•°æ®
        all_matched_data = []
        for result in self.match_results:
            if result.is_success:
                # ä¸ºè¯„çº§ç»Ÿè®¡åˆ›å»ºæ•°æ®é¡¹
                item = self._create_offset_data_item(result)
                all_matched_data.append(item)

        # æ€»é…å¯¹æ•° = æˆåŠŸçš„åŒ¹é…å¯¹æ•°
        total_successful_matches = len(all_matched_data)

        # åˆå§‹åŒ–ç»Ÿè®¡ - åªç»Ÿè®¡æˆåŠŸåŒ¹é…çš„è¯„çº§åˆ†å¸ƒ
        stats = {
            'correct': 0,      # ä¼˜ç§€ (â‰¤20ms)
            'minor': 0,        # è‰¯å¥½ (20-30ms)
            'moderate': 0,     # ä¸€èˆ¬ (30-50ms)
            'large': 0,        # è¾ƒå·® (50-1000ms)
            'severe': 0,       # ä¸¥é‡ (>1000ms)
            # æ³¨æ„ï¼šä¸å†ç»Ÿè®¡å¤±è´¥åŒ¹é…ï¼Œå› ä¸ºå¤±è´¥åŒ¹é…ä¸å‚ä¸è´¨é‡è¯„çº§
        }

        # åŸºäºè¯¯å·®èŒƒå›´å¯¹æ‰€æœ‰æˆåŠŸåŒ¹é…è¿›è¡Œè¯„çº§
        for item in all_matched_data:
            error_abs = abs(item['corrected_offset'])
            error_ms = error_abs / 10.0

            if error_ms <= 20:
                stats['correct'] += 1      # ä¼˜ç§€
            elif error_ms > 20 and error_ms <= 30:
                stats['minor'] += 1        # è‰¯å¥½
            elif error_ms > 30 and error_ms <= 50:
                stats['moderate'] += 1     # ä¸€èˆ¬
            elif error_ms > 50 and error_ms <= 1000:
                stats['large'] += 1        # è¾ƒå·®
            else:  # error_ms > 1000
                stats['severe'] += 1       # ä¸¥é‡

        # è®¡ç®—ç™¾åˆ†æ¯”ï¼ˆåŸºäºæˆåŠŸçš„åŒ¹é…å¯¹æ€»æ•°ï¼‰
        # è¯„çº§ç»Ÿè®¡åªåæ˜ æˆåŠŸåŒ¹é…çš„è´¨é‡åˆ†å¸ƒï¼Œä¸åŒ…æ‹¬å¤±è´¥åŒ¹é…
        result = {}
        for key, count in stats.items():
            result[key] = {
                'count': count,
                'percent': (count / total_successful_matches * 100) if total_successful_matches > 0 else 0.0
            }

        result['total_successful_matches'] = total_successful_matches  # æˆåŠŸåŒ¹é…æ€»æ•°
        result['global_offset_ms'] = self.global_time_offset / 10.0

        logger.info(f"ğŸ“Š [åç«¯] åŒ¹é…è´¨é‡è¯„çº§ç»Ÿè®¡: æˆåŠŸé…å¯¹æ•°={total_successful_matches} (åªç»Ÿè®¡æˆåŠŸåŒ¹é…çš„è´¨é‡åˆ†å¸ƒ)")

        return result

    def _get_precision_matches_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–ç²¾ç¡®åŒ¹é…å¯¹çš„åç§»æ•°æ®

        Returns:
            List[Dict]: ç²¾ç¡®åŒ¹é…å¯¹çš„åç§»æ•°æ®
        """
        return self._get_matches_data_by_type(MatchType.PRECISION)

    def _get_approximate_matches_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–è¾ƒå·®åŒ¹é…å¯¹çš„åç§»æ•°æ® (50-100ms)

        Returns:
            List[Dict]: è¾ƒå·®åŒ¹é…å¯¹çš„åç§»æ•°æ®
        """
        return self._get_matches_data_by_type(MatchType.POOR)

    def _get_large_error_matches_data(self) -> List[Dict[str, Union[int, float]]]:
        """
        è·å–å¤§è¯¯å·®åŒ¹é…å¯¹çš„åç§»æ•°æ® (>1000ms)

        Returns:
            List[Dict]: å¤§è¯¯å·®åŒ¹é…å¯¹çš„åç§»æ•°æ®
        """
        return self._get_matches_data_by_type(MatchType.FAILED)

    def _get_matches_data_by_type(self, match_type: MatchType) -> List[Dict[str, Union[int, float]]]:
        """
        æ ¹æ®åŒ¹é…ç±»å‹è·å–å¯¹åº”çš„åç§»æ•°æ®

        Args:
            match_type: åŒ¹é…ç±»å‹

        Returns:
            List[Dict]: è¯¥ç±»å‹åŒ¹é…å¯¹çš„åç§»æ•°æ®
        """
        offset_data = []

        # ç¡®å®šæ•°æ®æºå’Œç­›é€‰æ¡ä»¶ - åŸºäºæ–°çš„åŒ¹é…ç±»å‹
        pairs_source = []
        error_filter = None

        if match_type == MatchType.EXCELLENT:
            # ä¼˜ç§€åŒ¹é…ï¼šä»precision_matched_pairsä¸­ç­›é€‰ â‰¤20ms çš„
            pairs_source = self.precision_matched_pairs
            error_filter = lambda error_ms: error_ms <= 20
        elif match_type == MatchType.GOOD:
            # è‰¯å¥½åŒ¹é…ï¼šä»precision_matched_pairsä¸­ç­›é€‰ 20-30ms çš„
            pairs_source = self.precision_matched_pairs
            error_filter = lambda error_ms: 20 < error_ms <= 30
        elif match_type == MatchType.FAIR:
            # ä¸€èˆ¬åŒ¹é…ï¼šä»precision_matched_pairsä¸­ç­›é€‰ 30-50ms çš„
            pairs_source = self.precision_matched_pairs
            error_filter = lambda error_ms: 30 < error_ms <= 50
        elif match_type == MatchType.POOR:
            # è¾ƒå·®åŒ¹é…ï¼šæ‰€æœ‰æ¥è‡ªloose_matched_pairsçš„åŒ¹é…
            pairs_source = self.loose_matched_pairs
            error_filter = lambda error_ms: True  # ä¸éœ€è¦é¢å¤–ç­›é€‰
        elif match_type == MatchType.SEVERE:
            # ä¸¥é‡è¯¯å·®ï¼šæ‰€æœ‰æ¥è‡ªsevere_matched_pairsçš„åŒ¹é…
            pairs_source = self.severe_matched_pairs
            error_filter = lambda error_ms: True  # ä¸éœ€è¦é¢å¤–ç­›é€‰
        elif match_type == MatchType.FAILED:
            # å¤±è´¥åŒ¹é…ï¼šæ— åŒ¹é…çš„æƒ…å†µï¼Œä¸åœ¨æ­¤å¤„ç†
            return []
        else:
            return []

        for record_idx, replay_idx, record_note, replay_note in pairs_source:
            # è®¡ç®—å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦çš„æ—¶é—´
            record_keyon, record_keyoff = self._calculate_note_times(record_note)
            replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

            # è®¡ç®—åŸå§‹åç§»é‡
            keyon_offset = replay_keyon - record_keyon

            # è®¡ç®—æ ¡å‡†åçš„åç§»ï¼ˆå»é™¤å…¨å±€å›ºå®šå»¶æ—¶ï¼‰
            corrected_offset = keyon_offset - self.global_time_offset

            # è®¡ç®—è¯¯å·®ï¼ˆæ¯«ç§’ï¼‰
            error_ms = abs(corrected_offset) / 10.0

            # æ ¹æ®åŒ¹é…ç±»å‹ç­›é€‰
            if not error_filter(error_ms):
                continue

            record_duration = record_keyoff - record_keyon
            replay_duration = replay_keyoff - replay_keyon
            duration_diff = replay_duration - record_duration
            duration_offset = duration_diff

            offset_data.append({
                'record_index': record_idx,
                'replay_index': replay_idx,
                'key_id': record_note.id,
                'record_keyon': record_keyon,
                'replay_keyon': replay_keyon,
                'keyon_offset': keyon_offset,       # åŸå§‹åç§»
                'corrected_offset': corrected_offset, # æ ¡å‡†ååç§»ï¼ˆç”¨äºåˆ†æï¼‰
                'record_keyoff': record_keyoff,
                'replay_keyoff': replay_keyoff,
                'duration_offset': duration_offset,
                'average_offset': abs(corrected_offset),
                'record_duration': record_duration,
                'replay_duration': replay_duration,
                'duration_diff': duration_diff
            })

        return offset_data
    
    def get_invalid_notes_offset_analysis(self, record_data: List[Note], replay_data: List[Note]) -> List[Dict[str, Union[int, float, str]]]:
        """
        è·å–æ— æ•ˆéŸ³ç¬¦çš„åç§»å¯¹é½åˆ†æ
        
        Args:
            record_data: å½•åˆ¶æ•°æ®
            replay_data: æ’­æ”¾æ•°æ®
            
        Returns:
            List[Dict[str, Union[int, float, str]]]: æ— æ•ˆéŸ³ç¬¦åç§»åˆ†ææ•°æ®
        """
        invalid_offset_data = []
        
        # è·å–å·²åŒ¹é…çš„éŸ³ç¬¦ç´¢å¼•
        matched_record_indices = set(pair[0] for pair in self.matched_pairs)
        matched_replay_indices = set(pair[1] for pair in self.matched_pairs)
        
        # åˆ†æå½•åˆ¶æ•°æ®ä¸­çš„æ— æ•ˆéŸ³ç¬¦ï¼ˆæœªåŒ¹é…çš„éŸ³ç¬¦ï¼‰
        invalid_offset_data.extend(
            self._analyze_invalid_notes(record_data, matched_record_indices, 'record', replay_data)
        )
        
        # åˆ†ææ’­æ”¾æ•°æ®ä¸­çš„æ— æ•ˆéŸ³ç¬¦ï¼ˆæœªåŒ¹é…çš„éŸ³ç¬¦ï¼‰
        invalid_offset_data.extend(
            self._analyze_invalid_notes(replay_data, matched_replay_indices, 'replay', record_data)
        )
        
        return invalid_offset_data
    
    def _analyze_invalid_notes(self, notes_data: List[Note], matched_indices: set, data_type: str, 
                              other_notes_data: List[Note] = None) -> List[Dict[str, Union[int, float, str]]]:
        """
        åˆ†ææ— æ•ˆéŸ³ç¬¦çš„é€šç”¨æ–¹æ³•
        
        Args:
            notes_data: éŸ³ç¬¦æ•°æ®åˆ—è¡¨
            matched_indices: å·²åŒ¹é…çš„éŸ³ç¬¦ç´¢å¼•é›†åˆ
            data_type: æ•°æ®ç±»å‹ ('record' æˆ– 'replay')
            other_notes_data: å¦ä¸€ä¸ªæ•°æ®ç±»å‹çš„éŸ³ç¬¦åˆ—è¡¨ï¼Œç”¨äºåˆ†æåŒ¹é…å¤±è´¥åŸå› 
            
        Returns:
            List[Dict[str, Union[int, float, str]]]: æ— æ•ˆéŸ³ç¬¦åˆ†ææ•°æ®
        """
        invalid_notes = []
        
        for i, note in enumerate(notes_data):
            if i not in matched_indices:  # æœªåŒ¹é…çš„éŸ³ç¬¦
                try:
                    keyon_time, keyoff_time = self._calculate_note_times(note)
                    
                    # ä¼˜å…ˆä½¿ç”¨åŒ¹é…é˜¶æ®µè®°å½•çš„çœŸå®å¤±è´¥åŸå› ï¼ˆä»…recordä¾§æœ‰ï¼‰
                    analysis_reason = None
                    if data_type == 'record' and (data_type, i) in self.failure_reasons:
                        analysis_reason = self.failure_reasons[(data_type, i)]
                    else:
                        # å›æ”¾ä¾§æˆ–æ— è®°å½•æ—¶ï¼Œå†åšæ¨æ–­åˆ†æ
                        analysis_reason = self._get_actual_unmatch_reason(note, data_type, i, other_notes_data)
                    
                    invalid_notes.append({
                        'data_type': data_type,
                        'note_index': i,
                        'key_id': note.id,
                        'keyon_time': keyon_time,
                        'keyoff_time': keyoff_time,
                        'status': 'unmatched',
                        'analysis_reason': analysis_reason
                    })
                except (IndexError, AttributeError) as e:
                    # å¤„ç†æ•°æ®å¼‚å¸¸çš„æƒ…å†µ
                    invalid_notes.append({
                        'data_type': data_type,
                        'note_index': i,
                        'key_id': note.id,
                        'keyon_time': 0.0,
                        'keyoff_time': 0.0,
                        'status': 'data_error',
                        'analysis_reason': f'æ•°æ®å¼‚å¸¸: {str(e)}'
                    })
        
        return invalid_notes
    
    def _get_actual_unmatch_reason(self, note: Note, data_type: str, note_index: int, 
                                  other_notes_data: List[Note] = None) -> str:
        """
        åˆ†ææœªåŒ¹é…éŸ³ç¬¦çš„å®é™…å¤±è´¥åŸå› 
        
        Args:
            note: éŸ³ç¬¦å¯¹è±¡
            data_type: æ•°æ®ç±»å‹ ('record' æˆ– 'replay')
            note_index: éŸ³ç¬¦ç´¢å¼•
            other_notes_data: å¦ä¸€ä¸ªæ•°æ®ç±»å‹çš„éŸ³ç¬¦åˆ—è¡¨
            
        Returns:
            str: åŒ¹é…å¤±è´¥åŸå› 
        """
        if other_notes_data is None:
            return "æ— æ³•åˆ†æåŒ¹é…å¤±è´¥åŸå› (ç¼ºå°‘å¯¹æ¯”æ•°æ®)"
        
        try:
            # æå–å½“å‰éŸ³ç¬¦ä¿¡æ¯
            note_info = self._extract_note_info(note, note_index)
            
            # åˆ†æåŒ¹é…å¤±è´¥çš„å…·ä½“åŸå› 
            return self._analyze_match_failure_reason(note_info, other_notes_data, data_type)
            
        except Exception as e:
            return f"åˆ†æåŒ¹é…å¤±è´¥åŸå› æ—¶å‡ºé”™: {str(e)}"
    
    def _analyze_match_failure_reason(self, note_info: Dict, other_notes_data: List[Note], data_type: str) -> str:
        """
        åˆ†æåŒ¹é…å¤±è´¥çš„å…·ä½“åŸå› ï¼ˆå›æ”¾ä¾§æ¨æ–­ç”¨ï¼‰
        
        æ³¨æ„ï¼šå½•åˆ¶ä¾§å·²åœ¨åŒ¹é…é˜¶æ®µè®°å½•çœŸå®åŸå› ï¼Œæ­¤æ–¹æ³•ä¸»è¦ç”¨äºå›æ”¾ä¾§æ¨æ–­
        
        Args:
            note_info: éŸ³ç¬¦ä¿¡æ¯å­—å…¸
            other_notes_data: å¦ä¸€ä¸ªæ•°æ®ç±»å‹çš„éŸ³ç¬¦åˆ—è¡¨
            data_type: æ•°æ®ç±»å‹
            
        Returns:
            str: åŒ¹é…å¤±è´¥åŸå› 
        """
        target_key_id = note_info["key_id"]
        target_keyon = note_info["keyon"]
        target_keyoff = note_info["keyoff"]
        
        # è°ƒç”¨ç›¸åŒçš„å€™é€‰ç”Ÿæˆé€»è¾‘ï¼ˆç¡®ä¿ä¸åŒ¹é…é˜¶æ®µä¸€è‡´ï¼‰
        candidates, threshold, reason_if_empty = self._generate_sorted_candidates_within_threshold(
            other_notes_data,
            target_keyon=target_keyon,
            target_keyoff=target_keyoff,
            target_key_id=target_key_id
        )
        
        if not candidates:
            return reason_if_empty
        
        # æœ‰åœ¨é˜ˆå€¼å†…çš„å€™é€‰ï¼Œä½†æœªè¢«åŒ¹é… -> å¯èƒ½å…¨è¢«å ç”¨ï¼ˆå›æ”¾ä¾§æ— æ³•å¾—çŸ¥å ç”¨æƒ…å†µï¼‰
        return f"å¯èƒ½æ‰€æœ‰å€™é€‰å·²è¢«å ç”¨(å€™é€‰æ•°:{len(candidates)}, é˜ˆå€¼:{threshold:.1f}ms)"
    
    def _calculate_note_times(self, note: Note) -> Tuple[float, float]:
        """
        è®¡ç®—éŸ³ç¬¦çš„æŒ‰é”®å¼€å§‹å’Œç»“æŸæ—¶é—´
        
        Args:
            note: éŸ³ç¬¦å¯¹è±¡
            
        Returns:
            Tuple[float, float]: (keyon_time, keyoff_time)
        """

        try:
            keyon_time = note.after_touch.index[0] + note.offset
            keyoff_time = note.after_touch.index[-1] + note.offset
        except (IndexError, AttributeError) as e:
            raise ValueError(f"éŸ³ç¬¦ID {note.id} çš„after_touchæ•°æ®æ— æ•ˆ: {e}") from e
        
        return keyon_time, keyoff_time
    
    # TODO  
    def get_global_average_delay(self) -> float:
        """
        è®¡ç®—æ•´é¦–æ›²å­çš„å¹³å‡æ—¶å»¶ï¼ˆåŸºäºå·²é…å¯¹æ•°æ®ï¼‰
        
        ä½¿ç”¨å¸¦ç¬¦å·çš„ keyon_offset è®¡ç®—ï¼šå…¨å±€å¹³å‡æ—¶å»¶ = mean(keyon_offset)
        æ­£å€¼è¡¨ç¤º replay å»¶è¿Ÿï¼Œè´Ÿå€¼è¡¨ç¤º replay æå‰
        
        æ³¨æ„ï¼šæ­¤æŒ‡æ ‡ä¸å¹³å‡è¯¯å·®ï¼ˆMEï¼Œget_mean_error()ï¼‰åœ¨è®¡ç®—å’Œæ¦‚å¿µä¸Šå®Œå…¨ç›¸åŒï¼Œ
        éƒ½æ˜¯å¯¹æ‰€æœ‰ keyon_offset æ±‚ç®—æœ¯å¹³å‡ï¼Œåæ˜ æ•´ä½“çš„æå‰/æ»åæ–¹å‘æ€§ã€‚
        å¦‚æœéœ€è¦ä¸è€ƒè™‘æ–¹å‘çš„å¹³å‡å»¶æ—¶å¹…åº¦ï¼Œåº”ä½¿ç”¨å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ã€‚
        
        Returns:
            float: å¹³å‡æ—¶å»¶ï¼ˆ0.1mså•ä½ï¼Œå¸¦ç¬¦å·ï¼‰
        """
        if not self.matched_pairs:
            return 0.0

        # è·å–åç§»æ•°æ®ï¼ˆåªä½¿ç”¨ç²¾ç¡®åŒ¹é…å¯¹ï¼Œè¯¯å·® â‰¤ 50msï¼‰
        offset_data = self.get_precision_offset_alignment_data()

        # ä½¿ç”¨å¸¦ç¬¦å·çš„æ ¡å‡†ååç§»ï¼ˆä¸å–ç»å¯¹å€¼ï¼Œå»é™¤å…¨å±€ç³»ç»Ÿå»¶æ—¶ï¼‰
        corrected_offsets = [item.get('corrected_offset', 0) for item in offset_data if item.get('corrected_offset') is not None]
        
        if not corrected_offsets:
            return 0.0

        # è®¡ç®—å¹³å‡å€¼ï¼ˆ0.1mså•ä½ï¼Œå¸¦ç¬¦å·ï¼‰
        average_delay = sum(corrected_offsets) / len(corrected_offsets)

        logger.info(f"ğŸ“Š [åç«¯] å…¨å±€å¹³å‡å»¶æ—¶: {average_delay/10:.2f}ms ({average_delay:.1f}å•ä½ï¼ŒåŸºäº{len(corrected_offsets)}ä¸ªç²¾ç¡®åŒ¹é…å¯¹)")
        
        return average_delay
    
    def get_variance(self) -> float:
        """
        è®¡ç®—å·²åŒ¹é…æŒ‰é”®å¯¹çš„æ€»ä½“æ–¹å·®ï¼ˆPopulation Varianceï¼‰
        
        è¯´æ˜ï¼š
        - "åŒ¹é…å¯¹"æŒ‡çš„æ˜¯matched_pairsä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œæ˜¯ä¸€ä¸ª(record_note, replay_note)çš„é…å¯¹
        - å¯¹æ¯ä¸ªåŒ¹é…å¯¹è®¡ç®—keyon_offset = replay_keyon - record_keyon
        - ä½¿ç”¨å¸¦ç¬¦å·çš„keyon_offsetè®¡ç®—æ–¹å·®ï¼ŒæŒ‰ç…§æ ‡å‡†æ€»ä½“æ–¹å·®å…¬å¼
        
        æ ‡å‡†æ•°å­¦å…¬å¼ï¼š
        ÏƒÂ² = (1/n) * Î£(x_i - Î¼)Â²
        å…¶ä¸­ x_i æ˜¯å¸¦ç¬¦å·çš„keyon_offsetï¼ŒÎ¼ = (1/n) * Î£ x_iï¼ˆæ€»ä½“å‡å€¼ï¼‰
        
        Returns:
            float: æ€»ä½“æ–¹å·®ï¼ˆå•ä½ï¼š(0.1ms)Â²ï¼Œè½¬æ¢ä¸ºmsÂ²éœ€è¦é™¤ä»¥100ï¼‰
        """
        if not self.matched_pairs:
            return 0.0

        # è·å–åç§»å¯¹é½æ•°æ®ï¼ˆåªä½¿ç”¨ç²¾ç¡®åŒ¹é…å¯¹ï¼Œè¯¯å·® â‰¤ 50msï¼‰
        offset_data = self.get_precision_offset_alignment_data()

        # æå–æ‰€æœ‰å¸¦ç¬¦å·çš„æ ¡å‡†ååç§»ï¼ˆå»é™¤å…¨å±€ç³»ç»Ÿå»¶æ—¶ï¼‰
        offsets = []
        for item in offset_data:
            corrected_offset = item.get('corrected_offset', 0)
            offsets.append(corrected_offset)  # ä½¿ç”¨æ ¡å‡†åçš„åç§»å€¼
        
        if len(offsets) <= 1:
            return 0.0
        
        # è®¡ç®—æ€»ä½“æ–¹å·®ï¼ˆä½¿ç”¨æ ‡å‡†å…¬å¼ï¼Œåˆ†æ¯ nï¼‰
        # å…¬å¼ï¼šÏƒÂ² = (1/n) * Î£(x_i - Î¼)Â²
        # å…¶ä¸­ Î¼ = (1/n) * Î£ x_iï¼ˆæ€»ä½“å‡å€¼ï¼‰
        mean = sum(offsets) / len(offsets)  # æ€»ä½“å‡å€¼ï¼ˆå¸¦ç¬¦å·ï¼‰
        variance = sum((x - mean) ** 2 for x in offsets) / len(offsets)  # æ€»ä½“æ–¹å·®ä½¿ç”¨ n
        return variance
    
    def get_standard_deviation(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„æ€»ä½“æ ‡å‡†å·®ï¼ˆPopulation Standard Deviationï¼‰
        å¯¹æ‰€æœ‰å·²åŒ¹é…æŒ‰é”®å¯¹çš„å¸¦ç¬¦å·keyon_offsetè®¡ç®—æ€»ä½“æ ‡å‡†å·®
        æ€»ä½“æ ‡å‡†å·® = sqrt(æ€»ä½“æ–¹å·®)
        
        æŒ‰ç…§æ ‡å‡†æ•°å­¦å…¬å¼ï¼šÏƒ = âˆš(ÏƒÂ²) = âˆš((1/n) * Î£(x_i - Î¼)Â²)
        å…¶ä¸­ x_i æ˜¯å¸¦ç¬¦å·çš„keyon_offsetï¼ŒÎ¼ = (1/n) * Î£ x_iï¼ˆæ€»ä½“å‡å€¼ï¼‰
        
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ç›´æ¥è°ƒç”¨ get_variance() ç„¶åå¼€å¹³æ–¹æ ¹ï¼Œç¡®ä¿ä¸æ–¹å·®è®¡ç®—çš„ä¸€è‡´æ€§
        ç”±äº get_variance() ä½¿ç”¨å¸¦ç¬¦å·å€¼è®¡ç®—ï¼Œæ­¤æ–¹æ³•ä¹Ÿä½¿ç”¨å¸¦ç¬¦å·å€¼
        
        Returns:
            float: æ€»ä½“æ ‡å‡†å·®ï¼ˆå•ä½ï¼š0.1msï¼Œè½¬æ¢ä¸ºmséœ€è¦é™¤ä»¥10ï¼‰
        """
        variance = self.get_variance()
        if variance < 0:
            # ç†è®ºä¸Šä¸åº”è¯¥å‡ºç°è´Ÿæ•°ï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§
            logger.warning(f"æ€»ä½“æ–¹å·®ä¸ºè´Ÿæ•°: {variance}ï¼Œè¿”å›0")
            return 0.0
        std = variance ** 0.5
        logger.info(f"[åç«¯] æ€»ä½“æ ‡å‡†å·®: {std/10:.2f}ms ({std:.1f}å•ä½ï¼ŒåŸºäºç²¾ç¡®åŒ¹é…æ•°æ®)")
        return std
    
    def get_mean_absolute_error(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰
        å¯¹æ‰€æœ‰å·²åŒ¹é…æŒ‰é”®å¯¹çš„å»¶æ—¶ç»å¯¹å€¼æ±‚å¹³å‡
        
        Returns:
            float: å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆå•ä½ï¼š0.1msï¼Œè½¬æ¢ä¸ºmséœ€è¦é™¤ä»¥10ï¼‰
        """
        if not self.matched_pairs:
            return 0.0

        # è·å–åç§»å¯¹é½æ•°æ®ï¼ˆåªä½¿ç”¨ç²¾ç¡®åŒ¹é…å¯¹ï¼Œè¯¯å·® â‰¤ 50msï¼‰
        offset_data = self.get_precision_offset_alignment_data()

        # æå–æ‰€æœ‰æ ¡å‡†åå»¶æ—¶çš„ç»å¯¹å€¼ï¼ˆå»é™¤å…¨å±€ç³»ç»Ÿå»¶æ—¶ï¼‰
        abs_errors = []
        for item in offset_data:
            corrected_offset = item.get('corrected_offset', 0)
            abs_error = abs(corrected_offset)
            abs_errors.append(abs_error)
        
        # è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·®
        if abs_errors:
            mae = sum(abs_errors) / len(abs_errors)
            logger.info(f"[åç«¯] å¹³å‡ç»å¯¹è¯¯å·® MAE: {mae/10:.2f}ms ({mae:.1f}å•ä½ï¼ŒåŸºäº{len(abs_errors)}ä¸ªç²¾ç¡®åŒ¹é…å¯¹)")
            return mae
        else:
            return 0.0
    
    def get_coefficient_of_variation(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„å˜å¼‚ç³»æ•°ï¼ˆCoefficient of Variation, CVï¼‰
        å˜å¼‚ç³»æ•° = æ€»ä½“æ ‡å‡†å·®ï¼ˆÏƒï¼‰/ |æ€»ä½“å‡å€¼ï¼ˆÎ¼ï¼‰| Ã— 100%
        
        ä½¿ç”¨æ€»ä½“æ ‡å‡†å·®ï¼ˆÏƒï¼‰ä¸æ€»ä½“å‡å€¼ï¼ˆÎ¼ï¼‰è®¡ç®—ï¼Œåæ˜ ç›¸å¯¹å˜å¼‚ç¨‹åº¦
        
        æ³¨æ„ï¼šå¦‚æœæ€»ä½“å‡å€¼ï¼ˆÎ¼ï¼‰ä¸º0æˆ–æ¥è¿‘0ï¼Œå˜å¼‚ç³»æ•°å¯èƒ½æ— æ„ä¹‰æˆ–éå¸¸å¤§
        
        Returns:
            float: å˜å¼‚ç³»æ•°ï¼ˆç™¾åˆ†æ¯”ï¼Œä¾‹å¦‚ 15.5 è¡¨ç¤º 15.5%ï¼‰
        """
        if not self.matched_pairs:
            return 0.0
        
        # è·å–æ€»ä½“å‡å€¼ï¼ˆÎ¼ï¼Œå¸¦ç¬¦å·ï¼‰
        mean_0_1ms = self.get_mean_error()
        if abs(mean_0_1ms) < 1e-6:  # å¦‚æœå‡å€¼æ¥è¿‘0ï¼Œæ— æ³•è®¡ç®—CV
            return 0.0
        
        # è·å–æ€»ä½“æ ‡å‡†å·®ï¼ˆÏƒï¼‰
        std_0_1ms = self.get_standard_deviation()
        if std_0_1ms == 0:
            return 0.0
        
        # è®¡ç®—å˜å¼‚ç³»æ•°ï¼šCV = (Ïƒ / |Î¼|) Ã— 100%
        cv = (std_0_1ms / abs(mean_0_1ms)) * 100.0
        return cv
    
    def get_mean_squared_error(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰
        å¯¹æ‰€æœ‰å·²åŒ¹é…æŒ‰é”®å¯¹çš„å»¶æ—¶çš„å¹³æ–¹æ±‚å¹³å‡
        
        Returns:
            float: å‡æ–¹è¯¯å·®ï¼ˆå•ä½ï¼š(0.1ms)Â²ï¼Œè½¬æ¢ä¸ºmsÂ²éœ€è¦é™¤ä»¥100ï¼‰
        """
        if not self.matched_pairs:
            return 0.0
        
        # è·å–åç§»å¯¹é½æ•°æ®ï¼ˆåªä½¿ç”¨ç²¾ç¡®åŒ¹é…å¯¹ï¼Œè¯¯å·® â‰¤ 50msï¼‰
        offset_data = self.get_precision_offset_alignment_data()
        
        # æå–æ‰€æœ‰æ ¡å‡†åå»¶æ—¶çš„å¹³æ–¹å€¼ï¼ˆå»é™¤å…¨å±€ç³»ç»Ÿå»¶æ—¶ï¼‰
        squared_errors = []
        for item in offset_data:
            corrected_offset = item.get('corrected_offset', 0)
            squared_error = corrected_offset ** 2  # ä½¿ç”¨æ ¡å‡†åçš„åç§»å€¼
            squared_errors.append(squared_error)
        
        # è®¡ç®—å‡æ–¹è¯¯å·®
        if squared_errors:
            mse = sum(squared_errors) / len(squared_errors)
            return mse
        else:
            return 0.0

    def get_root_mean_squared_error(self) -> float:
        """
        è®¡ç®—å·²é…å¯¹æŒ‰é”®çš„å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰
        RMSE = sqrt(MSE) = sqrt(mean((keyon_offset)^2))
        
        Returns:
            float: å‡æ–¹æ ¹è¯¯å·®ï¼ˆå•ä½ï¼š0.1msï¼Œè½¬æ¢ä¸ºmséœ€è¦é™¤ä»¥10ï¼‰
        """
        if not self.matched_pairs:
            return 0.0
        
        # è·å–MSE
        mse = self.get_mean_squared_error()
        
        # è®¡ç®—RMSE = sqrt(MSE)
        import math
        rmse = math.sqrt(mse) if mse > 0 else 0.0
        
        return rmse
    
    def get_mean_error(self) -> float:
        """
        è·å–å·²åŒ¹é…æŒ‰é”®å¯¹çš„å¹³å‡è¯¯å·®ï¼ˆMEï¼Œå¸¦ç¬¦å·çš„å¹³å‡åå·®ï¼‰
        å¯¹æ‰€æœ‰åŒ¹é…å¯¹çš„keyon_offsetï¼ˆreplay_keyon - record_keyonï¼‰æ±‚ç®—æœ¯å¹³å‡ã€‚

        Returns:
            float: å¹³å‡è¯¯å·®MEï¼ˆå•ä½ï¼š0.1msï¼ŒUIæ˜¾ç¤ºä¸ºmséœ€é™¤ä»¥10ï¼‰
        """
        # è¿”å›ç¼“å­˜çš„å¹³å‡è¯¯å·®ï¼Œå¦‚æœæ²¡æœ‰ç¼“å­˜åˆ™è®¡ç®—
        if self._mean_error_cached is None:
            self._mean_error_cached = self._calculate_mean_error()
        return self._mean_error_cached

    def _calculate_mean_error(self) -> float:
        """
        è®¡ç®—å·²åŒ¹é…æŒ‰é”®å¯¹çš„å¹³å‡è¯¯å·®ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        Returns:
            float: å¹³å‡è¯¯å·®MEï¼ˆå•ä½ï¼š0.1msï¼‰
        """
        if not self.matched_pairs:
            return 0.0

        offset_data = self.get_precision_offset_alignment_data()
        offsets = [item.get('corrected_offset', 0) for item in offset_data]
        if not offsets:
            return 0.0
        mean_error = sum(offsets) / len(offsets)
        logger.info(f"ğŸ“Š [åç«¯] å¹³å‡è¯¯å·® ME: {mean_error/10:.2f}ms ({mean_error:.1f}å•ä½ï¼ŒåŸºäº{len(offsets)}ä¸ªç²¾ç¡®åŒ¹é…å¯¹)")
        return mean_error

    def _clear_mean_error_cache(self) -> None:
        """
        æ¸…é™¤å¹³å‡è¯¯å·®ç¼“å­˜
        å½“åŒ¹é…å¯¹å‘ç”Ÿå˜åŒ–æ—¶è°ƒç”¨æ­¤æ–¹æ³•
        """
        self._mean_error_cached = None
    
    def get_offset_statistics(self) -> Dict[str, Union[int, Dict[str, float]]]:
        """
        è·å–åç§»ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Union[int, Dict[str, float]]]: åç§»ç»Ÿè®¡ä¿¡æ¯
        """
        if not self.matched_pairs:
            return {
                'total_pairs': 0,
                'keyon_offset_stats': {'average': 0.0, 'max': 0.0, 'min': 0.0, 'std': 0.0},
                'duration_offset_stats': {'average': 0.0, 'max': 0.0, 'min': 0.0, 'std': 0.0},
                'overall_offset_stats': {'average': 0.0, 'max': 0.0, 'min': 0.0, 'std': 0.0}
            }
        
        # è·å–åç§»æ•°æ®ï¼ˆåªä½¿ç”¨ç²¾ç¡®åŒ¹é…å¯¹ï¼Œè¯¯å·® â‰¤ 50msï¼‰
        offset_data = self.get_precision_offset_alignment_data()
        
        # æå–åç§»å€¼ï¼ˆä½¿ç”¨æ ¡å‡†åçš„keyon_offsetï¼‰
        corrected_offsets = [item['corrected_offset'] for item in offset_data]
        duration_offsets = [item.get('duration_offset', 0.0) for item in offset_data]
        # æ•´ä½“ç»Ÿè®¡åªä½¿ç”¨æ ¡å‡†ååç§»çš„ç»å¯¹å€¼
        overall_offsets = [abs(item.get('corrected_offset', 0)) for item in offset_data if item.get('corrected_offset') is not None]
        
        return {
            'total_pairs': len(self.matched_pairs),
            'keyon_offset_stats': self._calculate_offset_stats(corrected_offsets),
            'duration_offset_stats': self._calculate_offset_stats(duration_offsets),
            'overall_offset_stats': self._calculate_offset_stats(overall_offsets)  # ä½¿ç”¨æ ¡å‡†åçš„åç§»
        }
    
    def _calculate_offset_stats(self, offsets: List[float]) -> Dict[str, float]:
        """
        è®¡ç®—åç§»ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            offsets: åç§»å€¼åˆ—è¡¨
            
        Returns:
            Dict[str, float]: ç»Ÿè®¡ä¿¡æ¯
        """
        if not offsets:
            return {'average': 0.0, 'max': 0.0, 'min': 0.0, 'std': 0.0}
        
        average = sum(offsets) / len(offsets)
        max_val = max(offsets)
        min_val = min(offsets)
        
        # è®¡ç®—æ ‡å‡†å·®
        if len(offsets) <= 1:
            std = 0.0
        else:
            variance = sum((x - average) ** 2 for x in offsets) / (len(offsets) - 1)
            std = variance ** 0.5
        
        return {
            'average': average,
            'max': max_val,
            'min': min_val,
            'std': std
        }

    def _create_offset_data_item(self, match_result: MatchResult) -> Dict[str, Union[int, float]]:
        """
        ä¸ºè¯„çº§ç»Ÿè®¡åˆ›å»ºåç§»æ•°æ®é¡¹

        Args:
            match_result: åŒ¹é…ç»“æœ

        Returns:
            Dict: åŒ…å«åç§»æ•°æ®çš„å­—å…¸
        """
        record_note, replay_note = match_result.pair
        record_keyon, record_keyoff = self._calculate_note_times(record_note)
        replay_keyon, replay_keyoff = self._calculate_note_times(replay_note)

        # è®¡ç®—åŸå§‹åç§»é‡
        keyon_offset = replay_keyon - record_keyon

        # è®¡ç®—æ ¡å‡†åçš„åç§»ï¼ˆå»é™¤å…¨å±€å›ºå®šå»¶æ—¶ï¼‰
        corrected_offset = keyon_offset - self.global_time_offset

        record_duration = record_keyoff - record_keyon
        replay_duration = replay_keyoff - replay_keyon
        duration_diff = replay_duration - record_duration
        duration_offset = duration_diff

        return {
            'record_index': match_result.record_index,
            'replay_index': match_result.replay_index,
            'key_id': record_note.id,
            'record_keyon': record_keyon,
            'replay_keyon': replay_keyon,
            'keyon_offset': keyon_offset,       # åŸå§‹åç§»
            'corrected_offset': corrected_offset, # æ ¡å‡†ååç§»ï¼ˆç”¨äºåˆ†æï¼‰
            'record_keyoff': record_keyoff,
            'replay_keyoff': replay_keyoff,
            'duration_offset': duration_offset,
            'average_offset': abs(corrected_offset),
            'record_duration': record_duration,
            'replay_duration': replay_duration,
            'duration_diff': duration_diff
        }
