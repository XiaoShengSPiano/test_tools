#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¯¼å‡ºåŒ¹é…åçš„æŒ‰é”®æ•°æ®ï¼ˆé”¤é€Ÿä¸æ—¶å»¶ï¼‰åˆ°Excelè¡¨æ ¼

ä½¿ç”¨æ–¹æ³•:
    python tools/export_matched_data_to_excel.py <spmid_file_path> [output_excel_path]

ç¤ºä¾‹:
    python tools/export_matched_data_to_excel.py data/example.spmid output.xlsx
"""

import sys
import os
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from spmid.spmid_reader import SPMidReader, Note
from spmid.spmid_analyzer import SPMIDAnalyzer
from utils.logger import Logger

logger = Logger.get_logger()


def iter_hammer_rows(pair_id: int, key_id: int, data_type: str, note: Note) -> List[Dict[str, Any]]:
    """
    ç”ŸæˆæŸä¸ªéŸ³ç¬¦çš„ç¬¬ä¸€ä¸ªé”¤é€Ÿè¡Œï¼ˆé€šè¿‡é˜ˆå€¼æ£€æŸ¥çš„é”¤é€Ÿï¼‰
    
    æ³¨æ„ï¼šåŒ¹é…å¯¹ä¸­çš„éŸ³ç¬¦å¯¹è±¡æ¥è‡ªè¿‡æ»¤åçš„æœ‰æ•ˆæ•°æ®ï¼Œè¿™äº›éŸ³ç¬¦çš„ç¬¬ä¸€ä¸ªé”¤é€Ÿå·²ç»é€šè¿‡äº†é˜ˆå€¼æ£€æŸ¥
    ï¼ˆPWMå€¼ >= é˜ˆå€¼ï¼‰ã€‚å› æ­¤ï¼Œè¿™é‡Œå¯¼å‡ºçš„é”¤é€Ÿå€¼å°±æ˜¯ç”¨äºé˜ˆå€¼æ£€æŸ¥å¹¶é€šè¿‡æ£€æŸ¥çš„é‚£ä¸ªé”¤é€Ÿå€¼ã€‚

    Args:
        pair_id: åŒ¹é…å¯¹åºå·ï¼ˆä»1å¼€å§‹ï¼‰
        key_id: é”®ID
        data_type: 'record' æˆ– 'replay'
        note: éŸ³ç¬¦å¯¹è±¡ï¼ˆæ¥è‡ªè¿‡æ»¤åçš„æœ‰æ•ˆæ•°æ®ï¼Œå·²é€šè¿‡é˜ˆå€¼æ£€æŸ¥ï¼‰

    Returns:
        List[Dict[str, Any]]: åªåŒ…å«ç¬¬ä¸€ä¸ªé”¤é€Ÿçš„ä¸€è¡Œæ•°æ®ï¼ˆè¯¥é”¤é€Ÿå·²é€šè¿‡é˜ˆå€¼æ£€æŸ¥ï¼‰
    """
    rows: List[Dict[str, Any]] = []
    if note is None or note.hammers is None or len(note.hammers) == 0:
        return rows
    
    # è·å–æ—¶é—´ä¸Šæœ€æ—©çš„é”¤é€Ÿå€¼ï¼ˆç¬¬ä¸€ä¸ªé”¤é€Ÿï¼‰
    # æ³¨æ„ï¼šhammers Seriesçš„indexæ˜¯æ—¶é—´æˆ³ï¼Œéœ€è¦æ‰¾åˆ°æœ€å°æ—¶é—´æˆ³å¯¹åº”çš„é”¤é€Ÿå€¼
    # è¿™ä¸ªé”¤é€Ÿå€¼æ˜¯åœ¨æ•°æ®è¿‡æ»¤é˜¶æ®µç”¨äºé˜ˆå€¼æ£€æŸ¥çš„é”¤é€Ÿï¼Œå¹¶ä¸”å·²ç»é€šè¿‡äº†é˜ˆå€¼æ£€æŸ¥
    min_timestamp = note.hammers.index.min()
    first_hammer_velocity_raw = note.hammers.loc[min_timestamp]
    # å¦‚æœè¿”å›Seriesï¼ˆå¤šä¸ªç›¸åŒæ—¶é—´æˆ³ï¼‰ï¼Œå–ç¬¬ä¸€ä¸ªå€¼
    if isinstance(first_hammer_velocity_raw, pd.Series):
        first_hammer_velocity = first_hammer_velocity_raw.iloc[0]
    else:
        first_hammer_velocity = first_hammer_velocity_raw
    
    # å¯¼å‡ºç¬¬ä¸€ä¸ªé”¤é€Ÿå€¼ï¼ˆè¯¥å€¼å·²ç»é€šè¿‡é˜ˆå€¼æ£€æŸ¥ï¼ŒåŒ¹é…å¯¹ä¸­çš„éŸ³ç¬¦æ¥è‡ªè¿‡æ»¤åçš„æœ‰æ•ˆæ•°æ®ï¼‰
    # ç†è®ºä¸Šé”¤é€Ÿä¸åº”è¯¥ä¸º0ï¼ˆå› ä¸ºå·²ç»é€šè¿‡è¿‡æ»¤ï¼‰ï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§ï¼Œä»ç„¶æ£€æŸ¥
    if first_hammer_velocity != 0:
        rows.append({
            'åŒ¹é…å¯¹åºå·': pair_id,
            'é”®ID': key_id,
            'æ•°æ®ç±»å‹': 'å½•åˆ¶' if data_type == 'record' else 'æ’­æ”¾',
            'é”¤é€Ÿå€¼': int(first_hammer_velocity)  # è¿™æ˜¯é€šè¿‡é˜ˆå€¼æ£€æŸ¥çš„é”¤é€Ÿå€¼
        })
    
    return rows


def calculate_note_times(note: Note) -> tuple:
    """
    è®¡ç®—éŸ³ç¬¦çš„æŒ‰é”®å¼€å§‹å’Œç»“æŸæ—¶é—´
    
    Args:
        note: éŸ³ç¬¦å¯¹è±¡
        
    Returns:
        tuple: (keyon_time, keyoff_time) å•ä½ï¼š0.1ms
    """
    if note.after_touch is None or len(note.after_touch) == 0:
        return 0.0, 0.0
    
    keyon_time = note.after_touch.index[0] + note.offset
    keyoff_time = note.after_touch.index[-1] + note.offset
    
    return keyon_time, keyoff_time


def export_matched_data_to_excel(spmid_file_path: str, output_excel_path: str = None) -> str:
    """
    å¯¼å‡ºåŒ¹é…åçš„æŒ‰é”®æ•°æ®ï¼ˆé”¤é€Ÿä¸æ—¶å»¶ï¼‰åˆ°Excelè¡¨æ ¼
    
    Args:
        spmid_file_path: SPMIDæ–‡ä»¶è·¯å¾„
        output_excel_path: è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰
        
    Returns:
        str: è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„
    """
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(spmid_file_path):
        raise FileNotFoundError(f"SPMIDæ–‡ä»¶ä¸å­˜åœ¨: {spmid_file_path}")
    
    logger.info(f"ğŸ“‚ å¼€å§‹å¤„ç†SPMIDæ–‡ä»¶: {spmid_file_path}")
    
    # 1. åŠ è½½SPMIDæ–‡ä»¶
    reader = SPMidReader.from_file(spmid_file_path, verbose=False)
    
    if reader.get_track_count < 2:
        raise ValueError("SPMIDæ–‡ä»¶å¿…é¡»åŒ…å«è‡³å°‘2ä¸ªè½¨é“")
    
    # è·å–å½•åˆ¶å’Œæ’­æ”¾æ•°æ®
    record_data = reader.get_track(0)  # å½•åˆ¶æ•°æ®ï¼ˆå®é™…æ¼”å¥ï¼‰
    replay_data = reader.get_track(1)  # æ’­æ”¾æ•°æ®ï¼ˆMIDIå›æ”¾ï¼‰
    
    logger.info(f"ğŸ“Š åŠ è½½æ•°æ®: å½•åˆ¶æ•°æ®{len(record_data)}ä¸ªéŸ³ç¬¦, æ’­æ”¾æ•°æ®{len(replay_data)}ä¸ªéŸ³ç¬¦")
    
    # 2. æ‰§è¡Œåˆ†æ
    analyzer = SPMIDAnalyzer()
    analyzer.analyze(record_data, replay_data)
    
    # 3. è·å–åŒ¹é…å¯¹
    matched_pairs = analyzer.note_matcher.get_matched_pairs()
    logger.info(f"âœ… æˆåŠŸåŒ¹é… {len(matched_pairs)} å¯¹æŒ‰é”®")
    
    if len(matched_pairs) == 0:
        logger.warning("âš ï¸ æ²¡æœ‰åŒ¹é…çš„æŒ‰é”®å¯¹ï¼Œæ— æ³•å¯¼å‡ºæ•°æ®")
        return None
    
    # 4. æå–æ•°æ®
    # è¡¨1ï¼šæ¯ä¸ªåŒ¹é…å¯¹çš„ç¬¬ä¸€ä¸ªé”¤é€Ÿå€¼ï¼ˆé€šè¿‡é˜ˆå€¼æ£€æŸ¥çš„é”¤é€Ÿï¼‰
    # æ³¨æ„ï¼šmatched_pairsä¸­çš„éŸ³ç¬¦å¯¹è±¡æ¥è‡ªè¿‡æ»¤åçš„æœ‰æ•ˆæ•°æ®ï¼ˆvalid_record_dataå’Œvalid_replay_dataï¼‰ï¼Œ
    # è¿™äº›éŸ³ç¬¦çš„ç¬¬ä¸€ä¸ªé”¤é€Ÿå·²ç»é€šè¿‡äº†é˜ˆå€¼æ£€æŸ¥ï¼ˆPWMå€¼ >= é˜ˆå€¼ï¼‰ï¼Œå› æ­¤å¯¼å‡ºçš„é”¤é€Ÿå€¼å°±æ˜¯é€šè¿‡é˜ˆå€¼æ£€æŸ¥çš„é‚£ä¸ªé”¤é€Ÿ
    hammer_rows: List[Dict[str, Any]] = []
    
    for pair_idx, (record_idx, replay_idx, record_note, replay_note) in enumerate(matched_pairs, 1):
        # æå–å½•åˆ¶å’Œæ’­æ”¾éŸ³ç¬¦çš„ç¬¬ä¸€ä¸ªé”¤é€Ÿå€¼ï¼ˆè¯¥å€¼å·²ç»é€šè¿‡é˜ˆå€¼æ£€æŸ¥ï¼‰
        hammer_rows.extend(iter_hammer_rows(pair_idx, record_note.id, 'record', record_note))
        hammer_rows.extend(iter_hammer_rows(pair_idx, record_note.id, 'replay', replay_note))
    
    # 5. è·å–åç§»å¯¹é½æ•°æ®å¹¶æŒ‰æŒ‰é”®IDåˆ†ç»„ç»Ÿè®¡ï¼ˆè®¡ç®—æ–¹å·®è€Œä¸æ˜¯æ ‡å‡†å·®ï¼‰
    offset_data = analyzer.note_matcher.get_offset_alignment_data()
    
    # æŒ‰æŒ‰é”®IDåˆ†ç»„æœ‰æ•ˆåŒ¹é…çš„åç§»æ•°æ®ï¼ˆåªä½¿ç”¨keyon_offsetçš„ç»å¯¹å€¼ï¼‰
    from collections import defaultdict
    import numpy as np
    
    key_groups = defaultdict(list)
    for item in offset_data:
        key_id = item.get('key_id', 'N/A')
        keyon_offset_abs = abs(item.get('keyon_offset', 0))  # åªä½¿ç”¨keyon_offsetçš„ç»å¯¹å€¼
        key_groups[key_id].append(keyon_offset_abs)
    
    # è½¬æ¢ä¸ºåç§»å¯¹é½åˆ†æè¡¨æ ¼æ ¼å¼ï¼ˆæ ‡å‡†å·®æ”¹ä¸ºæ–¹å·®ï¼‰
    alignment_stats_rows: List[Dict[str, Any]] = []
    
    for key_id, offsets in key_groups.items():
        if offsets:
            median_val = np.median(offsets) / 10.0  # è½¬æ¢ä¸ºms
            mean_val = np.mean(offsets) / 10.0  # è½¬æ¢ä¸ºms
            # è®¡ç®—æ€»ä½“æ–¹å·®ï¼ˆåˆ†æ¯nï¼Œddof=0ï¼‰ï¼Œä¸æ˜¯æ ‡å‡†å·®
            variance_val = np.var(offsets, ddof=0) / 100.0  # è½¬æ¢ä¸ºmsÂ²ï¼ˆ(0.1ms)Â² -> msÂ²ï¼‰
            
            alignment_stats_rows.append({
                'é”®ä½ID': key_id,
                'é…å¯¹æ•°': len(offsets),
                'ä¸­ä½æ•°(ms)': round(median_val, 2),
                'å‡å€¼(ms)': round(mean_val, 2),
                'æ–¹å·®(msÂ²)': round(variance_val, 2),
                'çŠ¶æ€': 'matched'
            })
    
    # 6. åˆ›å»ºDataFrame
    hammer_df = pd.DataFrame(hammer_rows)
    alignment_stats_df = pd.DataFrame(alignment_stats_rows)
    
    # 7. ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
    if output_excel_path is None:
        # è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶åï¼šåŸæ–‡ä»¶å_åŒ¹é…æ•°æ®_æ—¶é—´æˆ³.xlsx
        base_name = Path(spmid_file_path).stem
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_excel_path = f"{base_name}_åŒ¹é…æ•°æ®_{timestamp}.xlsx"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = Path(output_excel_path).parent
    if output_dir and not output_dir.exists():
        output_dir.mkdir(parents=True, exist_ok=True)
    
    # 8. å¯¼å‡ºåˆ°Excelï¼ˆä¸¤ä¸ªå·¥ä½œè¡¨ï¼šç¬¬ä¸€ä¸ªé”¤é€Ÿæ•°æ®ã€åç§»å¯¹é½åˆ†æï¼‰
    with pd.ExcelWriter(output_excel_path, engine='openpyxl') as writer:
        hammer_df.to_excel(writer, sheet_name='ç¬¬ä¸€ä¸ªé”¤é€Ÿæ•°æ®', index=False)
        alignment_stats_df.to_excel(writer, sheet_name='åç§»å¯¹é½åˆ†æ', index=False)
    
    logger.info(f"âœ… æ•°æ®å·²æˆåŠŸå¯¼å‡ºåˆ°: {output_excel_path}")
    logger.info(f"ğŸ“Š å…±å¯¼å‡º {len(matched_pairs)} ä¸ªåŒ¹é…å¯¹çš„æ•°æ®")
    logger.info(f"ğŸ“Š ç¬¬ä¸€ä¸ªé”¤é€Ÿæ•°æ®æ€»æ•°: {len(hammer_rows)}")
    
    return output_excel_path


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python tools/export_matched_data_to_excel.py <spmid_file_path> [output_excel_path]")
        print("\nç¤ºä¾‹:")
        print("  python tools/export_matched_data_to_excel.py data/example.spmid")
        print("  python tools/export_matched_data_to_excel.py data/example.spmid output.xlsx")
        sys.exit(1)
    
    spmid_file_path = sys.argv[1]
    output_excel_path = sys.argv[2] if len(sys.argv) > 2 else None
    
    try:
        output_path = export_matched_data_to_excel(spmid_file_path, output_excel_path)
        if output_path:
            print(f"\nâœ… æˆåŠŸï¼æ•°æ®å·²å¯¼å‡ºåˆ°: {output_path}")
        else:
            print("\nâš ï¸ è­¦å‘Šï¼šæ²¡æœ‰åŒ¹é…çš„æŒ‰é”®å¯¹ï¼Œæ— æ³•å¯¼å‡ºæ•°æ®")
    except Exception as e:
        logger.error(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        print(f"\nâŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()

